{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from proj1_helpers import load_csv_data\n",
    "from functions import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = load_csv_data('Data/train.csv', sub_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>s</td>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.91</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>258.733</td>\n",
       "      <td>2</td>\n",
       "      <td>67.435</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>b</td>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.473</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.916</td>\n",
       "      <td>164.546</td>\n",
       "      <td>1</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.158</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>46.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>b</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.148</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.186</td>\n",
       "      <td>260.414</td>\n",
       "      <td>1</td>\n",
       "      <td>44.251</td>\n",
       "      <td>2.053</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>44.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>b</td>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060</td>\n",
       "      <td>86.062</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>b</td>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.891</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>53.131</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id Prediction  DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  \\\n",
       "0  100000          s       138.470                       51.655        97.827   \n",
       "1  100001          b       160.937                       68.768       103.235   \n",
       "2  100002          b      -999.000                      162.172       125.953   \n",
       "3  100003          b       143.905                       81.417        80.943   \n",
       "4  100004          b       175.864                       16.915       134.805   \n",
       "\n",
       "   DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0    27.980                  0.91           124.711                2.666   \n",
       "1    48.146               -999.00          -999.000             -999.000   \n",
       "2    35.635               -999.00          -999.000             -999.000   \n",
       "3     0.414               -999.00          -999.000             -999.000   \n",
       "4    16.405               -999.00          -999.000             -999.000   \n",
       "\n",
       "   DER_deltar_tau_lep       ...        PRI_met_phi  PRI_met_sumet  \\\n",
       "0               3.064       ...             -0.277        258.733   \n",
       "1               3.473       ...             -1.916        164.546   \n",
       "2               3.148       ...             -2.186        260.414   \n",
       "3               3.310       ...              0.060         86.062   \n",
       "4               3.891       ...             -0.871         53.131   \n",
       "\n",
       "   PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  PRI_jet_leading_phi  \\\n",
       "0            2              67.435                2.150                0.444   \n",
       "1            1              46.226                0.725                1.158   \n",
       "2            1              44.251                2.053               -2.028   \n",
       "3            0            -999.000             -999.000             -999.000   \n",
       "4            0            -999.000             -999.000             -999.000   \n",
       "\n",
       "   PRI_jet_subleading_pt  PRI_jet_subleading_eta  PRI_jet_subleading_phi  \\\n",
       "0                 46.062                    1.24                  -2.475   \n",
       "1               -999.000                 -999.00                -999.000   \n",
       "2               -999.000                 -999.00                -999.000   \n",
       "3               -999.000                 -999.00                -999.000   \n",
       "4               -999.000                 -999.00                -999.000   \n",
       "\n",
       "   PRI_jet_all_pt  \n",
       "0         113.497  \n",
       "1          46.226  \n",
       "2          44.251  \n",
       "3           0.000  \n",
       "4           0.000  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_pd = pd.read_csv('Data/train.csv')\n",
    "train_set_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_set[1]\n",
    "y_train = train_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_zero_for_neg(x):\n",
    "    if x < 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0., ...,  1.,  0.,  1.])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range (len(y_train)):\n",
    "    if(y_train[i] < 0):\n",
    "        y_train[i] = 0\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    ws = [initial_w]\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        gradient = compute_gradient_least_square(y, tx, w)\n",
    "        loss = compute_mse(y, tx, w)\n",
    "        w = w - gamma*gradient\n",
    "        print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return loss, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares_SGD(y, tx, initial_w, max_iters, gamma):\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):    \n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "            gradient = compute_stoch_gradient(minibatch_y, minibatch_tx, w)\n",
    "            loss = compute_mse(minibatch_y, minibatch_tx, w)\n",
    "            new_w = w - gamma*gradient\n",
    "            w = new_w\n",
    "            ws.append(w)\n",
    "            losses.append(loss)\n",
    "            print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(\n",
    "            bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    A = tx.T@tx\n",
    "    b = tx.T@y\n",
    "    w = np.linalg.solve(A, b)\n",
    "    loss = compute_mse(y, tx, w)\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    X = tx.T@tx\n",
    "    N = X.shape[0]\n",
    "    A = (X + 2*N*lambda_*np.identity(N))\n",
    "    b = tx.T@y\n",
    "    w = np.linalg.solve(A, b)\n",
    "    loss = compute_mse(y, tx, w)\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(y, tx, initial_w, max_iters, gamma):\n",
    "    losses, ws = gradient_descent_log_reg(y, tx, initial_w, max_iters, gamma)\n",
    "    w = ws[len(ws)-1]\n",
    "    loss = losses[len(losses)-1]\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reg_logistic_regression(y, tx, lambda_, initial_w, max_iters, gamma):\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TESTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/49): loss=3465.6359037995257, w0=202309.98480000003, w1=-50705.06139999999\n",
      "Gradient Descent(1/49): loss=19675.556709798744, w0=187195.62540000005, w1=-48799.00549999999\n",
      "Gradient Descent(2/49): loss=37198.24448740738, w0=546965.8012000001, w1=-146435.64459999994\n",
      "Gradient Descent(3/49): loss=19698.582580728595, w0=536047.2418000001, w1=-144904.04249999995\n",
      "Gradient Descent(4/49): loss=19445.298000500312, w0=516285.4956000001, w1=-141131.09569999995\n",
      "Gradient Descent(5/49): loss=17568.689519718006, w0=580048.3941, w1=-108250.76219999995\n",
      "Gradient Descent(6/49): loss=37601.19722867963, w0=930822.0292, w1=-207628.5567999999\n",
      "Gradient Descent(7/49): loss=19617.99203247414, w0=910812.5697999999, w1=-205044.7762999999\n",
      "Gradient Descent(8/49): loss=19525.888548754774, w0=885044.9279, w1=-201581.4275999999\n",
      "Gradient Descent(9/49): loss=19445.29800050038, w0=954625.9569, w1=-167075.81099999993\n",
      "Gradient Descent(10/49): loss=37486.06787403042, w0=1276886.8042, w1=-273884.8776999999\n",
      "Gradient Descent(11/49): loss=19560.427355149528, w0=1251982.2448, w1=-270907.3492999999\n",
      "Gradient Descent(12/49): loss=19525.888548754774, w0=1223344.0149, w1=-267155.51799999987\n",
      "Gradient Descent(13/49): loss=23405.74780043317, w0=1177211.476, w1=-274826.67099999986\n",
      "Gradient Descent(14/49): loss=18040.719873779784, w0=1165745.602, w1=-263874.41219999985\n",
      "Gradient Descent(15/49): loss=37624.22309960947, w0=1515639.4175999998, w1=-363339.3903999998\n",
      "Gradient Descent(16/49): loss=19525.888548754778, w0=1490196.2865999998, w1=-360132.1268999998\n",
      "Gradient Descent(17/49): loss=18996.29351736837, w0=1467534.4382999998, w1=-353369.5619999998\n",
      "Gradient Descent(18/49): loss=23048.84680102065, w0=1413879.8890999998, w1=-358874.6755999998\n",
      "Gradient Descent(19/49): loss=17315.404939489716, w0=1418588.4285999998, w1=-342384.36259999976\n",
      "Gradient Descent(20/49): loss=37681.78777693409, w0=1765443.3054999998, w1=-442622.6594999997\n",
      "Gradient Descent(21/49): loss=19525.888548754778, w0=1739372.8232999998, w1=-439253.5195999997\n",
      "Gradient Descent(22/49): loss=18812.08654992959, w0=1717778.9348999998, w1=-431857.3377999997\n",
      "Gradient Descent(23/49): loss=21632.75573883539, w0=1644452.8694999998, w1=-441584.3368999997\n",
      "Gradient Descent(24/49): loss=17073.633294726318, w0=1660931.2783, w1=-421152.0970999997\n",
      "Gradient Descent(25/49): loss=37647.24897053932, w0=2006541.1534, w1=-521678.4236999997\n",
      "Gradient Descent(26/49): loss=19537.401484219692, w0=1980561.3569, w1=-518291.6521999997\n",
      "Gradient Descent(27/49): loss=18581.827840631155, w0=1961461.6861, w1=-509790.4888999997\n",
      "Gradient Descent(28/49): loss=21287.367674887788, w0=1878694.8201000001, w1=-522094.4252999997\n",
      "Gradient Descent(29/49): loss=17050.60742379646, w0=1898718.5217000002, w1=-500684.27639999974\n",
      "Gradient Descent(30/49): loss=37693.30071239902, w0=2242602.8268, w1=-601628.4350999997\n",
      "Gradient Descent(31/49): loss=19514.375613289845, w0=2215554.9136, w1=-597883.2019999997\n",
      "Gradient Descent(32/49): loss=18535.776098771457, w0=2198908.7505, w1=-588474.9821999997\n",
      "Gradient Descent(33/49): loss=20769.285578966388, w0=2116910.1282, w1=-598728.0424999997\n",
      "Gradient Descent(34/49): loss=16946.991004612173, w0=2137946.5555000002, w1=-576749.7553999998\n",
      "Gradient Descent(35/49): loss=37658.76190600424, w0=2479654.7251000004, w1=-678216.7559999997\n",
      "Gradient Descent(36/49): loss=19502.862677824924, w0=2452742.6532000005, w1=-674316.5316999997\n",
      "Gradient Descent(37/49): loss=18386.107937727447, w0=2436721.9184000003, w1=-664650.5081999997\n",
      "Gradient Descent(38/49): loss=28126.051341050214, w0=2231228.6955000004, w1=-728808.4201999997\n",
      "Gradient Descent(39/49): loss=18858.138291789262, w0=2213903.9181000004, w1=-720900.9303999997\n",
      "Gradient Descent(40/49): loss=16970.016875542005, w0=2228855.6892000004, w1=-700501.4946999997\n",
      "Gradient Descent(41/49): loss=30037.198628226877, w0=2055493.1509000005, w1=-756914.9755999997\n",
      "Gradient Descent(42/49): loss=18973.2676464385, w0=2035946.4076000005, w1=-749536.4057999996\n",
      "Gradient Descent(43/49): loss=16877.91339182264, w0=2052451.5137000005, w1=-728653.3617999996\n",
      "Gradient Descent(44/49): loss=30267.45733752525, w0=1883378.2310000006, w1=-784212.9994999996\n",
      "Gradient Descent(45/49): loss=18973.267646438526, w0=1862963.5801000006, w1=-777167.1802999995\n",
      "Gradient Descent(46/49): loss=16970.01687554202, w0=1879316.8471000006, w1=-756201.6916999995\n",
      "Gradient Descent(47/49): loss=31487.82849680673, w0=1798475.3297000006, w1=-818378.5504999994\n",
      "Gradient Descent(48/49): loss=19111.422872017574, w0=1776166.4004000006, w1=-812038.4334999995\n",
      "Gradient Descent(49/49): loss=17062.1203592614, w0=1788083.7926000005, w1=-792194.7704999995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  1.78808379e+06,  -7.92194770e+05,  -4.75110404e+05,\n",
       "          2.28788819e+05,  -3.07284797e+05,  -6.80176865e+04,\n",
       "         -3.16077281e+05,  -7.83606985e+03,  -9.70922802e+04,\n",
       "         -3.36689164e+05,  -1.67868572e+04,   1.29444816e+04,\n",
       "         -3.04459065e+05,   1.97890835e+05,   2.11908795e+03,\n",
       "         -1.84352980e+03,  -2.47809878e+05,   3.46447010e+03,\n",
       "          2.73551460e+03,  -7.13471199e+04,   6.76448500e+02,\n",
       "         -5.40102068e+05,  -8.98590000e+03,   3.99421799e+05,\n",
       "          3.63000059e+05,   3.64647529e+05,  -4.95357899e+05,\n",
       "         -3.03309165e+05,  -3.05644151e+05,  -2.86769351e+05]),\n",
       " 17062.1203592614)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### WRONG RESULTS\n",
    "logistic_regression(y_train, x_train, np.zeros(x_train.shape[1]), 50, 0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
