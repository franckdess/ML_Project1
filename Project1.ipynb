{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from proj1_helpers import load_csv_data\n",
    "from functions import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = load_csv_data('Data/train.csv', sub_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  1.,  1., ...,  1.,  1.,  1.]),\n",
       " array([[-999.   ,   79.589,   23.916, ..., -999.   , -999.   ,    0.   ],\n",
       "        [ 106.398,   67.49 ,   87.949, ..., -999.   , -999.   ,   47.575],\n",
       "        [ 117.794,   56.226,   96.358, ..., -999.   , -999.   ,    0.   ],\n",
       "        ..., \n",
       "        [ 108.497,    9.837,   65.149, ..., -999.   , -999.   ,    0.   ],\n",
       "        [  96.711,   20.006,   66.942, ..., -999.   , -999.   ,   30.863],\n",
       "        [  92.373,   80.109,   77.619, ..., -999.   , -999.   ,    0.   ]]),\n",
       " array([350000, 350001, 350002, ..., 918235, 918236, 918237]))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = load_csv_data('Data/test.csv')\n",
    "test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_pd = pd.read_csv('Data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set_pd = pd.read_csv('Data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the data depending on the columns used. And clean the first column by replacing -999 by the mean of the clean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_pd_0 = train_set_pd[train_set_pd.PRI_jet_num == 0].drop(['DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet', 'DER_lep_eta_centrality', 'PRI_jet_leading_pt', 'PRI_jet_leading_eta', 'PRI_jet_leading_phi', 'PRI_jet_subleading_pt', 'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi', 'PRI_jet_num'], axis = 1)\n",
    "train_set_pd_1 = train_set_pd[train_set_pd.PRI_jet_num == 1].drop(['DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet', 'DER_lep_eta_centrality', 'PRI_jet_subleading_pt', 'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi', 'PRI_jet_num'], axis = 1)\n",
    "train_set_pd_2 = train_set_pd[train_set_pd.PRI_jet_num.isin([2, 3])].drop(['PRI_jet_num'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_0 = get_column_mean(-999.000, train_set_pd_0, 'DER_mass_MMC')\n",
    "mean_1 = get_column_mean(-999.000, train_set_pd_1, 'DER_mass_MMC')\n",
    "mean_2 = get_column_mean(-999.000, train_set_pd_2, 'DER_mass_MMC')\n",
    "\n",
    "train_set_pd_0['DER_mass_MMC'] = train_set_pd_0['DER_mass_MMC'].apply(lambda x: replace_by_mean(x, mean_0, 'DER_mass_MMC'))\n",
    "train_set_pd_1['DER_mass_MMC'] = train_set_pd_1['DER_mass_MMC'].apply(lambda x: replace_by_mean(x, mean_1, 'DER_mass_MMC'))\n",
    "train_set_pd_2['DER_mass_MMC'] = train_set_pd_2['DER_mass_MMC'].apply(lambda x: replace_by_mean(x, mean_2, 'DER_mass_MMC'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the dataframe then we can open them with the load_csv function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_pd_0.to_csv('Data/train_set_0.csv', index = False)\n",
    "train_set_pd_1.to_csv('Data/train_set_1.csv', index = False)\n",
    "train_set_pd_2.to_csv('Data/train_set_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_0 = load_csv_data('Data/train_set_0.csv', sub_sample=True)\n",
    "train_set_1 = load_csv_data('Data/train_set_1.csv', sub_sample=True)\n",
    "train_set_2 = load_csv_data('Data/train_set_2.csv', sub_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_0 = train_set_0[1]\n",
    "x_train_1 = train_set_1[1]\n",
    "x_train_2 = train_set_2[1]\n",
    "\n",
    "y_train_0 = train_set_0[0]\n",
    "y_train_1 = train_set_1[0]\n",
    "y_train_2 = train_set_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_0 = neg_to_zero(y_train_0)\n",
    "y_train_1 = neg_to_zero(y_train_1)\n",
    "y_train_2 = neg_to_zero(y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    ws = [initial_w]\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        gradient = compute_gradient_least_square(y, tx, w)\n",
    "        loss = compute_mse(y, tx, w)\n",
    "        w = w - gamma*gradient\n",
    "        print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return loss, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares_SGD(y, tx, initial_w, max_iters, gamma):\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):    \n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "            gradient = compute_stoch_gradient(minibatch_y, minibatch_tx, w)\n",
    "            loss = compute_mse(minibatch_y, minibatch_tx, w)\n",
    "            new_w = w - gamma*gradient\n",
    "            w = new_w\n",
    "            ws.append(w)\n",
    "            losses.append(loss)\n",
    "            print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(\n",
    "            bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    A = tx.T@tx\n",
    "    b = tx.T@y\n",
    "    w = np.linalg.solve(A, b)\n",
    "    loss = compute_mse(y, tx, w)\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    X = tx.T@tx\n",
    "    N = X.shape[0]\n",
    "    A = (X + 2*N*lambda_*np.identity(N))\n",
    "    b = tx.T@y\n",
    "    w = np.linalg.solve(A, b)\n",
    "    loss = compute_mse(y, tx, w)\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(y, tx, initial_w, max_iters, gamma):\n",
    "    loss, w = stoch_gradient_descent_log_reg(y, tx, initial_w, max_iters, gamma)\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reg_logistic_regression(y, tx, lambda_, initial_w, max_iters, gamma):\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TESTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests to find the right gamma\n",
    "gammas = np.logspace(-5, 0)\n",
    "losses = []\n",
    "for gamma in gammas:\n",
    "    w, loss = logistic_regression(y_train_2, x_train_2, np.zeros(x_train_2.shape[1]), 1000, gamma)\n",
    "    losses.append((gamma, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tests to find the right gamma\n",
    "losses.sort(key = lambda x: x[1])\n",
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_0, loss_0 = logistic_regression(y_train_0, x_train_0, np.zeros(x_train_0.shape[1]), 10000, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1, loss_1 = logistic_regression(y_train_1, x_train_1, np.zeros(x_train_1.shape[1]), 10000, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_2, loss_2 = logistic_regression(y_train_2, x_train_2, np.zeros(x_train_2.shape[1]), 10000, 1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEST ON TEST SET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
