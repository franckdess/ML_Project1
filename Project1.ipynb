{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from proj1_helpers import load_csv_data\n",
    "from functions import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%qtconsole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = load_csv_data('Data/train.csv', sub_sample=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "train_set_pd = pd.read_csv('Data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the data depending on the columns used. And clean the first column by replacing -999 by the mean of the clean values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_pd_0 = train_set_pd[train_set_pd.PRI_jet_num == 0].drop(['DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet', 'DER_lep_eta_centrality', 'PRI_jet_leading_pt', 'PRI_jet_leading_eta', 'PRI_jet_leading_phi', 'PRI_jet_subleading_pt', 'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi', 'PRI_jet_num'], axis = 1)\n",
    "train_set_pd_1 = train_set_pd[train_set_pd.PRI_jet_num == 1].drop(['DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet', 'DER_lep_eta_centrality', 'PRI_jet_subleading_pt', 'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi', 'PRI_jet_num'], axis = 1)\n",
    "train_set_pd_2 = train_set_pd[train_set_pd.PRI_jet_num.isin([2, 3])].drop(['PRI_jet_num'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_wrong_value(wrong_value, df):\n",
    "    s = 0\n",
    "    count = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        if row['DER_mass_MMC']!=wrong_value:\n",
    "            count += 1\n",
    "            s += row['DER_mass_MMC']\n",
    "    mean = s/count\n",
    "    \n",
    "    def replace_by_mean(x):\n",
    "        if x == -999:\n",
    "            return mean\n",
    "        else:\n",
    "            return x\n",
    "        \n",
    "    df['DER_mass_MMC'] = df['DER_mass_MMC'].apply(lambda x: replace_by_mean(x))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_pd_0_clean = replace_wrong_value(-999.000,train_set_pd_0)\n",
    "train_set_pd_1_clean = replace_wrong_value(-999.000,train_set_pd_1)\n",
    "train_set_pd_2_clean = replace_wrong_value(-999.000,train_set_pd_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the dataframe then we can open them with the load_csv function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set_pd_0_clean.to_csv('Data/train_set_0.csv', index = False)\n",
    "train_set_pd_1_clean.to_csv('Data/train_set_1.csv', index = False)\n",
    "train_set_pd_2_clean.to_csv('Data/train_set_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_0 = load_csv_data('Data/train_set_0.csv', sub_sample=True)\n",
    "train_set_1 = load_csv_data('Data/train_set_1.csv', sub_sample=True)\n",
    "train_set_2 = load_csv_data('Data/train_set_2.csv', sub_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_0 = train_set_0[1]\n",
    "x_train_1 = train_set_1[1]\n",
    "x_train_2 = train_set_2[1]\n",
    "\n",
    "y_train_0 = train_set_0[0]\n",
    "y_train_1 = train_set_1[0]\n",
    "y_train_2 = train_set_2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in enumerate(y_train_0):\n",
    "    if v == -1:\n",
    "        y_train_0[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, v in enumerate(y_train_1):\n",
    "    if v == -1:\n",
    "        y_train_1[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, v in enumerate(y_train_2):\n",
    "    if v == -1:\n",
    "        y_train_2[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    ws = [initial_w]\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        gradient = compute_gradient_least_square(y, tx, w)\n",
    "        loss = compute_mse(y, tx, w)\n",
    "        w = w - gamma*gradient\n",
    "        print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return loss, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares_SGD(y, tx, initial_w, max_iters, gamma):\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):    \n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "            gradient = compute_stoch_gradient(minibatch_y, minibatch_tx, w)\n",
    "            loss = compute_mse(minibatch_y, minibatch_tx, w)\n",
    "            new_w = w - gamma*gradient\n",
    "            w = new_w\n",
    "            ws.append(w)\n",
    "            losses.append(loss)\n",
    "            print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(\n",
    "            bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    A = tx.T@tx\n",
    "    b = tx.T@y\n",
    "    w = np.linalg.solve(A, b)\n",
    "    loss = compute_mse(y, tx, w)\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    X = tx.T@tx\n",
    "    N = X.shape[0]\n",
    "    A = (X + 2*N*lambda_*np.identity(N))\n",
    "    b = tx.T@y\n",
    "    w = np.linalg.solve(A, b)\n",
    "    loss = compute_mse(y, tx, w)\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(y, tx, initial_w, max_iters, gamma):\n",
    "    loss, w = stoch_gradient_descent_log_reg(y, tx, initial_w, max_iters, gamma)\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reg_logistic_regression(y, tx, lambda_, initial_w, max_iters, gamma):\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TESTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/9999): loss=1385.5612343391256, w0=-2.97735, w1=-3.4405500000000004\n",
      "Gradient Descent(1/9999): loss=5802.4994844197445, w0=-2.97735, w1=-3.4405500000000004\n",
      "Gradient Descent(2/9999): loss=5802.4994844197445, w0=10.222150000000001, w1=-2.4853500000000004\n",
      "Gradient Descent(3/9999): loss=17211.818530155688, w0=10.222150000000001, w1=-2.4853500000000004\n",
      "Gradient Descent(4/9999): loss=17211.818530155688, w0=-0.37544999999999895, w1=-7.06885\n",
      "Gradient Descent(5/9999): loss=5802.4994844197445, w0=-0.37544999999999895, w1=-7.06885\n",
      "Gradient Descent(6/9999): loss=5802.4994844197445, w0=-0.37544999999999895, w1=-7.06885\n",
      "Gradient Descent(7/9999): loss=5802.4994844197445, w0=-0.37544999999999895, w1=-7.06885\n",
      "Gradient Descent(8/9999): loss=5802.4994844197445, w0=-0.37544999999999895, w1=-7.06885\n",
      "Gradient Descent(9/9999): loss=5802.4994844197445, w0=-0.37544999999999895, w1=-7.06885\n",
      "Gradient Descent(10/9999): loss=5802.4994844197445, w0=-0.37544999999999895, w1=-7.06885\n",
      "Gradient Descent(11/9999): loss=5802.4994844197445, w0=11.71245, w1=-2.70695\n",
      "Gradient Descent(12/9999): loss=17211.818530155688, w0=1.5298499999999997, w1=-6.07275\n",
      "Gradient Descent(13/9999): loss=17234.84440108553, w0=-13.90995, w1=-12.610050000000001\n",
      "Gradient Descent(14/9999): loss=5848.696753532105, w0=-13.90995, w1=-12.610050000000001\n",
      "Gradient Descent(15/9999): loss=5848.696753532105, w0=-13.90995, w1=-12.610050000000001\n",
      "Gradient Descent(16/9999): loss=5848.696753532105, w0=-13.90995, w1=-12.610050000000001\n",
      "Gradient Descent(17/9999): loss=5848.696753532105, w0=-13.90995, w1=-12.610050000000001\n",
      "Gradient Descent(18/9999): loss=5848.696753532105, w0=-13.90995, w1=-12.610050000000001\n",
      "Gradient Descent(19/9999): loss=5848.696753532105, w0=-6.56025, w1=-8.42205\n",
      "Gradient Descent(20/9999): loss=11904.624989045622, w0=-6.56025, w1=-8.42205\n",
      "Gradient Descent(21/9999): loss=11904.624989045622, w0=-15.73315, w1=-15.028550000000001\n",
      "Gradient Descent(22/9999): loss=5802.4994844197445, w0=-15.73315, w1=-15.028550000000001\n",
      "Gradient Descent(23/9999): loss=5802.4994844197445, w0=-15.73315, w1=-15.028550000000001\n",
      "Gradient Descent(24/9999): loss=5802.4994844197445, w0=-15.73315, w1=-15.028550000000001\n",
      "Gradient Descent(25/9999): loss=5802.4994844197445, w0=-1.5569499999999987, w1=-14.442150000000002\n",
      "Gradient Descent(26/9999): loss=15230.483740000544, w0=-1.5569499999999987, w1=-14.442150000000002\n",
      "Gradient Descent(27/9999): loss=15230.483740000544, w0=-1.5569499999999987, w1=-14.442150000000002\n",
      "Gradient Descent(28/9999): loss=15230.483740000544, w0=-1.5569499999999987, w1=-14.442150000000002\n",
      "Gradient Descent(29/9999): loss=15230.483740000544, w0=-1.5569499999999987, w1=-14.442150000000002\n",
      "Gradient Descent(30/9999): loss=15230.483740000544, w0=-23.655749999999998, w1=-19.054250000000003\n",
      "Gradient Descent(31/9999): loss=5802.4994844197445, w0=-23.655749999999998, w1=-19.054250000000003\n",
      "Gradient Descent(32/9999): loss=5802.4994844197445, w0=-23.655749999999998, w1=-19.054250000000003\n",
      "Gradient Descent(33/9999): loss=5802.4994844197445, w0=-23.655749999999998, w1=-19.054250000000003\n",
      "Gradient Descent(34/9999): loss=5802.4994844197445, w0=-23.655749999999998, w1=-19.054250000000003\n",
      "Gradient Descent(35/9999): loss=5802.4994844197445, w0=-23.655749999999998, w1=-19.054250000000003\n",
      "Gradient Descent(36/9999): loss=5802.4994844197445, w0=-23.655749999999998, w1=-19.054250000000003\n",
      "Gradient Descent(37/9999): loss=5802.4994844197445, w0=-23.655749999999998, w1=-19.054250000000003\n",
      "Gradient Descent(38/9999): loss=5802.4994844197445, w0=-10.851549999999996, w1=-18.586750000000002\n",
      "Gradient Descent(39/9999): loss=8271.804560044366, w0=-10.851549999999996, w1=-18.586750000000002\n",
      "Gradient Descent(40/9999): loss=8271.804560044366, w0=-10.851549999999996, w1=-18.586750000000002\n",
      "Gradient Descent(41/9999): loss=8271.804560044366, w0=-20.22065, w1=-20.78535\n",
      "Gradient Descent(42/9999): loss=5802.4994844197445, w0=-20.22065, w1=-20.78535\n",
      "Gradient Descent(43/9999): loss=5802.4994844197445, w0=-20.22065, w1=-20.78535\n",
      "Gradient Descent(44/9999): loss=5802.4994844197445, w0=-8.919249999999998, w1=-19.264850000000003\n",
      "Gradient Descent(45/9999): loss=13988.725197840799, w0=-22.22485, w1=-21.782450000000004\n",
      "Gradient Descent(46/9999): loss=6435.923469883506, w0=-7.67625, w1=-20.238650000000003\n",
      "Gradient Descent(47/9999): loss=14473.975863348573, w0=-7.67625, w1=-20.238650000000003\n",
      "Gradient Descent(48/9999): loss=14473.975863348573, w0=-7.67625, w1=-20.238650000000003\n",
      "Gradient Descent(49/9999): loss=14473.975863348573, w0=-17.72945, w1=-27.900450000000003\n",
      "Gradient Descent(50/9999): loss=6251.285228218459, w0=-17.72945, w1=-27.900450000000003\n",
      "Gradient Descent(51/9999): loss=6251.285228218459, w0=-5.928649999999999, w1=-24.429850000000002\n",
      "Gradient Descent(52/9999): loss=13351.430597772247, w0=-21.09115, w1=-31.57525\n",
      "Gradient Descent(53/9999): loss=5802.4994844197445, w0=-21.09115, w1=-31.57525\n",
      "Gradient Descent(54/9999): loss=5802.4994844197445, w0=-21.09115, w1=-31.57525\n",
      "Gradient Descent(55/9999): loss=5802.4994844197445, w0=-21.09115, w1=-31.57525\n",
      "Gradient Descent(56/9999): loss=5802.4994844197445, w0=-21.09115, w1=-31.57525\n",
      "Gradient Descent(57/9999): loss=5802.4994844197445, w0=-21.09115, w1=-31.57525\n",
      "Gradient Descent(58/9999): loss=5802.4994844197445, w0=-9.54365, w1=-28.02085\n",
      "Gradient Descent(59/9999): loss=9773.757584242841, w0=-18.06045, w1=-30.06125\n",
      "Gradient Descent(60/9999): loss=6126.237727133801, w0=-18.06045, w1=-30.06125\n",
      "Gradient Descent(61/9999): loss=6126.237727133801, w0=-18.06045, w1=-30.06125\n",
      "Gradient Descent(62/9999): loss=6126.237727133801, w0=-6.758049999999999, w1=-27.27635\n",
      "Gradient Descent(63/9999): loss=14324.255556977554, w0=-14.16615, w1=-30.98935\n",
      "Gradient Descent(64/9999): loss=6106.089134978629, w0=-14.16615, w1=-30.98935\n",
      "Gradient Descent(65/9999): loss=6106.089134978629, w0=-14.16615, w1=-30.98935\n",
      "Gradient Descent(66/9999): loss=6106.089134978629, w0=-14.16615, w1=-30.98935\n",
      "Gradient Descent(67/9999): loss=6106.089134978629, w0=-14.16615, w1=-30.98935\n",
      "Gradient Descent(68/9999): loss=6106.089134978629, w0=-14.16615, w1=-30.98935\n",
      "Gradient Descent(69/9999): loss=6106.089134978629, w0=-14.16615, w1=-30.98935\n",
      "Gradient Descent(70/9999): loss=6106.089134978629, w0=-14.16615, w1=-30.98935\n",
      "Gradient Descent(71/9999): loss=6106.089134978629, w0=-14.16615, w1=-30.98935\n",
      "Gradient Descent(72/9999): loss=6106.089134978629, w0=-14.16615, w1=-30.98935\n",
      "Gradient Descent(73/9999): loss=6106.089134978629, w0=-14.16615, w1=-30.98935\n",
      "Gradient Descent(74/9999): loss=6106.089134978629, w0=-14.16615, w1=-30.98935\n",
      "Gradient Descent(75/9999): loss=6106.089134978629, w0=-31.31275, w1=-41.872150000000005\n",
      "Gradient Descent(76/9999): loss=5802.4994844197445, w0=-31.31275, w1=-41.872150000000005\n",
      "Gradient Descent(77/9999): loss=5802.4994844197445, w0=-31.31275, w1=-41.872150000000005\n",
      "Gradient Descent(78/9999): loss=5802.4994844197445, w0=-31.31275, w1=-41.872150000000005\n",
      "Gradient Descent(79/9999): loss=5802.4994844197445, w0=-31.31275, w1=-41.872150000000005\n",
      "Gradient Descent(80/9999): loss=5802.4994844197445, w0=-31.31275, w1=-41.872150000000005\n",
      "Gradient Descent(81/9999): loss=5802.4994844197445, w0=-17.73705, w1=-39.388850000000005\n",
      "Gradient Descent(82/9999): loss=5790.986548954824, w0=-17.73705, w1=-39.388850000000005\n",
      "Gradient Descent(83/9999): loss=5790.986548954824, w0=-5.44125, w1=-39.01955\n",
      "Gradient Descent(84/9999): loss=9434.644233323459, w0=-5.44125, w1=-39.01955\n",
      "Gradient Descent(85/9999): loss=9434.644233323459, w0=-14.16455, w1=-44.20835\n",
      "Gradient Descent(86/9999): loss=5802.866563137, w0=-14.16455, w1=-44.20835\n",
      "Gradient Descent(87/9999): loss=5802.866563137, w0=-14.16455, w1=-44.20835\n",
      "Gradient Descent(88/9999): loss=5802.866563137, w0=-2.097784614446466, w1=-25.380950000000002\n",
      "Gradient Descent(89/9999): loss=16319.246804003065, w0=-2.097784614446466, w1=-25.380950000000002\n",
      "Gradient Descent(90/9999): loss=16319.246804003065, w0=-2.097784614446466, w1=-25.380950000000002\n",
      "Gradient Descent(91/9999): loss=16319.246804003065, w0=-2.097784614446466, w1=-25.380950000000002\n",
      "Gradient Descent(92/9999): loss=16319.246804003065, w0=-14.16455, w1=-31.481450000000002\n",
      "Gradient Descent(93/9999): loss=6947.891002496566, w0=-14.16455, w1=-31.481450000000002\n",
      "Gradient Descent(94/9999): loss=6947.891002496566, w0=-14.16455, w1=-31.481450000000002\n",
      "Gradient Descent(95/9999): loss=6947.891002496566, w0=-14.16455, w1=-31.481450000000002\n",
      "Gradient Descent(96/9999): loss=6947.891002496566, w0=-14.16455, w1=-31.481450000000002\n",
      "Gradient Descent(97/9999): loss=6947.891002496566, w0=-14.16455, w1=-31.481450000000002\n",
      "Gradient Descent(98/9999): loss=6947.891002496566, w0=-14.16455, w1=-31.481450000000002\n",
      "Gradient Descent(99/9999): loss=6947.891002496566, w0=-14.16455, w1=-31.481450000000002\n",
      "Gradient Descent(100/9999): loss=6947.891002496566, w0=-14.16455, w1=-31.481450000000002\n",
      "Gradient Descent(101/9999): loss=6947.891002496566, w0=-24.540550000000003, w1=-36.46725000000001\n",
      "Gradient Descent(102/9999): loss=5802.4994844197445, w0=-24.540550000000003, w1=-36.46725000000001\n",
      "Gradient Descent(103/9999): loss=5802.4994844197445, w0=-24.540550000000003, w1=-36.46725000000001\n",
      "Gradient Descent(104/9999): loss=5802.4994844197445, w0=-14.903050000000002, w1=-33.44825000000001\n",
      "Gradient Descent(105/9999): loss=6316.55791204052, w0=-14.903050000000002, w1=-33.44825000000001\n",
      "Gradient Descent(106/9999): loss=6316.55791204052, w0=-7.301450000000001, w1=-29.22415000000001\n",
      "Gradient Descent(107/9999): loss=13908.794261128889, w0=-19.368215385553533, w1=-36.10005000000001\n",
      "Gradient Descent(108/9999): loss=6094.220918423092, w0=-3.559015385553531, w1=-32.20715000000001\n",
      "Gradient Descent(109/9999): loss=16613.145885969338, w0=-17.97131538555353, w1=-40.974750000000014\n",
      "Gradient Descent(110/9999): loss=6564.185083475251, w0=-5.904549999999997, w1=-28.25185000000001\n",
      "Gradient Descent(111/9999): loss=17165.76678829601, w0=-13.218349999999997, w1=-34.16605000000001\n",
      "Gradient Descent(112/9999): loss=11167.741705014243, w0=-21.84995, w1=-36.85375000000001\n",
      "Gradient Descent(113/9999): loss=5999.960579428855, w0=-13.473650000000001, w1=-34.78905000000001\n",
      "Gradient Descent(114/9999): loss=11260.626896639304, w0=-13.473650000000001, w1=-34.78905000000001\n",
      "Gradient Descent(115/9999): loss=11260.626896639304, w0=-13.473650000000001, w1=-34.78905000000001\n",
      "Gradient Descent(116/9999): loss=11260.626896639304, w0=-26.62105, w1=-41.06585000000001\n",
      "Gradient Descent(117/9999): loss=5917.62957701361, w0=-18.26795, w1=-35.70025000000001\n",
      "Gradient Descent(118/9999): loss=9884.507541721818, w0=-29.20895, w1=-43.58015000000001\n",
      "Gradient Descent(119/9999): loss=5867.806595342538, w0=-18.38095, w1=-39.43465000000001\n",
      "Gradient Descent(120/9999): loss=9445.641409601216, w0=-18.38095, w1=-39.43465000000001\n",
      "Gradient Descent(121/9999): loss=9445.641409601216, w0=-18.38095, w1=-39.43465000000001\n",
      "Gradient Descent(122/9999): loss=9445.641409601216, w0=-18.38095, w1=-39.43465000000001\n",
      "Gradient Descent(123/9999): loss=9445.641409601216, w0=-18.38095, w1=-39.43465000000001\n",
      "Gradient Descent(124/9999): loss=9445.641409601216, w0=-30.447715385553533, w1=-51.59875000000001\n",
      "Gradient Descent(125/9999): loss=5825.5253709634, w0=-30.447715385553533, w1=-51.59875000000001\n",
      "Gradient Descent(126/9999): loss=5825.5253709634, w0=-17.249915385553535, w1=-48.43675000000001\n",
      "Gradient Descent(127/9999): loss=5628.189298995352, w0=-17.249915385553535, w1=-48.43675000000001\n",
      "Gradient Descent(128/9999): loss=5628.189298995352, w0=-17.249915385553535, w1=-48.43675000000001\n",
      "Gradient Descent(129/9999): loss=5628.189298995352, w0=-17.249915385553535, w1=-48.43675000000001\n",
      "Gradient Descent(130/9999): loss=5628.189298995352, w0=-31.140615385553538, w1=-52.28235000000001\n",
      "Gradient Descent(131/9999): loss=5802.4994844197445, w0=-31.140615385553538, w1=-52.28235000000001\n",
      "Gradient Descent(132/9999): loss=5802.4994844197445, w0=-31.140615385553538, w1=-52.28235000000001\n",
      "Gradient Descent(133/9999): loss=5802.4994844197445, w0=-31.140615385553538, w1=-52.28235000000001\n",
      "Gradient Descent(134/9999): loss=5802.4994844197445, w0=-31.140615385553538, w1=-52.28235000000001\n",
      "Gradient Descent(135/9999): loss=5802.4994844197445, w0=-31.140615385553538, w1=-52.28235000000001\n",
      "Gradient Descent(136/9999): loss=5802.4994844197445, w0=-31.140615385553538, w1=-52.28235000000001\n",
      "Gradient Descent(137/9999): loss=5802.4994844197445, w0=-18.236615385553538, w1=-51.17965000000001\n",
      "Gradient Descent(138/9999): loss=5119.252538437308, w0=-18.236615385553538, w1=-51.17965000000001\n",
      "Gradient Descent(139/9999): loss=5119.252538437308, w0=-18.236615385553538, w1=-51.17965000000001\n",
      "Gradient Descent(140/9999): loss=5119.252538437308, w0=-18.236615385553538, w1=-51.17965000000001\n",
      "Gradient Descent(141/9999): loss=5119.252538437308, w0=-18.236615385553538, w1=-51.17965000000001\n",
      "Gradient Descent(142/9999): loss=5119.252538437308, w0=-18.236615385553538, w1=-51.17965000000001\n",
      "Gradient Descent(143/9999): loss=5119.252538437308, w0=-18.236615385553538, w1=-51.17965000000001\n",
      "Gradient Descent(144/9999): loss=5119.252538437308, w0=-18.236615385553538, w1=-51.17965000000001\n",
      "Gradient Descent(145/9999): loss=5119.252538437308, w0=-18.236615385553538, w1=-51.17965000000001\n",
      "Gradient Descent(146/9999): loss=5119.252538437308, w0=-18.236615385553538, w1=-51.17965000000001\n",
      "Gradient Descent(147/9999): loss=5119.252538437308, w0=-18.236615385553538, w1=-51.17965000000001\n",
      "Gradient Descent(148/9999): loss=5119.252538437308, w0=-18.236615385553538, w1=-51.17965000000001\n",
      "Gradient Descent(149/9999): loss=5119.252538437308, w0=-5.465715385553537, w1=-44.78255000000001\n",
      "Gradient Descent(150/9999): loss=15216.508697152833, w0=-27.564515385553538, w1=-49.394650000000006\n",
      "Gradient Descent(151/9999): loss=5841.593756546007, w0=-13.76961538555354, w1=-43.654650000000004\n",
      "Gradient Descent(152/9999): loss=10357.902571639353, w0=-13.76961538555354, w1=-43.654650000000004\n",
      "Gradient Descent(153/9999): loss=10357.902571639353, w0=-13.76961538555354, w1=-43.654650000000004\n",
      "Gradient Descent(154/9999): loss=10357.902571639353, w0=-13.76961538555354, w1=-43.654650000000004\n",
      "Gradient Descent(155/9999): loss=10357.902571639353, w0=-13.76961538555354, w1=-43.654650000000004\n",
      "Gradient Descent(156/9999): loss=10357.902571639353, w0=-13.76961538555354, w1=-43.654650000000004\n",
      "Gradient Descent(157/9999): loss=10357.902571639353, w0=-25.69371538555354, w1=-46.855250000000005\n",
      "Gradient Descent(158/9999): loss=5779.469509600365, w0=-25.69371538555354, w1=-46.855250000000005\n",
      "Gradient Descent(159/9999): loss=5779.469509600365, w0=-25.69371538555354, w1=-46.855250000000005\n",
      "Gradient Descent(160/9999): loss=5779.469509600365, w0=-25.69371538555354, w1=-46.855250000000005\n",
      "Gradient Descent(161/9999): loss=5779.469509600365, w0=-25.69371538555354, w1=-46.855250000000005\n",
      "Gradient Descent(162/9999): loss=5779.469509600365, w0=-25.69371538555354, w1=-46.855250000000005\n",
      "Gradient Descent(163/9999): loss=5779.469509600365, w0=-25.69371538555354, w1=-46.855250000000005\n",
      "Gradient Descent(164/9999): loss=5779.469509600365, w0=-13.892915385553538, w1=-43.38465000000001\n",
      "Gradient Descent(165/9999): loss=7010.114501604057, w0=-23.94071538555354, w1=-47.318850000000005\n",
      "Gradient Descent(166/9999): loss=5790.62249412679, w0=-23.94071538555354, w1=-47.318850000000005\n",
      "Gradient Descent(167/9999): loss=5790.62249412679, w0=-23.94071538555354, w1=-47.318850000000005\n",
      "Gradient Descent(168/9999): loss=5790.62249412679, w0=-23.94071538555354, w1=-47.318850000000005\n",
      "Gradient Descent(169/9999): loss=5790.62249412679, w0=-23.94071538555354, w1=-47.318850000000005\n",
      "Gradient Descent(170/9999): loss=5790.62249412679, w0=-12.817315385553538, w1=-44.966150000000006\n",
      "Gradient Descent(171/9999): loss=8322.464494240558, w0=-12.817315385553538, w1=-44.966150000000006\n",
      "Gradient Descent(172/9999): loss=8322.464494240558, w0=-23.939315385553538, w1=-50.331450000000004\n",
      "Gradient Descent(173/9999): loss=5653.276647699171, w0=-23.939315385553538, w1=-50.331450000000004\n",
      "Gradient Descent(174/9999): loss=5653.276647699171, w0=-23.939315385553538, w1=-50.331450000000004\n",
      "Gradient Descent(175/9999): loss=5653.276647699171, w0=-23.939315385553538, w1=-50.331450000000004\n",
      "Gradient Descent(176/9999): loss=5653.276647699171, w0=-23.939315385553538, w1=-50.331450000000004\n",
      "Gradient Descent(177/9999): loss=5653.276647699171, w0=-23.939315385553538, w1=-50.331450000000004\n",
      "Gradient Descent(178/9999): loss=5653.276647699171, w0=-23.939315385553538, w1=-50.331450000000004\n",
      "Gradient Descent(179/9999): loss=5653.276647699171, w0=-23.939315385553538, w1=-50.331450000000004\n",
      "Gradient Descent(180/9999): loss=5653.276647699171, w0=-23.939315385553538, w1=-50.331450000000004\n",
      "Gradient Descent(181/9999): loss=5653.276647699171, w0=-23.939315385553538, w1=-50.331450000000004\n",
      "Gradient Descent(182/9999): loss=5653.276647699171, w0=-16.07471538555354, w1=-46.41465\n",
      "Gradient Descent(183/9999): loss=5204.461034087855, w0=-4.007950000000005, w1=-27.05445\n",
      "Gradient Descent(184/9999): loss=17154.25378376641, w0=-4.007950000000005, w1=-27.05445\n",
      "Gradient Descent(185/9999): loss=17154.25378376641, w0=-16.07471538555354, w1=-34.92225\n",
      "Gradient Descent(186/9999): loss=5775.723855635672, w0=-16.07471538555354, w1=-34.92225\n",
      "Gradient Descent(187/9999): loss=5775.723855635672, w0=-16.07471538555354, w1=-34.92225\n",
      "Gradient Descent(188/9999): loss=5775.723855635672, w0=-16.07471538555354, w1=-34.92225\n",
      "Gradient Descent(189/9999): loss=5775.723855635672, w0=-16.07471538555354, w1=-34.92225\n",
      "Gradient Descent(190/9999): loss=5775.723855635672, w0=-16.07471538555354, w1=-34.92225\n",
      "Gradient Descent(191/9999): loss=5775.723855635672, w0=-16.07471538555354, w1=-34.92225\n",
      "Gradient Descent(192/9999): loss=5775.723855635672, w0=-16.07471538555354, w1=-34.92225\n",
      "Gradient Descent(193/9999): loss=5775.723855635672, w0=-16.07471538555354, w1=-34.92225\n",
      "Gradient Descent(194/9999): loss=5775.723855635672, w0=-16.07471538555354, w1=-34.92225\n",
      "Gradient Descent(195/9999): loss=5775.723855635672, w0=-2.757215385553536, w1=-25.525049999999997\n",
      "Gradient Descent(196/9999): loss=17211.818530155688, w0=-2.757215385553536, w1=-25.525049999999997\n",
      "Gradient Descent(197/9999): loss=17211.818530155688, w0=-14.82398077110707, w1=-32.94414999999999\n",
      "Gradient Descent(198/9999): loss=5268.5665353383665, w0=-14.82398077110707, w1=-32.94414999999999\n",
      "Gradient Descent(199/9999): loss=5268.5665353383665, w0=-4.5674807711070695, w1=-26.685549999999992\n",
      "Gradient Descent(200/9999): loss=17073.663303135334, w0=-16.634246156660602, w1=-34.30855\n",
      "Gradient Descent(201/9999): loss=5731.117289049013, w0=-16.634246156660602, w1=-34.30855\n",
      "Gradient Descent(202/9999): loss=5731.117289049013, w0=-16.634246156660602, w1=-34.30855\n",
      "Gradient Descent(203/9999): loss=5731.117289049013, w0=-16.634246156660602, w1=-34.30855\n",
      "Gradient Descent(204/9999): loss=5731.117289049013, w0=-3.0269461566606033, w1=-29.131749999999997\n",
      "Gradient Descent(205/9999): loss=17200.30559469077, w0=-3.0269461566606033, w1=-29.131749999999997\n",
      "Gradient Descent(206/9999): loss=17200.30559469077, w0=-3.0269461566606033, w1=-29.131749999999997\n",
      "Gradient Descent(207/9999): loss=17200.30559469077, w0=-15.093711542214137, w1=-36.29474999999999\n",
      "Gradient Descent(208/9999): loss=8662.458648222146, w0=-15.093711542214137, w1=-36.29474999999999\n",
      "Gradient Descent(209/9999): loss=8662.458648222146, w0=-33.98511154221414, w1=-38.11805\n",
      "Gradient Descent(210/9999): loss=5802.4994844197445, w0=-33.98511154221414, w1=-38.11805\n",
      "Gradient Descent(211/9999): loss=5802.4994844197445, w0=-33.98511154221414, w1=-38.11805\n",
      "Gradient Descent(212/9999): loss=5802.4994844197445, w0=-22.01741154221414, w1=-32.21875\n",
      "Gradient Descent(213/9999): loss=5227.420952389893, w0=-22.01741154221414, w1=-32.21875\n",
      "Gradient Descent(214/9999): loss=5227.420952389893, w0=-31.246111542214145, w1=-33.72415\n",
      "Gradient Descent(215/9999): loss=5802.4994844197445, w0=-17.658011542214144, w1=-33.18695\n",
      "Gradient Descent(216/9999): loss=5683.379792049873, w0=-17.658011542214144, w1=-33.18695\n",
      "Gradient Descent(217/9999): loss=5683.379792049873, w0=-32.99701154221414, w1=-41.02875\n",
      "Gradient Descent(218/9999): loss=5802.4994844197445, w0=-32.99701154221414, w1=-41.02875\n",
      "Gradient Descent(219/9999): loss=5802.4994844197445, w0=-32.99701154221414, w1=-41.02875\n",
      "Gradient Descent(220/9999): loss=5802.4994844197445, w0=-32.99701154221414, w1=-41.02875\n",
      "Gradient Descent(221/9999): loss=5802.4994844197445, w0=-32.99701154221414, w1=-41.02875\n",
      "Gradient Descent(222/9999): loss=5802.4994844197445, w0=-32.99701154221414, w1=-41.02875\n",
      "Gradient Descent(223/9999): loss=5802.4994844197445, w0=-32.99701154221414, w1=-41.02875\n",
      "Gradient Descent(224/9999): loss=5802.4994844197445, w0=-32.99701154221414, w1=-41.02875\n",
      "Gradient Descent(225/9999): loss=5802.4994844197445, w0=-32.99701154221414, w1=-41.02875\n",
      "Gradient Descent(226/9999): loss=5802.4994844197445, w0=-32.99701154221414, w1=-41.02875\n",
      "Gradient Descent(227/9999): loss=5802.4994844197445, w0=-23.428911542214138, w1=-40.227250000000005\n",
      "Gradient Descent(228/9999): loss=5664.344713379693, w0=-23.428911542214138, w1=-40.227250000000005\n",
      "Gradient Descent(229/9999): loss=5664.344713379693, w0=-23.428911542214138, w1=-40.227250000000005\n",
      "Gradient Descent(230/9999): loss=5664.344713379693, w0=-23.428911542214138, w1=-40.227250000000005\n",
      "Gradient Descent(231/9999): loss=5664.344713379693, w0=-15.046511542214137, w1=-37.618950000000005\n",
      "Gradient Descent(232/9999): loss=10587.59025123162, w0=-22.435211542214137, w1=-39.11815000000001\n",
      "Gradient Descent(233/9999): loss=4597.735454710894, w0=-22.435211542214137, w1=-39.11815000000001\n",
      "Gradient Descent(234/9999): loss=4597.735454710894, w0=-22.435211542214137, w1=-39.11815000000001\n",
      "Gradient Descent(235/9999): loss=4597.735454710894, w0=-11.481111542214137, w1=-38.185950000000005\n",
      "Gradient Descent(236/9999): loss=14411.264907988701, w0=-11.481111542214137, w1=-38.185950000000005\n",
      "Gradient Descent(237/9999): loss=14411.264907988701, w0=-18.862711542214136, w1=-42.458850000000005\n",
      "Gradient Descent(238/9999): loss=6771.416569034962, w0=-18.862711542214136, w1=-42.458850000000005\n",
      "Gradient Descent(239/9999): loss=6771.416569034962, w0=-32.88701154221414, w1=-48.920550000000006\n",
      "Gradient Descent(240/9999): loss=5802.4994844197445, w0=-32.88701154221414, w1=-48.920550000000006\n",
      "Gradient Descent(241/9999): loss=5802.4994844197445, w0=-32.88701154221414, w1=-48.920550000000006\n",
      "Gradient Descent(242/9999): loss=5802.4994844197445, w0=-32.88701154221414, w1=-48.920550000000006\n",
      "Gradient Descent(243/9999): loss=5802.4994844197445, w0=-32.88701154221414, w1=-48.920550000000006\n",
      "Gradient Descent(244/9999): loss=5802.4994844197445, w0=-32.88701154221414, w1=-48.920550000000006\n",
      "Gradient Descent(245/9999): loss=5802.4994844197445, w0=-32.88701154221414, w1=-48.920550000000006\n",
      "Gradient Descent(246/9999): loss=5802.4994844197445, w0=-32.88701154221414, w1=-48.920550000000006\n",
      "Gradient Descent(247/9999): loss=5802.4994844197445, w0=-32.88701154221414, w1=-48.920550000000006\n",
      "Gradient Descent(248/9999): loss=5802.4994844197445, w0=-32.88701154221414, w1=-48.920550000000006\n",
      "Gradient Descent(249/9999): loss=5802.4994844197445, w0=-20.397411542214137, w1=-42.65415000000001\n",
      "Gradient Descent(250/9999): loss=6768.369928157232, w0=-20.397411542214137, w1=-42.65415000000001\n",
      "Gradient Descent(251/9999): loss=6768.369928157232, w0=-27.695311542214135, w1=-44.368750000000006\n",
      "Gradient Descent(252/9999): loss=5802.4994844197445, w0=-27.695311542214135, w1=-44.368750000000006\n",
      "Gradient Descent(253/9999): loss=5802.4994844197445, w0=-15.293811542214135, w1=-40.81645\n",
      "Gradient Descent(254/9999): loss=10969.819377381595, w0=-21.326611542214135, w1=-43.84675\n",
      "Gradient Descent(255/9999): loss=4691.854679837443, w0=-21.326611542214135, w1=-43.84675\n",
      "Gradient Descent(256/9999): loss=4691.854679837443, w0=-21.326611542214135, w1=-43.84675\n",
      "Gradient Descent(257/9999): loss=4691.854679837443, w0=-28.110611542214137, w1=-44.71685\n",
      "Gradient Descent(258/9999): loss=5802.4994844197445, w0=-28.110611542214137, w1=-44.71685\n",
      "Gradient Descent(259/9999): loss=5802.4994844197445, w0=-28.110611542214137, w1=-44.71685\n",
      "Gradient Descent(260/9999): loss=5802.4994844197445, w0=-28.110611542214137, w1=-44.71685\n",
      "Gradient Descent(261/9999): loss=5802.4994844197445, w0=-28.110611542214137, w1=-44.71685\n",
      "Gradient Descent(262/9999): loss=5802.4994844197445, w0=-28.110611542214137, w1=-44.71685\n",
      "Gradient Descent(263/9999): loss=5802.4994844197445, w0=-17.719411542214136, w1=-44.08685\n",
      "Gradient Descent(264/9999): loss=5371.29474941302, w0=-17.719411542214136, w1=-44.08685\n",
      "Gradient Descent(265/9999): loss=5371.29474941302, w0=-17.719411542214136, w1=-44.08685\n",
      "Gradient Descent(266/9999): loss=5371.29474941302, w0=-17.719411542214136, w1=-44.08685\n",
      "Gradient Descent(267/9999): loss=5371.29474941302, w0=-17.719411542214136, w1=-44.08685\n",
      "Gradient Descent(268/9999): loss=5371.29474941302, w0=-25.265311542214135, w1=-46.15385\n",
      "Gradient Descent(269/9999): loss=5802.4994844197445, w0=-25.265311542214135, w1=-46.15385\n",
      "Gradient Descent(270/9999): loss=5802.4994844197445, w0=-12.588911542214134, w1=-44.723549999999996\n",
      "Gradient Descent(271/9999): loss=10751.859944477, w0=-12.588911542214134, w1=-44.723549999999996\n",
      "Gradient Descent(272/9999): loss=10751.859944477, w0=-12.588911542214134, w1=-44.723549999999996\n",
      "Gradient Descent(273/9999): loss=10751.859944477, w0=-12.588911542214134, w1=-44.723549999999996\n",
      "Gradient Descent(274/9999): loss=10751.859944477, w0=-23.976011542214138, w1=-49.303549999999994\n",
      "Gradient Descent(275/9999): loss=4872.293900662125, w0=-8.642911542214136, w1=-48.001349999999995\n",
      "Gradient Descent(276/9999): loss=14173.042295103663, w0=-8.642911542214136, w1=-48.001349999999995\n",
      "Gradient Descent(277/9999): loss=14173.042295103663, w0=-20.70967692776767, w1=-53.84455\n",
      "Gradient Descent(278/9999): loss=4734.82526180724, w0=-20.70967692776767, w1=-53.84455\n",
      "Gradient Descent(279/9999): loss=4734.82526180724, w0=-20.70967692776767, w1=-53.84455\n",
      "Gradient Descent(280/9999): loss=4734.82526180724, w0=-20.70967692776767, w1=-53.84455\n",
      "Gradient Descent(281/9999): loss=4734.82526180724, w0=-20.70967692776767, w1=-53.84455\n",
      "Gradient Descent(282/9999): loss=4734.82526180724, w0=-20.70967692776767, w1=-53.84455\n",
      "Gradient Descent(283/9999): loss=4734.82526180724, w0=-20.70967692776767, w1=-53.84455\n",
      "Gradient Descent(284/9999): loss=4734.82526180724, w0=-20.70967692776767, w1=-53.84455\n",
      "Gradient Descent(285/9999): loss=4734.82526180724, w0=-20.70967692776767, w1=-53.84455\n",
      "Gradient Descent(286/9999): loss=4734.82526180724, w0=-20.70967692776767, w1=-53.84455\n",
      "Gradient Descent(287/9999): loss=4734.82526180724, w0=-20.70967692776767, w1=-53.84455\n",
      "Gradient Descent(288/9999): loss=4734.82526180724, w0=-20.70967692776767, w1=-53.84455\n",
      "Gradient Descent(289/9999): loss=4734.82526180724, w0=-20.70967692776767, w1=-53.84455\n",
      "Gradient Descent(290/9999): loss=4734.82526180724, w0=-20.70967692776767, w1=-53.84455\n",
      "Gradient Descent(291/9999): loss=4734.82526180724, w0=-20.70967692776767, w1=-53.84455\n",
      "Gradient Descent(292/9999): loss=4734.82526180724, w0=-20.70967692776767, w1=-53.84455\n",
      "Gradient Descent(293/9999): loss=4734.82526180724, w0=-7.832276927767669, w1=-53.00815\n",
      "Gradient Descent(294/9999): loss=9728.386282165127, w0=-7.832276927767669, w1=-53.00815\n",
      "Gradient Descent(295/9999): loss=9728.386282165127, w0=-18.124076927767668, w1=-53.49675\n",
      "Gradient Descent(296/9999): loss=5454.452125777243, w0=-18.124076927767668, w1=-53.49675\n",
      "Gradient Descent(297/9999): loss=5454.452125777243, w0=-18.124076927767668, w1=-53.49675\n",
      "Gradient Descent(298/9999): loss=5454.452125777243, w0=-18.124076927767668, w1=-53.49675\n",
      "Gradient Descent(299/9999): loss=5454.452125777243, w0=-18.124076927767668, w1=-53.49675\n",
      "Gradient Descent(300/9999): loss=5454.452125777243, w0=-18.124076927767668, w1=-53.49675\n",
      "Gradient Descent(301/9999): loss=5454.452125777243, w0=-6.341776927767668, w1=-50.38325\n",
      "Gradient Descent(302/9999): loss=11970.555201479972, w0=-6.341776927767668, w1=-50.38325\n",
      "Gradient Descent(303/9999): loss=11970.555201479972, w0=-6.341776927767668, w1=-50.38325\n",
      "Gradient Descent(304/9999): loss=11970.555201479972, w0=-14.103776927767669, w1=-57.29985\n",
      "Gradient Descent(305/9999): loss=4439.274482451348, w0=-14.103776927767669, w1=-57.29985\n",
      "Gradient Descent(306/9999): loss=4439.274482451348, w0=-14.103776927767669, w1=-57.29985\n",
      "Gradient Descent(307/9999): loss=4439.274482451348, w0=-14.103776927767669, w1=-57.29985\n",
      "Gradient Descent(308/9999): loss=4439.274482451348, w0=-14.103776927767669, w1=-57.29985\n",
      "Gradient Descent(309/9999): loss=4439.274482451348, w0=-14.103776927767669, w1=-57.29985\n",
      "Gradient Descent(310/9999): loss=4439.274482451348, w0=-14.103776927767669, w1=-57.29985\n",
      "Gradient Descent(311/9999): loss=4439.274482451348, w0=-4.4959769277676696, w1=-54.67425\n",
      "Gradient Descent(312/9999): loss=12911.019228204343, w0=-4.4959769277676696, w1=-54.67425\n",
      "Gradient Descent(313/9999): loss=12911.019228204343, w0=-4.4959769277676696, w1=-54.67425\n",
      "Gradient Descent(314/9999): loss=12911.019228204343, w0=-4.4959769277676696, w1=-54.67425\n",
      "Gradient Descent(315/9999): loss=12911.019228204343, w0=-4.4959769277676696, w1=-54.67425\n",
      "Gradient Descent(316/9999): loss=12911.019228204343, w0=-16.92607692776767, w1=-61.22815\n",
      "Gradient Descent(317/9999): loss=4651.363763495912, w0=-16.92607692776767, w1=-61.22815\n",
      "Gradient Descent(318/9999): loss=4651.363763495912, w0=-16.92607692776767, w1=-61.22815\n",
      "Gradient Descent(319/9999): loss=4651.363763495912, w0=-16.92607692776767, w1=-61.22815\n",
      "Gradient Descent(320/9999): loss=4651.363763495912, w0=-16.92607692776767, w1=-61.22815\n",
      "Gradient Descent(321/9999): loss=4651.363763495912, w0=-16.92607692776767, w1=-61.22815\n",
      "Gradient Descent(322/9999): loss=4651.363763495912, w0=-16.92607692776767, w1=-61.22815\n",
      "Gradient Descent(323/9999): loss=4651.363763495912, w0=-16.92607692776767, w1=-61.22815\n",
      "Gradient Descent(324/9999): loss=4651.363763495912, w0=-16.92607692776767, w1=-61.22815\n",
      "Gradient Descent(325/9999): loss=4651.363763495912, w0=-16.92607692776767, w1=-61.22815\n",
      "Gradient Descent(326/9999): loss=4651.363763495912, w0=-16.92607692776767, w1=-61.22815\n",
      "Gradient Descent(327/9999): loss=4651.363763495912, w0=-16.92607692776767, w1=-61.22815\n",
      "Gradient Descent(328/9999): loss=4651.363763495912, w0=-16.92607692776767, w1=-61.22815\n",
      "Gradient Descent(329/9999): loss=4651.363763495912, w0=-16.92607692776767, w1=-61.22815\n",
      "Gradient Descent(330/9999): loss=4651.363763495912, w0=-4.909376927767671, w1=-58.70905\n",
      "Gradient Descent(331/9999): loss=9838.801769413687, w0=-4.909376927767671, w1=-58.70905\n",
      "Gradient Descent(332/9999): loss=9838.801769413687, w0=-18.49197692776767, w1=-64.88905\n",
      "Gradient Descent(333/9999): loss=5669.5760067556275, w0=-5.88817692776767, w1=-61.720749999999995\n",
      "Gradient Descent(334/9999): loss=5813.085382162128, w0=-5.88817692776767, w1=-61.720749999999995\n",
      "Gradient Descent(335/9999): loss=5813.085382162128, w0=-5.88817692776767, w1=-61.720749999999995\n",
      "Gradient Descent(336/9999): loss=5813.085382162128, w0=-5.88817692776767, w1=-61.720749999999995\n",
      "Gradient Descent(337/9999): loss=5813.085382162128, w0=-5.88817692776767, w1=-61.720749999999995\n",
      "Gradient Descent(338/9999): loss=5813.085382162128, w0=-27.849376927767672, w1=-64.31985\n",
      "Gradient Descent(339/9999): loss=5802.4994844197445, w0=-27.849376927767672, w1=-64.31985\n",
      "Gradient Descent(340/9999): loss=5802.4994844197445, w0=-14.209476927767671, w1=-61.768350000000005\n",
      "Gradient Descent(341/9999): loss=4593.143313264567, w0=-3.7454769277676707, w1=-54.62425\n",
      "Gradient Descent(342/9999): loss=13012.757226142203, w0=-15.221735961428493, w1=-60.187019884317515\n",
      "Gradient Descent(343/9999): loss=4766.834018857053, w0=-4.576935961428493, w1=-56.078919884317514\n",
      "Gradient Descent(344/9999): loss=12957.937979563685, w0=-16.643701346982027, w1=-65.5958198843175\n",
      "Gradient Descent(345/9999): loss=4459.839044425344, w0=-16.643701346982027, w1=-65.5958198843175\n",
      "Gradient Descent(346/9999): loss=4459.839044425344, w0=-16.643701346982027, w1=-65.5958198843175\n",
      "Gradient Descent(347/9999): loss=4459.839044425344, w0=-16.643701346982027, w1=-65.5958198843175\n",
      "Gradient Descent(348/9999): loss=4459.839044425344, w0=-16.643701346982027, w1=-65.5958198843175\n",
      "Gradient Descent(349/9999): loss=4459.839044425344, w0=-16.643701346982027, w1=-65.5958198843175\n",
      "Gradient Descent(350/9999): loss=4459.839044425344, w0=-16.643701346982027, w1=-65.5958198843175\n",
      "Gradient Descent(351/9999): loss=4459.839044425344, w0=-27.079501346982028, w1=-66.75781988431751\n",
      "Gradient Descent(352/9999): loss=5802.4994844197445, w0=-27.079501346982028, w1=-66.75781988431751\n",
      "Gradient Descent(353/9999): loss=5802.4994844197445, w0=-18.65470134698203, w1=-61.331919884317514\n",
      "Gradient Descent(354/9999): loss=4480.477197795161, w0=-18.65470134698203, w1=-61.331919884317514\n",
      "Gradient Descent(355/9999): loss=4480.477197795161, w0=-18.65470134698203, w1=-61.331919884317514\n",
      "Gradient Descent(356/9999): loss=4480.477197795161, w0=-6.040001346982029, w1=-58.34981988431751\n",
      "Gradient Descent(357/9999): loss=11472.620505270872, w0=-6.040001346982029, w1=-58.34981988431751\n",
      "Gradient Descent(358/9999): loss=11472.620505270872, w0=-6.040001346982029, w1=-58.34981988431751\n",
      "Gradient Descent(359/9999): loss=11472.620505270872, w0=-17.99100134698203, w1=-67.8916198843175\n",
      "Gradient Descent(360/9999): loss=5446.1052528971995, w0=-17.99100134698203, w1=-67.8916198843175\n",
      "Gradient Descent(361/9999): loss=5446.1052528971995, w0=-17.99100134698203, w1=-67.8916198843175\n",
      "Gradient Descent(362/9999): loss=5446.1052528971995, w0=-17.99100134698203, w1=-67.8916198843175\n",
      "Gradient Descent(363/9999): loss=5446.1052528971995, w0=-17.99100134698203, w1=-67.8916198843175\n",
      "Gradient Descent(364/9999): loss=5446.1052528971995, w0=-17.99100134698203, w1=-67.8916198843175\n",
      "Gradient Descent(365/9999): loss=5446.1052528971995, w0=-17.99100134698203, w1=-67.8916198843175\n",
      "Gradient Descent(366/9999): loss=5446.1052528971995, w0=-2.2463013469820297, w1=-64.1248198843175\n",
      "Gradient Descent(367/9999): loss=11507.869226932242, w0=-10.192201346982031, w1=-68.2642198843175\n",
      "Gradient Descent(368/9999): loss=4663.091786518746, w0=-10.192201346982031, w1=-68.2642198843175\n",
      "Gradient Descent(369/9999): loss=4663.091786518746, w0=-10.192201346982031, w1=-68.2642198843175\n",
      "Gradient Descent(370/9999): loss=4663.091786518746, w0=1.8745640385715028, w1=-58.3079198843175\n",
      "Gradient Descent(371/9999): loss=15498.104134070458, w0=-10.192201346982031, w1=-64.5415198843175\n",
      "Gradient Descent(372/9999): loss=5686.079039402064, w0=-10.192201346982031, w1=-64.5415198843175\n",
      "Gradient Descent(373/9999): loss=5686.079039402064, w0=-10.192201346982031, w1=-64.5415198843175\n",
      "Gradient Descent(374/9999): loss=5686.079039402064, w0=-10.192201346982031, w1=-64.5415198843175\n",
      "Gradient Descent(375/9999): loss=5686.079039402064, w0=-10.192201346982031, w1=-64.5415198843175\n",
      "Gradient Descent(376/9999): loss=5686.079039402064, w0=-10.192201346982031, w1=-64.5415198843175\n",
      "Gradient Descent(377/9999): loss=5686.079039402064, w0=-10.192201346982031, w1=-64.5415198843175\n",
      "Gradient Descent(378/9999): loss=5686.079039402064, w0=-10.192201346982031, w1=-64.5415198843175\n",
      "Gradient Descent(379/9999): loss=5686.079039402064, w0=-19.89510134698203, w1=-70.03921988431749\n",
      "Gradient Descent(380/9999): loss=5802.4994844197445, w0=-19.89510134698203, w1=-70.03921988431749\n",
      "Gradient Descent(381/9999): loss=5802.4994844197445, w0=-19.89510134698203, w1=-70.03921988431749\n",
      "Gradient Descent(382/9999): loss=5802.4994844197445, w0=-19.89510134698203, w1=-70.03921988431749\n",
      "Gradient Descent(383/9999): loss=5802.4994844197445, w0=-19.89510134698203, w1=-70.03921988431749\n",
      "Gradient Descent(384/9999): loss=5802.4994844197445, w0=-6.41000134698203, w1=-66.65821988431749\n",
      "Gradient Descent(385/9999): loss=5048.747299769753, w0=5.656764038571504, w1=-57.15841988431749\n",
      "Gradient Descent(386/9999): loss=15123.712925360658, w0=5.656764038571504, w1=-57.15841988431749\n",
      "Gradient Descent(387/9999): loss=15123.712925360658, w0=-6.41000134698203, w1=-66.27381988431749\n",
      "Gradient Descent(388/9999): loss=4765.481588818377, w0=0.1387986530179699, w1=-63.08071988431749\n",
      "Gradient Descent(389/9999): loss=14567.397034022237, w0=-6.05770134698203, w1=-70.19381988431749\n",
      "Gradient Descent(390/9999): loss=5231.542665389754, w0=-6.05770134698203, w1=-70.19381988431749\n",
      "Gradient Descent(391/9999): loss=5231.542665389754, w0=4.530998653017971, w1=-65.06601988431748\n",
      "Gradient Descent(392/9999): loss=15577.40441197055, w0=4.530998653017971, w1=-65.06601988431748\n",
      "Gradient Descent(393/9999): loss=15577.40441197055, w0=-7.7136013469820295, w1=-70.28781988431749\n",
      "Gradient Descent(394/9999): loss=5225.579995639691, w0=-18.93720134698203, w1=-74.68201988431748\n",
      "Gradient Descent(395/9999): loss=5675.894379217236, w0=-18.93720134698203, w1=-74.68201988431748\n",
      "Gradient Descent(396/9999): loss=5675.894379217236, w0=-18.93720134698203, w1=-74.68201988431748\n",
      "Gradient Descent(397/9999): loss=5675.894379217236, w0=-6.7457013469820275, w1=-71.45981988431748\n",
      "Gradient Descent(398/9999): loss=5564.162985442243, w0=-6.7457013469820275, w1=-71.45981988431748\n",
      "Gradient Descent(399/9999): loss=5564.162985442243, w0=2.643198653017972, w1=-65.29071988431748\n",
      "Gradient Descent(400/9999): loss=15315.138393755984, w0=-11.982901346982029, w1=-67.86851988431748\n",
      "Gradient Descent(401/9999): loss=4811.4885218305935, w0=0.5431986530179724, w1=-61.71811988431748\n",
      "Gradient Descent(402/9999): loss=15675.588021538933, w0=-8.059701346982028, w1=-70.62011988431748\n",
      "Gradient Descent(403/9999): loss=4380.032007677696, w0=-16.85200134698203, w1=-73.33711988431747\n",
      "Gradient Descent(404/9999): loss=5802.4994844197445, w0=-16.85200134698203, w1=-73.33711988431747\n",
      "Gradient Descent(405/9999): loss=5802.4994844197445, w0=-6.8131013469820285, w1=-70.84171988431747\n",
      "Gradient Descent(406/9999): loss=4343.114064192163, w0=-6.8131013469820285, w1=-70.84171988431747\n",
      "Gradient Descent(407/9999): loss=4343.114064192163, w0=-6.8131013469820285, w1=-70.84171988431747\n",
      "Gradient Descent(408/9999): loss=4343.114064192163, w0=-6.8131013469820285, w1=-70.84171988431747\n",
      "Gradient Descent(409/9999): loss=4343.114064192163, w0=-6.8131013469820285, w1=-70.84171988431747\n",
      "Gradient Descent(410/9999): loss=4343.114064192163, w0=-6.8131013469820285, w1=-70.84171988431747\n",
      "Gradient Descent(411/9999): loss=4343.114064192163, w0=-6.8131013469820285, w1=-70.84171988431747\n",
      "Gradient Descent(412/9999): loss=4343.114064192163, w0=-17.810001346982027, w1=-72.77061988431747\n",
      "Gradient Descent(413/9999): loss=5802.4994844197445, w0=-17.810001346982027, w1=-72.77061988431747\n",
      "Gradient Descent(414/9999): loss=5802.4994844197445, w0=-17.810001346982027, w1=-72.77061988431747\n",
      "Gradient Descent(415/9999): loss=5802.4994844197445, w0=-17.810001346982027, w1=-72.77061988431747\n",
      "Gradient Descent(416/9999): loss=5802.4994844197445, w0=-17.810001346982027, w1=-72.77061988431747\n",
      "Gradient Descent(417/9999): loss=5802.4994844197445, w0=-17.810001346982027, w1=-72.77061988431747\n",
      "Gradient Descent(418/9999): loss=5802.4994844197445, w0=-5.743235961428493, w1=-62.81431988431747\n",
      "Gradient Descent(419/9999): loss=4510.554713386965, w0=-5.743235961428493, w1=-62.81431988431747\n",
      "Gradient Descent(420/9999): loss=4510.554713386965, w0=-5.743235961428493, w1=-62.81431988431747\n",
      "Gradient Descent(421/9999): loss=4510.554713386965, w0=-5.743235961428493, w1=-62.81431988431747\n",
      "Gradient Descent(422/9999): loss=4510.554713386965, w0=-5.743235961428493, w1=-62.81431988431747\n",
      "Gradient Descent(423/9999): loss=4510.554713386965, w0=-5.743235961428493, w1=-62.81431988431747\n",
      "Gradient Descent(424/9999): loss=4510.554713386965, w0=-5.743235961428493, w1=-62.81431988431747\n",
      "Gradient Descent(425/9999): loss=4510.554713386965, w0=-5.743235961428493, w1=-62.81431988431747\n",
      "Gradient Descent(426/9999): loss=4510.554713386965, w0=-5.743235961428493, w1=-62.81431988431747\n",
      "Gradient Descent(427/9999): loss=4510.554713386965, w0=-5.743235961428493, w1=-62.81431988431747\n",
      "Gradient Descent(428/9999): loss=4510.554713386965, w0=-5.743235961428493, w1=-62.81431988431747\n",
      "Gradient Descent(429/9999): loss=4510.554713386965, w0=-14.054635961428492, w1=-64.81871988431747\n",
      "Gradient Descent(430/9999): loss=5558.924346680665, w0=-14.054635961428492, w1=-64.81871988431747\n",
      "Gradient Descent(431/9999): loss=5558.924346680665, w0=-14.054635961428492, w1=-64.81871988431747\n",
      "Gradient Descent(432/9999): loss=5558.924346680665, w0=-1.57513596142849, w1=-62.13221988431747\n",
      "Gradient Descent(433/9999): loss=6023.102627115718, w0=-9.93233596142849, w1=-62.84401988431747\n",
      "Gradient Descent(434/9999): loss=4743.321334418771, w0=6.277964038571509, w1=-60.15691988431747\n",
      "Gradient Descent(435/9999): loss=15390.322490875762, w0=6.277964038571509, w1=-60.15691988431747\n",
      "Gradient Descent(436/9999): loss=15390.322490875762, w0=6.277964038571509, w1=-60.15691988431747\n",
      "Gradient Descent(437/9999): loss=15390.322490875762, w0=-5.903435961428491, w1=-68.06171988431747\n",
      "Gradient Descent(438/9999): loss=4717.898763724275, w0=-5.903435961428491, w1=-68.06171988431747\n",
      "Gradient Descent(439/9999): loss=4717.898763724275, w0=3.4222640385715106, w1=-65.07191988431747\n",
      "Gradient Descent(440/9999): loss=9061.877280822635, w0=3.4222640385715106, w1=-65.07191988431747\n",
      "Gradient Descent(441/9999): loss=9061.877280822635, w0=3.4222640385715106, w1=-65.07191988431747\n",
      "Gradient Descent(442/9999): loss=9061.877280822635, w0=3.4222640385715106, w1=-65.07191988431747\n",
      "Gradient Descent(443/9999): loss=9061.877280822635, w0=3.4222640385715106, w1=-65.07191988431747\n",
      "Gradient Descent(444/9999): loss=9061.877280822635, w0=14.64706403857151, w1=-57.46681988431747\n",
      "Gradient Descent(445/9999): loss=17103.143062362633, w0=14.64706403857151, w1=-57.46681988431747\n",
      "Gradient Descent(446/9999): loss=17103.143062362633, w0=14.64706403857151, w1=-57.46681988431747\n",
      "Gradient Descent(447/9999): loss=17103.143062362633, w0=-3.4281359614284916, w1=-58.23251988431747\n",
      "Gradient Descent(448/9999): loss=6216.8166620147185, w0=-3.4281359614284916, w1=-58.23251988431747\n",
      "Gradient Descent(449/9999): loss=6216.8166620147185, w0=-3.4281359614284916, w1=-58.23251988431747\n",
      "Gradient Descent(450/9999): loss=6216.8166620147185, w0=-3.4281359614284916, w1=-58.23251988431747\n",
      "Gradient Descent(451/9999): loss=6216.8166620147185, w0=-12.055635961428493, w1=-60.121119884317466\n",
      "Gradient Descent(452/9999): loss=5226.8527051458, w0=-12.055635961428493, w1=-60.121119884317466\n",
      "Gradient Descent(453/9999): loss=5226.8527051458, w0=-12.055635961428493, w1=-60.121119884317466\n",
      "Gradient Descent(454/9999): loss=5226.8527051458, w0=-12.055635961428493, w1=-60.121119884317466\n",
      "Gradient Descent(455/9999): loss=5226.8527051458, w0=-12.055635961428493, w1=-60.121119884317466\n",
      "Gradient Descent(456/9999): loss=5226.8527051458, w0=-12.055635961428493, w1=-60.121119884317466\n",
      "Gradient Descent(457/9999): loss=5226.8527051458, w0=-12.055635961428493, w1=-60.121119884317466\n",
      "Gradient Descent(458/9999): loss=5226.8527051458, w0=-2.1595359614284924, w1=-54.095819884317464\n",
      "Gradient Descent(459/9999): loss=6179.972636305602, w0=-2.1595359614284924, w1=-54.095819884317464\n",
      "Gradient Descent(460/9999): loss=6179.972636305602, w0=-2.1595359614284924, w1=-54.095819884317464\n",
      "Gradient Descent(461/9999): loss=6179.972636305602, w0=8.103564038571509, w1=-47.44721988431746\n",
      "Gradient Descent(462/9999): loss=16015.64132937153, w0=8.103564038571509, w1=-47.44721988431746\n",
      "Gradient Descent(463/9999): loss=16015.64132937153, w0=8.103564038571509, w1=-47.44721988431746\n",
      "Gradient Descent(464/9999): loss=16015.64132937153, w0=1.015964038571508, w1=-51.328719884317465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(465/9999): loss=6717.092631423491, w0=1.015964038571508, w1=-51.328719884317465\n",
      "Gradient Descent(466/9999): loss=6717.092631423491, w0=-21.662235961428497, w1=-60.88271988431747\n",
      "Gradient Descent(467/9999): loss=5802.4994844197445, w0=-21.662235961428497, w1=-60.88271988431747\n",
      "Gradient Descent(468/9999): loss=5802.4994844197445, w0=-21.662235961428497, w1=-60.88271988431747\n",
      "Gradient Descent(469/9999): loss=5802.4994844197445, w0=-21.662235961428497, w1=-60.88271988431747\n",
      "Gradient Descent(470/9999): loss=5802.4994844197445, w0=-21.662235961428497, w1=-60.88271988431747\n",
      "Gradient Descent(471/9999): loss=5802.4994844197445, w0=-21.662235961428497, w1=-60.88271988431747\n",
      "Gradient Descent(472/9999): loss=5802.4994844197445, w0=-21.662235961428497, w1=-60.88271988431747\n",
      "Gradient Descent(473/9999): loss=5802.4994844197445, w0=-21.662235961428497, w1=-60.88271988431747\n",
      "Gradient Descent(474/9999): loss=5802.4994844197445, w0=-21.662235961428497, w1=-60.88271988431747\n",
      "Gradient Descent(475/9999): loss=5802.4994844197445, w0=-21.662235961428497, w1=-60.88271988431747\n",
      "Gradient Descent(476/9999): loss=5802.4994844197445, w0=-21.662235961428497, w1=-60.88271988431747\n",
      "Gradient Descent(477/9999): loss=5802.4994844197445, w0=-21.662235961428497, w1=-60.88271988431747\n",
      "Gradient Descent(478/9999): loss=5802.4994844197445, w0=-21.662235961428497, w1=-60.88271988431747\n",
      "Gradient Descent(479/9999): loss=5802.4994844197445, w0=-8.858035961428495, w1=-60.415219884317466\n",
      "Gradient Descent(480/9999): loss=4911.553859237946, w0=-8.858035961428495, w1=-60.415219884317466\n",
      "Gradient Descent(481/9999): loss=4911.553859237946, w0=3.3714640385715064, w1=-58.23651988431747\n",
      "Gradient Descent(482/9999): loss=11585.533873650864, w0=-10.143735961428495, w1=-66.69321988431747\n",
      "Gradient Descent(483/9999): loss=4516.6347437917775, w0=-10.143735961428495, w1=-66.69321988431747\n",
      "Gradient Descent(484/9999): loss=4516.6347437917775, w0=-10.143735961428495, w1=-66.69321988431747\n",
      "Gradient Descent(485/9999): loss=4516.6347437917775, w0=-10.143735961428495, w1=-66.69321988431747\n",
      "Gradient Descent(486/9999): loss=4516.6347437917775, w0=-10.143735961428495, w1=-66.69321988431747\n",
      "Gradient Descent(487/9999): loss=4516.6347437917775, w0=-10.143735961428495, w1=-66.69321988431747\n",
      "Gradient Descent(488/9999): loss=4516.6347437917775, w0=-23.057235961428496, w1=-70.43961988431747\n",
      "Gradient Descent(489/9999): loss=5802.4994844197445, w0=-23.057235961428496, w1=-70.43961988431747\n",
      "Gradient Descent(490/9999): loss=5802.4994844197445, w0=-23.057235961428496, w1=-70.43961988431747\n",
      "Gradient Descent(491/9999): loss=5802.4994844197445, w0=-23.057235961428496, w1=-70.43961988431747\n",
      "Gradient Descent(492/9999): loss=5802.4994844197445, w0=-23.057235961428496, w1=-70.43961988431747\n",
      "Gradient Descent(493/9999): loss=5802.4994844197445, w0=-23.057235961428496, w1=-70.43961988431747\n",
      "Gradient Descent(494/9999): loss=5802.4994844197445, w0=-23.057235961428496, w1=-70.43961988431747\n",
      "Gradient Descent(495/9999): loss=5802.4994844197445, w0=-23.057235961428496, w1=-70.43961988431747\n",
      "Gradient Descent(496/9999): loss=5802.4994844197445, w0=-7.248035961428494, w1=-66.54671988431747\n",
      "Gradient Descent(497/9999): loss=4683.746614893396, w0=-7.248035961428494, w1=-66.54671988431747\n",
      "Gradient Descent(498/9999): loss=4683.746614893396, w0=6.679464038571508, w1=-58.453519884317465\n",
      "Gradient Descent(499/9999): loss=16460.42595505109, w0=6.679464038571508, w1=-58.453519884317465\n",
      "Gradient Descent(500/9999): loss=16460.42595505109, w0=-18.900935961428495, w1=-62.99961988431747\n",
      "Gradient Descent(501/9999): loss=4985.081088194067, w0=-18.900935961428495, w1=-62.99961988431747\n",
      "Gradient Descent(502/9999): loss=4985.081088194067, w0=-18.900935961428495, w1=-62.99961988431747\n",
      "Gradient Descent(503/9999): loss=4985.081088194067, w0=-8.546935961428494, w1=-58.49841988431747\n",
      "Gradient Descent(504/9999): loss=9284.067881326398, w0=-8.546935961428494, w1=-58.49841988431747\n",
      "Gradient Descent(505/9999): loss=9284.067881326398, w0=-8.546935961428494, w1=-58.49841988431747\n",
      "Gradient Descent(506/9999): loss=9284.067881326398, w0=-8.546935961428494, w1=-58.49841988431747\n",
      "Gradient Descent(507/9999): loss=9284.067881326398, w0=3.5198294241250405, w1=-45.84651988431747\n",
      "Gradient Descent(508/9999): loss=17223.33146562061, w0=3.5198294241250405, w1=-45.84651988431747\n",
      "Gradient Descent(509/9999): loss=17223.33146562061, w0=-9.16997057587496, w1=-53.09051988431747\n",
      "Gradient Descent(510/9999): loss=7548.313675875304, w0=-9.16997057587496, w1=-53.09051988431747\n",
      "Gradient Descent(511/9999): loss=7548.313675875304, w0=-9.16997057587496, w1=-53.09051988431747\n",
      "Gradient Descent(512/9999): loss=7548.313675875304, w0=-9.16997057587496, w1=-53.09051988431747\n",
      "Gradient Descent(513/9999): loss=7548.313675875304, w0=-9.16997057587496, w1=-53.09051988431747\n",
      "Gradient Descent(514/9999): loss=7548.313675875304, w0=-9.16997057587496, w1=-53.09051988431747\n",
      "Gradient Descent(515/9999): loss=7548.313675875304, w0=-21.236735961428494, w1=-58.18401988431747\n",
      "Gradient Descent(516/9999): loss=5669.533770538183, w0=-11.585535961428493, w1=-57.67171988431747\n",
      "Gradient Descent(517/9999): loss=4714.473977048947, w0=-11.585535961428493, w1=-57.67171988431747\n",
      "Gradient Descent(518/9999): loss=4714.473977048947, w0=-11.585535961428493, w1=-57.67171988431747\n",
      "Gradient Descent(519/9999): loss=4714.473977048947, w0=-4.4144359614284925, w1=-54.32421988431747\n",
      "Gradient Descent(520/9999): loss=13774.14530474936, w0=-4.4144359614284925, w1=-54.32421988431747\n",
      "Gradient Descent(521/9999): loss=13774.14530474936, w0=-4.4144359614284925, w1=-54.32421988431747\n",
      "Gradient Descent(522/9999): loss=13774.14530474936, w0=-4.4144359614284925, w1=-54.32421988431747\n",
      "Gradient Descent(523/9999): loss=13774.14530474936, w0=-19.255235961428493, w1=-60.20001988431747\n",
      "Gradient Descent(524/9999): loss=4686.522667496632, w0=-7.188470575874959, w1=-53.08571988431747\n",
      "Gradient Descent(525/9999): loss=8434.067938560958, w0=-18.18537057587496, w1=-55.01461988431747\n",
      "Gradient Descent(526/9999): loss=4927.516484991245, w0=-18.18537057587496, w1=-55.01461988431747\n",
      "Gradient Descent(527/9999): loss=4927.516484991245, w0=-18.18537057587496, w1=-55.01461988431747\n",
      "Gradient Descent(528/9999): loss=4927.516484991245, w0=-18.18537057587496, w1=-55.01461988431747\n",
      "Gradient Descent(529/9999): loss=4927.516484991245, w0=-18.18537057587496, w1=-55.01461988431747\n",
      "Gradient Descent(530/9999): loss=4927.516484991245, w0=-18.18537057587496, w1=-55.01461988431747\n",
      "Gradient Descent(531/9999): loss=4927.516484991245, w0=-18.18537057587496, w1=-55.01461988431747\n",
      "Gradient Descent(532/9999): loss=4927.516484991245, w0=-1.695870575874956, w1=-48.27811988431747\n",
      "Gradient Descent(533/9999): loss=16247.460442986994, w0=-10.585870575874957, w1=-53.69991988431747\n",
      "Gradient Descent(534/9999): loss=4987.684780066993, w0=-10.585870575874957, w1=-53.69991988431747\n",
      "Gradient Descent(535/9999): loss=4987.684780066993, w0=-20.918170575874957, w1=-56.25751988431747\n",
      "Gradient Descent(536/9999): loss=5629.809100634886, w0=-20.918170575874957, w1=-56.25751988431747\n",
      "Gradient Descent(537/9999): loss=5629.809100634886, w0=-20.918170575874957, w1=-56.25751988431747\n",
      "Gradient Descent(538/9999): loss=5629.809100634886, w0=-6.931270575874956, w1=-47.784419884317465\n",
      "Gradient Descent(539/9999): loss=9728.643255192048, w0=-6.931270575874956, w1=-47.784419884317465\n",
      "Gradient Descent(540/9999): loss=9728.643255192048, w0=-6.931270575874956, w1=-47.784419884317465\n",
      "Gradient Descent(541/9999): loss=9728.643255192048, w0=-18.998035961428492, w1=-56.486019884317464\n",
      "Gradient Descent(542/9999): loss=5641.347408683017, w0=-18.998035961428492, w1=-56.486019884317464\n",
      "Gradient Descent(543/9999): loss=5641.347408683017, w0=-18.998035961428492, w1=-56.486019884317464\n",
      "Gradient Descent(544/9999): loss=5641.347408683017, w0=-18.998035961428492, w1=-56.486019884317464\n",
      "Gradient Descent(545/9999): loss=5641.347408683017, w0=-18.998035961428492, w1=-56.486019884317464\n",
      "Gradient Descent(546/9999): loss=5641.347408683017, w0=-18.998035961428492, w1=-56.486019884317464\n",
      "Gradient Descent(547/9999): loss=5641.347408683017, w0=-18.998035961428492, w1=-56.486019884317464\n",
      "Gradient Descent(548/9999): loss=5641.347408683017, w0=-18.998035961428492, w1=-56.486019884317464\n",
      "Gradient Descent(549/9999): loss=5641.347408683017, w0=-18.998035961428492, w1=-56.486019884317464\n",
      "Gradient Descent(550/9999): loss=5641.347408683017, w0=-18.998035961428492, w1=-56.486019884317464\n",
      "Gradient Descent(551/9999): loss=5641.347408683017, w0=-18.998035961428492, w1=-56.486019884317464\n",
      "Gradient Descent(552/9999): loss=5641.347408683017, w0=-5.952835961428491, w1=-51.93221988431746\n",
      "Gradient Descent(553/9999): loss=5975.8717606227365, w0=-18.019601346982025, w1=-58.82921988431746\n",
      "Gradient Descent(554/9999): loss=5802.4994844197445, w0=-18.019601346982025, w1=-58.82921988431746\n",
      "Gradient Descent(555/9999): loss=5802.4994844197445, w0=-18.019601346982025, w1=-58.82921988431746\n",
      "Gradient Descent(556/9999): loss=5802.4994844197445, w0=-18.019601346982025, w1=-58.82921988431746\n",
      "Gradient Descent(557/9999): loss=5802.4994844197445, w0=-18.019601346982025, w1=-58.82921988431746\n",
      "Gradient Descent(558/9999): loss=5802.4994844197445, w0=-18.019601346982025, w1=-58.82921988431746\n",
      "Gradient Descent(559/9999): loss=5802.4994844197445, w0=-18.019601346982025, w1=-58.82921988431746\n",
      "Gradient Descent(560/9999): loss=5802.4994844197445, w0=-18.019601346982025, w1=-58.82921988431746\n",
      "Gradient Descent(561/9999): loss=5802.4994844197445, w0=-18.019601346982025, w1=-58.82921988431746\n",
      "Gradient Descent(562/9999): loss=5802.4994844197445, w0=-18.019601346982025, w1=-58.82921988431746\n",
      "Gradient Descent(563/9999): loss=5802.4994844197445, w0=-18.019601346982025, w1=-58.82921988431746\n",
      "Gradient Descent(564/9999): loss=5802.4994844197445, w0=-6.3438013469820245, w1=-58.20271988431746\n",
      "Gradient Descent(565/9999): loss=4772.652566574751, w0=3.0429986530179747, w1=-54.93911988431746\n",
      "Gradient Descent(566/9999): loss=8642.879115215608, w0=-10.100401346982025, w1=-62.298319884317465\n",
      "Gradient Descent(567/9999): loss=4869.951712448026, w0=-10.100401346982025, w1=-62.298319884317465\n",
      "Gradient Descent(568/9999): loss=4869.951712448026, w0=-10.100401346982025, w1=-62.298319884317465\n",
      "Gradient Descent(569/9999): loss=4869.951712448026, w0=-10.100401346982025, w1=-62.298319884317465\n",
      "Gradient Descent(570/9999): loss=4869.951712448026, w0=-10.100401346982025, w1=-62.298319884317465\n",
      "Gradient Descent(571/9999): loss=4869.951712448026, w0=0.0829986530179756, w1=-58.840319884317466\n",
      "Gradient Descent(572/9999): loss=11555.27801912887, w0=-6.829201346982025, w1=-64.23031988431747\n",
      "Gradient Descent(573/9999): loss=4939.151810623622, w0=-6.829201346982025, w1=-64.23031988431747\n",
      "Gradient Descent(574/9999): loss=4939.151810623622, w0=-14.278401346982026, w1=-67.05791988431747\n",
      "Gradient Descent(575/9999): loss=4999.72874967696, w0=-14.278401346982026, w1=-67.05791988431747\n",
      "Gradient Descent(576/9999): loss=4999.72874967696, w0=-5.896001346982025, w1=-64.44961988431747\n",
      "Gradient Descent(577/9999): loss=7009.018041066442, w0=-5.896001346982025, w1=-64.44961988431747\n",
      "Gradient Descent(578/9999): loss=7009.018041066442, w0=-5.896001346982025, w1=-64.44961988431747\n",
      "Gradient Descent(579/9999): loss=7009.018041066442, w0=-5.896001346982025, w1=-64.44961988431747\n",
      "Gradient Descent(580/9999): loss=7009.018041066442, w0=-17.96276673253556, w1=-70.10521988431748\n",
      "Gradient Descent(581/9999): loss=5595.453216545262, w0=-17.96276673253556, w1=-70.10521988431748\n",
      "Gradient Descent(582/9999): loss=5595.453216545262, w0=-17.96276673253556, w1=-70.10521988431748\n",
      "Gradient Descent(583/9999): loss=5595.453216545262, w0=-17.96276673253556, w1=-70.10521988431748\n",
      "Gradient Descent(584/9999): loss=5595.453216545262, w0=-17.96276673253556, w1=-70.10521988431748\n",
      "Gradient Descent(585/9999): loss=5595.453216545262, w0=-9.61796673253556, w1=-67.36091988431748\n",
      "Gradient Descent(586/9999): loss=5106.584906398249, w0=-9.61796673253556, w1=-67.36091988431748\n",
      "Gradient Descent(587/9999): loss=5106.584906398249, w0=-9.61796673253556, w1=-67.36091988431748\n",
      "Gradient Descent(588/9999): loss=5106.584906398249, w0=-9.61796673253556, w1=-67.36091988431748\n",
      "Gradient Descent(589/9999): loss=5106.584906398249, w0=-27.817366732535564, w1=-73.79061988431748\n",
      "Gradient Descent(590/9999): loss=5802.4994844197445, w0=-27.817366732535564, w1=-73.79061988431748\n",
      "Gradient Descent(591/9999): loss=5802.4994844197445, w0=-27.817366732535564, w1=-73.79061988431748\n",
      "Gradient Descent(592/9999): loss=5802.4994844197445, w0=-27.817366732535564, w1=-73.79061988431748\n",
      "Gradient Descent(593/9999): loss=5802.4994844197445, w0=-27.817366732535564, w1=-73.79061988431748\n",
      "Gradient Descent(594/9999): loss=5802.4994844197445, w0=-27.817366732535564, w1=-73.79061988431748\n",
      "Gradient Descent(595/9999): loss=5802.4994844197445, w0=-27.817366732535564, w1=-73.79061988431748\n",
      "Gradient Descent(596/9999): loss=5802.4994844197445, w0=-27.817366732535564, w1=-73.79061988431748\n",
      "Gradient Descent(597/9999): loss=5802.4994844197445, w0=-27.817366732535564, w1=-73.79061988431748\n",
      "Gradient Descent(598/9999): loss=5802.4994844197445, w0=-27.817366732535564, w1=-73.79061988431748\n",
      "Gradient Descent(599/9999): loss=5802.4994844197445, w0=-27.817366732535564, w1=-73.79061988431748\n",
      "Gradient Descent(600/9999): loss=5802.4994844197445, w0=-18.705366732535566, w1=-73.69411988431747\n",
      "Gradient Descent(601/9999): loss=5797.503644335986, w0=-18.705366732535566, w1=-73.69411988431747\n",
      "Gradient Descent(602/9999): loss=5797.503644335986, w0=-5.388766732535565, w1=-71.34351988431747\n",
      "Gradient Descent(603/9999): loss=5127.071184062801, w0=-5.388766732535565, w1=-71.34351988431747\n",
      "Gradient Descent(604/9999): loss=5127.071184062801, w0=-5.388766732535565, w1=-71.34351988431747\n",
      "Gradient Descent(605/9999): loss=5127.071184062801, w0=-5.388766732535565, w1=-71.34351988431747\n",
      "Gradient Descent(606/9999): loss=5127.071184062801, w0=-33.28446673253556, w1=-81.19241988431747\n",
      "Gradient Descent(607/9999): loss=5802.4994844197445, w0=-33.28446673253556, w1=-81.19241988431747\n",
      "Gradient Descent(608/9999): loss=5802.4994844197445, w0=-33.28446673253556, w1=-81.19241988431747\n",
      "Gradient Descent(609/9999): loss=5802.4994844197445, w0=-23.617766732535564, w1=-79.65651988431748\n",
      "Gradient Descent(610/9999): loss=5802.4994844197445, w0=-10.765966732535563, w1=-78.17741988431747\n",
      "Gradient Descent(611/9999): loss=4513.4796515461585, w0=-10.765966732535563, w1=-78.17741988431747\n",
      "Gradient Descent(612/9999): loss=4513.4796515461585, w0=-10.765966732535563, w1=-78.17741988431747\n",
      "Gradient Descent(613/9999): loss=4513.4796515461585, w0=-10.765966732535563, w1=-78.17741988431747\n",
      "Gradient Descent(614/9999): loss=4513.4796515461585, w0=-10.765966732535563, w1=-78.17741988431747\n",
      "Gradient Descent(615/9999): loss=4513.4796515461585, w0=-10.765966732535563, w1=-78.17741988431747\n",
      "Gradient Descent(616/9999): loss=4513.4796515461585, w0=1.3940179335177039, w1=-75.11302374857293\n",
      "Gradient Descent(617/9999): loss=12295.460266911301, w0=-8.501982066482297, w1=-78.00372374857292\n",
      "Gradient Descent(618/9999): loss=5274.026522799681, w0=-8.501982066482297, w1=-78.00372374857292\n",
      "Gradient Descent(619/9999): loss=5274.026522799681, w0=-8.501982066482297, w1=-78.00372374857292\n",
      "Gradient Descent(620/9999): loss=5274.026522799681, w0=3.5647833190712372, w1=-68.90832374857293\n",
      "Gradient Descent(621/9999): loss=11972.522324358066, w0=3.5647833190712372, w1=-68.90832374857293\n",
      "Gradient Descent(622/9999): loss=11972.522324358066, w0=3.5647833190712372, w1=-68.90832374857293\n",
      "Gradient Descent(623/9999): loss=11972.522324358066, w0=3.5647833190712372, w1=-68.90832374857293\n",
      "Gradient Descent(624/9999): loss=11972.522324358066, w0=3.5647833190712372, w1=-68.90832374857293\n",
      "Gradient Descent(625/9999): loss=11972.522324358066, w0=-3.7760166809287634, w1=-71.42072374857293\n",
      "Gradient Descent(626/9999): loss=4409.650665054753, w0=-3.7760166809287634, w1=-71.42072374857293\n",
      "Gradient Descent(627/9999): loss=4409.650665054753, w0=-3.7760166809287634, w1=-71.42072374857293\n",
      "Gradient Descent(628/9999): loss=4409.650665054753, w0=-13.484916680928762, w1=-73.35082374857292\n",
      "Gradient Descent(629/9999): loss=5802.4994844197445, w0=-13.484916680928762, w1=-73.35082374857292\n",
      "Gradient Descent(630/9999): loss=5802.4994844197445, w0=-13.484916680928762, w1=-73.35082374857292\n",
      "Gradient Descent(631/9999): loss=5802.4994844197445, w0=-2.8000166809287634, w1=-73.13902374857292\n",
      "Gradient Descent(632/9999): loss=4835.252590324273, w0=-2.8000166809287634, w1=-73.13902374857292\n",
      "Gradient Descent(633/9999): loss=4835.252590324273, w0=-2.8000166809287634, w1=-73.13902374857292\n",
      "Gradient Descent(634/9999): loss=4835.252590324273, w0=-2.8000166809287634, w1=-73.13902374857292\n",
      "Gradient Descent(635/9999): loss=4835.252590324273, w0=-2.8000166809287634, w1=-73.13902374857292\n",
      "Gradient Descent(636/9999): loss=4835.252590324273, w0=-2.8000166809287634, w1=-73.13902374857292\n",
      "Gradient Descent(637/9999): loss=4835.252590324273, w0=-14.866782066482298, w1=-80.03602374857293\n",
      "Gradient Descent(638/9999): loss=5802.4994844197445, w0=-14.866782066482298, w1=-80.03602374857293\n",
      "Gradient Descent(639/9999): loss=5802.4994844197445, w0=-14.866782066482298, w1=-80.03602374857293\n",
      "Gradient Descent(640/9999): loss=5802.4994844197445, w0=-14.866782066482298, w1=-80.03602374857293\n",
      "Gradient Descent(641/9999): loss=5802.4994844197445, w0=-6.682882066482298, w1=-78.48362374857292\n",
      "Gradient Descent(642/9999): loss=5103.153060838062, w0=6.067917933517702, w1=-72.88262374857293\n",
      "Gradient Descent(643/9999): loss=7118.555216091132, w0=6.067917933517702, w1=-72.88262374857293\n",
      "Gradient Descent(644/9999): loss=7118.555216091132, w0=6.067917933517702, w1=-72.88262374857293\n",
      "Gradient Descent(645/9999): loss=7118.555216091132, w0=-3.754182066482299, w1=-80.68762374857292\n",
      "Gradient Descent(646/9999): loss=5502.68063240521, w0=-3.754182066482299, w1=-80.68762374857292\n",
      "Gradient Descent(647/9999): loss=5502.68063240521, w0=-3.754182066482299, w1=-80.68762374857292\n",
      "Gradient Descent(648/9999): loss=5502.68063240521, w0=-3.754182066482299, w1=-80.68762374857292\n",
      "Gradient Descent(649/9999): loss=5502.68063240521, w0=-3.754182066482299, w1=-80.68762374857292\n",
      "Gradient Descent(650/9999): loss=5502.68063240521, w0=-3.754182066482299, w1=-80.68762374857292\n",
      "Gradient Descent(651/9999): loss=5502.68063240521, w0=9.5283179335177, w1=-75.09472374857292\n",
      "Gradient Descent(652/9999): loss=5808.724516525723, w0=9.5283179335177, w1=-75.09472374857292\n",
      "Gradient Descent(653/9999): loss=5808.724516525723, w0=9.5283179335177, w1=-75.09472374857292\n",
      "Gradient Descent(654/9999): loss=5808.724516525723, w0=9.5283179335177, w1=-75.09472374857292\n",
      "Gradient Descent(655/9999): loss=5808.724516525723, w0=-2.6705820664823, w1=-79.16342374857291\n",
      "Gradient Descent(656/9999): loss=4724.535087718312, w0=-2.6705820664823, w1=-79.16342374857291\n",
      "Gradient Descent(657/9999): loss=4724.535087718312, w0=-2.6705820664823, w1=-79.16342374857291\n",
      "Gradient Descent(658/9999): loss=4724.535087718312, w0=-2.6705820664823, w1=-79.16342374857291\n",
      "Gradient Descent(659/9999): loss=4724.535087718312, w0=-10.155870572517703, w1=-79.81242891573494\n",
      "Gradient Descent(660/9999): loss=5802.4994844197445, w0=-10.155870572517703, w1=-79.81242891573494\n",
      "Gradient Descent(661/9999): loss=5802.4994844197445, w0=-10.155870572517703, w1=-79.81242891573494\n",
      "Gradient Descent(662/9999): loss=5802.4994844197445, w0=-10.155870572517703, w1=-79.81242891573494\n",
      "Gradient Descent(663/9999): loss=5802.4994844197445, w0=-1.1795705725177026, w1=-75.86562891573494\n",
      "Gradient Descent(664/9999): loss=4685.894844189732, w0=-1.1795705725177026, w1=-75.86562891573494\n",
      "Gradient Descent(665/9999): loss=4685.894844189732, w0=-1.1795705725177026, w1=-75.86562891573494\n",
      "Gradient Descent(666/9999): loss=4685.894844189732, w0=-1.1795705725177026, w1=-75.86562891573494\n",
      "Gradient Descent(667/9999): loss=4685.894844189732, w0=-1.1795705725177026, w1=-75.86562891573494\n",
      "Gradient Descent(668/9999): loss=4685.894844189732, w0=-1.1795705725177026, w1=-75.86562891573494\n",
      "Gradient Descent(669/9999): loss=4685.894844189732, w0=-1.1795705725177026, w1=-75.86562891573494\n",
      "Gradient Descent(670/9999): loss=4685.894844189732, w0=-1.1795705725177026, w1=-75.86562891573494\n",
      "Gradient Descent(671/9999): loss=4685.894844189732, w0=-26.648570572517706, w1=-79.25692891573495\n",
      "Gradient Descent(672/9999): loss=5802.4994844197445, w0=-14.044170572517706, w1=-78.36732891573494\n",
      "Gradient Descent(673/9999): loss=5802.4994844197445, w0=-14.044170572517706, w1=-78.36732891573494\n",
      "Gradient Descent(674/9999): loss=5802.4994844197445, w0=-14.044170572517706, w1=-78.36732891573494\n",
      "Gradient Descent(675/9999): loss=5802.4994844197445, w0=-2.2758705725177055, w1=-76.53572891573495\n",
      "Gradient Descent(676/9999): loss=4521.175000504851, w0=-2.2758705725177055, w1=-76.53572891573495\n",
      "Gradient Descent(677/9999): loss=4521.175000504851, w0=-2.2758705725177055, w1=-76.53572891573495\n",
      "Gradient Descent(678/9999): loss=4521.175000504851, w0=-2.2758705725177055, w1=-76.53572891573495\n",
      "Gradient Descent(679/9999): loss=4521.175000504851, w0=7.970129427482295, w1=-72.35762891573495\n",
      "Gradient Descent(680/9999): loss=11310.733821335374, w0=-4.096635958071239, w1=-80.43852891573495\n",
      "Gradient Descent(681/9999): loss=4614.820480596695, w0=-4.096635958071239, w1=-80.43852891573495\n",
      "Gradient Descent(682/9999): loss=4614.820480596695, w0=-4.096635958071239, w1=-80.43852891573495\n",
      "Gradient Descent(683/9999): loss=4614.820480596695, w0=6.073164041928761, w1=-76.60812891573495\n",
      "Gradient Descent(684/9999): loss=10680.374904418979, w0=-1.7793359580712398, w1=-82.62522891573495\n",
      "Gradient Descent(685/9999): loss=4649.374659892817, w0=-12.77623595807124, w1=-84.55412891573495\n",
      "Gradient Descent(686/9999): loss=5790.986548954825, w0=-12.77623595807124, w1=-84.55412891573495\n",
      "Gradient Descent(687/9999): loss=5790.986548954825, w0=-12.77623595807124, w1=-84.55412891573495\n",
      "Gradient Descent(688/9999): loss=5790.986548954825, w0=-4.59233595807124, w1=-83.00172891573494\n",
      "Gradient Descent(689/9999): loss=4682.147503356954, w0=-4.59233595807124, w1=-83.00172891573494\n",
      "Gradient Descent(690/9999): loss=4682.147503356954, w0=-4.59233595807124, w1=-83.00172891573494\n",
      "Gradient Descent(691/9999): loss=4682.147503356954, w0=-13.866035958071242, w1=-85.62752891573494\n",
      "Gradient Descent(692/9999): loss=5790.986549252893, w0=-13.866035958071242, w1=-85.62752891573494\n",
      "Gradient Descent(693/9999): loss=5790.986549252893, w0=-13.866035958071242, w1=-85.62752891573494\n",
      "Gradient Descent(694/9999): loss=5790.986549252893, w0=-13.866035958071242, w1=-85.62752891573494\n",
      "Gradient Descent(695/9999): loss=5790.986549252893, w0=-13.866035958071242, w1=-85.62752891573494\n",
      "Gradient Descent(696/9999): loss=5790.986549252893, w0=-3.1803359580712396, w1=-80.28162891573494\n",
      "Gradient Descent(697/9999): loss=4578.561359663908, w0=-3.1803359580712396, w1=-80.28162891573494\n",
      "Gradient Descent(698/9999): loss=4578.561359663908, w0=-3.1803359580712396, w1=-80.28162891573494\n",
      "Gradient Descent(699/9999): loss=4578.561359663908, w0=-3.1803359580712396, w1=-80.28162891573494\n",
      "Gradient Descent(700/9999): loss=4578.561359663908, w0=-3.1803359580712396, w1=-80.28162891573494\n",
      "Gradient Descent(701/9999): loss=4578.561359663908, w0=-3.1803359580712396, w1=-80.28162891573494\n",
      "Gradient Descent(702/9999): loss=4578.561359663908, w0=-3.1803359580712396, w1=-80.28162891573494\n",
      "Gradient Descent(703/9999): loss=4578.561359663908, w0=-3.1803359580712396, w1=-80.28162891573494\n",
      "Gradient Descent(704/9999): loss=4578.561359663908, w0=-3.1803359580712396, w1=-80.28162891573494\n",
      "Gradient Descent(705/9999): loss=4578.561359663908, w0=-22.752635958071238, w1=-85.36852891573494\n",
      "Gradient Descent(706/9999): loss=5802.4994844197445, w0=-13.115435958071236, w1=-85.16632891573494\n",
      "Gradient Descent(707/9999): loss=5786.480066429171, w0=-13.115435958071236, w1=-85.16632891573494\n",
      "Gradient Descent(708/9999): loss=5786.480066429171, w0=-13.115435958071236, w1=-85.16632891573494\n",
      "Gradient Descent(709/9999): loss=5786.480066429171, w0=-1.413235958071235, w1=-81.55162891573494\n",
      "Gradient Descent(710/9999): loss=4546.334429716015, w0=-1.413235958071235, w1=-81.55162891573494\n",
      "Gradient Descent(711/9999): loss=4546.334429716015, w0=12.928564041928766, w1=-74.62852891573493\n",
      "Gradient Descent(712/9999): loss=12649.140022742618, w0=12.928564041928766, w1=-74.62852891573493\n",
      "Gradient Descent(713/9999): loss=12649.140022742618, w0=6.062964041928765, w1=-77.15792891573493\n",
      "Gradient Descent(714/9999): loss=5008.245678362242, w0=6.062964041928765, w1=-77.15792891573493\n",
      "Gradient Descent(715/9999): loss=5008.245678362242, w0=6.062964041928765, w1=-77.15792891573493\n",
      "Gradient Descent(716/9999): loss=5008.245678362242, w0=6.062964041928765, w1=-77.15792891573493\n",
      "Gradient Descent(717/9999): loss=5008.245678362242, w0=6.062964041928765, w1=-77.15792891573493\n",
      "Gradient Descent(718/9999): loss=5008.245678362242, w0=6.062964041928765, w1=-77.15792891573493\n",
      "Gradient Descent(719/9999): loss=5008.245678362242, w0=13.812464041928767, w1=-72.36562891573493\n",
      "Gradient Descent(720/9999): loss=13392.846231729725, w0=13.812464041928767, w1=-72.36562891573493\n",
      "Gradient Descent(721/9999): loss=13392.846231729725, w0=13.812464041928767, w1=-72.36562891573493\n",
      "Gradient Descent(722/9999): loss=13392.846231729725, w0=13.812464041928767, w1=-72.36562891573493\n",
      "Gradient Descent(723/9999): loss=13392.846231729725, w0=25.8792294274823, w1=-59.71372891573493\n",
      "Gradient Descent(724/9999): loss=17234.84440108553, w0=13.812464041928767, w1=-67.74902891573494\n",
      "Gradient Descent(725/9999): loss=15455.681710155826, w0=13.812464041928767, w1=-67.74902891573494\n",
      "Gradient Descent(726/9999): loss=15455.681710155826, w0=5.3021640419287674, w1=-69.65632891573495\n",
      "Gradient Descent(727/9999): loss=5019.58571741846, w0=20.43366404192877, w1=-62.81842891573495\n",
      "Gradient Descent(728/9999): loss=17154.253852831087, w0=8.550164041928769, w1=-71.89382891573494\n",
      "Gradient Descent(729/9999): loss=5110.122430454814, w0=8.550164041928769, w1=-71.89382891573494\n",
      "Gradient Descent(730/9999): loss=5110.122430454814, w0=8.550164041928769, w1=-71.89382891573494\n",
      "Gradient Descent(731/9999): loss=5110.122430454814, w0=8.550164041928769, w1=-71.89382891573494\n",
      "Gradient Descent(732/9999): loss=5110.122430454814, w0=8.550164041928769, w1=-71.89382891573494\n",
      "Gradient Descent(733/9999): loss=5110.122430454814, w0=-9.368235958071233, w1=-75.67672891573494\n",
      "Gradient Descent(734/9999): loss=5767.964739786648, w0=-9.368235958071233, w1=-75.67672891573494\n",
      "Gradient Descent(735/9999): loss=5767.964739786648, w0=-1.3705359580712324, w1=-72.99412891573495\n",
      "Gradient Descent(736/9999): loss=4462.897127642116, w0=-1.3705359580712324, w1=-72.99412891573495\n",
      "Gradient Descent(737/9999): loss=4462.897127642116, w0=13.720964041928767, w1=-67.03632891573494\n",
      "Gradient Descent(738/9999): loss=15016.984947536394, w0=1.6541986563752324, w1=-73.98932891573494\n",
      "Gradient Descent(739/9999): loss=4677.0612161122845, w0=13.720964041928767, w1=-61.836728915734945\n",
      "Gradient Descent(740/9999): loss=17177.279700538194, w0=25.7877294274823, w1=-38.40952891573494\n",
      "Gradient Descent(741/9999): loss=17211.818530155688, w0=13.720964041928767, w1=-46.36112891573494\n",
      "Gradient Descent(742/9999): loss=17211.818530155688, w0=7.796364041928766, w1=-54.72572891573494\n",
      "Gradient Descent(743/9999): loss=14166.81405354786, w0=-3.294435958071234, w1=-60.51352891573494\n",
      "Gradient Descent(744/9999): loss=4678.536607673853, w0=-3.294435958071234, w1=-60.51352891573494\n",
      "Gradient Descent(745/9999): loss=4678.536607673853, w0=-3.294435958071234, w1=-60.51352891573494\n",
      "Gradient Descent(746/9999): loss=4678.536607673853, w0=-3.294435958071234, w1=-60.51352891573494\n",
      "Gradient Descent(747/9999): loss=4678.536607673853, w0=-3.294435958071234, w1=-60.51352891573494\n",
      "Gradient Descent(748/9999): loss=4678.536607673853, w0=-3.294435958071234, w1=-60.51352891573494\n",
      "Gradient Descent(749/9999): loss=4678.536607673853, w0=-13.491735958071235, w1=-61.57792891573494\n",
      "Gradient Descent(750/9999): loss=5802.4994844197445, w0=-2.266935958071235, w1=-53.97282891573494\n",
      "Gradient Descent(751/9999): loss=4888.204565797129, w0=-2.266935958071235, w1=-53.97282891573494\n",
      "Gradient Descent(752/9999): loss=4888.204565797129, w0=-2.266935958071235, w1=-53.97282891573494\n",
      "Gradient Descent(753/9999): loss=4888.204565797129, w0=5.597664041928765, w1=-50.056028915734935\n",
      "Gradient Descent(754/9999): loss=7866.633793247645, w0=5.597664041928765, w1=-50.056028915734935\n",
      "Gradient Descent(755/9999): loss=7866.633793247645, w0=-14.578235958071236, w1=-57.23312891573494\n",
      "Gradient Descent(756/9999): loss=5652.831323375759, w0=-14.578235958071236, w1=-57.23312891573494\n",
      "Gradient Descent(757/9999): loss=5652.831323375759, w0=-14.578235958071236, w1=-57.23312891573494\n",
      "Gradient Descent(758/9999): loss=5652.831323375759, w0=-14.578235958071236, w1=-57.23312891573494\n",
      "Gradient Descent(759/9999): loss=5652.831323375759, w0=-3.8407359580712352, w1=-56.86612891573494\n",
      "Gradient Descent(760/9999): loss=5340.325962804554, w0=-3.8407359580712352, w1=-56.86612891573494\n",
      "Gradient Descent(761/9999): loss=5340.325962804554, w0=-3.8407359580712352, w1=-56.86612891573494\n",
      "Gradient Descent(762/9999): loss=5340.325962804554, w0=-15.90750134362477, w1=-61.94062891573494\n",
      "Gradient Descent(763/9999): loss=5498.9328534317065, w0=-15.90750134362477, w1=-61.94062891573494\n",
      "Gradient Descent(764/9999): loss=5498.9328534317065, w0=-5.2226013436247705, w1=-61.728828915734944\n",
      "Gradient Descent(765/9999): loss=7722.5602537529485, w0=-5.2226013436247705, w1=-61.728828915734944\n",
      "Gradient Descent(766/9999): loss=7722.5602537529485, w0=-5.2226013436247705, w1=-61.728828915734944\n",
      "Gradient Descent(767/9999): loss=7722.5602537529485, w0=-5.2226013436247705, w1=-61.728828915734944\n",
      "Gradient Descent(768/9999): loss=7722.5602537529485, w0=-5.2226013436247705, w1=-61.728828915734944\n",
      "Gradient Descent(769/9999): loss=7722.5602537529485, w0=-5.2226013436247705, w1=-61.728828915734944\n",
      "Gradient Descent(770/9999): loss=7722.5602537529485, w0=-5.2226013436247705, w1=-61.728828915734944\n",
      "Gradient Descent(771/9999): loss=7722.5602537529485, w0=-5.2226013436247705, w1=-61.728828915734944\n",
      "Gradient Descent(772/9999): loss=7722.5602537529485, w0=-5.2226013436247705, w1=-61.728828915734944\n",
      "Gradient Descent(773/9999): loss=7722.5602537529485, w0=-13.681801343624771, w1=-62.03782891573494\n",
      "Gradient Descent(774/9999): loss=4545.318775644186, w0=-13.681801343624771, w1=-62.03782891573494\n",
      "Gradient Descent(775/9999): loss=4545.318775644186, w0=-13.681801343624771, w1=-62.03782891573494\n",
      "Gradient Descent(776/9999): loss=4545.318775644186, w0=-13.681801343624771, w1=-62.03782891573494\n",
      "Gradient Descent(777/9999): loss=4545.318775644186, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(778/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(779/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(780/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(781/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(782/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(783/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(784/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(785/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(786/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(787/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(788/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(789/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(790/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(791/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(792/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(793/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(794/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(795/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(796/9999): loss=4545.3187837239975, w0=-13.681801328794021, w1=-62.037828913924095\n",
      "Gradient Descent(797/9999): loss=4545.3187837239975, w0=-26.24870132879402, w1=-64.7330289139241\n",
      "Gradient Descent(798/9999): loss=5802.4994844197445, w0=-26.24870132879402, w1=-64.7330289139241\n",
      "Gradient Descent(799/9999): loss=5802.4994844197445, w0=-26.24870132879402, w1=-64.7330289139241\n",
      "Gradient Descent(800/9999): loss=5802.4994844197445, w0=-18.012101328794017, w1=-62.033628913924105\n",
      "Gradient Descent(801/9999): loss=5388.074474815545, w0=-18.012101328794017, w1=-62.033628913924105\n",
      "Gradient Descent(802/9999): loss=5388.074474815545, w0=-18.012101328794017, w1=-62.033628913924105\n",
      "Gradient Descent(803/9999): loss=5388.074474815545, w0=-18.012101328794017, w1=-62.033628913924105\n",
      "Gradient Descent(804/9999): loss=5388.074474815545, w0=-18.012101328794017, w1=-62.033628913924105\n",
      "Gradient Descent(805/9999): loss=5388.074474815545, w0=-18.012101328794017, w1=-62.033628913924105\n",
      "Gradient Descent(806/9999): loss=5388.074474815545, w0=-18.012101328794017, w1=-62.033628913924105\n",
      "Gradient Descent(807/9999): loss=5388.074474815545, w0=-18.012101328794017, w1=-62.033628913924105\n",
      "Gradient Descent(808/9999): loss=5388.074474815545, w0=-18.012101328794017, w1=-62.033628913924105\n",
      "Gradient Descent(809/9999): loss=5388.074474815545, w0=-18.012101328794017, w1=-62.033628913924105\n",
      "Gradient Descent(810/9999): loss=5388.074474815545, w0=-18.012101328794017, w1=-62.033628913924105\n",
      "Gradient Descent(811/9999): loss=5388.074474815545, w0=-9.736401328794017, w1=-55.70642891392411\n",
      "Gradient Descent(812/9999): loss=6940.667609643749, w0=-17.37900132879402, w1=-59.32392891392411\n",
      "Gradient Descent(813/9999): loss=4881.670446595175, w0=-5.312235943240484, w1=-47.896228913924105\n",
      "Gradient Descent(814/9999): loss=10150.510121882176, w0=-5.312235943240484, w1=-47.896228913924105\n",
      "Gradient Descent(815/9999): loss=10150.510121882176, w0=-5.312235943240484, w1=-47.896228913924105\n",
      "Gradient Descent(816/9999): loss=10150.510121882176, w0=-5.312235943240484, w1=-47.896228913924105\n",
      "Gradient Descent(817/9999): loss=10150.510121882176, w0=-21.495735943240486, w1=-53.36652891392411\n",
      "Gradient Descent(818/9999): loss=5780.3485582780995, w0=-0.7495359432404847, w1=-49.37882891392411\n",
      "Gradient Descent(819/9999): loss=15579.367371601218, w0=-0.7495359432404847, w1=-49.37882891392411\n",
      "Gradient Descent(820/9999): loss=15579.367371601218, w0=-14.698135943240484, w1=-56.71502891392411\n",
      "Gradient Descent(821/9999): loss=4562.172887589457, w0=-14.698135943240484, w1=-56.71502891392411\n",
      "Gradient Descent(822/9999): loss=4562.172887589457, w0=-26.764901328794018, w1=-62.59362891392411\n",
      "Gradient Descent(823/9999): loss=5802.4994844197445, w0=-26.764901328794018, w1=-62.59362891392411\n",
      "Gradient Descent(824/9999): loss=5802.4994844197445, w0=-16.41090132879402, w1=-58.09242891392411\n",
      "Gradient Descent(825/9999): loss=5802.4994844197445, w0=-16.41090132879402, w1=-58.09242891392411\n",
      "Gradient Descent(826/9999): loss=5802.4994844197445, w0=-16.41090132879402, w1=-58.09242891392411\n",
      "Gradient Descent(827/9999): loss=5802.4994844197445, w0=-16.41090132879402, w1=-58.09242891392411\n",
      "Gradient Descent(828/9999): loss=5802.4994844197445, w0=-16.41090132879402, w1=-58.09242891392411\n",
      "Gradient Descent(829/9999): loss=5802.4994844197445, w0=-16.41090132879402, w1=-58.09242891392411\n",
      "Gradient Descent(830/9999): loss=5802.4994844197445, w0=-16.41090132879402, w1=-58.09242891392411\n",
      "Gradient Descent(831/9999): loss=5802.4994844197445, w0=-16.41090132879402, w1=-58.09242891392411\n",
      "Gradient Descent(832/9999): loss=5802.4994844197445, w0=-3.9486013287940196, w1=-56.87322891392411\n",
      "Gradient Descent(833/9999): loss=4681.412570819295, w0=-3.9486013287940196, w1=-56.87322891392411\n",
      "Gradient Descent(834/9999): loss=4681.412570819295, w0=-3.9486013287940196, w1=-56.87322891392411\n",
      "Gradient Descent(835/9999): loss=4681.412570819295, w0=-3.9486013287940196, w1=-56.87322891392411\n",
      "Gradient Descent(836/9999): loss=4681.412570819295, w0=-3.9486013287940196, w1=-56.87322891392411\n",
      "Gradient Descent(837/9999): loss=4681.412570819295, w0=-15.72350132879402, w1=-59.62882891392411\n",
      "Gradient Descent(838/9999): loss=5802.4994844197445, w0=-15.72350132879402, w1=-59.62882891392411\n",
      "Gradient Descent(839/9999): loss=5802.4994844197445, w0=-4.404501328794019, w1=-58.60992891392411\n",
      "Gradient Descent(840/9999): loss=4575.426331853011, w0=-4.404501328794019, w1=-58.60992891392411\n",
      "Gradient Descent(841/9999): loss=4575.426331853011, w0=-4.404501328794019, w1=-58.60992891392411\n",
      "Gradient Descent(842/9999): loss=4575.426331853011, w0=-4.404501328794019, w1=-58.60992891392411\n",
      "Gradient Descent(843/9999): loss=4575.426331853011, w0=-4.404501328794019, w1=-58.60992891392411\n",
      "Gradient Descent(844/9999): loss=4575.426331853011, w0=6.196898671205981, w1=-53.97642891392411\n",
      "Gradient Descent(845/9999): loss=14892.476006082594, w0=-5.869866714347554, w1=-61.55302891392411\n",
      "Gradient Descent(846/9999): loss=4543.45224612341, w0=-5.869866714347554, w1=-61.55302891392411\n",
      "Gradient Descent(847/9999): loss=4543.45224612341, w0=-5.869866714347554, w1=-61.55302891392411\n",
      "Gradient Descent(848/9999): loss=4543.45224612341, w0=-5.869866714347554, w1=-61.55302891392411\n",
      "Gradient Descent(849/9999): loss=4543.45224612341, w0=-5.869866714347554, w1=-61.55302891392411\n",
      "Gradient Descent(850/9999): loss=4543.45224612341, w0=-5.869866714347554, w1=-61.55302891392411\n",
      "Gradient Descent(851/9999): loss=4543.45224612341, w0=-21.20886671434755, w1=-69.39482891392412\n",
      "Gradient Descent(852/9999): loss=5802.4994844197445, w0=-21.20886671434755, w1=-69.39482891392412\n",
      "Gradient Descent(853/9999): loss=5802.4994844197445, w0=-21.20886671434755, w1=-69.39482891392412\n",
      "Gradient Descent(854/9999): loss=5802.4994844197445, w0=-21.20886671434755, w1=-69.39482891392412\n",
      "Gradient Descent(855/9999): loss=5802.4994844197445, w0=-9.142101328794016, w1=-64.11872891392412\n",
      "Gradient Descent(856/9999): loss=4630.34649778667, w0=-0.09020132879401643, w1=-58.726128913924114\n",
      "Gradient Descent(857/9999): loss=6793.940937092428, w0=-0.09020132879401643, w1=-58.726128913924114\n",
      "Gradient Descent(858/9999): loss=6793.940937092428, w0=-0.09020132879401643, w1=-58.726128913924114\n",
      "Gradient Descent(859/9999): loss=6793.940937092428, w0=-0.09020132879401643, w1=-58.726128913924114\n",
      "Gradient Descent(860/9999): loss=6793.940937092428, w0=-9.864601328794016, w1=-60.83172891392412\n",
      "Gradient Descent(861/9999): loss=4931.459088865813, w0=-9.864601328794016, w1=-60.83172891392412\n",
      "Gradient Descent(862/9999): loss=4931.459088865813, w0=-9.864601328794016, w1=-60.83172891392412\n",
      "Gradient Descent(863/9999): loss=4931.459088865813, w0=-9.864601328794016, w1=-60.83172891392412\n",
      "Gradient Descent(864/9999): loss=4931.459088865813, w0=-9.864601328794016, w1=-60.83172891392412\n",
      "Gradient Descent(865/9999): loss=4931.459088865813, w0=-9.864601328794016, w1=-60.83172891392412\n",
      "Gradient Descent(866/9999): loss=4931.459088865813, w0=-9.864601328794016, w1=-60.83172891392412\n",
      "Gradient Descent(867/9999): loss=4931.459088865813, w0=-9.864601328794016, w1=-60.83172891392412\n",
      "Gradient Descent(868/9999): loss=4931.459088865813, w0=-0.42540132879401504, w1=-60.796528913924114\n",
      "Gradient Descent(869/9999): loss=8354.382984843543, w0=-0.42540132879401504, w1=-60.796528913924114\n",
      "Gradient Descent(870/9999): loss=8354.382984843543, w0=-7.493001328794016, w1=-66.19412891392412\n",
      "Gradient Descent(871/9999): loss=5096.070864707464, w0=-7.493001328794016, w1=-66.19412891392412\n",
      "Gradient Descent(872/9999): loss=5096.070864707464, w0=-7.493001328794016, w1=-66.19412891392412\n",
      "Gradient Descent(873/9999): loss=5096.070864707464, w0=-7.493001328794016, w1=-66.19412891392412\n",
      "Gradient Descent(874/9999): loss=5096.070864707464, w0=-7.493001328794016, w1=-66.19412891392412\n",
      "Gradient Descent(875/9999): loss=5096.070864707464, w0=-7.493001328794016, w1=-66.19412891392412\n",
      "Gradient Descent(876/9999): loss=5096.070864707464, w0=-7.493001328794016, w1=-66.19412891392412\n",
      "Gradient Descent(877/9999): loss=5096.070864707464, w0=-7.493001328794016, w1=-66.19412891392412\n",
      "Gradient Descent(878/9999): loss=5096.070864707464, w0=-7.493001328794016, w1=-66.19412891392412\n",
      "Gradient Descent(879/9999): loss=5096.070864707464, w0=-7.493001328794016, w1=-66.19412891392412\n",
      "Gradient Descent(880/9999): loss=5096.070864707464, w0=5.033098671205986, w1=-60.04372891392412\n",
      "Gradient Descent(881/9999): loss=8079.225388190787, w0=5.033098671205986, w1=-60.04372891392412\n",
      "Gradient Descent(882/9999): loss=8079.225388190787, w0=5.033098671205986, w1=-60.04372891392412\n",
      "Gradient Descent(883/9999): loss=8079.225388190787, w0=-7.033666714347548, w1=-66.74912891392412\n",
      "Gradient Descent(884/9999): loss=4904.193595509897, w0=4.491133285652451, w1=-64.20242891392412\n",
      "Gradient Descent(885/9999): loss=9310.895909045115, w0=4.491133285652451, w1=-64.20242891392412\n",
      "Gradient Descent(886/9999): loss=9310.895909045115, w0=4.491133285652451, w1=-64.20242891392412\n",
      "Gradient Descent(887/9999): loss=9310.895909045115, w0=4.491133285652451, w1=-64.20242891392412\n",
      "Gradient Descent(888/9999): loss=9310.895909045115, w0=4.491133285652451, w1=-64.20242891392412\n",
      "Gradient Descent(889/9999): loss=9310.895909045115, w0=-0.020166714347549686, w1=-70.24042891392412\n",
      "Gradient Descent(890/9999): loss=4587.814151253187, w0=-0.020166714347549686, w1=-70.24042891392412\n",
      "Gradient Descent(891/9999): loss=4587.814151253187, w0=-8.97336671434755, w1=-74.33532891392412\n",
      "Gradient Descent(892/9999): loss=5569.342259576969, w0=-0.6285667143475511, w1=-71.59102891392412\n",
      "Gradient Descent(893/9999): loss=4620.068959501684, w0=-0.6285667143475511, w1=-71.59102891392412\n",
      "Gradient Descent(894/9999): loss=4620.068959501684, w0=-0.6285667143475511, w1=-71.59102891392412\n",
      "Gradient Descent(895/9999): loss=4620.068959501684, w0=-0.6285667143475511, w1=-71.59102891392412\n",
      "Gradient Descent(896/9999): loss=4620.068959501684, w0=-24.971266714347557, w1=-73.65982891392412\n",
      "Gradient Descent(897/9999): loss=5802.4994844197445, w0=-24.971266714347557, w1=-73.65982891392412\n",
      "Gradient Descent(898/9999): loss=5802.4994844197445, w0=-24.971266714347557, w1=-73.65982891392412\n",
      "Gradient Descent(899/9999): loss=5802.4994844197445, w0=-10.958866714347558, w1=-72.46002891392412\n",
      "Gradient Descent(900/9999): loss=4923.8496637676235, w0=-10.958866714347558, w1=-72.46002891392412\n",
      "Gradient Descent(901/9999): loss=4923.8496637676235, w0=-10.958866714347558, w1=-72.46002891392412\n",
      "Gradient Descent(902/9999): loss=4923.8496637676235, w0=-10.958866714347558, w1=-72.46002891392412\n",
      "Gradient Descent(903/9999): loss=4923.8496637676235, w0=-10.958866714347558, w1=-72.46002891392412\n",
      "Gradient Descent(904/9999): loss=4923.8496637676235, w0=-10.958866714347558, w1=-72.46002891392412\n",
      "Gradient Descent(905/9999): loss=4923.8496637676235, w0=-10.958866714347558, w1=-72.46002891392412\n",
      "Gradient Descent(906/9999): loss=4923.8496637676235, w0=-10.958866714347558, w1=-72.46002891392412\n",
      "Gradient Descent(907/9999): loss=4923.8496637676235, w0=-10.958866714347558, w1=-72.46002891392412\n",
      "Gradient Descent(908/9999): loss=4923.8496637676235, w0=-10.958866714347558, w1=-72.46002891392412\n",
      "Gradient Descent(909/9999): loss=4923.8496637676235, w0=3.3086332856524443, w1=-69.78682891392413\n",
      "Gradient Descent(910/9999): loss=11824.606271469898, w0=-6.354866714347557, w1=-76.37452891392412\n",
      "Gradient Descent(911/9999): loss=4531.35255169368, w0=-6.354866714347557, w1=-76.37452891392412\n",
      "Gradient Descent(912/9999): loss=4531.35255169368, w0=-6.354866714347557, w1=-76.37452891392412\n",
      "Gradient Descent(913/9999): loss=4531.35255169368, w0=-6.354866714347557, w1=-76.37452891392412\n",
      "Gradient Descent(914/9999): loss=4531.35255169368, w0=-6.354866714347557, w1=-76.37452891392412\n",
      "Gradient Descent(915/9999): loss=4531.35255169368, w0=-6.354866714347557, w1=-76.37452891392412\n",
      "Gradient Descent(916/9999): loss=4531.35255169368, w0=-6.354866714347557, w1=-76.37452891392412\n",
      "Gradient Descent(917/9999): loss=4531.35255169368, w0=5.437733285652444, w1=-72.49062891392413\n",
      "Gradient Descent(918/9999): loss=8311.564527126451, w0=-4.087266714347557, w1=-74.88812891392412\n",
      "Gradient Descent(919/9999): loss=4497.920004914069, w0=-4.087266714347557, w1=-74.88812891392412\n",
      "Gradient Descent(920/9999): loss=4497.920004914069, w0=9.840233285652445, w1=-66.79492891392412\n",
      "Gradient Descent(921/9999): loss=14562.048390149115, w0=9.840233285652445, w1=-66.79492891392412\n",
      "Gradient Descent(922/9999): loss=14562.048390149115, w0=9.840233285652445, w1=-66.79492891392412\n",
      "Gradient Descent(923/9999): loss=14562.048390149115, w0=1.3274332856524467, w1=-73.79522891392412\n",
      "Gradient Descent(924/9999): loss=5378.454951250163, w0=1.3274332856524467, w1=-73.79522891392412\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(925/9999): loss=5378.454951250163, w0=-7.217566714347553, w1=-77.57552891392412\n",
      "Gradient Descent(926/9999): loss=5422.970472762095, w0=6.475033285652449, w1=-67.62372891392411\n",
      "Gradient Descent(927/9999): loss=9166.774029675551, w0=6.475033285652449, w1=-67.62372891392411\n",
      "Gradient Descent(928/9999): loss=9166.774029675551, w0=-2.5715667143475525, w1=-72.58912891392411\n",
      "Gradient Descent(929/9999): loss=4489.314522267609, w0=13.17313328565245, w1=-68.82232891392411\n",
      "Gradient Descent(930/9999): loss=15711.567950061113, w0=1.106367900098915, w1=-78.02182891392411\n",
      "Gradient Descent(931/9999): loss=4656.415193890874, w0=1.106367900098915, w1=-78.02182891392411\n",
      "Gradient Descent(932/9999): loss=4656.415193890874, w0=1.106367900098915, w1=-78.02182891392411\n",
      "Gradient Descent(933/9999): loss=4656.415193890874, w0=-7.011732099901085, w1=-81.7048289139241\n",
      "Gradient Descent(934/9999): loss=5802.499273306972, w0=-7.011732099901085, w1=-81.7048289139241\n",
      "Gradient Descent(935/9999): loss=5802.499273306972, w0=-7.011732099901085, w1=-81.7048289139241\n",
      "Gradient Descent(936/9999): loss=5802.499273306972, w0=-7.011732099901085, w1=-81.7048289139241\n",
      "Gradient Descent(937/9999): loss=5802.499273306972, w0=5.055033285652449, w1=-73.7982289139241\n",
      "Gradient Descent(938/9999): loss=5180.8081336700025, w0=5.055033285652449, w1=-73.7982289139241\n",
      "Gradient Descent(939/9999): loss=5180.8081336700025, w0=-6.743166714347552, w1=-78.40662891392411\n",
      "Gradient Descent(940/9999): loss=5212.483551967008, w0=-6.743166714347552, w1=-78.40662891392411\n",
      "Gradient Descent(941/9999): loss=5212.483551967008, w0=-6.743166714347552, w1=-78.40662891392411\n",
      "Gradient Descent(942/9999): loss=5212.483551967008, w0=-6.743166714347552, w1=-78.40662891392411\n",
      "Gradient Descent(943/9999): loss=5212.483551967008, w0=-6.743166714347552, w1=-78.40662891392411\n",
      "Gradient Descent(944/9999): loss=5212.483551967008, w0=5.208633285652446, w1=-75.10702891392411\n",
      "Gradient Descent(945/9999): loss=5980.1744924550985, w0=-2.869166714347555, w1=-75.56592891392411\n",
      "Gradient Descent(946/9999): loss=4811.086359068475, w0=-2.869166714347555, w1=-75.56592891392411\n",
      "Gradient Descent(947/9999): loss=4811.086359068475, w0=-2.869166714347555, w1=-75.56592891392411\n",
      "Gradient Descent(948/9999): loss=4811.086359068475, w0=-2.869166714347555, w1=-75.56592891392411\n",
      "Gradient Descent(949/9999): loss=4811.086359068475, w0=9.197598671205979, w1=-68.63352891392411\n",
      "Gradient Descent(950/9999): loss=5813.923200783854, w0=9.197598671205979, w1=-68.63352891392411\n",
      "Gradient Descent(951/9999): loss=5813.923200783854, w0=9.197598671205979, w1=-68.63352891392411\n",
      "Gradient Descent(952/9999): loss=5813.923200783854, w0=9.197598671205979, w1=-68.63352891392411\n",
      "Gradient Descent(953/9999): loss=5813.923200783854, w0=9.197598671205979, w1=-68.63352891392411\n",
      "Gradient Descent(954/9999): loss=5813.923200783854, w0=9.197598671205979, w1=-68.63352891392411\n",
      "Gradient Descent(955/9999): loss=5813.923200783854, w0=9.197598671205979, w1=-68.63352891392411\n",
      "Gradient Descent(956/9999): loss=5813.923200783854, w0=9.197598671205979, w1=-68.63352891392411\n",
      "Gradient Descent(957/9999): loss=5813.923200783854, w0=9.197598671205979, w1=-68.63352891392411\n",
      "Gradient Descent(958/9999): loss=5813.923200783854, w0=9.197598671205979, w1=-68.63352891392411\n",
      "Gradient Descent(959/9999): loss=5813.923200783854, w0=24.41759867120598, w1=-60.74412891392411\n",
      "Gradient Descent(960/9999): loss=17154.253852831087, w0=12.350833285652445, w1=-67.2009289139241\n",
      "Gradient Descent(961/9999): loss=7843.740866872982, w0=12.350833285652445, w1=-67.2009289139241\n",
      "Gradient Descent(962/9999): loss=7843.740866872982, w0=12.350833285652445, w1=-67.2009289139241\n",
      "Gradient Descent(963/9999): loss=7843.740866872982, w0=12.350833285652445, w1=-67.2009289139241\n",
      "Gradient Descent(964/9999): loss=7843.740866872982, w0=12.350833285652445, w1=-67.2009289139241\n",
      "Gradient Descent(965/9999): loss=7843.740866872982, w0=12.350833285652445, w1=-67.2009289139241\n",
      "Gradient Descent(966/9999): loss=7843.740866872982, w0=12.350833285652445, w1=-67.2009289139241\n",
      "Gradient Descent(967/9999): loss=7843.740866872982, w0=-10.875466714347557, w1=-69.7785289139241\n",
      "Gradient Descent(968/9999): loss=5802.4994844197445, w0=3.3060332856524433, w1=-68.5486289139241\n",
      "Gradient Descent(969/9999): loss=4514.067829178459, w0=10.066233285652444, w1=-63.140028913924105\n",
      "Gradient Descent(970/9999): loss=8981.603418214909, w0=19.770433285652445, w1=-57.316428913924106\n",
      "Gradient Descent(971/9999): loss=17246.357336550333, w0=7.70366790009891, w1=-63.75782891392411\n",
      "Gradient Descent(972/9999): loss=14098.278063368734, w0=-2.8871320999010894, w1=-70.4376289139241\n",
      "Gradient Descent(973/9999): loss=4953.2215088823, w0=-2.8871320999010894, w1=-70.4376289139241\n",
      "Gradient Descent(974/9999): loss=4953.2215088823, w0=-12.16213209990109, w1=-74.9600289139241\n",
      "Gradient Descent(975/9999): loss=5514.087286453721, w0=-12.16213209990109, w1=-74.9600289139241\n",
      "Gradient Descent(976/9999): loss=5514.087286453721, w0=-12.16213209990109, w1=-74.9600289139241\n",
      "Gradient Descent(977/9999): loss=5514.087286453721, w0=1.1423679000989093, w1=-71.2973289139241\n",
      "Gradient Descent(978/9999): loss=8476.076772556824, w0=-6.215632099901091, w1=-76.04142891392411\n",
      "Gradient Descent(979/9999): loss=4458.79647755893, w0=-6.215632099901091, w1=-76.04142891392411\n",
      "Gradient Descent(980/9999): loss=4458.79647755893, w0=-6.215632099901091, w1=-76.04142891392411\n",
      "Gradient Descent(981/9999): loss=4458.79647755893, w0=-6.215632099901091, w1=-76.04142891392411\n",
      "Gradient Descent(982/9999): loss=4458.79647755893, w0=-6.215632099901091, w1=-76.04142891392411\n",
      "Gradient Descent(983/9999): loss=4458.79647755893, w0=-6.215632099901091, w1=-76.04142891392411\n",
      "Gradient Descent(984/9999): loss=4458.79647755893, w0=5.27936790009891, w1=-70.0023289139241\n",
      "Gradient Descent(985/9999): loss=11021.089663577692, w0=5.27936790009891, w1=-70.0023289139241\n",
      "Gradient Descent(986/9999): loss=11021.089663577692, w0=5.27936790009891, w1=-70.0023289139241\n",
      "Gradient Descent(987/9999): loss=11021.089663577692, w0=-10.52813209990109, w1=-71.1855289139241\n",
      "Gradient Descent(988/9999): loss=4801.29731200538, w0=-10.52813209990109, w1=-71.1855289139241\n",
      "Gradient Descent(989/9999): loss=4801.29731200538, w0=-10.52813209990109, w1=-71.1855289139241\n",
      "Gradient Descent(990/9999): loss=4801.29731200538, w0=-20.24823209990109, w1=-72.4489289139241\n",
      "Gradient Descent(991/9999): loss=5802.4994844197445, w0=-20.24823209990109, w1=-72.4489289139241\n",
      "Gradient Descent(992/9999): loss=5802.4994844197445, w0=-20.24823209990109, w1=-72.4489289139241\n",
      "Gradient Descent(993/9999): loss=5802.4994844197445, w0=-20.24823209990109, w1=-72.4489289139241\n",
      "Gradient Descent(994/9999): loss=5802.4994844197445, w0=-20.24823209990109, w1=-72.4489289139241\n",
      "Gradient Descent(995/9999): loss=5802.4994844197445, w0=-20.24823209990109, w1=-72.4489289139241\n",
      "Gradient Descent(996/9999): loss=5802.4994844197445, w0=-20.24823209990109, w1=-72.4489289139241\n",
      "Gradient Descent(997/9999): loss=5802.4994844197445, w0=-20.24823209990109, w1=-72.4489289139241\n",
      "Gradient Descent(998/9999): loss=5802.4994844197445, w0=-13.02063209990109, w1=-72.15062891392411\n",
      "Gradient Descent(999/9999): loss=5351.4571110832385, w0=-13.02063209990109, w1=-72.15062891392411\n",
      "Gradient Descent(1000/9999): loss=5351.4571110832385, w0=-13.02063209990109, w1=-72.15062891392411\n",
      "Gradient Descent(1001/9999): loss=5351.4571110832385, w0=-13.02063209990109, w1=-72.15062891392411\n",
      "Gradient Descent(1002/9999): loss=5351.4571110832385, w0=-13.02063209990109, w1=-72.15062891392411\n",
      "Gradient Descent(1003/9999): loss=5351.4571110832385, w0=-13.02063209990109, w1=-72.15062891392411\n",
      "Gradient Descent(1004/9999): loss=5351.4571110832385, w0=-13.02063209990109, w1=-72.15062891392411\n",
      "Gradient Descent(1005/9999): loss=5351.4571110832385, w0=-13.02063209990109, w1=-72.15062891392411\n",
      "Gradient Descent(1006/9999): loss=5351.4571110832385, w0=-13.02063209990109, w1=-72.15062891392411\n",
      "Gradient Descent(1007/9999): loss=5351.4571110832385, w0=-13.02063209990109, w1=-72.15062891392411\n",
      "Gradient Descent(1008/9999): loss=5351.4571110832385, w0=-13.02063209990109, w1=-72.15062891392411\n",
      "Gradient Descent(1009/9999): loss=5351.4571110832385, w0=-13.02063209990109, w1=-72.15062891392411\n",
      "Gradient Descent(1010/9999): loss=5351.4571110832385, w0=-13.02063209990109, w1=-72.15062891392411\n",
      "Gradient Descent(1011/9999): loss=5351.4571110832385, w0=-13.02063209990109, w1=-72.15062891392411\n",
      "Gradient Descent(1012/9999): loss=5351.4571110832385, w0=-2.8739320999010864, w1=-69.32312891392411\n",
      "Gradient Descent(1013/9999): loss=4838.405557962233, w0=4.990667900098914, w1=-65.40632891392411\n",
      "Gradient Descent(1014/9999): loss=10121.929937140878, w0=-1.7933320999010869, w1=-66.27642891392411\n",
      "Gradient Descent(1015/9999): loss=4487.204836306985, w0=-1.7933320999010869, w1=-66.27642891392411\n",
      "Gradient Descent(1016/9999): loss=4487.204836306985, w0=-1.7933320999010869, w1=-66.27642891392411\n",
      "Gradient Descent(1017/9999): loss=4487.204836306985, w0=-1.7933320999010869, w1=-66.27642891392411\n",
      "Gradient Descent(1018/9999): loss=4487.204836306985, w0=-12.554432099901089, w1=-69.0828289139241\n",
      "Gradient Descent(1019/9999): loss=5802.4994844197445, w0=-12.554432099901089, w1=-69.0828289139241\n",
      "Gradient Descent(1020/9999): loss=5802.4994844197445, w0=-2.986332099901089, w1=-68.2813289139241\n",
      "Gradient Descent(1021/9999): loss=4328.230068118555, w0=-2.986332099901089, w1=-68.2813289139241\n",
      "Gradient Descent(1022/9999): loss=4328.230068118555, w0=8.033267900098911, w1=-64.8794289139241\n",
      "Gradient Descent(1023/9999): loss=11277.333438256761, w0=8.033267900098911, w1=-64.8794289139241\n",
      "Gradient Descent(1024/9999): loss=11277.333438256761, w0=8.033267900098911, w1=-64.8794289139241\n",
      "Gradient Descent(1025/9999): loss=11277.333438256761, w0=-10.882632099901093, w1=-74.3681289139241\n",
      "Gradient Descent(1026/9999): loss=4639.6735375823755, w0=-10.882632099901093, w1=-74.3681289139241\n",
      "Gradient Descent(1027/9999): loss=4639.6735375823755, w0=-10.882632099901093, w1=-74.3681289139241\n",
      "Gradient Descent(1028/9999): loss=4639.6735375823755, w0=-10.882632099901093, w1=-74.3681289139241\n",
      "Gradient Descent(1029/9999): loss=4639.6735375823755, w0=-10.882632099901093, w1=-74.3681289139241\n",
      "Gradient Descent(1030/9999): loss=4639.6735375823755, w0=-0.6366320999010924, w1=-70.1900289139241\n",
      "Gradient Descent(1031/9999): loss=8050.499206195866, w0=-0.6366320999010924, w1=-70.1900289139241\n",
      "Gradient Descent(1032/9999): loss=8050.499206195866, w0=-0.6366320999010924, w1=-70.1900289139241\n",
      "Gradient Descent(1033/9999): loss=8050.499206195866, w0=-0.6366320999010924, w1=-70.1900289139241\n",
      "Gradient Descent(1034/9999): loss=8050.499206195866, w0=11.155967900098908, w1=-66.3061289139241\n",
      "Gradient Descent(1035/9999): loss=16228.191476555028, w0=-0.9107974854546264, w1=-76.8736289139241\n",
      "Gradient Descent(1036/9999): loss=4584.446140543915, w0=13.076102514545374, w1=-68.40052891392409\n",
      "Gradient Descent(1037/9999): loss=16516.190414704877, w0=13.076102514545374, w1=-68.40052891392409\n",
      "Gradient Descent(1038/9999): loss=16516.190414704877, w0=8.679002514545374, w1=-74.86312891392409\n",
      "Gradient Descent(1039/9999): loss=9039.777325339095, w0=8.679002514545374, w1=-74.86312891392409\n",
      "Gradient Descent(1040/9999): loss=9039.777325339095, w0=8.679002514545374, w1=-74.86312891392409\n",
      "Gradient Descent(1041/9999): loss=9039.777325339095, w0=-13.453297485454627, w1=-87.14522891392409\n",
      "Gradient Descent(1042/9999): loss=5489.237441079331, w0=-0.13579748545462422, w1=-77.74802891392409\n",
      "Gradient Descent(1043/9999): loss=5407.994965671417, w0=-12.926197485454624, w1=-84.55782891392408\n",
      "Gradient Descent(1044/9999): loss=5663.84465846953, w0=-12.926197485454624, w1=-84.55782891392408\n",
      "Gradient Descent(1045/9999): loss=5663.84465846953, w0=-12.926197485454624, w1=-84.55782891392408\n",
      "Gradient Descent(1046/9999): loss=5663.84465846953, w0=-12.926197485454624, w1=-84.55782891392408\n",
      "Gradient Descent(1047/9999): loss=5663.84465846953, w0=0.47230251454537786, w1=-83.59002891392409\n",
      "Gradient Descent(1048/9999): loss=5030.862278616502, w0=0.47230251454537786, w1=-83.59002891392409\n",
      "Gradient Descent(1049/9999): loss=5030.862278616502, w0=0.47230251454537786, w1=-83.59002891392409\n",
      "Gradient Descent(1050/9999): loss=5030.862278616502, w0=0.47230251454537786, w1=-83.59002891392409\n",
      "Gradient Descent(1051/9999): loss=5030.862278616502, w0=0.47230251454537786, w1=-83.59002891392409\n",
      "Gradient Descent(1052/9999): loss=5030.862278616502, w0=-16.116597485454626, w1=-88.02612891392408\n",
      "Gradient Descent(1053/9999): loss=5802.4994844197445, w0=-0.9110974854546257, w1=-86.26102891392408\n",
      "Gradient Descent(1054/9999): loss=4724.419756479878, w0=-9.542697485454626, w1=-88.94872891392409\n",
      "Gradient Descent(1055/9999): loss=4890.123841136406, w0=-9.542697485454626, w1=-88.94872891392409\n",
      "Gradient Descent(1056/9999): loss=4890.123841136406, w0=1.3602025145453744, w1=-88.62372891392408\n",
      "Gradient Descent(1057/9999): loss=5150.506949544841, w0=1.3602025145453744, w1=-88.62372891392408\n",
      "Gradient Descent(1058/9999): loss=5150.506949544841, w0=-6.553997485454626, w1=-90.77802891392409\n",
      "Gradient Descent(1059/9999): loss=4501.300898225167, w0=4.423602514545377, w1=-87.31442891392409\n",
      "Gradient Descent(1060/9999): loss=6750.8743525219525, w0=4.423602514545377, w1=-87.31442891392409\n",
      "Gradient Descent(1061/9999): loss=6750.8743525219525, w0=4.423602514545377, w1=-87.31442891392409\n",
      "Gradient Descent(1062/9999): loss=6750.8743525219525, w0=4.423602514545377, w1=-87.31442891392409\n",
      "Gradient Descent(1063/9999): loss=6750.8743525219525, w0=4.423602514545377, w1=-87.31442891392409\n",
      "Gradient Descent(1064/9999): loss=6750.8743525219525, w0=4.423602514545377, w1=-87.31442891392409\n",
      "Gradient Descent(1065/9999): loss=6750.8743525219525, w0=-5.294197485454624, w1=-91.69372891392409\n",
      "Gradient Descent(1066/9999): loss=5194.090626125602, w0=-5.294197485454624, w1=-91.69372891392409\n",
      "Gradient Descent(1067/9999): loss=5194.090626125602, w0=6.7725679000989105, w1=-78.6618289139241\n",
      "Gradient Descent(1068/9999): loss=6357.065192333972, w0=6.7725679000989105, w1=-78.6618289139241\n",
      "Gradient Descent(1069/9999): loss=6357.065192333972, w0=6.7725679000989105, w1=-78.6618289139241\n",
      "Gradient Descent(1070/9999): loss=6357.065192333972, w0=6.7725679000989105, w1=-78.6618289139241\n",
      "Gradient Descent(1071/9999): loss=6357.065192333972, w0=-4.69503209990109, w1=-81.40782891392409\n",
      "Gradient Descent(1072/9999): loss=4624.4914835273175, w0=2.0651679000989107, w1=-75.99922891392409\n",
      "Gradient Descent(1073/9999): loss=4680.028755805814, w0=2.0651679000989107, w1=-75.99922891392409\n",
      "Gradient Descent(1074/9999): loss=4680.028755805814, w0=2.0651679000989107, w1=-75.99922891392409\n",
      "Gradient Descent(1075/9999): loss=4680.028755805814, w0=2.0651679000989107, w1=-75.99922891392409\n",
      "Gradient Descent(1076/9999): loss=4680.028755805814, w0=2.0651679000989107, w1=-75.99922891392409\n",
      "Gradient Descent(1077/9999): loss=4680.028755805814, w0=2.0651679000989107, w1=-75.99922891392409\n",
      "Gradient Descent(1078/9999): loss=4680.028755805814, w0=2.0651679000989107, w1=-75.99922891392409\n",
      "Gradient Descent(1079/9999): loss=4680.028755805814, w0=-8.26713209990109, w1=-78.55682891392408\n",
      "Gradient Descent(1080/9999): loss=5600.237297605697, w0=-8.26713209990109, w1=-78.55682891392408\n",
      "Gradient Descent(1081/9999): loss=5600.237297605697, w0=1.9108679000989106, w1=-72.73612891392408\n",
      "Gradient Descent(1082/9999): loss=4409.444726201997, w0=1.9108679000989106, w1=-72.73612891392408\n",
      "Gradient Descent(1083/9999): loss=4409.444726201997, w0=1.9108679000989106, w1=-72.73612891392408\n",
      "Gradient Descent(1084/9999): loss=4409.444726201997, w0=1.9108679000989106, w1=-72.73612891392408\n",
      "Gradient Descent(1085/9999): loss=4409.444726201997, w0=1.9108679000989106, w1=-72.73612891392408\n",
      "Gradient Descent(1086/9999): loss=4409.444726201997, w0=1.9108679000989106, w1=-72.73612891392408\n",
      "Gradient Descent(1087/9999): loss=4409.444726201997, w0=1.9108679000989106, w1=-72.73612891392408\n",
      "Gradient Descent(1088/9999): loss=4409.444726201997, w0=13.977633285652445, w1=-65.80372891392408\n",
      "Gradient Descent(1089/9999): loss=11981.08948780219, w0=13.977633285652445, w1=-65.80372891392408\n",
      "Gradient Descent(1090/9999): loss=11981.08948780219, w0=-10.36506671434756, w1=-67.87252891392407\n",
      "Gradient Descent(1091/9999): loss=5730.800038952124, w0=-10.36506671434756, w1=-67.87252891392407\n",
      "Gradient Descent(1092/9999): loss=5730.800038952124, w0=-2.78786671434756, w1=-64.66272891392407\n",
      "Gradient Descent(1093/9999): loss=4438.542610973024, w0=-2.78786671434756, w1=-64.66272891392407\n",
      "Gradient Descent(1094/9999): loss=4438.542610973024, w0=-2.78786671434756, w1=-64.66272891392407\n",
      "Gradient Descent(1095/9999): loss=4438.542610973024, w0=-2.78786671434756, w1=-64.66272891392407\n",
      "Gradient Descent(1096/9999): loss=4438.542610973024, w0=7.390133285652441, w1=-58.84202891392407\n",
      "Gradient Descent(1097/9999): loss=9936.272493910717, w0=7.390133285652441, w1=-58.84202891392407\n",
      "Gradient Descent(1098/9999): loss=9936.272493910717, w0=7.390133285652441, w1=-58.84202891392407\n",
      "Gradient Descent(1099/9999): loss=9936.272493910717, w0=1.3068332856524405, w1=-60.13362891392407\n",
      "Gradient Descent(1100/9999): loss=4532.6087364473415, w0=1.3068332856524405, w1=-60.13362891392407\n",
      "Gradient Descent(1101/9999): loss=4532.6087364473415, w0=1.3068332856524405, w1=-60.13362891392407\n",
      "Gradient Descent(1102/9999): loss=4532.6087364473415, w0=1.3068332856524405, w1=-60.13362891392407\n",
      "Gradient Descent(1103/9999): loss=4532.6087364473415, w0=1.3068332856524405, w1=-60.13362891392407\n",
      "Gradient Descent(1104/9999): loss=4532.6087364473415, w0=11.936333285652442, w1=-57.03502891392407\n",
      "Gradient Descent(1105/9999): loss=13882.88873232445, w0=5.419833285652441, w1=-62.92752891392407\n",
      "Gradient Descent(1106/9999): loss=4796.55196768856, w0=5.419833285652441, w1=-62.92752891392407\n",
      "Gradient Descent(1107/9999): loss=4796.55196768856, w0=5.419833285652441, w1=-62.92752891392407\n",
      "Gradient Descent(1108/9999): loss=4796.55196768856, w0=5.419833285653268, w1=-62.92752891392371\n",
      "Gradient Descent(1109/9999): loss=4796.551967688518, w0=5.419833285653268, w1=-62.92752891392371\n",
      "Gradient Descent(1110/9999): loss=4796.551967688518, w0=5.419833285653268, w1=-62.92752891392371\n",
      "Gradient Descent(1111/9999): loss=4796.551967688518, w0=5.419833285653268, w1=-62.92752891392371\n",
      "Gradient Descent(1112/9999): loss=4796.551967688518, w0=14.943133285653268, w1=-58.10712891392371\n",
      "Gradient Descent(1113/9999): loss=15019.060761794106, w0=14.943133285653268, w1=-58.10712891392371\n",
      "Gradient Descent(1114/9999): loss=15019.060761794106, w0=14.943133285653268, w1=-58.10712891392371\n",
      "Gradient Descent(1115/9999): loss=15019.060761794106, w0=4.991633285653267, w1=-61.04412891392371\n",
      "Gradient Descent(1116/9999): loss=4548.603869977478, w0=4.991633285653267, w1=-61.04412891392371\n",
      "Gradient Descent(1117/9999): loss=4548.603869977478, w0=4.991633285653267, w1=-61.04412891392371\n",
      "Gradient Descent(1118/9999): loss=4548.603869977478, w0=4.991633285653267, w1=-61.04412891392371\n",
      "Gradient Descent(1119/9999): loss=4548.603869977478, w0=-22.114066714346734, w1=-71.58682891392371\n",
      "Gradient Descent(1120/9999): loss=5802.4994844197445, w0=-22.114066714346734, w1=-71.58682891392371\n",
      "Gradient Descent(1121/9999): loss=5802.4994844197445, w0=-22.114066714346734, w1=-71.58682891392371\n",
      "Gradient Descent(1122/9999): loss=5802.4994844197445, w0=-22.114066714346734, w1=-71.58682891392371\n",
      "Gradient Descent(1123/9999): loss=5802.4994844197445, w0=-22.114066714346734, w1=-71.58682891392371\n",
      "Gradient Descent(1124/9999): loss=5802.4994844197445, w0=-22.114066714346734, w1=-71.58682891392371\n",
      "Gradient Descent(1125/9999): loss=5802.4994844197445, w0=-10.341066714346733, w1=-63.85862891392371\n",
      "Gradient Descent(1126/9999): loss=5802.4994844197445, w0=1.4804332856532678, w1=-61.73672891392371\n",
      "Gradient Descent(1127/9999): loss=4655.146160395247, w0=1.4804332856532678, w1=-61.73672891392371\n",
      "Gradient Descent(1128/9999): loss=4655.146160395247, w0=1.4804332856532678, w1=-61.73672891392371\n",
      "Gradient Descent(1129/9999): loss=4655.146160395247, w0=1.4804332856532678, w1=-61.73672891392371\n",
      "Gradient Descent(1130/9999): loss=4655.146160395247, w0=1.4804332856532678, w1=-61.73672891392371\n",
      "Gradient Descent(1131/9999): loss=4655.146160395247, w0=1.4804332856532678, w1=-61.73672891392371\n",
      "Gradient Descent(1132/9999): loss=4655.146160395247, w0=13.547198671206802, w1=-52.554828913923714\n",
      "Gradient Descent(1133/9999): loss=16869.993902445294, w0=-9.936001328793198, w1=-62.558728913923716\n",
      "Gradient Descent(1134/9999): loss=5802.4994844197445, w0=-9.936001328793198, w1=-62.558728913923716\n",
      "Gradient Descent(1135/9999): loss=5802.4994844197445, w0=-9.936001328793198, w1=-62.558728913923716\n",
      "Gradient Descent(1136/9999): loss=5802.4994844197445, w0=-9.936001328793198, w1=-62.558728913923716\n",
      "Gradient Descent(1137/9999): loss=5802.4994844197445, w0=-9.936001328793198, w1=-62.558728913923716\n",
      "Gradient Descent(1138/9999): loss=5802.4994844197445, w0=-9.936001328793198, w1=-62.558728913923716\n",
      "Gradient Descent(1139/9999): loss=5802.4994844197445, w0=2.6677986712068016, w1=-59.390428913923714\n",
      "Gradient Descent(1140/9999): loss=4753.184916356409, w0=2.6677986712068016, w1=-59.390428913923714\n",
      "Gradient Descent(1141/9999): loss=4753.184916356409, w0=2.6677986712068016, w1=-59.390428913923714\n",
      "Gradient Descent(1142/9999): loss=4753.184916356409, w0=2.6677986712068016, w1=-59.390428913923714\n",
      "Gradient Descent(1143/9999): loss=4753.184916356409, w0=2.6677986712068016, w1=-59.390428913923714\n",
      "Gradient Descent(1144/9999): loss=4753.184916356409, w0=13.405298671206802, w1=-59.023428913923716\n",
      "Gradient Descent(1145/9999): loss=10709.765286352249, w0=-5.361401328793198, w1=-67.85832891392371\n",
      "Gradient Descent(1146/9999): loss=4907.381631303611, w0=-5.361401328793198, w1=-67.85832891392371\n",
      "Gradient Descent(1147/9999): loss=4907.381631303611, w0=-5.361401328793198, w1=-67.85832891392371\n",
      "Gradient Descent(1148/9999): loss=4907.381631303611, w0=-5.361401328793198, w1=-67.85832891392371\n",
      "Gradient Descent(1149/9999): loss=4907.381631303611, w0=-5.361401328793198, w1=-67.85832891392371\n",
      "Gradient Descent(1150/9999): loss=4907.381631303611, w0=-5.361401328793198, w1=-67.85832891392371\n",
      "Gradient Descent(1151/9999): loss=4907.381631303611, w0=7.380598671206803, w1=-63.71572891392371\n",
      "Gradient Descent(1152/9999): loss=8192.136055334628, w0=7.380598671206803, w1=-63.71572891392371\n",
      "Gradient Descent(1153/9999): loss=8192.136055334628, w0=-1.018801328793197, w1=-65.24012891392371\n",
      "Gradient Descent(1154/9999): loss=4454.327064361141, w0=8.306898671206804, w1=-62.25032891392371\n",
      "Gradient Descent(1155/9999): loss=11175.887542083168, w0=-0.3337013287931967, w1=-65.64292891392371\n",
      "Gradient Descent(1156/9999): loss=4383.888269592371, w0=-0.3337013287931967, w1=-65.64292891392371\n",
      "Gradient Descent(1157/9999): loss=4383.888269592371, w0=9.844298671206804, w1=-59.82222891392371\n",
      "Gradient Descent(1158/9999): loss=11714.671457555003, w0=-13.141401328793197, w1=-65.6243289139237\n",
      "Gradient Descent(1159/9999): loss=5571.4914629266805, w0=-13.141401328793197, w1=-65.6243289139237\n",
      "Gradient Descent(1160/9999): loss=5571.4914629266805, w0=-13.141401328793197, w1=-65.6243289139237\n",
      "Gradient Descent(1161/9999): loss=5571.4914629266805, w0=-13.141401328793197, w1=-65.6243289139237\n",
      "Gradient Descent(1162/9999): loss=5571.4914629266805, w0=-4.016301328793196, w1=-63.309228913923704\n",
      "Gradient Descent(1163/9999): loss=4809.034898347714, w0=-4.016301328793196, w1=-63.309228913923704\n",
      "Gradient Descent(1164/9999): loss=4809.034898347714, w0=-4.016301328793196, w1=-63.309228913923704\n",
      "Gradient Descent(1165/9999): loss=4809.034898347714, w0=8.258798671206806, w1=-58.1276289139237\n",
      "Gradient Descent(1166/9999): loss=16107.531313810723, w0=-24.161301328793193, w1=-61.8282289139237\n",
      "Gradient Descent(1167/9999): loss=5802.121052250607, w0=-24.161301328793193, w1=-61.8282289139237\n",
      "Gradient Descent(1168/9999): loss=5802.121052250607, w0=-24.161301328793193, w1=-61.8282289139237\n",
      "Gradient Descent(1169/9999): loss=5802.121052250607, w0=-24.161301328793193, w1=-61.8282289139237\n",
      "Gradient Descent(1170/9999): loss=5802.121052250607, w0=-11.865501328793194, w1=-61.4589289139237\n",
      "Gradient Descent(1171/9999): loss=7086.197976827918, w0=-11.865501328793194, w1=-61.4589289139237\n",
      "Gradient Descent(1172/9999): loss=7086.197976827918, w0=-26.067201328793196, w1=-62.2449289139237\n",
      "Gradient Descent(1173/9999): loss=5803.488926884147, w0=-12.792101328793194, w1=-59.2401289139237\n",
      "Gradient Descent(1174/9999): loss=9487.062633823678, w0=-18.975901328793196, w1=-66.7128289139237\n",
      "Gradient Descent(1175/9999): loss=4754.735001480389, w0=-18.975901328793196, w1=-66.7128289139237\n",
      "Gradient Descent(1176/9999): loss=4754.735001480389, w0=-18.975901328793196, w1=-66.7128289139237\n",
      "Gradient Descent(1177/9999): loss=4754.735001480389, w0=-24.475301328793197, w1=-70.1690289139237\n",
      "Gradient Descent(1178/9999): loss=5802.4994844197445, w0=-13.764801328793196, w1=-66.1411289139237\n",
      "Gradient Descent(1179/9999): loss=5131.240307057889, w0=-13.764801328793196, w1=-66.1411289139237\n",
      "Gradient Descent(1180/9999): loss=5131.240307057889, w0=-13.764801328793196, w1=-66.1411289139237\n",
      "Gradient Descent(1181/9999): loss=5131.240307057889, w0=-13.764801328793196, w1=-66.1411289139237\n",
      "Gradient Descent(1182/9999): loss=5131.240307057889, w0=-13.764801328793196, w1=-66.1411289139237\n",
      "Gradient Descent(1183/9999): loss=5131.240307057889, w0=-13.764801328793196, w1=-66.1411289139237\n",
      "Gradient Descent(1184/9999): loss=5131.240307057889, w0=-13.764801328793196, w1=-66.1411289139237\n",
      "Gradient Descent(1185/9999): loss=5131.240307057889, w0=-13.764801328793196, w1=-66.1411289139237\n",
      "Gradient Descent(1186/9999): loss=5131.240307057889, w0=-13.764801328793196, w1=-66.1411289139237\n",
      "Gradient Descent(1187/9999): loss=5131.240307057889, w0=-13.764801328793196, w1=-66.1411289139237\n",
      "Gradient Descent(1188/9999): loss=5131.240307057889, w0=-0.44730132879319306, w1=-56.743928913923696\n",
      "Gradient Descent(1189/9999): loss=16314.532136358808, w0=-0.44730132879319306, w1=-56.743928913923696\n",
      "Gradient Descent(1190/9999): loss=16314.532136358808, w0=-12.514066714346727, w1=-64.5741289139237\n",
      "Gradient Descent(1191/9999): loss=5436.890845734793, w0=-12.514066714346727, w1=-64.5741289139237\n",
      "Gradient Descent(1192/9999): loss=5436.890845734793, w0=-12.514066714346727, w1=-64.5741289139237\n",
      "Gradient Descent(1193/9999): loss=5436.890845734793, w0=-2.3360667143467264, w1=-58.7534289139237\n",
      "Gradient Descent(1194/9999): loss=14919.34396416268, w0=-2.3360667143467264, w1=-58.7534289139237\n",
      "Gradient Descent(1195/9999): loss=14919.34396416268, w0=-14.40283209990026, w1=-66.7218289139237\n",
      "Gradient Descent(1196/9999): loss=4698.1907014516455, w0=-22.489432099900263, w1=-69.7258289139237\n",
      "Gradient Descent(1197/9999): loss=5779.473709908169, w0=-11.324732099900261, w1=-61.763028913923705\n",
      "Gradient Descent(1198/9999): loss=5087.445979271713, w0=-11.324732099900261, w1=-61.763028913923705\n",
      "Gradient Descent(1199/9999): loss=5087.445979271713, w0=-11.324732099900261, w1=-61.763028913923705\n",
      "Gradient Descent(1200/9999): loss=5087.445979271713, w0=-11.324732099900261, w1=-61.763028913923705\n",
      "Gradient Descent(1201/9999): loss=5087.445979271713, w0=-11.324732099900261, w1=-61.763028913923705\n",
      "Gradient Descent(1202/9999): loss=5087.445979271713, w0=-11.324732099900265, w1=-61.763028913923705\n",
      "Gradient Descent(1203/9999): loss=5087.445979271707, w0=-11.324732099900265, w1=-61.763028913923705\n",
      "Gradient Descent(1204/9999): loss=5087.445979271707, w0=-11.324732099900265, w1=-61.763028913923705\n",
      "Gradient Descent(1205/9999): loss=5087.445979271707, w0=-11.324732099900265, w1=-61.763028913923705\n",
      "Gradient Descent(1206/9999): loss=5087.445979271707, w0=-11.324732099900265, w1=-61.763028913923705\n",
      "Gradient Descent(1207/9999): loss=5087.445979271707, w0=-11.324732099900265, w1=-61.763028913923705\n",
      "Gradient Descent(1208/9999): loss=5087.445979271707, w0=-11.324732099900265, w1=-61.763028913923705\n",
      "Gradient Descent(1209/9999): loss=5087.445979271707, w0=-11.324732099900265, w1=-61.763028913923705\n",
      "Gradient Descent(1210/9999): loss=5087.445979271707, w0=-16.169332099900267, w1=-66.49472891392371\n",
      "Gradient Descent(1211/9999): loss=5710.241499757074, w0=-16.169332099900267, w1=-66.49472891392371\n",
      "Gradient Descent(1212/9999): loss=5710.241499757074, w0=-16.169332099900267, w1=-66.49472891392371\n",
      "Gradient Descent(1213/9999): loss=5710.241499757074, w0=-16.169332099900267, w1=-66.49472891392371\n",
      "Gradient Descent(1214/9999): loss=5710.241499757074, w0=-4.571332099900266, w1=-65.9484289139237\n",
      "Gradient Descent(1215/9999): loss=4651.05540207289, w0=-4.571332099900266, w1=-65.9484289139237\n",
      "Gradient Descent(1216/9999): loss=4651.05540207289, w0=-4.571332099900266, w1=-65.9484289139237\n",
      "Gradient Descent(1217/9999): loss=4651.05540207289, w0=-4.571332099900266, w1=-65.9484289139237\n",
      "Gradient Descent(1218/9999): loss=4651.05540207289, w0=-4.571332099900266, w1=-65.9484289139237\n",
      "Gradient Descent(1219/9999): loss=4651.05540207289, w0=-4.571332099900266, w1=-65.9484289139237\n",
      "Gradient Descent(1220/9999): loss=4651.05540207289, w0=-4.571332099900266, w1=-65.9484289139237\n",
      "Gradient Descent(1221/9999): loss=4651.05540207289, w0=7.5710679000997345, w1=-63.033328913923704\n",
      "Gradient Descent(1222/9999): loss=16486.300694807585, w0=-4.4956974854538, w1=-71.6611289139237\n",
      "Gradient Descent(1223/9999): loss=5267.786869675852, w0=-4.4956974854538, w1=-71.6611289139237\n",
      "Gradient Descent(1224/9999): loss=5267.786869675852, w0=-4.4956974854538, w1=-71.6611289139237\n",
      "Gradient Descent(1225/9999): loss=5267.786869675852, w0=7.5710679000997345, w1=-59.5739289139237\n",
      "Gradient Descent(1226/9999): loss=17174.19250830947, w0=-2.615032099900267, w1=-66.5368289139237\n",
      "Gradient Descent(1227/9999): loss=10747.252383247418, w0=-2.6150321009117103, w1=-66.53682891433962\n",
      "Gradient Descent(1228/9999): loss=10747.252382860897, w0=-2.6150321009117103, w1=-66.53682891433962\n",
      "Gradient Descent(1229/9999): loss=10747.252382860897, w0=-2.6150321009117103, w1=-66.53682891433962\n",
      "Gradient Descent(1230/9999): loss=10747.252382860897, w0=-2.6150321009117103, w1=-66.53682891433962\n",
      "Gradient Descent(1231/9999): loss=10747.252382860897, w0=-2.6150321009117103, w1=-66.53682891433962\n",
      "Gradient Descent(1232/9999): loss=10747.252382860897, w0=-12.860132100911711, w1=-73.55512891433962\n",
      "Gradient Descent(1233/9999): loss=4471.425156382303, w0=-12.860132100911711, w1=-73.55512891433962\n",
      "Gradient Descent(1234/9999): loss=4471.425156382303, w0=-25.543432100911712, w1=-75.60752891433962\n",
      "Gradient Descent(1235/9999): loss=5802.4994844197445, w0=-25.543432100911712, w1=-75.60752891433962\n",
      "Gradient Descent(1236/9999): loss=5802.4994844197445, w0=-25.543432100911712, w1=-75.60752891433962\n",
      "Gradient Descent(1237/9999): loss=5802.4994844197445, w0=-25.543432100911712, w1=-75.60752891433962\n",
      "Gradient Descent(1238/9999): loss=5802.4994844197445, w0=-25.543432100911712, w1=-75.60752891433962\n",
      "Gradient Descent(1239/9999): loss=5802.4994844197445, w0=-25.543432100911712, w1=-75.60752891433962\n",
      "Gradient Descent(1240/9999): loss=5802.4994844197445, w0=-17.16103210091171, w1=-72.99922891433962\n",
      "Gradient Descent(1241/9999): loss=5042.770094158542, w0=-17.16103210091171, w1=-72.99922891433962\n",
      "Gradient Descent(1242/9999): loss=5042.770094158542, w0=-6.729232100911711, w1=-68.62622891433962\n",
      "Gradient Descent(1243/9999): loss=6600.967898936574, w0=-6.729232100911711, w1=-68.62622891433962\n",
      "Gradient Descent(1244/9999): loss=6600.967898936574, w0=-6.729232100911711, w1=-68.62622891433962\n",
      "Gradient Descent(1245/9999): loss=6600.967898936574, w0=-6.729247190730782, w1=-68.62623491344351\n",
      "Gradient Descent(1246/9999): loss=6600.963859857899, w0=-14.474147190730783, w1=-72.55453491344352\n",
      "Gradient Descent(1247/9999): loss=4626.521840067204, w0=-5.528547190730782, w1=-63.96593491344352\n",
      "Gradient Descent(1248/9999): loss=9366.789912678116, w0=-5.528547190730782, w1=-63.96593491344352\n",
      "Gradient Descent(1249/9999): loss=9366.789912678116, w0=-5.528547190730782, w1=-63.96593491344352\n",
      "Gradient Descent(1250/9999): loss=9366.789912678116, w0=-5.528547190730782, w1=-63.96593491344352\n",
      "Gradient Descent(1251/9999): loss=9366.789912678116, w0=-9.220347190730783, w1=-70.70673491344351\n",
      "Gradient Descent(1252/9999): loss=4536.157723391567, w0=-9.220347190730783, w1=-70.70673491344351\n",
      "Gradient Descent(1253/9999): loss=4536.157723391567, w0=-9.220347190730783, w1=-70.70673491344351\n",
      "Gradient Descent(1254/9999): loss=4536.157723391567, w0=3.3117528092692172, w1=-68.8889349134435\n",
      "Gradient Descent(1255/9999): loss=14337.91834091011, w0=-6.819847190730783, w1=-73.4115349134435\n",
      "Gradient Descent(1256/9999): loss=5336.503110335762, w0=-6.819847190730783, w1=-73.4115349134435\n",
      "Gradient Descent(1257/9999): loss=5336.503110335762, w0=-6.819847190730783, w1=-73.4115349134435\n",
      "Gradient Descent(1258/9999): loss=5336.503110335762, w0=-6.819847190730783, w1=-73.4115349134435\n",
      "Gradient Descent(1259/9999): loss=5336.503110335762, w0=-6.819847190730783, w1=-73.4115349134435\n",
      "Gradient Descent(1260/9999): loss=5336.503110335762, w0=-6.819847190730783, w1=-73.4115349134435\n",
      "Gradient Descent(1261/9999): loss=5336.503110335762, w0=-6.819847190730783, w1=-73.4115349134435\n",
      "Gradient Descent(1262/9999): loss=5336.503110335762, w0=-6.819847190730783, w1=-73.4115349134435\n",
      "Gradient Descent(1263/9999): loss=5336.503110335762, w0=4.6119528092692175, w1=-64.8099349134435\n",
      "Gradient Descent(1264/9999): loss=17177.279723760927, w0=-9.591747190730784, w1=-76.1164349134435\n",
      "Gradient Descent(1265/9999): loss=5775.982703003527, w0=-19.844747190730786, w1=-77.1379349134435\n",
      "Gradient Descent(1266/9999): loss=4681.512150820653, w0=-19.844747190730786, w1=-77.1379349134435\n",
      "Gradient Descent(1267/9999): loss=4681.512150820653, w0=-19.844747190730786, w1=-77.1379349134435\n",
      "Gradient Descent(1268/9999): loss=4681.512150820653, w0=-19.844747190730786, w1=-77.1379349134435\n",
      "Gradient Descent(1269/9999): loss=4681.512150820653, w0=-31.91151257628432, w1=-85.8395349134435\n",
      "Gradient Descent(1270/9999): loss=5802.4994844197445, w0=-31.91151257628432, w1=-85.8395349134435\n",
      "Gradient Descent(1271/9999): loss=5802.4994844197445, w0=-31.91151257628432, w1=-85.8395349134435\n",
      "Gradient Descent(1272/9999): loss=5802.4994844197445, w0=-31.91151257628432, w1=-85.8395349134435\n",
      "Gradient Descent(1273/9999): loss=5802.4994844197445, w0=-31.91151257628432, w1=-85.8395349134435\n",
      "Gradient Descent(1274/9999): loss=5802.4994844197445, w0=-31.91151257628432, w1=-85.8395349134435\n",
      "Gradient Descent(1275/9999): loss=5802.4994844197445, w0=-24.633512576284318, w1=-82.5744349134435\n",
      "Gradient Descent(1276/9999): loss=5779.473613489938, w0=-24.633512576284318, w1=-82.5744349134435\n",
      "Gradient Descent(1277/9999): loss=5779.473613489938, w0=-24.633512576284318, w1=-82.5744349134435\n",
      "Gradient Descent(1278/9999): loss=5779.473613489938, w0=-24.633512576284318, w1=-82.5744349134435\n",
      "Gradient Descent(1279/9999): loss=5779.473613489938, w0=-24.633512576284318, w1=-82.5744349134435\n",
      "Gradient Descent(1280/9999): loss=5779.473613489938, w0=-24.633512576284318, w1=-82.5744349134435\n",
      "Gradient Descent(1281/9999): loss=5779.473613489938, w0=-24.633512576284318, w1=-82.5744349134435\n",
      "Gradient Descent(1282/9999): loss=5779.473613489938, w0=-24.633512576284318, w1=-82.5744349134435\n",
      "Gradient Descent(1283/9999): loss=5779.473613489938, w0=-24.633512576284318, w1=-82.5744349134435\n",
      "Gradient Descent(1284/9999): loss=5779.473613489938, w0=-24.633512576284318, w1=-82.5744349134435\n",
      "Gradient Descent(1285/9999): loss=5779.473613489938, w0=-24.633512576284318, w1=-82.5744349134435\n",
      "Gradient Descent(1286/9999): loss=5779.473613489938, w0=-24.633512576284318, w1=-82.5744349134435\n",
      "Gradient Descent(1287/9999): loss=5779.473613489938, w0=-16.884012576284317, w1=-77.7821349134435\n",
      "Gradient Descent(1288/9999): loss=4606.131228017119, w0=-16.884012576284317, w1=-77.7821349134435\n",
      "Gradient Descent(1289/9999): loss=4606.131228017119, w0=-16.884012576284317, w1=-77.7821349134435\n",
      "Gradient Descent(1290/9999): loss=4606.131228017119, w0=-16.884012576284317, w1=-77.7821349134435\n",
      "Gradient Descent(1291/9999): loss=4606.131228017119, w0=-16.884012576284317, w1=-77.7821349134435\n",
      "Gradient Descent(1292/9999): loss=4606.131228017119, w0=-25.002412576284314, w1=-79.0892349134435\n",
      "Gradient Descent(1293/9999): loss=5790.986548954825, w0=-14.956412576284315, w1=-79.0116349134435\n",
      "Gradient Descent(1294/9999): loss=4660.633383857887, w0=-24.276912576284317, w1=-81.5802349134435\n",
      "Gradient Descent(1295/9999): loss=5802.4994844197445, w0=-24.276912576284317, w1=-81.5802349134435\n",
      "Gradient Descent(1296/9999): loss=5802.4994844197445, w0=-15.171412576284316, w1=-79.5968349134435\n",
      "Gradient Descent(1297/9999): loss=4509.307025441161, w0=-15.171412576284316, w1=-79.5968349134435\n",
      "Gradient Descent(1298/9999): loss=4509.307025441161, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1299/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1300/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1301/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1302/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1303/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1304/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1305/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1306/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1307/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1308/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1309/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1310/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1311/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1312/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1313/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1314/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1315/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1316/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1317/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1318/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1319/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1320/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1321/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1322/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1323/9999): loss=4509.30702544116, w0=-15.171412576284325, w1=-79.5968349134435\n",
      "Gradient Descent(1324/9999): loss=4509.30702544116, w0=3.7195874237156765, w1=-71.4136349134435\n",
      "Gradient Descent(1325/9999): loss=13159.26523982346, w0=-8.347177961837858, w1=-81.2817349134435\n",
      "Gradient Descent(1326/9999): loss=4393.48288236126, w0=-8.347177961837858, w1=-81.2817349134435\n",
      "Gradient Descent(1327/9999): loss=4393.48288236126, w0=2.1168220381621428, w1=-74.1376349134435\n",
      "Gradient Descent(1328/9999): loss=8349.056882879471, w0=-10.673577961837857, w1=-80.9474349134435\n",
      "Gradient Descent(1329/9999): loss=4694.166124842649, w0=-10.673577961837857, w1=-80.9474349134435\n",
      "Gradient Descent(1330/9999): loss=4694.166124842649, w0=-10.673577961837857, w1=-80.9474349134435\n",
      "Gradient Descent(1331/9999): loss=4694.166124842649, w0=0.30402203816214524, w1=-77.4838349134435\n",
      "Gradient Descent(1332/9999): loss=5998.771596929607, w0=0.30402203816214524, w1=-77.4838349134435\n",
      "Gradient Descent(1333/9999): loss=5998.771596929607, w0=0.30402203816214524, w1=-77.4838349134435\n",
      "Gradient Descent(1334/9999): loss=5998.771596929607, w0=0.30402203816214524, w1=-77.4838349134435\n",
      "Gradient Descent(1335/9999): loss=5998.771596929607, w0=0.30402203816214524, w1=-77.4838349134435\n",
      "Gradient Descent(1336/9999): loss=5998.771596929607, w0=0.30402203816214524, w1=-77.4838349134435\n",
      "Gradient Descent(1337/9999): loss=5998.771596929607, w0=0.30402203816214524, w1=-77.4838349134435\n",
      "Gradient Descent(1338/9999): loss=5998.771596929607, w0=0.30402203816214524, w1=-77.4838349134435\n",
      "Gradient Descent(1339/9999): loss=5998.771596929607, w0=0.30402203816214524, w1=-77.4838349134435\n",
      "Gradient Descent(1340/9999): loss=5998.771596929607, w0=-11.568677961837857, w1=-80.6910349134435\n",
      "Gradient Descent(1341/9999): loss=4455.486595590586, w0=-25.350577961837857, w1=-83.3465349134435\n",
      "Gradient Descent(1342/9999): loss=5802.4994844197445, w0=-25.350577961837857, w1=-83.3465349134435\n",
      "Gradient Descent(1343/9999): loss=5802.4994844197445, w0=-25.350577961837857, w1=-83.3465349134435\n",
      "Gradient Descent(1344/9999): loss=5802.4994844197445, w0=-25.350577961837857, w1=-83.3465349134435\n",
      "Gradient Descent(1345/9999): loss=5802.4994844197445, w0=-25.350577961837857, w1=-83.3465349134435\n",
      "Gradient Descent(1346/9999): loss=5802.4994844197445, w0=-25.350577961837857, w1=-83.3465349134435\n",
      "Gradient Descent(1347/9999): loss=5802.4994844197445, w0=-13.758377961837855, w1=-82.00553491344351\n",
      "Gradient Descent(1348/9999): loss=4865.5817427268785, w0=-13.758377961837855, w1=-82.00553491344351\n",
      "Gradient Descent(1349/9999): loss=4865.5817427268785, w0=-13.758377961837855, w1=-82.00553491344351\n",
      "Gradient Descent(1350/9999): loss=4865.5817427268785, w0=-13.758377961837855, w1=-82.00553491344351\n",
      "Gradient Descent(1351/9999): loss=4865.5817427268785, w0=-13.758377961837855, w1=-82.00553491344351\n",
      "Gradient Descent(1352/9999): loss=4865.5817427268785, w0=-13.758377961837855, w1=-82.00553491344351\n",
      "Gradient Descent(1353/9999): loss=4865.5817427268785, w0=-13.758377961837855, w1=-82.00553491344351\n",
      "Gradient Descent(1354/9999): loss=4865.5817427268785, w0=-4.782077961837855, w1=-78.05873491344352\n",
      "Gradient Descent(1355/9999): loss=4901.183466374087, w0=-4.782077961837855, w1=-78.05873491344352\n",
      "Gradient Descent(1356/9999): loss=4901.183466374087, w0=4.337922038162146, w1=-73.78533491344352\n",
      "Gradient Descent(1357/9999): loss=13055.725776537707, w0=-7.701477961837854, w1=-79.00723491344353\n",
      "Gradient Descent(1358/9999): loss=4697.815548707535, w0=-7.701477961837854, w1=-79.00723491344353\n",
      "Gradient Descent(1359/9999): loss=4697.815548707535, w0=-7.701477961837854, w1=-79.00723491344353\n",
      "Gradient Descent(1360/9999): loss=4697.815548707535, w0=-7.701477961837854, w1=-79.00723491344353\n",
      "Gradient Descent(1361/9999): loss=4697.815548707535, w0=-7.701477961837854, w1=-79.00723491344353\n",
      "Gradient Descent(1362/9999): loss=4697.815548707535, w0=-7.701477963850126, w1=-79.00723491404605\n",
      "Gradient Descent(1363/9999): loss=4697.815548872815, w0=-7.701477963850126, w1=-79.00723491404605\n",
      "Gradient Descent(1364/9999): loss=4697.815548872815, w0=-7.701477963850126, w1=-79.00723491404605\n",
      "Gradient Descent(1365/9999): loss=4697.815548872815, w0=-7.701477963850126, w1=-79.00723491404605\n",
      "Gradient Descent(1366/9999): loss=4697.815548872815, w0=-7.701477963850126, w1=-79.00723491404605\n",
      "Gradient Descent(1367/9999): loss=4697.815548872815, w0=-7.701477963850126, w1=-79.00723491404605\n",
      "Gradient Descent(1368/9999): loss=4697.815548872815, w0=-7.701477963850126, w1=-79.00723491404605\n",
      "Gradient Descent(1369/9999): loss=4697.815548872815, w0=-7.701477963850126, w1=-79.00723491404605\n",
      "Gradient Descent(1370/9999): loss=4697.815548872815, w0=-7.701477963850126, w1=-79.00723491404605\n",
      "Gradient Descent(1371/9999): loss=4697.815548872815, w0=-7.701477963850126, w1=-79.00723491404605\n",
      "Gradient Descent(1372/9999): loss=4697.815548872815, w0=-7.701477963850126, w1=-79.00723491404605\n",
      "Gradient Descent(1373/9999): loss=4697.815548872815, w0=-19.522177963850126, w1=-79.18593491404606\n",
      "Gradient Descent(1374/9999): loss=5478.03488012455, w0=-19.522177963850126, w1=-79.18593491404606\n",
      "Gradient Descent(1375/9999): loss=5478.03488012455, w0=-19.52217780896938, w1=-79.18593490839113\n",
      "Gradient Descent(1376/9999): loss=5478.034829845483, w0=-19.52217780896938, w1=-79.18593490839113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(1377/9999): loss=5478.034829845483, w0=-19.52217780896938, w1=-79.18593490839113\n",
      "Gradient Descent(1378/9999): loss=5478.034829845483, w0=-7.455412423415847, w1=-69.22963490839113\n",
      "Gradient Descent(1379/9999): loss=5258.6054595730075, w0=-15.440412423415847, w1=-71.06423490839113\n",
      "Gradient Descent(1380/9999): loss=4469.151864225009, w0=-15.440412423415847, w1=-71.06423490839113\n",
      "Gradient Descent(1381/9999): loss=4469.151864225009, w0=-15.440412423415847, w1=-71.06423490839113\n",
      "Gradient Descent(1382/9999): loss=4469.151864225009, w0=-3.3736470378623125, w1=-61.10793490839113\n",
      "Gradient Descent(1383/9999): loss=10047.645032839806, w0=-12.132047037862312, w1=-64.92613490839113\n",
      "Gradient Descent(1384/9999): loss=4441.067710070276, w0=-12.132047037862312, w1=-64.92613490839113\n",
      "Gradient Descent(1385/9999): loss=4441.067710070276, w0=-12.132047037862312, w1=-64.92613490839113\n",
      "Gradient Descent(1386/9999): loss=4441.067710070276, w0=-12.132047037862312, w1=-64.92613490839113\n",
      "Gradient Descent(1387/9999): loss=4441.067710070276, w0=-12.132047037862312, w1=-64.92613490839113\n",
      "Gradient Descent(1388/9999): loss=4441.067710070276, w0=-12.132047037862312, w1=-64.92613490839113\n",
      "Gradient Descent(1389/9999): loss=4441.067710070276, w0=-12.132047037862312, w1=-64.92613490839113\n",
      "Gradient Descent(1390/9999): loss=4441.067710070276, w0=-12.132047037862312, w1=-64.92613490839113\n",
      "Gradient Descent(1391/9999): loss=4441.067710070276, w0=-12.132047037862312, w1=-64.92613490839113\n",
      "Gradient Descent(1392/9999): loss=4441.067710070276, w0=-27.003847037862315, w1=-65.04683490839113\n",
      "Gradient Descent(1393/9999): loss=5802.4994844197445, w0=-27.003847037862315, w1=-65.04683490839113\n",
      "Gradient Descent(1394/9999): loss=5802.4994844197445, w0=-27.003847037862315, w1=-65.04683490839113\n",
      "Gradient Descent(1395/9999): loss=5802.4994844197445, w0=-27.003847037862315, w1=-65.04683490839113\n",
      "Gradient Descent(1396/9999): loss=5802.4994844197445, w0=-27.003847037862315, w1=-65.04683490839113\n",
      "Gradient Descent(1397/9999): loss=5802.4994844197445, w0=-27.003847037862315, w1=-65.04683490839113\n",
      "Gradient Descent(1398/9999): loss=5802.4994844197445, w0=-27.003847037862315, w1=-65.04683490839113\n",
      "Gradient Descent(1399/9999): loss=5802.4994844197445, w0=-27.003847037862315, w1=-65.04683490839113\n",
      "Gradient Descent(1400/9999): loss=5802.4994844197445, w0=-14.477947037862315, w1=-63.407334908391135\n",
      "Gradient Descent(1401/9999): loss=4721.304385907562, w0=-14.477947037862315, w1=-63.407334908391135\n",
      "Gradient Descent(1402/9999): loss=4721.304385907562, w0=-14.477947037862315, w1=-63.407334908391135\n",
      "Gradient Descent(1403/9999): loss=4721.304385907562, w0=-14.477947037862315, w1=-63.407334908391135\n",
      "Gradient Descent(1404/9999): loss=4721.304385907562, w0=-14.477947037862315, w1=-63.407334908391135\n",
      "Gradient Descent(1405/9999): loss=4721.304385907562, w0=-14.477947037862315, w1=-63.407334908391135\n",
      "Gradient Descent(1406/9999): loss=4721.304385907562, w0=-23.705947037862316, w1=-63.614734908391135\n",
      "Gradient Descent(1407/9999): loss=5802.4994844197445, w0=-23.705947037862316, w1=-63.614734908391135\n",
      "Gradient Descent(1408/9999): loss=5802.4994844197445, w0=-23.705947037862316, w1=-63.614734908391135\n",
      "Gradient Descent(1409/9999): loss=5802.4994844197445, w0=-23.705947037862316, w1=-63.614734908391135\n",
      "Gradient Descent(1410/9999): loss=5802.4994844197445, w0=-23.705947037862316, w1=-63.614734908391135\n",
      "Gradient Descent(1411/9999): loss=5802.4994844197445, w0=-23.705947037862316, w1=-63.614734908391135\n",
      "Gradient Descent(1412/9999): loss=5802.4994844197445, w0=-23.705947037862316, w1=-63.614734908391135\n",
      "Gradient Descent(1413/9999): loss=5802.4994844197445, w0=-23.705947037862316, w1=-63.614734908391135\n",
      "Gradient Descent(1414/9999): loss=5802.4994844197445, w0=-23.705947037862316, w1=-63.614734908391135\n",
      "Gradient Descent(1415/9999): loss=5802.4994844197445, w0=-23.705947037862316, w1=-63.614734908391135\n",
      "Gradient Descent(1416/9999): loss=5802.4994844197445, w0=-23.705947037862316, w1=-63.614734908391135\n",
      "Gradient Descent(1417/9999): loss=5802.4994844197445, w0=-15.430247037862316, w1=-57.28753490839114\n",
      "Gradient Descent(1418/9999): loss=4492.903488874506, w0=-5.391347037862316, w1=-54.792134908391134\n",
      "Gradient Descent(1419/9999): loss=12860.36494355179, w0=-5.391347037862316, w1=-54.792134908391134\n",
      "Gradient Descent(1420/9999): loss=12860.36494355179, w0=-13.329447037862316, w1=-59.99563490839113\n",
      "Gradient Descent(1421/9999): loss=4574.256756756891, w0=-13.329447037862316, w1=-59.99563490839113\n",
      "Gradient Descent(1422/9999): loss=4574.256756756891, w0=-13.329447037862316, w1=-59.99563490839113\n",
      "Gradient Descent(1423/9999): loss=4574.256756756891, w0=-26.778447037862318, w1=-60.66443490839113\n",
      "Gradient Descent(1424/9999): loss=5802.4994844197445, w0=-26.778447037862318, w1=-60.66443490839113\n",
      "Gradient Descent(1425/9999): loss=5802.4994844197445, w0=-17.335847037862315, w1=-57.961634908391126\n",
      "Gradient Descent(1426/9999): loss=4952.557874120995, w0=-17.335847037862315, w1=-57.961634908391126\n",
      "Gradient Descent(1427/9999): loss=4952.557874120995, w0=-17.335847037862315, w1=-57.961634908391126\n",
      "Gradient Descent(1428/9999): loss=4952.557874120995, w0=-17.335847037862315, w1=-57.961634908391126\n",
      "Gradient Descent(1429/9999): loss=4952.557874120995, w0=-17.335847037862315, w1=-57.961634908391126\n",
      "Gradient Descent(1430/9999): loss=4952.557874120995, w0=-17.335847037862315, w1=-57.961634908391126\n",
      "Gradient Descent(1431/9999): loss=4952.557874120995, w0=-17.335847037862315, w1=-57.961634908391126\n",
      "Gradient Descent(1432/9999): loss=4952.557874120995, w0=-17.335847037862315, w1=-57.961634908391126\n",
      "Gradient Descent(1433/9999): loss=4952.557874120995, w0=-17.335847037862315, w1=-57.961634908391126\n",
      "Gradient Descent(1434/9999): loss=4952.557874120995, w0=-17.335847037862315, w1=-57.961634908391126\n",
      "Gradient Descent(1435/9999): loss=4952.557874120995, w0=-17.335847037862315, w1=-57.961634908391126\n",
      "Gradient Descent(1436/9999): loss=4952.557874120995, w0=-17.335847037862315, w1=-57.961634908391126\n",
      "Gradient Descent(1437/9999): loss=4952.557874120995, w0=-17.335847037862315, w1=-57.961634908391126\n",
      "Gradient Descent(1438/9999): loss=4952.557874120995, w0=-17.335847037862315, w1=-57.961634908391126\n",
      "Gradient Descent(1439/9999): loss=4952.557874120995, w0=-17.335847037862315, w1=-57.961634908391126\n",
      "Gradient Descent(1440/9999): loss=4952.557874120995, w0=-10.164747037862316, w1=-54.61413490839112\n",
      "Gradient Descent(1441/9999): loss=7254.254594722124, w0=-10.164747037862316, w1=-54.61413490839112\n",
      "Gradient Descent(1442/9999): loss=7254.254594722124, w0=-10.164747037862316, w1=-54.61413490839112\n",
      "Gradient Descent(1443/9999): loss=7254.254594722124, w0=-10.164747037862316, w1=-54.61413490839112\n",
      "Gradient Descent(1444/9999): loss=7254.254594722124, w0=-19.68974703786232, w1=-57.01163490839112\n",
      "Gradient Descent(1445/9999): loss=4915.210048230732, w0=-19.68974703786232, w1=-57.01163490839112\n",
      "Gradient Descent(1446/9999): loss=4915.210048230732, w0=-19.68974703786232, w1=-57.01163490839112\n",
      "Gradient Descent(1447/9999): loss=4915.210048230732, w0=-31.51044703786232, w1=-57.19033490839112\n",
      "Gradient Descent(1448/9999): loss=5802.4994844197445, w0=-19.98564703786232, w1=-54.64363490839112\n",
      "Gradient Descent(1449/9999): loss=4624.151221382883, w0=-19.98564703786232, w1=-54.64363490839112\n",
      "Gradient Descent(1450/9999): loss=4624.151221382883, w0=-19.98564703786232, w1=-54.64363490839112\n",
      "Gradient Descent(1451/9999): loss=4624.151221382883, w0=-19.98564703786232, w1=-54.64363490839112\n",
      "Gradient Descent(1452/9999): loss=4624.151221382883, w0=-19.98564703786232, w1=-54.64363490839112\n",
      "Gradient Descent(1453/9999): loss=4624.151221382883, w0=-8.21264703786232, w1=-46.91543490839112\n",
      "Gradient Descent(1454/9999): loss=15733.359024482535, w0=-20.680447037862322, w1=-52.42473490839112\n",
      "Gradient Descent(1455/9999): loss=4615.191064170197, w0=-8.529247037862321, w1=-49.27073490839112\n",
      "Gradient Descent(1456/9999): loss=14886.82956527845, w0=-17.26304703786232, w1=-55.16673490839112\n",
      "Gradient Descent(1457/9999): loss=4932.677810039635, w0=-17.26304703786232, w1=-55.16673490839112\n",
      "Gradient Descent(1458/9999): loss=4932.677810039635, w0=-17.26304703786232, w1=-55.16673490839112\n",
      "Gradient Descent(1459/9999): loss=4932.677810039635, w0=-17.26304703786232, w1=-55.16673490839112\n",
      "Gradient Descent(1460/9999): loss=4932.677810039635, w0=-3.570447037862319, w1=-45.21493490839112\n",
      "Gradient Descent(1461/9999): loss=17085.118137838024, w0=-16.23134703786232, w1=-50.689734908391124\n",
      "Gradient Descent(1462/9999): loss=7988.160006372844, w0=-24.672847037862322, w1=-52.51713490839112\n",
      "Gradient Descent(1463/9999): loss=4698.496995439804, w0=-24.672847037862322, w1=-52.51713490839112\n",
      "Gradient Descent(1464/9999): loss=4698.496995439804, w0=-24.672847037862322, w1=-52.51713490839112\n",
      "Gradient Descent(1465/9999): loss=4698.496995439804, w0=-24.672847037862322, w1=-52.51713490839112\n",
      "Gradient Descent(1466/9999): loss=4698.496995439804, w0=-24.672847037862322, w1=-52.51713490839112\n",
      "Gradient Descent(1467/9999): loss=4698.496995439804, w0=-24.672847037862322, w1=-52.51713490839112\n",
      "Gradient Descent(1468/9999): loss=4698.496995439804, w0=-38.28744703786232, w1=-54.11433490839112\n",
      "Gradient Descent(1469/9999): loss=5802.4994844197445, w0=-38.28744703786232, w1=-54.11433490839112\n",
      "Gradient Descent(1470/9999): loss=5802.4994844197445, w0=-38.28744703786232, w1=-54.11433490839112\n",
      "Gradient Descent(1471/9999): loss=5802.4994844197445, w0=-38.28744703786232, w1=-54.11433490839112\n",
      "Gradient Descent(1472/9999): loss=5802.4994844197445, w0=-38.28744703786232, w1=-54.11433490839112\n",
      "Gradient Descent(1473/9999): loss=5802.4994844197445, w0=-38.28744703786232, w1=-54.11433490839112\n",
      "Gradient Descent(1474/9999): loss=5802.4994844197445, w0=-38.28744703786232, w1=-54.11433490839112\n",
      "Gradient Descent(1475/9999): loss=5802.4994844197445, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1476/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1477/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1478/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1479/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1480/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1481/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1482/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1483/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1484/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1485/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1486/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1487/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1488/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1489/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1490/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1491/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1492/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1493/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1494/9999): loss=4808.545804162281, w0=-25.95024703786232, w1=-51.87973490839112\n",
      "Gradient Descent(1495/9999): loss=4808.545804162281, w0=-16.08364703786232, w1=-49.24233490839112\n",
      "Gradient Descent(1496/9999): loss=8273.064321831902, w0=-16.08364703786232, w1=-49.24233490839112\n",
      "Gradient Descent(1497/9999): loss=8273.064321831902, w0=-28.150412423415855, w1=-54.847934908391125\n",
      "Gradient Descent(1498/9999): loss=5802.4994844197445, w0=-28.150412423415855, w1=-54.847934908391125\n",
      "Gradient Descent(1499/9999): loss=5802.4994844197445, w0=-28.150412423415855, w1=-54.847934908391125\n",
      "Gradient Descent(1500/9999): loss=5802.4994844197445, w0=-28.150412423415855, w1=-54.847934908391125\n",
      "Gradient Descent(1501/9999): loss=5802.4994844197445, w0=-28.150412423415855, w1=-54.847934908391125\n",
      "Gradient Descent(1502/9999): loss=5802.4994844197445, w0=-28.150412423415855, w1=-54.847934908391125\n",
      "Gradient Descent(1503/9999): loss=5802.4994844197445, w0=-16.333612423415854, w1=-51.338134908391126\n",
      "Gradient Descent(1504/9999): loss=5104.330309749719, w0=-16.333612423415854, w1=-51.338134908391126\n",
      "Gradient Descent(1505/9999): loss=5104.330309749719, w0=-16.333612423415854, w1=-51.338134908391126\n",
      "Gradient Descent(1506/9999): loss=5104.330309749719, w0=-8.495612423415853, w1=-49.05313490839113\n",
      "Gradient Descent(1507/9999): loss=6918.349042968145, w0=-29.706012423415856, w1=-53.35793490839113\n",
      "Gradient Descent(1508/9999): loss=5802.4994844197445, w0=-29.706012423415856, w1=-53.35793490839113\n",
      "Gradient Descent(1509/9999): loss=5802.4994844197445, w0=-29.706012423415856, w1=-53.35793490839113\n",
      "Gradient Descent(1510/9999): loss=5802.4994844197445, w0=-29.706012423415856, w1=-53.35793490839113\n",
      "Gradient Descent(1511/9999): loss=5802.4994844197445, w0=-29.706012423415856, w1=-53.35793490839113\n",
      "Gradient Descent(1512/9999): loss=5802.4994844197445, w0=-29.706012423415856, w1=-53.35793490839113\n",
      "Gradient Descent(1513/9999): loss=5802.4994844197445, w0=-29.706012423415856, w1=-53.35793490839113\n",
      "Gradient Descent(1514/9999): loss=5802.4994844197445, w0=-17.110212423415856, w1=-51.85843490839113\n",
      "Gradient Descent(1515/9999): loss=4747.5782272296965, w0=-17.110212423415856, w1=-51.85843490839113\n",
      "Gradient Descent(1516/9999): loss=4747.5782272296965, w0=-0.7213124234158528, w1=-46.65543490839113\n",
      "Gradient Descent(1517/9999): loss=16451.96478229231, w0=-7.3533124234158525, w1=-51.70733490839113\n",
      "Gradient Descent(1518/9999): loss=7614.6840940794455, w0=-7.3533124234158525, w1=-51.70733490839113\n",
      "Gradient Descent(1519/9999): loss=7614.6840940794455, w0=-7.3533124234158525, w1=-51.70733490839113\n",
      "Gradient Descent(1520/9999): loss=7614.6840940794455, w0=-7.3533124234158525, w1=-51.70733490839113\n",
      "Gradient Descent(1521/9999): loss=7614.6840940794455, w0=-7.3533124234158525, w1=-51.70733490839113\n",
      "Gradient Descent(1522/9999): loss=7614.6840940794455, w0=-7.3533124234158525, w1=-51.70733490839113\n",
      "Gradient Descent(1523/9999): loss=7614.6840940794455, w0=-7.3533124234158525, w1=-51.70733490839113\n",
      "Gradient Descent(1524/9999): loss=7614.6840940794455, w0=-15.426912423415853, w1=-53.71473490839113\n",
      "Gradient Descent(1525/9999): loss=4579.601597623556, w0=-15.426912423415853, w1=-53.71473490839113\n",
      "Gradient Descent(1526/9999): loss=4579.601597623556, w0=-15.426912423415853, w1=-53.71473490839113\n",
      "Gradient Descent(1527/9999): loss=4579.601597623556, w0=-15.426912423415853, w1=-53.71473490839113\n",
      "Gradient Descent(1528/9999): loss=4579.601597623556, w0=-3.284512423415853, w1=-50.79963490839113\n",
      "Gradient Descent(1529/9999): loss=14341.696019389348, w0=-3.284512423415853, w1=-50.79963490839113\n",
      "Gradient Descent(1530/9999): loss=14341.696019389348, w0=-3.284512423415853, w1=-50.79963490839113\n",
      "Gradient Descent(1531/9999): loss=14341.696019389348, w0=-12.774912423415852, w1=-58.058534908391124\n",
      "Gradient Descent(1532/9999): loss=5556.063671454309, w0=-12.774912423415852, w1=-58.058534908391124\n",
      "Gradient Descent(1533/9999): loss=5556.063671454309, w0=-12.774912423415852, w1=-58.058534908391124\n",
      "Gradient Descent(1534/9999): loss=5556.063671454309, w0=-12.774912423415852, w1=-58.058534908391124\n",
      "Gradient Descent(1535/9999): loss=5556.063671454309, w0=-12.774912423415852, w1=-58.058534908391124\n",
      "Gradient Descent(1536/9999): loss=5556.063671454309, w0=-12.774912423415852, w1=-58.058534908391124\n",
      "Gradient Descent(1537/9999): loss=5556.063671454309, w0=-12.774912423415852, w1=-58.058534908391124\n",
      "Gradient Descent(1538/9999): loss=5556.063671454309, w0=-12.774912423415852, w1=-58.058534908391124\n",
      "Gradient Descent(1539/9999): loss=5556.063671454309, w0=-20.30131242341585, w1=-61.36753490839112\n",
      "Gradient Descent(1540/9999): loss=5776.583854607157, w0=-20.30131242341585, w1=-61.36753490839112\n",
      "Gradient Descent(1541/9999): loss=5776.583854607157, w0=-13.22831242341585, w1=-58.79533490839112\n",
      "Gradient Descent(1542/9999): loss=5815.9721159006, w0=-13.22831242341585, w1=-58.79533490839112\n",
      "Gradient Descent(1543/9999): loss=5815.9721159006, w0=-13.22831242341585, w1=-58.79533490839112\n",
      "Gradient Descent(1544/9999): loss=5815.9721159006, w0=-13.22831242341585, w1=-58.79533490839112\n",
      "Gradient Descent(1545/9999): loss=5815.9721159006, w0=-13.22831242341585, w1=-58.79533490839112\n",
      "Gradient Descent(1546/9999): loss=5815.9721159006, w0=-25.295077808969385, w1=-63.91773490839112\n",
      "Gradient Descent(1547/9999): loss=5802.4994844197445, w0=-13.976077808969384, w1=-62.898834908391116\n",
      "Gradient Descent(1548/9999): loss=4685.768007537742, w0=-5.954777808969382, w1=-58.46333490839112\n",
      "Gradient Descent(1549/9999): loss=12602.174865844483, w0=-5.954777808969382, w1=-58.46333490839112\n",
      "Gradient Descent(1550/9999): loss=12602.174865844483, w0=-19.274477808969383, w1=-65.49213490839112\n",
      "Gradient Descent(1551/9999): loss=4809.848696582338, w0=-19.274477808969383, w1=-65.49213490839112\n",
      "Gradient Descent(1552/9999): loss=4809.848696582338, w0=-19.274477808969383, w1=-65.49213490839112\n",
      "Gradient Descent(1553/9999): loss=4809.848696582338, w0=-19.274477808969383, w1=-65.49213490839112\n",
      "Gradient Descent(1554/9999): loss=4809.848696582338, w0=-29.490377808969384, w1=-69.64613490839112\n",
      "Gradient Descent(1555/9999): loss=5802.4994844197445, w0=-29.490377808969384, w1=-69.64613490839112\n",
      "Gradient Descent(1556/9999): loss=5802.4994844197445, w0=-17.623277808969384, w1=-69.34943490839112\n",
      "Gradient Descent(1557/9999): loss=5008.964992820056, w0=-17.623277808969384, w1=-69.34943490839112\n",
      "Gradient Descent(1558/9999): loss=5008.964992820056, w0=-5.55651242341585, w1=-65.15353490839112\n",
      "Gradient Descent(1559/9999): loss=8530.179268350712, w0=-5.55651242341585, w1=-65.15353490839112\n",
      "Gradient Descent(1560/9999): loss=8530.179268350712, w0=-12.897312423415851, w1=-67.66593490839112\n",
      "Gradient Descent(1561/9999): loss=4643.489218265324, w0=0.37778757658415074, w1=-64.66113490839112\n",
      "Gradient Descent(1562/9999): loss=12348.563982648466, w0=-11.688977808969383, w1=-74.06453490839112\n",
      "Gradient Descent(1563/9999): loss=4493.725031374068, w0=-11.688977808969383, w1=-74.06453490839112\n",
      "Gradient Descent(1564/9999): loss=4493.725031374068, w0=-11.688977808969383, w1=-74.06453490839112\n",
      "Gradient Descent(1565/9999): loss=4493.725031374068, w0=-11.688977808969383, w1=-74.06453490839112\n",
      "Gradient Descent(1566/9999): loss=4493.725031374068, w0=-11.688977808969383, w1=-74.06453490839112\n",
      "Gradient Descent(1567/9999): loss=4493.725031374068, w0=-11.688977808969383, w1=-74.06453490839112\n",
      "Gradient Descent(1568/9999): loss=4493.725031374068, w0=-11.688977808969383, w1=-74.06453490839112\n",
      "Gradient Descent(1569/9999): loss=4493.725031374068, w0=-11.688977808969383, w1=-74.06453490839112\n",
      "Gradient Descent(1570/9999): loss=4493.725031374068, w0=-11.688977808969383, w1=-74.06453490839112\n",
      "Gradient Descent(1571/9999): loss=4493.725031374068, w0=-11.688977808969383, w1=-74.06453490839112\n",
      "Gradient Descent(1572/9999): loss=4493.725031374068, w0=-25.137977808969385, w1=-74.73333490839113\n",
      "Gradient Descent(1573/9999): loss=5802.4994844197445, w0=-15.811777808969385, w1=-70.09983490839113\n",
      "Gradient Descent(1574/9999): loss=4943.792540345962, w0=-15.811777808969385, w1=-70.09983490839113\n",
      "Gradient Descent(1575/9999): loss=4943.792540345962, w0=-39.03807780896939, w1=-72.67743490839113\n",
      "Gradient Descent(1576/9999): loss=5802.4994844197445, w0=-39.03807780896939, w1=-72.67743490839113\n",
      "Gradient Descent(1577/9999): loss=5802.4994844197445, w0=-39.03807780896939, w1=-72.67743490839113\n",
      "Gradient Descent(1578/9999): loss=5802.4994844197445, w0=-27.54897780896939, w1=-72.32653490839114\n",
      "Gradient Descent(1579/9999): loss=5802.4994844197445, w0=-27.54897780896939, w1=-72.32653490839114\n",
      "Gradient Descent(1580/9999): loss=5802.4994844197445, w0=-27.54897780896939, w1=-72.32653490839114\n",
      "Gradient Descent(1581/9999): loss=5802.4994844197445, w0=-27.54897780896939, w1=-72.32653490839114\n",
      "Gradient Descent(1582/9999): loss=5802.4994844197445, w0=-27.54897780896939, w1=-72.32653490839114\n",
      "Gradient Descent(1583/9999): loss=5802.4994844197445, w0=-13.941677808969391, w1=-67.14973490839114\n",
      "Gradient Descent(1584/9999): loss=4478.1038373729025, w0=-13.941677808969391, w1=-67.14973490839114\n",
      "Gradient Descent(1585/9999): loss=4478.1038373729025, w0=-13.941677808969391, w1=-67.14973490839114\n",
      "Gradient Descent(1586/9999): loss=4478.1038373729025, w0=-13.941677808969391, w1=-67.14973490839114\n",
      "Gradient Descent(1587/9999): loss=4478.1038373729025, w0=-13.941677808969391, w1=-67.14973490839114\n",
      "Gradient Descent(1588/9999): loss=4478.1038373729025, w0=-4.759377808969392, w1=-62.68273490839114\n",
      "Gradient Descent(1589/9999): loss=11992.731263827585, w0=-4.759377808969392, w1=-62.68273490839114\n",
      "Gradient Descent(1590/9999): loss=11992.731263827585, w0=-4.759377808969392, w1=-62.68273490839114\n",
      "Gradient Descent(1591/9999): loss=11992.731263827585, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1592/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1593/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1594/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1595/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1596/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1597/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1598/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1599/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1600/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1601/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1602/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1603/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1604/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1605/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1606/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1607/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1608/9999): loss=4491.045861201452, w0=-15.020177808969391, w1=-69.84423490839114\n",
      "Gradient Descent(1609/9999): loss=4491.045861201452, w0=-6.942677808969391, w1=-67.24793490839114\n",
      "Gradient Descent(1610/9999): loss=8837.571088848135, w0=-19.68857780896939, w1=-74.23683490839115\n",
      "Gradient Descent(1611/9999): loss=4814.241849501939, w0=-19.68857780896939, w1=-74.23683490839115\n",
      "Gradient Descent(1612/9999): loss=4814.241849501939, w0=-19.68857780896939, w1=-74.23683490839115\n",
      "Gradient Descent(1613/9999): loss=4814.241849501939, w0=-19.68857780896939, w1=-74.23683490839115\n",
      "Gradient Descent(1614/9999): loss=4814.241849501939, w0=-5.799477808969392, w1=-65.22093490839114\n",
      "Gradient Descent(1615/9999): loss=12215.440935287043, w0=-5.799477808969392, w1=-65.22093490839114\n",
      "Gradient Descent(1616/9999): loss=12215.440935287043, w0=-5.799477808969392, w1=-65.22093490839114\n",
      "Gradient Descent(1617/9999): loss=12215.440935287043, w0=-5.799477808969392, w1=-65.22093490839114\n",
      "Gradient Descent(1618/9999): loss=12215.440935287043, w0=-19.757177808969395, w1=-73.44783490839114\n",
      "Gradient Descent(1619/9999): loss=4777.549783904036, w0=-5.415377808969394, w1=-66.52473490839114\n",
      "Gradient Descent(1620/9999): loss=9696.265928349863, w0=-5.415377808969394, w1=-66.52473490839114\n",
      "Gradient Descent(1621/9999): loss=9696.265928349863, w0=-13.771677808969393, w1=-71.82073490839115\n",
      "Gradient Descent(1622/9999): loss=4645.689868390917, w0=-13.771677808969393, w1=-71.82073490839115\n",
      "Gradient Descent(1623/9999): loss=4645.689868390917, w0=-13.771677808969393, w1=-71.82073490839115\n",
      "Gradient Descent(1624/9999): loss=4645.689868390917, w0=-13.771677808969393, w1=-71.82073490839115\n",
      "Gradient Descent(1625/9999): loss=4645.689868390917, w0=-13.771677808969393, w1=-71.82073490839115\n",
      "Gradient Descent(1626/9999): loss=4645.689868390917, w0=-13.771677808969393, w1=-71.82073490839115\n",
      "Gradient Descent(1627/9999): loss=4645.689868390917, w0=-1.704912423415859, w1=-66.54483490839115\n",
      "Gradient Descent(1628/9999): loss=7010.051215796515, w0=8.558187576584142, w1=-59.89623490839115\n",
      "Gradient Descent(1629/9999): loss=16709.457587717236, w0=-1.1782124234158573, w1=-65.09773490839115\n",
      "Gradient Descent(1630/9999): loss=5229.906507697129, w0=-1.1782124234158573, w1=-65.09773490839115\n",
      "Gradient Descent(1631/9999): loss=5229.906507697129, w0=-1.1782124234158573, w1=-65.09773490839115\n",
      "Gradient Descent(1632/9999): loss=5229.906507697129, w0=-1.1782124234158573, w1=-65.09773490839115\n",
      "Gradient Descent(1633/9999): loss=5229.906507697129, w0=-1.1782124234158573, w1=-65.09773490839115\n",
      "Gradient Descent(1634/9999): loss=5229.906507697129, w0=-1.1782124234158573, w1=-65.09773490839115\n",
      "Gradient Descent(1635/9999): loss=5229.906507697129, w0=-1.1782124234158573, w1=-65.09773490839115\n",
      "Gradient Descent(1636/9999): loss=5229.906507697129, w0=-1.1782124234158573, w1=-65.09773490839115\n",
      "Gradient Descent(1637/9999): loss=5229.906507697129, w0=-1.1782124234158573, w1=-65.09773490839115\n",
      "Gradient Descent(1638/9999): loss=5229.906507697129, w0=-13.244977808969391, w1=-77.11953490839115\n",
      "Gradient Descent(1639/9999): loss=5802.4994844197445, w0=-13.244977808969391, w1=-77.11953490839115\n",
      "Gradient Descent(1640/9999): loss=5802.4994844197445, w0=-13.244977808969391, w1=-77.11953490839115\n",
      "Gradient Descent(1641/9999): loss=5802.4994844197445, w0=-4.93297780896939, w1=-73.32103490839114\n",
      "Gradient Descent(1642/9999): loss=5802.4994844197445, w0=-4.93297780896939, w1=-73.32103490839114\n",
      "Gradient Descent(1643/9999): loss=5802.4994844197445, w0=3.411822191030609, w1=-70.57673490839115\n",
      "Gradient Descent(1644/9999): loss=4467.184113503861, w0=3.411822191030609, w1=-70.57673490839115\n",
      "Gradient Descent(1645/9999): loss=4467.184113503861, w0=3.411822191030609, w1=-70.57673490839115\n",
      "Gradient Descent(1646/9999): loss=4467.184113503861, w0=18.631822191030608, w1=-62.68733490839114\n",
      "Gradient Descent(1647/9999): loss=15815.394773648855, w0=10.663322191030607, w1=-63.43793490839114\n",
      "Gradient Descent(1648/9999): loss=5042.672878414611, w0=-0.17467780896939367, w1=-67.67603490839114\n",
      "Gradient Descent(1649/9999): loss=5740.736054184419, w0=-0.17467780896939367, w1=-67.67603490839114\n",
      "Gradient Descent(1650/9999): loss=5740.736054184419, w0=-0.17467780896939367, w1=-67.67603490839114\n",
      "Gradient Descent(1651/9999): loss=5740.736054184419, w0=-0.17467780896939367, w1=-67.67603490839114\n",
      "Gradient Descent(1652/9999): loss=5740.736054184419, w0=-0.17467780896939367, w1=-67.67603490839114\n",
      "Gradient Descent(1653/9999): loss=5740.736054184419, w0=-0.17467780896939367, w1=-67.67603490839114\n",
      "Gradient Descent(1654/9999): loss=5740.736054184419, w0=-0.17467780896939367, w1=-67.67603490839114\n",
      "Gradient Descent(1655/9999): loss=5740.736054184419, w0=-0.17467780896939367, w1=-67.67603490839114\n",
      "Gradient Descent(1656/9999): loss=5740.736054184419, w0=11.591022191030609, w1=-64.47663490839115\n",
      "Gradient Descent(1657/9999): loss=5079.701552912842, w0=11.591022191030609, w1=-64.47663490839115\n",
      "Gradient Descent(1658/9999): loss=5079.701552912842, w0=11.591022191030609, w1=-64.47663490839115\n",
      "Gradient Descent(1659/9999): loss=5079.701552912842, w0=3.5722221910306082, w1=-66.37093490839115\n",
      "Gradient Descent(1660/9999): loss=5426.676647564484, w0=3.5722221910306082, w1=-66.37093490839115\n",
      "Gradient Descent(1661/9999): loss=5426.676647564484, w0=15.159422191030611, w1=-65.25983490839116\n",
      "Gradient Descent(1662/9999): loss=7075.395160164808, w0=15.159422191030611, w1=-65.25983490839116\n",
      "Gradient Descent(1663/9999): loss=7075.395160164808, w0=15.159422191030611, w1=-65.25983490839116\n",
      "Gradient Descent(1664/9999): loss=7075.395160164808, w0=15.159422191030611, w1=-65.25983490839116\n",
      "Gradient Descent(1665/9999): loss=7075.395160164808, w0=-10.30957780896939, w1=-68.65113490839116\n",
      "Gradient Descent(1666/9999): loss=5802.4994844197445, w0=-10.30957780896939, w1=-68.65113490839116\n",
      "Gradient Descent(1667/9999): loss=5802.4994844197445, w0=-1.5906778089693905, w1=-68.60513490839115\n",
      "Gradient Descent(1668/9999): loss=5802.4994844197445, w0=12.420722191030611, w1=-67.38373490839115\n",
      "Gradient Descent(1669/9999): loss=5664.397635460291, w0=25.88642219103061, w1=-60.28083490839115\n",
      "Gradient Descent(1670/9999): loss=17096.689175506486, w0=13.819656805477077, w1=-65.34793490839115\n",
      "Gradient Descent(1671/9999): loss=6723.152722341996, w0=13.819656805477077, w1=-65.34793490839115\n",
      "Gradient Descent(1672/9999): loss=6723.152722341996, w0=13.819656805477077, w1=-65.34793490839115\n",
      "Gradient Descent(1673/9999): loss=6723.152722341996, w0=13.819656805477077, w1=-65.34793490839115\n",
      "Gradient Descent(1674/9999): loss=6723.152722341996, w0=3.544856805477078, w1=-71.11763490839115\n",
      "Gradient Descent(1675/9999): loss=5802.4994844197445, w0=3.544856805477078, w1=-71.11763490839115\n",
      "Gradient Descent(1676/9999): loss=5802.4994844197445, w0=3.544856805477078, w1=-71.11763490839115\n",
      "Gradient Descent(1677/9999): loss=5802.4994844197445, w0=3.544856805477078, w1=-71.11763490839115\n",
      "Gradient Descent(1678/9999): loss=5802.4994844197445, w0=12.54955680547708, w1=-66.85753490839116\n",
      "Gradient Descent(1679/9999): loss=4979.837717217847, w0=12.54955680547708, w1=-66.85753490839116\n",
      "Gradient Descent(1680/9999): loss=4979.837717217847, w0=12.54955680547708, w1=-66.85753490839116\n",
      "Gradient Descent(1681/9999): loss=4979.837717217847, w0=12.54955680547708, w1=-66.85753490839116\n",
      "Gradient Descent(1682/9999): loss=4979.837717217847, w0=12.54955680547708, w1=-66.85753490839116\n",
      "Gradient Descent(1683/9999): loss=4979.837717217847, w0=12.54955680547708, w1=-66.85753490839116\n",
      "Gradient Descent(1684/9999): loss=4979.837717217847, w0=12.54955680547708, w1=-66.85753490839116\n",
      "Gradient Descent(1685/9999): loss=4979.837717217847, w0=12.54955680547708, w1=-66.85753490839116\n",
      "Gradient Descent(1686/9999): loss=4979.837717217847, w0=2.75825680547708, w1=-71.49983490839116\n",
      "Gradient Descent(1687/9999): loss=5802.4994844197445, w0=2.75825680547708, w1=-71.49983490839116\n",
      "Gradient Descent(1688/9999): loss=5802.4994844197445, w0=13.99435680547708, w1=-65.04363490839117\n",
      "Gradient Descent(1689/9999): loss=4922.338793491641, w0=13.99435680547708, w1=-65.04363490839117\n",
      "Gradient Descent(1690/9999): loss=4922.338793491641, w0=13.99435680547708, w1=-65.04363490839117\n",
      "Gradient Descent(1691/9999): loss=4922.338793491641, w0=13.99435680547708, w1=-65.04363490839117\n",
      "Gradient Descent(1692/9999): loss=4922.338793491641, w0=-5.508043194522921, w1=-68.41263490839117\n",
      "Gradient Descent(1693/9999): loss=5802.4994844197445, w0=-5.508043194522921, w1=-68.41263490839117\n",
      "Gradient Descent(1694/9999): loss=5802.4994844197445, w0=3.49455680547708, w1=-65.84143490839116\n",
      "Gradient Descent(1695/9999): loss=5766.628901519944, w0=3.49455680547708, w1=-65.84143490839116\n",
      "Gradient Descent(1696/9999): loss=5766.628901519944, w0=3.49455680547708, w1=-65.84143490839116\n",
      "Gradient Descent(1697/9999): loss=5766.628901519944, w0=3.49455680547708, w1=-65.84143490839116\n",
      "Gradient Descent(1698/9999): loss=5766.628901519944, w0=3.49455680547708, w1=-65.84143490839116\n",
      "Gradient Descent(1699/9999): loss=5766.628901519944, w0=3.49455680547708, w1=-65.84143490839116\n",
      "Gradient Descent(1700/9999): loss=5766.628901519944, w0=3.49455680547708, w1=-65.84143490839116\n",
      "Gradient Descent(1701/9999): loss=5766.628901519944, w0=3.49455680547708, w1=-65.84143490839116\n",
      "Gradient Descent(1702/9999): loss=5766.628901519944, w0=3.49455680547708, w1=-65.84143490839116\n",
      "Gradient Descent(1703/9999): loss=5766.628901519944, w0=16.65085680547708, w1=-62.57533490839116\n",
      "Gradient Descent(1704/9999): loss=12476.561208553157, w0=16.65085680547708, w1=-62.57533490839116\n",
      "Gradient Descent(1705/9999): loss=12476.561208553157, w0=4.584091419923546, w1=-72.71813490839116\n",
      "Gradient Descent(1706/9999): loss=4812.626082782772, w0=4.584091419923546, w1=-72.71813490839116\n",
      "Gradient Descent(1707/9999): loss=4812.626082782772, w0=4.584091419923546, w1=-72.71813490839116\n",
      "Gradient Descent(1708/9999): loss=4812.626082782772, w0=16.65085680547708, w1=-60.066234908391166\n",
      "Gradient Descent(1709/9999): loss=14015.373499659952, w0=7.53125680547708, w1=-64.80653490839117\n",
      "Gradient Descent(1710/9999): loss=5004.340975246796, w0=7.53125680547708, w1=-64.80653490839117\n",
      "Gradient Descent(1711/9999): loss=5004.340975246796, w0=-1.6938431945229215, w1=-65.35413490839117\n",
      "Gradient Descent(1712/9999): loss=5790.9865488204205, w0=-1.6938431945229215, w1=-65.35413490839117\n",
      "Gradient Descent(1713/9999): loss=5790.9865488204205, w0=-1.6938431945229215, w1=-65.35413490839117\n",
      "Gradient Descent(1714/9999): loss=5790.9865488204205, w0=-1.6938431945229215, w1=-65.35413490839117\n",
      "Gradient Descent(1715/9999): loss=5790.9865488204205, w0=-1.6938431945229215, w1=-65.35413490839117\n",
      "Gradient Descent(1716/9999): loss=5790.9865488204205, w0=-1.6938431945229215, w1=-65.35413490839117\n",
      "Gradient Descent(1717/9999): loss=5790.9865488204205, w0=-1.6938431945229215, w1=-65.35413490839117\n",
      "Gradient Descent(1718/9999): loss=5790.9865488204205, w0=11.156556805477079, w1=-64.34603490839118\n",
      "Gradient Descent(1719/9999): loss=5940.671394619958, w0=11.156556805477079, w1=-64.34603490839118\n",
      "Gradient Descent(1720/9999): loss=5940.671394619958, w0=11.156556805477079, w1=-64.34603490839118\n",
      "Gradient Descent(1721/9999): loss=5940.671394619958, w0=11.156556805477079, w1=-64.34603490839118\n",
      "Gradient Descent(1722/9999): loss=5940.671394619958, w0=11.156556805477079, w1=-64.34603490839118\n",
      "Gradient Descent(1723/9999): loss=5940.671394619958, w0=11.156556805477079, w1=-64.34603490839118\n",
      "Gradient Descent(1724/9999): loss=5940.671394619958, w0=11.156556805477079, w1=-64.34603490839118\n",
      "Gradient Descent(1725/9999): loss=5940.671394619958, w0=11.156556805477079, w1=-64.34603490839118\n",
      "Gradient Descent(1726/9999): loss=5940.671394619958, w0=11.156556805477079, w1=-64.34603490839118\n",
      "Gradient Descent(1727/9999): loss=5940.671394619958, w0=11.156556805477079, w1=-64.34603490839118\n",
      "Gradient Descent(1728/9999): loss=5940.671394619958, w0=11.156556805477079, w1=-64.34603490839118\n",
      "Gradient Descent(1729/9999): loss=5940.671394619958, w0=11.156556805477079, w1=-64.34603490839118\n",
      "Gradient Descent(1730/9999): loss=5940.671394619958, w0=-0.9102085800764552, w1=-70.00163490839118\n",
      "Gradient Descent(1731/9999): loss=5790.986548954825, w0=-0.9102085800764552, w1=-70.00163490839118\n",
      "Gradient Descent(1732/9999): loss=5790.986548954825, w0=-0.9102085800764552, w1=-70.00163490839118\n",
      "Gradient Descent(1733/9999): loss=5790.986548954825, w0=-0.9102085800764552, w1=-70.00163490839118\n",
      "Gradient Descent(1734/9999): loss=5790.986548954825, w0=-0.9102085800764552, w1=-70.00163490839118\n",
      "Gradient Descent(1735/9999): loss=5790.986548954825, w0=10.911291419923545, w1=-67.87973490839119\n",
      "Gradient Descent(1736/9999): loss=5983.560922736251, w0=-2.542208580076455, w1=-69.37523490839119\n",
      "Gradient Descent(1737/9999): loss=5802.4994844197445, w0=13.090891419923548, w1=-62.84473490839119\n",
      "Gradient Descent(1738/9999): loss=11164.475092622473, w0=4.947991419923547, w1=-64.74703490839119\n",
      "Gradient Descent(1739/9999): loss=4940.425205200732, w0=4.947991419923547, w1=-64.74703490839119\n",
      "Gradient Descent(1740/9999): loss=4940.425205200732, w0=15.416991419923548, w1=-59.43873490839118\n",
      "Gradient Descent(1741/9999): loss=13500.921992888021, w0=-1.619208580076453, w1=-67.37823490839118\n",
      "Gradient Descent(1742/9999): loss=5513.4950093069365, w0=-1.619208580076453, w1=-67.37823490839118\n",
      "Gradient Descent(1743/9999): loss=5513.4950093069365, w0=8.707391419923548, w1=-65.79123490839117\n",
      "Gradient Descent(1744/9999): loss=6826.344216412475, w0=8.707391419923548, w1=-65.79123490839117\n",
      "Gradient Descent(1745/9999): loss=6826.344216412475, w0=8.707391419923548, w1=-65.79123490839117\n",
      "Gradient Descent(1746/9999): loss=6826.344216412475, w0=0.19919141992354739, w1=-70.38423490839118\n",
      "Gradient Descent(1747/9999): loss=5563.579936135741, w0=0.19919141992354739, w1=-70.38423490839118\n",
      "Gradient Descent(1748/9999): loss=5563.579936135741, w0=0.19919141992354739, w1=-70.38423490839118\n",
      "Gradient Descent(1749/9999): loss=5563.579936135741, w0=0.19919141992354739, w1=-70.38423490839118\n",
      "Gradient Descent(1750/9999): loss=5563.579936135741, w0=0.19919141992354739, w1=-70.38423490839118\n",
      "Gradient Descent(1751/9999): loss=5563.579936135741, w0=0.19919141992354739, w1=-70.38423490839118\n",
      "Gradient Descent(1752/9999): loss=5563.579936135741, w0=11.397991419923548, w1=-64.18023490839118\n",
      "Gradient Descent(1753/9999): loss=9609.77636169266, w0=-0.6687739656085121, w1=-72.26173490837681\n",
      "Gradient Descent(1754/9999): loss=4861.321622330734, w0=-0.6687739656085121, w1=-72.26173490837681\n",
      "Gradient Descent(1755/9999): loss=4861.321622330734, w0=-0.6687739656085121, w1=-72.26173490837681\n",
      "Gradient Descent(1756/9999): loss=4861.321622330734, w0=-0.6687739656085121, w1=-72.26173490837681\n",
      "Gradient Descent(1757/9999): loss=4861.321622330734, w0=-0.6687739656085121, w1=-72.26173490837681\n",
      "Gradient Descent(1758/9999): loss=4861.321622330734, w0=-0.6687739656085121, w1=-72.26173490837681\n",
      "Gradient Descent(1759/9999): loss=4861.321622330734, w0=-0.6687739656085121, w1=-72.26173490837681\n",
      "Gradient Descent(1760/9999): loss=4861.321622330734, w0=-0.6687739656085121, w1=-72.26173490837681\n",
      "Gradient Descent(1761/9999): loss=4861.321622330734, w0=-10.402673965608512, w1=-74.43933490837681\n",
      "Gradient Descent(1762/9999): loss=5802.4994844197445, w0=-10.402673965608512, w1=-74.43933490837681\n",
      "Gradient Descent(1763/9999): loss=5802.4994844197445, w0=-10.402673965608512, w1=-74.43933490837681\n",
      "Gradient Descent(1764/9999): loss=5802.4994844197445, w0=-10.402673965608512, w1=-74.43933490837681\n",
      "Gradient Descent(1765/9999): loss=5802.4994844197445, w0=-10.402673965608512, w1=-74.43933490837681\n",
      "Gradient Descent(1766/9999): loss=5802.4994844197445, w0=-10.402673965608512, w1=-74.43933490837681\n",
      "Gradient Descent(1767/9999): loss=5802.4994844197445, w0=-10.402673965608512, w1=-74.43933490837681\n",
      "Gradient Descent(1768/9999): loss=5802.4994844197445, w0=-2.727873965608511, w1=-71.63583490837681\n",
      "Gradient Descent(1769/9999): loss=5253.270359468104, w0=-7.572473965608512, w1=-76.36753490837681\n",
      "Gradient Descent(1770/9999): loss=5802.4994844197445, w0=-7.572473965608512, w1=-76.36753490837681\n",
      "Gradient Descent(1771/9999): loss=5802.4994844197445, w0=-7.572473965608512, w1=-76.36753490837681\n",
      "Gradient Descent(1772/9999): loss=5802.4994844197445, w0=0.004726034391487666, w1=-73.15773490837681\n",
      "Gradient Descent(1773/9999): loss=5802.499481637113, w0=0.004726034391487666, w1=-73.15773490837681\n",
      "Gradient Descent(1774/9999): loss=5802.499481637113, w0=13.04992603439149, w1=-68.60393490837681\n",
      "Gradient Descent(1775/9999): loss=5175.921464615701, w0=13.04992603439149, w1=-68.60393490837681\n",
      "Gradient Descent(1776/9999): loss=5175.921464615701, w0=23.05272603439149, w1=-62.65613490837681\n",
      "Gradient Descent(1777/9999): loss=14669.99033344859, w0=9.47492603439149, w1=-69.9705349083768\n",
      "Gradient Descent(1778/9999): loss=4455.658189160555, w0=9.47492603439149, w1=-69.9705349083768\n",
      "Gradient Descent(1779/9999): loss=4455.658189160555, w0=0.9197260343914895, w1=-71.23943490837681\n",
      "Gradient Descent(1780/9999): loss=5802.4994844197445, w0=0.9197260343914895, w1=-71.23943490837681\n",
      "Gradient Descent(1781/9999): loss=5802.4994844197445, w0=0.9197260343914895, w1=-71.23943490837681\n",
      "Gradient Descent(1782/9999): loss=5802.4994844197445, w0=0.9197260343914895, w1=-71.23943490837681\n",
      "Gradient Descent(1783/9999): loss=5802.4994844197445, w0=0.9197260343914895, w1=-71.23943490837681\n",
      "Gradient Descent(1784/9999): loss=5802.4994844197445, w0=12.986491419945024, w1=-62.23533490837681\n",
      "Gradient Descent(1785/9999): loss=6509.003845468337, w0=12.986491419945024, w1=-62.23533490837681\n",
      "Gradient Descent(1786/9999): loss=6509.003845468337, w0=2.0467914199450217, w1=-70.1792349083768\n",
      "Gradient Descent(1787/9999): loss=5802.4994844197445, w0=2.0467914199450217, w1=-70.1792349083768\n",
      "Gradient Descent(1788/9999): loss=5802.4994844197445, w0=2.0467914199450217, w1=-70.1792349083768\n",
      "Gradient Descent(1789/9999): loss=5802.4994844197445, w0=11.614391419945022, w1=-69.5933349083768\n",
      "Gradient Descent(1790/9999): loss=4392.921141491463, w0=11.614391419945022, w1=-69.5933349083768\n",
      "Gradient Descent(1791/9999): loss=4392.921141491463, w0=11.614391419945022, w1=-69.5933349083768\n",
      "Gradient Descent(1792/9999): loss=4392.921141491463, w0=11.614391419945022, w1=-69.5933349083768\n",
      "Gradient Descent(1793/9999): loss=4392.921141491463, w0=11.614391419945022, w1=-69.5933349083768\n",
      "Gradient Descent(1794/9999): loss=4392.921141491463, w0=11.614391419945022, w1=-69.5933349083768\n",
      "Gradient Descent(1795/9999): loss=4392.921141491463, w0=11.614391419945022, w1=-69.5933349083768\n",
      "Gradient Descent(1796/9999): loss=4392.921141491463, w0=11.614391419945022, w1=-69.5933349083768\n",
      "Gradient Descent(1797/9999): loss=4392.921141491463, w0=11.614391419945022, w1=-69.5933349083768\n",
      "Gradient Descent(1798/9999): loss=4392.921141491463, w0=11.614391419945022, w1=-69.5933349083768\n",
      "Gradient Descent(1799/9999): loss=4392.921141491463, w0=11.614391419945022, w1=-69.5933349083768\n",
      "Gradient Descent(1800/9999): loss=4392.921141491463, w0=11.614391419945022, w1=-69.5933349083768\n",
      "Gradient Descent(1801/9999): loss=4392.921141491463, w0=11.614391419945022, w1=-69.5933349083768\n",
      "Gradient Descent(1802/9999): loss=4392.921141491463, w0=11.614391419945022, w1=-69.5933349083768\n",
      "Gradient Descent(1803/9999): loss=4392.921141491463, w0=11.614391419945022, w1=-69.5933349083768\n",
      "Gradient Descent(1804/9999): loss=4392.921141491463, w0=11.614391419945022, w1=-69.5933349083768\n",
      "Gradient Descent(1805/9999): loss=4392.921141491463, w0=23.316591419945023, w1=-65.9786349083768\n",
      "Gradient Descent(1806/9999): loss=11132.107137143863, w0=23.316591419945023, w1=-65.9786349083768\n",
      "Gradient Descent(1807/9999): loss=11132.107137143863, w0=23.316591419945023, w1=-65.9786349083768\n",
      "Gradient Descent(1808/9999): loss=11132.107137143863, w0=12.310391419945022, w1=-72.8892349083768\n",
      "Gradient Descent(1809/9999): loss=4594.072352867236, w0=12.310391419945022, w1=-72.8892349083768\n",
      "Gradient Descent(1810/9999): loss=4594.072352867236, w0=12.310391419945022, w1=-72.8892349083768\n",
      "Gradient Descent(1811/9999): loss=4594.072352867236, w0=12.310391419945022, w1=-72.8892349083768\n",
      "Gradient Descent(1812/9999): loss=4594.072352867236, w0=12.310391419945022, w1=-72.8892349083768\n",
      "Gradient Descent(1813/9999): loss=4594.072352867236, w0=12.310391419945022, w1=-72.8892349083768\n",
      "Gradient Descent(1814/9999): loss=4594.072352867236, w0=12.310391419945022, w1=-72.8892349083768\n",
      "Gradient Descent(1815/9999): loss=4594.072352867236, w0=24.44929141994502, w1=-69.9508349083768\n",
      "Gradient Descent(1816/9999): loss=8598.538933553822, w0=24.44929141994502, w1=-69.9508349083768\n",
      "Gradient Descent(1817/9999): loss=8598.538933553822, w0=33.13159141994502, w1=-63.63133490837681\n",
      "Gradient Descent(1818/9999): loss=16853.68656487482, w0=33.13159141994502, w1=-63.63133490837681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(1819/9999): loss=16853.68656487482, w0=28.499591419945016, w1=-70.03183490837681\n",
      "Gradient Descent(1820/9999): loss=9480.10956874191, w0=28.499591419945016, w1=-70.03183490837681\n",
      "Gradient Descent(1821/9999): loss=9480.10956874191, w0=18.014791419945016, w1=-76.2937349083768\n",
      "Gradient Descent(1822/9999): loss=4512.904615336796, w0=18.014791419945016, w1=-76.2937349083768\n",
      "Gradient Descent(1823/9999): loss=4512.904615336796, w0=18.014791419945016, w1=-76.2937349083768\n",
      "Gradient Descent(1824/9999): loss=4512.904615336796, w0=18.014791419945016, w1=-76.2937349083768\n",
      "Gradient Descent(1825/9999): loss=4512.904615336796, w0=18.014791419945016, w1=-76.2937349083768\n",
      "Gradient Descent(1826/9999): loss=4512.904615336796, w0=8.894691419945016, w1=-76.5979349083768\n",
      "Gradient Descent(1827/9999): loss=5802.4994844197445, w0=20.96145680549855, w1=-72.4020349083768\n",
      "Gradient Descent(1828/9999): loss=4362.8651939472875, w0=20.96145680549855, w1=-72.4020349083768\n",
      "Gradient Descent(1829/9999): loss=4362.8651939472875, w0=20.96145680549855, w1=-72.4020349083768\n",
      "Gradient Descent(1830/9999): loss=4362.8651939472875, w0=20.96145680549855, w1=-72.4020349083768\n",
      "Gradient Descent(1831/9999): loss=4362.8651939472875, w0=20.96145680549855, w1=-72.4020349083768\n",
      "Gradient Descent(1832/9999): loss=4362.8651939472875, w0=20.96145680549855, w1=-72.4020349083768\n",
      "Gradient Descent(1833/9999): loss=4362.8651939472875, w0=20.96145680549855, w1=-72.4020349083768\n",
      "Gradient Descent(1834/9999): loss=4362.8651939472875, w0=20.96145680549855, w1=-72.4020349083768\n",
      "Gradient Descent(1835/9999): loss=4362.8651939472875, w0=20.96145680549855, w1=-72.4020349083768\n",
      "Gradient Descent(1836/9999): loss=4362.8651939472875, w0=20.96145680549855, w1=-72.4020349083768\n",
      "Gradient Descent(1837/9999): loss=4362.8651939472875, w0=20.96145680549855, w1=-72.4020349083768\n",
      "Gradient Descent(1838/9999): loss=4362.8651939472875, w0=20.96145680549855, w1=-72.4020349083768\n",
      "Gradient Descent(1839/9999): loss=4362.8651939472875, w0=20.96145680549855, w1=-72.4020349083768\n",
      "Gradient Descent(1840/9999): loss=4362.8651939472875, w0=1.4590568054985482, w1=-75.7710349083768\n",
      "Gradient Descent(1841/9999): loss=5802.4994844197445, w0=1.4590568054985482, w1=-75.7710349083768\n",
      "Gradient Descent(1842/9999): loss=5802.4994844197445, w0=1.4590568054985482, w1=-75.7710349083768\n",
      "Gradient Descent(1843/9999): loss=5802.4994844197445, w0=15.421256805498551, w1=-75.42743490837681\n",
      "Gradient Descent(1844/9999): loss=5652.831323374482, w0=15.421256805498551, w1=-75.42743490837681\n",
      "Gradient Descent(1845/9999): loss=5652.831323374482, w0=15.421256805498551, w1=-75.42743490837681\n",
      "Gradient Descent(1846/9999): loss=5652.831323374482, w0=15.421256805498551, w1=-75.42743490837681\n",
      "Gradient Descent(1847/9999): loss=5652.831323374482, w0=15.421256805498551, w1=-75.42743490837681\n",
      "Gradient Descent(1848/9999): loss=5652.831323374482, w0=15.421256805498551, w1=-75.42743490837681\n",
      "Gradient Descent(1849/9999): loss=5652.831323374482, w0=26.585956805498554, w1=-67.46463490837681\n",
      "Gradient Descent(1850/9999): loss=4616.690066286663, w0=26.585956805498554, w1=-67.46463490837681\n",
      "Gradient Descent(1851/9999): loss=4616.690066286663, w0=26.585956805498554, w1=-67.46463490837681\n",
      "Gradient Descent(1852/9999): loss=4616.690066286663, w0=26.585956805498554, w1=-67.46463490837681\n",
      "Gradient Descent(1853/9999): loss=4616.690066286663, w0=26.585956805498554, w1=-67.46463490837681\n",
      "Gradient Descent(1854/9999): loss=4616.690066286663, w0=26.585956805498554, w1=-67.46463490837681\n",
      "Gradient Descent(1855/9999): loss=4616.690066286663, w0=26.585956805498554, w1=-67.46463490837681\n",
      "Gradient Descent(1856/9999): loss=4616.690066286663, w0=26.585956805498554, w1=-67.46463490837681\n",
      "Gradient Descent(1857/9999): loss=4616.690066286663, w0=36.812456805498556, w1=-63.93933490837681\n",
      "Gradient Descent(1858/9999): loss=17073.663304576643, w0=36.812456805498556, w1=-63.93933490837681\n",
      "Gradient Descent(1859/9999): loss=17073.663304576643, w0=24.74569141994502, w1=-71.56233490837681\n",
      "Gradient Descent(1860/9999): loss=10138.232797154069, w0=24.74569141994502, w1=-71.56233490837681\n",
      "Gradient Descent(1861/9999): loss=10138.232797154069, w0=15.10609141994502, w1=-73.21933490837681\n",
      "Gradient Descent(1862/9999): loss=4411.417067280046, w0=15.10609141994502, w1=-73.21933490837681\n",
      "Gradient Descent(1863/9999): loss=4411.417067280046, w0=15.10609141994502, w1=-73.21933490837681\n",
      "Gradient Descent(1864/9999): loss=4411.417067280046, w0=15.10609141994502, w1=-73.21933490837681\n",
      "Gradient Descent(1865/9999): loss=4411.417067280046, w0=15.10609141994502, w1=-73.21933490837681\n",
      "Gradient Descent(1866/9999): loss=4411.417067280046, w0=2.7792914199450216, w1=-76.21993490837681\n",
      "Gradient Descent(1867/9999): loss=5802.4994844197445, w0=2.7792914199450216, w1=-76.21993490837681\n",
      "Gradient Descent(1868/9999): loss=5802.4994844197445, w0=2.7792914199450216, w1=-76.21993490837681\n",
      "Gradient Descent(1869/9999): loss=5802.4994844197445, w0=2.7792914199450216, w1=-76.21993490837681\n",
      "Gradient Descent(1870/9999): loss=5802.4994844197445, w0=2.7792914199450216, w1=-76.21993490837681\n",
      "Gradient Descent(1871/9999): loss=5802.4994844197445, w0=13.330491419945023, w1=-73.88293490837681\n",
      "Gradient Descent(1872/9999): loss=5581.992683106972, w0=13.330491419945023, w1=-73.88293490837681\n",
      "Gradient Descent(1873/9999): loss=5581.992683106972, w0=26.917091419945024, w1=-72.53453490837681\n",
      "Gradient Descent(1874/9999): loss=5226.158700400907, w0=4.1290914199450235, w1=-84.93483490837681\n",
      "Gradient Descent(1875/9999): loss=5802.4994844197445, w0=4.1290914199450235, w1=-84.93483490837681\n",
      "Gradient Descent(1876/9999): loss=5802.4994844197445, w0=4.1290914199450235, w1=-84.93483490837681\n",
      "Gradient Descent(1877/9999): loss=5802.4994844197445, w0=16.118391419945024, w1=-84.64653490837681\n",
      "Gradient Descent(1878/9999): loss=4662.2297213457105, w0=16.118391419945024, w1=-84.64653490837681\n",
      "Gradient Descent(1879/9999): loss=4662.2297213457105, w0=16.118391419945024, w1=-84.64653490837681\n",
      "Gradient Descent(1880/9999): loss=4662.2297213457105, w0=16.118391419945024, w1=-84.64653490837681\n",
      "Gradient Descent(1881/9999): loss=4662.2297213457105, w0=16.118391419945024, w1=-84.64653490837681\n",
      "Gradient Descent(1882/9999): loss=4662.2297213457105, w0=29.31619141994502, w1=-81.4845349083768\n",
      "Gradient Descent(1883/9999): loss=5986.625178904602, w0=10.42479141994502, w1=-83.3078349083768\n",
      "Gradient Descent(1884/9999): loss=5526.188995014984, w0=10.42479141994502, w1=-83.3078349083768\n",
      "Gradient Descent(1885/9999): loss=5526.188995014984, w0=10.42479141994502, w1=-83.3078349083768\n",
      "Gradient Descent(1886/9999): loss=5526.188995014984, w0=22.491556805498554, w1=-76.1935349083768\n",
      "Gradient Descent(1887/9999): loss=4287.480575754393, w0=31.496256805498554, w1=-71.93343490837681\n",
      "Gradient Descent(1888/9999): loss=13946.463684685485, w0=31.496256805498554, w1=-71.93343490837681\n",
      "Gradient Descent(1889/9999): loss=13946.463684685485, w0=19.42949141994502, w1=-77.5390349083768\n",
      "Gradient Descent(1890/9999): loss=5438.97796341771, w0=28.54949141994502, w1=-73.26563490837681\n",
      "Gradient Descent(1891/9999): loss=4381.842820285321, w0=28.54949141994502, w1=-73.26563490837681\n",
      "Gradient Descent(1892/9999): loss=4381.842820285321, w0=28.54949141994502, w1=-73.26563490837681\n",
      "Gradient Descent(1893/9999): loss=4381.842820285321, w0=28.54949141994502, w1=-73.26563490837681\n",
      "Gradient Descent(1894/9999): loss=4381.842820285321, w0=28.54949141994502, w1=-73.26563490837681\n",
      "Gradient Descent(1895/9999): loss=4381.842820285321, w0=36.570791419945024, w1=-68.8301349083768\n",
      "Gradient Descent(1896/9999): loss=13094.765360343175, w0=23.61519141994502, w1=-75.13213490837681\n",
      "Gradient Descent(1897/9999): loss=4378.7486021621025, w0=10.763791419945019, w1=-75.90433490837681\n",
      "Gradient Descent(1898/9999): loss=5802.4994844197445, w0=21.36519141994502, w1=-71.27083490837681\n",
      "Gradient Descent(1899/9999): loss=4580.918960479903, w0=3.9009914199450186, w1=-72.82303490837681\n",
      "Gradient Descent(1900/9999): loss=5802.4994844197445, w0=15.655491419945019, w1=-72.3134349083768\n",
      "Gradient Descent(1901/9999): loss=5468.659852905148, w0=15.655491419945019, w1=-72.3134349083768\n",
      "Gradient Descent(1902/9999): loss=5468.659852905148, w0=15.655491419945019, w1=-72.3134349083768\n",
      "Gradient Descent(1903/9999): loss=5468.659852905148, w0=28.97209141994502, w1=-69.9628349083768\n",
      "Gradient Descent(1904/9999): loss=5335.213589798389, w0=28.97209141994502, w1=-69.9628349083768\n",
      "Gradient Descent(1905/9999): loss=5335.213589798389, w0=18.71909141994502, w1=-70.98433490837681\n",
      "Gradient Descent(1906/9999): loss=4933.449603577653, w0=18.71909141994502, w1=-70.98433490837681\n",
      "Gradient Descent(1907/9999): loss=4933.449603577653, w0=30.35159141994502, w1=-67.1503349083768\n",
      "Gradient Descent(1908/9999): loss=6437.094718421435, w0=30.35159141994502, w1=-67.1503349083768\n",
      "Gradient Descent(1909/9999): loss=6437.094718421435, w0=30.35159141994502, w1=-67.1503349083768\n",
      "Gradient Descent(1910/9999): loss=6437.094718421435, w0=30.35159141994502, w1=-67.1503349083768\n",
      "Gradient Descent(1911/9999): loss=6437.094718421435, w0=30.35159141994502, w1=-67.1503349083768\n",
      "Gradient Descent(1912/9999): loss=6437.094718421435, w0=30.35159141994502, w1=-67.1503349083768\n",
      "Gradient Descent(1913/9999): loss=6437.094718421435, w0=30.35159141994502, w1=-67.1503349083768\n",
      "Gradient Descent(1914/9999): loss=6437.094718421435, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1915/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1916/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1917/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1918/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1919/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1920/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1921/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1922/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1923/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1924/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1925/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1926/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1927/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1928/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1929/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1930/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1931/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1932/9999): loss=5393.773770439678, w0=19.91579141994502, w1=-68.31233490837681\n",
      "Gradient Descent(1933/9999): loss=5393.773770439678, w0=31.38049141994502, w1=-64.75183490837681\n",
      "Gradient Descent(1934/9999): loss=5106.373494750462, w0=31.38049141994502, w1=-64.75183490837681\n",
      "Gradient Descent(1935/9999): loss=5106.373494750462, w0=21.353491420177715, w1=-68.99013490827845\n",
      "Gradient Descent(1936/9999): loss=5047.945520786445, w0=21.353491420177715, w1=-68.99013490827845\n",
      "Gradient Descent(1937/9999): loss=5047.945520786445, w0=21.353491420177715, w1=-68.99013490827845\n",
      "Gradient Descent(1938/9999): loss=5047.945520786445, w0=21.353491420177715, w1=-68.99013490827845\n",
      "Gradient Descent(1939/9999): loss=5047.945520786445, w0=21.353491420177715, w1=-68.99013490827845\n",
      "Gradient Descent(1940/9999): loss=5047.945520786445, w0=21.353491420177715, w1=-68.99013490827845\n",
      "Gradient Descent(1941/9999): loss=5047.945520786445, w0=33.42025680573125, w1=-63.71423490827845\n",
      "Gradient Descent(1942/9999): loss=4818.042735084741, w0=33.42025680573125, w1=-63.71423490827845\n",
      "Gradient Descent(1943/9999): loss=4818.042735084741, w0=33.42025680573125, w1=-63.71423490827845\n",
      "Gradient Descent(1944/9999): loss=4818.042735084741, w0=33.42025680573125, w1=-63.71423490827845\n",
      "Gradient Descent(1945/9999): loss=4818.042735084741, w0=33.42025680573125, w1=-63.71423490827845\n",
      "Gradient Descent(1946/9999): loss=4818.042735084741, w0=33.42025680573125, w1=-63.71423490827845\n",
      "Gradient Descent(1947/9999): loss=4818.042735084741, w0=33.42025680573125, w1=-63.71423490827845\n",
      "Gradient Descent(1948/9999): loss=4818.042735084741, w0=33.42025680573125, w1=-63.71423490827845\n",
      "Gradient Descent(1949/9999): loss=4818.042735084741, w0=33.42025680573125, w1=-63.71423490827845\n",
      "Gradient Descent(1950/9999): loss=4818.042735084741, w0=46.57655680573125, w1=-60.44813490827845\n",
      "Gradient Descent(1951/9999): loss=16958.102860996798, w0=27.43125680573125, w1=-68.71533490827845\n",
      "Gradient Descent(1952/9999): loss=5219.479546960432, w0=27.43125680573125, w1=-68.71533490827845\n",
      "Gradient Descent(1953/9999): loss=5219.479546960432, w0=27.43125680573125, w1=-68.71533490827845\n",
      "Gradient Descent(1954/9999): loss=5219.479546960432, w0=35.728156805731246, w1=-64.32273490827845\n",
      "Gradient Descent(1955/9999): loss=14704.264031134826, w0=35.728156805731246, w1=-64.32273490827845\n",
      "Gradient Descent(1956/9999): loss=14704.264031134826, w0=23.66139142017771, w1=-71.15043490827844\n",
      "Gradient Descent(1957/9999): loss=4269.6119703900895, w0=16.39509142017771, w1=-72.91523490827844\n",
      "Gradient Descent(1958/9999): loss=5675.857217132251, w0=30.42519142017771, w1=-71.43153490827844\n",
      "Gradient Descent(1959/9999): loss=6417.777182718937, w0=30.42519142017771, w1=-71.43153490827844\n",
      "Gradient Descent(1960/9999): loss=6417.777182718937, w0=18.04519142017771, w1=-75.59873490827843\n",
      "Gradient Descent(1961/9999): loss=4628.180061161604, w0=18.04519142017771, w1=-75.59873490827843\n",
      "Gradient Descent(1962/9999): loss=4628.180061161604, w0=18.04519142017771, w1=-75.59873490827843\n",
      "Gradient Descent(1963/9999): loss=4628.180061161604, w0=18.04519142017771, w1=-75.59873490827843\n",
      "Gradient Descent(1964/9999): loss=4628.180061161604, w0=18.04519142017771, w1=-75.59873490827843\n",
      "Gradient Descent(1965/9999): loss=4628.180061161604, w0=18.04519142017771, w1=-75.59873490827843\n",
      "Gradient Descent(1966/9999): loss=4628.180061161604, w0=18.04519142017771, w1=-75.59873490827843\n",
      "Gradient Descent(1967/9999): loss=4628.180061161604, w0=18.04519142017771, w1=-75.59873490827843\n",
      "Gradient Descent(1968/9999): loss=4628.180061161604, w0=18.04519142017771, w1=-75.59873490827843\n",
      "Gradient Descent(1969/9999): loss=4628.180061161604, w0=30.111956805731243, w1=-63.29603490827843\n",
      "Gradient Descent(1970/9999): loss=8817.472614830243, w0=30.111956805731243, w1=-63.29603490827843\n",
      "Gradient Descent(1971/9999): loss=8817.472614830243, w0=30.111956805731243, w1=-63.29603490827843\n",
      "Gradient Descent(1972/9999): loss=8817.472614830243, w0=20.403056805731243, w1=-65.22613490827842\n",
      "Gradient Descent(1973/9999): loss=4743.3094554667905, w0=31.660356805731244, w1=-62.477034908278426\n",
      "Gradient Descent(1974/9999): loss=11846.756536459772, w0=31.660356805731244, w1=-62.477034908278426\n",
      "Gradient Descent(1975/9999): loss=11846.756536459772, w0=31.660356805731244, w1=-62.477034908278426\n",
      "Gradient Descent(1976/9999): loss=11846.756536459772, w0=31.660356805731244, w1=-62.477034908278426\n",
      "Gradient Descent(1977/9999): loss=11846.756536459772, w0=19.59359142017771, w1=-70.44543490827843\n",
      "Gradient Descent(1978/9999): loss=4415.2779094325815, w0=19.59359142017771, w1=-70.44543490827843\n",
      "Gradient Descent(1979/9999): loss=4415.2779094325815, w0=19.59359142017771, w1=-70.44543490827843\n",
      "Gradient Descent(1980/9999): loss=4415.2779094325815, w0=19.59359142017771, w1=-70.44543490827843\n",
      "Gradient Descent(1981/9999): loss=4415.2779094325815, w0=19.59359142017771, w1=-70.44543490827843\n",
      "Gradient Descent(1982/9999): loss=4415.2779094325815, w0=19.59359142017771, w1=-70.44543490827843\n",
      "Gradient Descent(1983/9999): loss=4415.2779094325815, w0=19.59359142017771, w1=-70.44543490827843\n",
      "Gradient Descent(1984/9999): loss=4415.2779094325815, w0=19.59359142017771, w1=-70.44543490827843\n",
      "Gradient Descent(1985/9999): loss=4415.2779094325815, w0=19.59359142017771, w1=-70.44543490827843\n",
      "Gradient Descent(1986/9999): loss=4415.2779094325815, w0=19.59359142017771, w1=-70.44543490827843\n",
      "Gradient Descent(1987/9999): loss=4415.2779094325815, w0=19.59359142017771, w1=-70.44543490827843\n",
      "Gradient Descent(1988/9999): loss=4415.2779094325815, w0=19.59359142017771, w1=-70.44543490827843\n",
      "Gradient Descent(1989/9999): loss=4415.2779094325815, w0=19.59359142017771, w1=-70.44543490827843\n",
      "Gradient Descent(1990/9999): loss=4415.2779094325815, w0=19.59359142017771, w1=-70.44543490827843\n",
      "Gradient Descent(1991/9999): loss=4415.2779094325815, w0=19.59359142017771, w1=-70.44543490827843\n",
      "Gradient Descent(1992/9999): loss=4415.2779094325815, w0=34.19169142017771, w1=-69.10053490827843\n",
      "Gradient Descent(1993/9999): loss=10256.42484225906, w0=34.19169142017771, w1=-69.10053490827843\n",
      "Gradient Descent(1994/9999): loss=10256.42484225906, w0=26.234991420177714, w1=-71.60823490827843\n",
      "Gradient Descent(1995/9999): loss=4699.562717310347, w0=36.183191420177714, w1=-66.78993490827844\n",
      "Gradient Descent(1996/9999): loss=7665.660695633275, w0=50.07229142017771, w1=-57.77403490827844\n",
      "Gradient Descent(1997/9999): loss=17154.244826461138, w0=38.00552603462418, w1=-66.56363490827843\n",
      "Gradient Descent(1998/9999): loss=10625.294344028542, w0=28.301126034624183, w1=-68.12833490827843\n",
      "Gradient Descent(1999/9999): loss=4842.359401462419, w0=28.301126034624183, w1=-68.12833490827843\n",
      "Gradient Descent(2000/9999): loss=4842.359401462419, w0=28.301126034624183, w1=-68.12833490827843\n",
      "Gradient Descent(2001/9999): loss=4842.359401462419, w0=28.301126034624183, w1=-68.12833490827843\n",
      "Gradient Descent(2002/9999): loss=4842.359401462419, w0=39.79852603462418, w1=-61.050934908278435\n",
      "Gradient Descent(2003/9999): loss=15585.835106550781, w0=27.10702603462418, w1=-69.35403490827844\n",
      "Gradient Descent(2004/9999): loss=4703.034974748499, w0=37.51012603462418, w1=-63.85883490827844\n",
      "Gradient Descent(2005/9999): loss=14505.138360152512, w0=24.061126034624177, w1=-64.52763490827844\n",
      "Gradient Descent(2006/9999): loss=4838.317627930444, w0=24.061126034624177, w1=-64.52763490827844\n",
      "Gradient Descent(2007/9999): loss=4838.317627930444, w0=24.061126034624177, w1=-64.52763490827844\n",
      "Gradient Descent(2008/9999): loss=4838.317627930444, w0=32.297726034624176, w1=-61.828234908278446\n",
      "Gradient Descent(2009/9999): loss=7859.959257598314, w0=24.817326034624177, w1=-63.923634908278444\n",
      "Gradient Descent(2010/9999): loss=4894.61456347521, w0=24.817326034624177, w1=-63.923634908278444\n",
      "Gradient Descent(2011/9999): loss=4894.61456347521, w0=24.817326034624177, w1=-63.923634908278444\n",
      "Gradient Descent(2012/9999): loss=4894.61456347521, w0=24.817326034624177, w1=-63.923634908278444\n",
      "Gradient Descent(2013/9999): loss=4894.61456347521, w0=24.817326034624177, w1=-63.923634908278444\n",
      "Gradient Descent(2014/9999): loss=4894.61456347521, w0=24.817326034624177, w1=-63.923634908278444\n",
      "Gradient Descent(2015/9999): loss=4894.61456347521, w0=24.817326034624177, w1=-63.923634908278444\n",
      "Gradient Descent(2016/9999): loss=4894.61456347521, w0=24.817326034624177, w1=-63.923634908278444\n",
      "Gradient Descent(2017/9999): loss=4894.61456347521, w0=24.817326034624177, w1=-63.923634908278444\n",
      "Gradient Descent(2018/9999): loss=4894.61456347521, w0=24.817326034624177, w1=-63.923634908278444\n",
      "Gradient Descent(2019/9999): loss=4894.61456347521, w0=24.817326034624177, w1=-63.923634908278444\n",
      "Gradient Descent(2020/9999): loss=4894.61456347521, w0=13.756026034624176, w1=-64.33233490827844\n",
      "Gradient Descent(2021/9999): loss=5629.805452453683, w0=23.991226034624177, w1=-58.70673490827844\n",
      "Gradient Descent(2022/9999): loss=4883.616980949821, w0=23.991226034624177, w1=-58.70673490827844\n",
      "Gradient Descent(2023/9999): loss=4883.616980949821, w0=35.95892603462418, w1=-52.80743490827844\n",
      "Gradient Descent(2024/9999): loss=14131.122399946602, w0=23.63212603462418, w1=-55.80803490827844\n",
      "Gradient Descent(2025/9999): loss=5136.646151094571, w0=23.63212603462418, w1=-55.80803490827844\n",
      "Gradient Descent(2026/9999): loss=5136.646151094571, w0=23.63212603462418, w1=-55.80803490827844\n",
      "Gradient Descent(2027/9999): loss=5136.646151094571, w0=23.63212603462418, w1=-55.80803490827844\n",
      "Gradient Descent(2028/9999): loss=5136.646151094571, w0=23.63212603462418, w1=-55.80803490827844\n",
      "Gradient Descent(2029/9999): loss=5136.646151094571, w0=34.12332603462418, w1=-53.19183490827844\n",
      "Gradient Descent(2030/9999): loss=8316.515260570923, w0=21.953226034624176, w1=-58.50263490827844\n",
      "Gradient Descent(2031/9999): loss=4836.234852281437, w0=21.953226034624176, w1=-58.50263490827844\n",
      "Gradient Descent(2032/9999): loss=4836.234852281437, w0=21.953226034624176, w1=-58.50263490827844\n",
      "Gradient Descent(2033/9999): loss=4836.234852281437, w0=35.16932603462418, w1=-52.84453490827843\n",
      "Gradient Descent(2034/9999): loss=11334.257271081657, w0=19.751526034624177, w1=-56.23343490827843\n",
      "Gradient Descent(2035/9999): loss=5095.09984553182, w0=19.751526034624177, w1=-56.23343490827843\n",
      "Gradient Descent(2036/9999): loss=5095.09984553182, w0=19.751526034624177, w1=-56.23343490827843\n",
      "Gradient Descent(2037/9999): loss=5095.09984553182, w0=19.751526034624177, w1=-56.23343490827843\n",
      "Gradient Descent(2038/9999): loss=5095.09984553182, w0=30.21822603462418, w1=-50.726634908278434\n",
      "Gradient Descent(2039/9999): loss=7823.886042913431, w0=19.650426034624182, w1=-55.174634908278435\n",
      "Gradient Descent(2040/9999): loss=5016.350557334092, w0=19.650426034624182, w1=-55.174634908278435\n",
      "Gradient Descent(2041/9999): loss=5016.350557334092, w0=32.93292603462418, w1=-49.581734908278435\n",
      "Gradient Descent(2042/9999): loss=10512.805571215493, w0=32.93292603462418, w1=-49.581734908278435\n",
      "Gradient Descent(2043/9999): loss=10512.805571215493, w0=21.871626034624178, w1=-49.99043490827844\n",
      "Gradient Descent(2044/9999): loss=4839.713732480386, w0=21.871626034624178, w1=-49.99043490827844\n",
      "Gradient Descent(2045/9999): loss=4839.713732480386, w0=21.871626034624178, w1=-49.99043490827844\n",
      "Gradient Descent(2046/9999): loss=4839.713732480386, w0=21.871626034624178, w1=-49.99043490827844\n",
      "Gradient Descent(2047/9999): loss=4839.713732480386, w0=32.50112603462418, w1=-46.89183490827844\n",
      "Gradient Descent(2048/9999): loss=10096.016787804872, w0=32.50112603462418, w1=-46.89183490827844\n",
      "Gradient Descent(2049/9999): loss=10096.016787804872, w0=32.50112603462418, w1=-46.89183490827844\n",
      "Gradient Descent(2050/9999): loss=10096.016787804872, w0=14.627426034624179, w1=-50.76383490827844\n",
      "Gradient Descent(2051/9999): loss=5242.493549986171, w0=26.06512603462418, w1=-45.14313490827844\n",
      "Gradient Descent(2052/9999): loss=6859.468457646085, w0=26.06512603462418, w1=-45.14313490827844\n",
      "Gradient Descent(2053/9999): loss=6859.468457646085, w0=38.13189142017771, w1=-35.96123490827844\n",
      "Gradient Descent(2054/9999): loss=16417.11415045486, w0=17.955991420177707, w1=-43.138334908278445\n",
      "Gradient Descent(2055/9999): loss=5456.733264347232, w0=17.955991420177707, w1=-43.138334908278445\n",
      "Gradient Descent(2056/9999): loss=5456.733264347232, w0=17.955991420177707, w1=-43.138334908278445\n",
      "Gradient Descent(2057/9999): loss=5456.733264347232, w0=17.955991420177707, w1=-43.138334908278445\n",
      "Gradient Descent(2058/9999): loss=5456.733264347232, w0=17.955991420177707, w1=-43.138334908278445\n",
      "Gradient Descent(2059/9999): loss=5456.733264347232, w0=7.388191420177707, w1=-47.586334908278445\n",
      "Gradient Descent(2060/9999): loss=5573.606633006777, w0=7.388191420177707, w1=-47.586334908278445\n",
      "Gradient Descent(2061/9999): loss=5573.606633006777, w0=7.388191420177707, w1=-47.586334908278445\n",
      "Gradient Descent(2062/9999): loss=5573.606633006777, w0=7.388191420177707, w1=-47.586334908278445\n",
      "Gradient Descent(2063/9999): loss=5573.606633006777, w0=7.388191420177707, w1=-47.586334908278445\n",
      "Gradient Descent(2064/9999): loss=5573.606633006777, w0=7.388191420177707, w1=-47.586334908278445\n",
      "Gradient Descent(2065/9999): loss=5573.606633006777, w0=7.388191420177707, w1=-47.586334908278445\n",
      "Gradient Descent(2066/9999): loss=5573.606633006777, w0=18.416091420177708, w1=-46.81593490827844\n",
      "Gradient Descent(2067/9999): loss=6145.3006137894845, w0=8.468623779596143, w1=-51.136127925923105\n",
      "Gradient Descent(2068/9999): loss=5457.111416013384, w0=8.468623779596143, w1=-51.136127925923105\n",
      "Gradient Descent(2069/9999): loss=5457.111416013384, w0=8.468623779596143, w1=-51.136127925923105\n",
      "Gradient Descent(2070/9999): loss=5457.111416013384, w0=8.468623779596143, w1=-51.136127925923105\n",
      "Gradient Descent(2071/9999): loss=5457.111416013384, w0=8.468623779596143, w1=-51.136127925923105\n",
      "Gradient Descent(2072/9999): loss=5457.111416013384, w0=8.468623779596143, w1=-51.136127925923105\n",
      "Gradient Descent(2073/9999): loss=5457.111416013384, w0=8.468623779596143, w1=-51.136127925923105\n",
      "Gradient Descent(2074/9999): loss=5457.111416013384, w0=19.057323779596146, w1=-46.008327925923105\n",
      "Gradient Descent(2075/9999): loss=6254.686616474361, w0=19.057323779596146, w1=-46.008327925923105\n",
      "Gradient Descent(2076/9999): loss=6254.686616474361, w0=19.057323779596146, w1=-46.008327925923105\n",
      "Gradient Descent(2077/9999): loss=6254.686616474361, w0=19.057323779596146, w1=-46.008327925923105\n",
      "Gradient Descent(2078/9999): loss=6254.686616474361, w0=7.783423779596147, w1=-49.13322792592311\n",
      "Gradient Descent(2079/9999): loss=5375.461639463702, w0=7.783423779596147, w1=-49.13322792592311\n",
      "Gradient Descent(2080/9999): loss=5375.461639463702, w0=19.04072377959615, w1=-46.38412792592311\n",
      "Gradient Descent(2081/9999): loss=9875.988919834888, w0=27.39382377959615, w1=-41.01852792592311\n",
      "Gradient Descent(2082/9999): loss=17096.68887756161, w0=27.39382377959615, w1=-41.01852792592311\n",
      "Gradient Descent(2083/9999): loss=17096.68887756161, w0=15.327058394042616, w1=-48.51132792592311\n",
      "Gradient Descent(2084/9999): loss=7651.180494313987, w0=15.327058394042616, w1=-48.51132792592311\n",
      "Gradient Descent(2085/9999): loss=7651.180494313987, w0=15.327058394042616, w1=-48.51132792592311\n",
      "Gradient Descent(2086/9999): loss=7651.180494313987, w0=6.021758394042616, w1=-48.68252792592311\n",
      "Gradient Descent(2087/9999): loss=4881.467961148885, w0=6.021758394042616, w1=-48.68252792592311\n",
      "Gradient Descent(2088/9999): loss=4881.467961148885, w0=19.066958394042615, w1=-44.12872792592311\n",
      "Gradient Descent(2089/9999): loss=10761.648022060086, w0=19.066958394042615, w1=-44.12872792592311\n",
      "Gradient Descent(2090/9999): loss=10761.648022060086, w0=11.381258394042614, w1=-47.68222792592311\n",
      "Gradient Descent(2091/9999): loss=4452.978890239172, w0=11.381258394042614, w1=-47.68222792592311\n",
      "Gradient Descent(2092/9999): loss=4452.978890239172, w0=11.381258394042614, w1=-47.68222792592311\n",
      "Gradient Descent(2093/9999): loss=4452.978890239172, w0=23.44802377959615, w1=-34.65032792592311\n",
      "Gradient Descent(2094/9999): loss=16804.376040968724, w0=13.17322377959615, w1=-40.42002792592311\n",
      "Gradient Descent(2095/9999): loss=4948.420389893623, w0=1.1064583940426154, w1=-46.68252792592311\n",
      "Gradient Descent(2096/9999): loss=5641.3183881033, w0=1.1064583940426154, w1=-46.68252792592311\n",
      "Gradient Descent(2097/9999): loss=5641.3183881033, w0=1.1064583940426154, w1=-46.68252792592311\n",
      "Gradient Descent(2098/9999): loss=5641.3183881033, w0=1.1064583940426154, w1=-46.68252792592311\n",
      "Gradient Descent(2099/9999): loss=5641.3183881033, w0=1.1064583940426154, w1=-46.68252792592311\n",
      "Gradient Descent(2100/9999): loss=5641.3183881033, w0=1.1064583940426154, w1=-46.68252792592311\n",
      "Gradient Descent(2101/9999): loss=5641.3183881033, w0=1.1064583940426154, w1=-46.68252792592311\n",
      "Gradient Descent(2102/9999): loss=5641.3183881033, w0=13.17322377959615, w1=-27.32232792592311\n",
      "Gradient Descent(2103/9999): loss=7891.4710269527695, w0=13.17322377959615, w1=-27.32232792592311\n",
      "Gradient Descent(2104/9999): loss=7891.4710269527695, w0=13.17322377959615, w1=-27.32232792592311\n",
      "Gradient Descent(2105/9999): loss=7891.4710269527695, w0=24.337412636013667, w1=-23.391931849064633\n",
      "Gradient Descent(2106/9999): loss=17004.585691787124, w0=24.337412636013667, w1=-23.391931849064633\n",
      "Gradient Descent(2107/9999): loss=17004.585691787124, w0=24.337412636013667, w1=-23.391931849064633\n",
      "Gradient Descent(2108/9999): loss=17004.585691787124, w0=14.009112636013668, w1=-28.87283184906463\n",
      "Gradient Descent(2109/9999): loss=9057.217971971404, w0=14.009112636013668, w1=-28.87283184906463\n",
      "Gradient Descent(2110/9999): loss=9057.217971971404, w0=14.009112636013668, w1=-28.87283184906463\n",
      "Gradient Descent(2111/9999): loss=9057.217971971404, w0=1.9423472504601342, w1=-36.286631849064634\n",
      "Gradient Descent(2112/9999): loss=5353.494999132126, w0=12.543747250460134, w1=-31.653131849064632\n",
      "Gradient Descent(2113/9999): loss=10963.665322385827, w0=12.543747250460134, w1=-31.653131849064632\n",
      "Gradient Descent(2114/9999): loss=10963.665322385827, w0=-0.5057527495398677, w1=-35.001531849064634\n",
      "Gradient Descent(2115/9999): loss=5110.180091261912, w0=-0.5057527495398677, w1=-35.001531849064634\n",
      "Gradient Descent(2116/9999): loss=5110.180091261912, w0=-0.5057527495398677, w1=-35.001531849064634\n",
      "Gradient Descent(2117/9999): loss=5110.180091261912, w0=-0.5057527495398677, w1=-35.001531849064634\n",
      "Gradient Descent(2118/9999): loss=5110.180091261912, w0=-0.5057527495398677, w1=-35.001531849064634\n",
      "Gradient Descent(2119/9999): loss=5110.180091261912, w0=-0.5057527495398677, w1=-35.001531849064634\n",
      "Gradient Descent(2120/9999): loss=5110.180091261912, w0=-0.5057527495398677, w1=-35.001531849064634\n",
      "Gradient Descent(2121/9999): loss=5110.180091261912, w0=-0.5057527495398677, w1=-35.001531849064634\n",
      "Gradient Descent(2122/9999): loss=5110.180091261912, w0=13.524347250460135, w1=-33.517831849064635\n",
      "Gradient Descent(2123/9999): loss=16429.700692858147, w0=2.1716472504601345, w1=-40.654631849064636\n",
      "Gradient Descent(2124/9999): loss=4856.823515468392, w0=11.291647250460136, w1=-36.38123184906463\n",
      "Gradient Descent(2125/9999): loss=15578.02830830021, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2126/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2127/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2128/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2129/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2130/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2131/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2132/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2133/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2134/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2135/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2136/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2137/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2138/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2139/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2140/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2141/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2142/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2143/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2144/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2145/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2146/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2147/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2148/9999): loss=4607.5886406587815, w0=-0.7751181350933987, w1=-45.608831849064636\n",
      "Gradient Descent(2149/9999): loss=4607.5886406587815, w0=-29.214218135093397, w1=-56.49353184906464\n",
      "Gradient Descent(2150/9999): loss=5802.4994844197445, w0=-18.049518135093393, w1=-48.53073184906464\n",
      "Gradient Descent(2151/9999): loss=5802.4994844197445, w0=-18.049518135093393, w1=-48.53073184906464\n",
      "Gradient Descent(2152/9999): loss=5802.4994844197445, w0=-18.049518135093393, w1=-48.53073184906464\n",
      "Gradient Descent(2153/9999): loss=5802.4994844197445, w0=-18.049518135093393, w1=-48.53073184906464\n",
      "Gradient Descent(2154/9999): loss=5802.4994844197445, w0=-10.211518135093392, w1=-46.24573184906464\n",
      "Gradient Descent(2155/9999): loss=5648.054915542497, w0=-10.211518135093392, w1=-46.24573184906464\n",
      "Gradient Descent(2156/9999): loss=5648.054915542497, w0=-10.211518135093392, w1=-46.24573184906464\n",
      "Gradient Descent(2157/9999): loss=5648.054915542497, w0=-10.211518135093392, w1=-46.24573184906464\n",
      "Gradient Descent(2158/9999): loss=5648.054915542497, w0=-10.211518135093392, w1=-46.24573184906464\n",
      "Gradient Descent(2159/9999): loss=5648.054915542497, w0=-10.211518135093392, w1=-46.24573184906464\n",
      "Gradient Descent(2160/9999): loss=5648.054915542497, w0=-10.211518135093392, w1=-46.24573184906464\n",
      "Gradient Descent(2161/9999): loss=5648.054915542497, w0=-10.211518135093392, w1=-46.24573184906464\n",
      "Gradient Descent(2162/9999): loss=5648.054915542497, w0=0.2796818649066086, w1=-43.62953184906464\n",
      "Gradient Descent(2163/9999): loss=9105.234925138899, w0=0.2796818649066086, w1=-43.62953184906464\n",
      "Gradient Descent(2164/9999): loss=9105.234925138899, w0=-11.787083520646926, w1=-52.24623184906464\n",
      "Gradient Descent(2165/9999): loss=5802.4994844197445, w0=-11.787083520646926, w1=-52.24623184906464\n",
      "Gradient Descent(2166/9999): loss=5802.4994844197445, w0=-11.787083520646926, w1=-52.24623184906464\n",
      "Gradient Descent(2167/9999): loss=5802.4994844197445, w0=-11.787083520646926, w1=-52.24623184906464\n",
      "Gradient Descent(2168/9999): loss=5802.4994844197445, w0=-11.787083520646926, w1=-52.24623184906464\n",
      "Gradient Descent(2169/9999): loss=5802.4994844197445, w0=-11.787083520646926, w1=-52.24623184906464\n",
      "Gradient Descent(2170/9999): loss=5802.4994844197445, w0=0.2796818649066086, w1=-45.252731849064645\n",
      "Gradient Descent(2171/9999): loss=6317.379229683758, w0=-8.478718135093391, w1=-49.07093184906464\n",
      "Gradient Descent(2172/9999): loss=5825.525355349585, w0=-8.478718135093391, w1=-49.07093184906464\n",
      "Gradient Descent(2173/9999): loss=5825.525355349585, w0=-8.478718135093391, w1=-49.07093184906464\n",
      "Gradient Descent(2174/9999): loss=5825.525355349585, w0=-8.478718135093391, w1=-49.07093184906464\n",
      "Gradient Descent(2175/9999): loss=5825.525355349585, w0=0.4182818649066089, w1=-48.62203184906464\n",
      "Gradient Descent(2176/9999): loss=6826.345845708036, w0=0.4182818649066089, w1=-48.62203184906464\n",
      "Gradient Descent(2177/9999): loss=6826.345845708036, w0=12.183981864906611, w1=-45.42263184906464\n",
      "Gradient Descent(2178/9999): loss=16279.078574645131, w0=12.183981864906611, w1=-45.42263184906464\n",
      "Gradient Descent(2179/9999): loss=16279.078574645131, w0=12.183981471397614, w1=-45.422632065125406\n",
      "Gradient Descent(2180/9999): loss=16279.078550807732, w0=12.183981471397614, w1=-45.422632065125406\n",
      "Gradient Descent(2181/9999): loss=16279.078550807732, w0=12.183981471397614, w1=-45.422632065125406\n",
      "Gradient Descent(2182/9999): loss=16279.078550807732, w0=4.655381471397613, w1=-52.168932065125404\n",
      "Gradient Descent(2183/9999): loss=6535.014273335903, w0=4.655381471397613, w1=-52.168932065125404\n",
      "Gradient Descent(2184/9999): loss=6535.014273335903, w0=4.655381471397613, w1=-52.168932065125404\n",
      "Gradient Descent(2185/9999): loss=6535.014273335903, w0=-4.6936185286023875, w1=-56.301232065125404\n",
      "Gradient Descent(2186/9999): loss=5802.4994844197445, w0=-4.6936185286023875, w1=-56.301232065125404\n",
      "Gradient Descent(2187/9999): loss=5802.4994844197445, w0=-4.6936185286023875, w1=-56.301232065125404\n",
      "Gradient Descent(2188/9999): loss=5802.4994844197445, w0=-4.6936185286023875, w1=-56.301232065125404\n",
      "Gradient Descent(2189/9999): loss=5802.4994844197445, w0=-4.6936185286023875, w1=-56.301232065125404\n",
      "Gradient Descent(2190/9999): loss=5802.4994844197445, w0=-4.6936185286023875, w1=-56.301232065125404\n",
      "Gradient Descent(2191/9999): loss=5802.4994844197445, w0=-4.6936185286023875, w1=-56.301232065125404\n",
      "Gradient Descent(2192/9999): loss=5802.4994844197445, w0=10.206381471397613, w1=-51.54083206512541\n",
      "Gradient Descent(2193/9999): loss=6453.64567176691, w0=1.806981471397613, w1=-53.06523206512541\n",
      "Gradient Descent(2194/9999): loss=4902.251388511758, w0=1.806981471397613, w1=-53.06523206512541\n",
      "Gradient Descent(2195/9999): loss=4902.251388511758, w0=1.806981471397613, w1=-53.06523206512541\n",
      "Gradient Descent(2196/9999): loss=4902.251388511758, w0=1.806981471397613, w1=-53.06523206512541\n",
      "Gradient Descent(2197/9999): loss=4902.251388511758, w0=1.806981471397613, w1=-53.06523206512541\n",
      "Gradient Descent(2198/9999): loss=4902.251388511758, w0=1.806981471397613, w1=-53.06523206512541\n",
      "Gradient Descent(2199/9999): loss=4902.251388511758, w0=10.797981471397613, w1=-49.07403206512541\n",
      "Gradient Descent(2200/9999): loss=10879.156629777688, w0=-1.2687839141559216, w1=-54.14113206512541\n",
      "Gradient Descent(2201/9999): loss=5814.012419884665, w0=-1.2687839141559216, w1=-54.14113206512541\n",
      "Gradient Descent(2202/9999): loss=5814.012419884665, w0=-1.2687839141559216, w1=-54.14113206512541\n",
      "Gradient Descent(2203/9999): loss=5814.012419884665, w0=7.113616085844079, w1=-51.53283206512541\n",
      "Gradient Descent(2204/9999): loss=6671.167556238142, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2205/9999): loss=4908.510031332267, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2206/9999): loss=4908.510031332267, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2207/9999): loss=4908.510031332267, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2208/9999): loss=4908.510031332267, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2209/9999): loss=4908.510031332267, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2210/9999): loss=4908.510031332267, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2211/9999): loss=4908.510031332267, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2212/9999): loss=4908.510031332267, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2213/9999): loss=4908.510031332267, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2214/9999): loss=4908.510031332267, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2215/9999): loss=4908.510031332267, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2216/9999): loss=4908.510031332267, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2217/9999): loss=4908.510031332267, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2218/9999): loss=4908.510031332267, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2219/9999): loss=4908.510031332267, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2220/9999): loss=4908.510031332267, w0=1.0303160858440785, w1=-52.824432065125414\n",
      "Gradient Descent(2221/9999): loss=4908.510031332267, w0=-11.652983914155921, w1=-54.87683206512541\n",
      "Gradient Descent(2222/9999): loss=5802.4994844197445, w0=0.4137814713976127, w1=-45.694932065125414\n",
      "Gradient Descent(2223/9999): loss=5825.52481189834, w0=12.876081471397612, w1=-44.47573206512541\n",
      "Gradient Descent(2224/9999): loss=6033.332210368671, w0=12.876081471397612, w1=-44.47573206512541\n",
      "Gradient Descent(2225/9999): loss=6033.332210368671, w0=8.342181471397613, w1=-48.84613206512541\n",
      "Gradient Descent(2226/9999): loss=5389.38405171364, w0=21.930281471397613, w1=-48.30893206512541\n",
      "Gradient Descent(2227/9999): loss=11744.603850466068, w0=21.930281471397613, w1=-48.30893206512541\n",
      "Gradient Descent(2228/9999): loss=11744.603850466068, w0=33.997046856951144, w1=-37.98533206512541\n",
      "Gradient Descent(2229/9999): loss=17050.637433646807, w0=21.93028147139761, w1=-46.017332065125416\n",
      "Gradient Descent(2230/9999): loss=8158.421965613772, w0=21.93028147139761, w1=-46.017332065125416\n",
      "Gradient Descent(2231/9999): loss=8158.421965613772, w0=10.12248147139761, w1=-50.96733206512542\n",
      "Gradient Descent(2232/9999): loss=5711.784523122397, w0=23.06518147139761, w1=-43.080632065125414\n",
      "Gradient Descent(2233/9999): loss=9480.777282147523, w0=13.83698147139761, w1=-45.542532065125414\n",
      "Gradient Descent(2234/9999): loss=5374.064859196915, w0=13.83698147139761, w1=-45.542532065125414\n",
      "Gradient Descent(2235/9999): loss=5374.064859196915, w0=13.83698147139761, w1=-45.542532065125414\n",
      "Gradient Descent(2236/9999): loss=5374.064859196915, w0=13.83698147139761, w1=-45.542532065125414\n",
      "Gradient Descent(2237/9999): loss=5374.064859196915, w0=23.474181471397614, w1=-45.340332065125416\n",
      "Gradient Descent(2238/9999): loss=6915.210906766479, w0=23.474181471397614, w1=-45.340332065125416\n",
      "Gradient Descent(2239/9999): loss=6915.210906766479, w0=10.162281471397613, w1=-52.114232065125414\n",
      "Gradient Descent(2240/9999): loss=5794.356174944709, w0=10.162281471397613, w1=-52.114232065125414\n",
      "Gradient Descent(2241/9999): loss=5794.356174944709, w0=10.162281471397613, w1=-52.114232065125414\n",
      "Gradient Descent(2242/9999): loss=5794.356174944709, w0=10.162281471397613, w1=-52.114232065125414\n",
      "Gradient Descent(2243/9999): loss=5794.356174944709, w0=10.162281471397613, w1=-52.114232065125414\n",
      "Gradient Descent(2244/9999): loss=5794.356174944709, w0=10.162281471397613, w1=-52.114232065125414\n",
      "Gradient Descent(2245/9999): loss=5794.356174944709, w0=22.966481471397614, w1=-51.64673206512541\n",
      "Gradient Descent(2246/9999): loss=5032.676260934124, w0=13.070481471397613, w1=-54.537432065125415\n",
      "Gradient Descent(2247/9999): loss=5388.038245240348, w0=13.070481471397613, w1=-54.537432065125415\n",
      "Gradient Descent(2248/9999): loss=5388.038245240348, w0=13.070481471397613, w1=-54.537432065125415\n",
      "Gradient Descent(2249/9999): loss=5388.038245240348, w0=23.780981471397617, w1=-50.50953206512541\n",
      "Gradient Descent(2250/9999): loss=11342.423875766754, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2251/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2252/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2253/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2254/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2255/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2256/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2257/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2258/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2259/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2260/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2261/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2262/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2263/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2264/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(2265/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2266/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2267/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2268/9999): loss=5491.650559775626, w0=11.714216085844082, w1=-57.20003206512541\n",
      "Gradient Descent(2269/9999): loss=5491.650559775626, w0=25.895716085844082, w1=-55.97013206512541\n",
      "Gradient Descent(2270/9999): loss=8834.805161609685, w0=25.895716085844082, w1=-55.97013206512541\n",
      "Gradient Descent(2271/9999): loss=8834.805161609685, w0=25.895716085844082, w1=-55.97013206512541\n",
      "Gradient Descent(2272/9999): loss=8834.805161609685, w0=25.895716085844082, w1=-55.97013206512541\n",
      "Gradient Descent(2273/9999): loss=8834.805161609685, w0=13.212416085844081, w1=-58.02253206512541\n",
      "Gradient Descent(2274/9999): loss=5652.827800389465, w0=13.212416085844081, w1=-58.02253206512541\n",
      "Gradient Descent(2275/9999): loss=5652.827800389465, w0=24.650116085844083, w1=-52.40183206512541\n",
      "Gradient Descent(2276/9999): loss=4719.151328713267, w0=24.650116085844083, w1=-52.40183206512541\n",
      "Gradient Descent(2277/9999): loss=4719.151328713267, w0=33.03251608584408, w1=-49.79353206512541\n",
      "Gradient Descent(2278/9999): loss=16026.4115722021, w0=16.20241608584408, w1=-56.662832065125414\n",
      "Gradient Descent(2279/9999): loss=4384.407648504273, w0=16.20241608584408, w1=-56.662832065125414\n",
      "Gradient Descent(2280/9999): loss=4384.407648504273, w0=16.20241608584408, w1=-56.662832065125414\n",
      "Gradient Descent(2281/9999): loss=4384.407648504273, w0=16.20241608584408, w1=-56.662832065125414\n",
      "Gradient Descent(2282/9999): loss=4384.407648504273, w0=16.20241608584408, w1=-56.662832065125414\n",
      "Gradient Descent(2283/9999): loss=4384.407648504273, w0=16.20241608584408, w1=-56.662832065125414\n",
      "Gradient Descent(2284/9999): loss=4384.407648504273, w0=16.20241608584408, w1=-56.662832065125414\n",
      "Gradient Descent(2285/9999): loss=4384.407648504273, w0=16.20241608584408, w1=-56.662832065125414\n",
      "Gradient Descent(2286/9999): loss=4384.407648504273, w0=16.20241608584408, w1=-56.662832065125414\n",
      "Gradient Descent(2287/9999): loss=4384.407648504273, w0=16.20241608584408, w1=-56.662832065125414\n",
      "Gradient Descent(2288/9999): loss=4384.407648504273, w0=7.082316085844081, w1=-56.967032065125416\n",
      "Gradient Descent(2289/9999): loss=5802.4994844197445, w0=16.721416085844083, w1=-54.73873206512542\n",
      "Gradient Descent(2290/9999): loss=4579.66423066639, w0=16.721416085844083, w1=-54.73873206512542\n",
      "Gradient Descent(2291/9999): loss=4579.66423066639, w0=16.721416085844083, w1=-54.73873206512542\n",
      "Gradient Descent(2292/9999): loss=4579.66423066639, w0=16.721416085844083, w1=-54.73873206512542\n",
      "Gradient Descent(2293/9999): loss=4579.66423066639, w0=16.721416085844083, w1=-54.73873206512542\n",
      "Gradient Descent(2294/9999): loss=4579.66423066639, w0=16.721416085844083, w1=-54.73873206512542\n",
      "Gradient Descent(2295/9999): loss=4579.66423066639, w0=16.721416085844083, w1=-54.73873206512542\n",
      "Gradient Descent(2296/9999): loss=4579.66423066639, w0=16.721416085844083, w1=-54.73873206512542\n",
      "Gradient Descent(2297/9999): loss=4579.66423066639, w0=24.323016085844085, w1=-50.51463206512542\n",
      "Gradient Descent(2298/9999): loss=14173.738380587933, w0=12.25625070029055, w1=-61.00693206512542\n",
      "Gradient Descent(2299/9999): loss=4765.211248412479, w0=12.25625070029055, w1=-61.00693206512542\n",
      "Gradient Descent(2300/9999): loss=4765.211248412479, w0=12.25625070029055, w1=-61.00693206512542\n",
      "Gradient Descent(2301/9999): loss=4765.211248412479, w0=12.25625070029055, w1=-61.00693206512542\n",
      "Gradient Descent(2302/9999): loss=4765.211248412479, w0=12.25625070029055, w1=-61.00693206512542\n",
      "Gradient Descent(2303/9999): loss=4765.211248412479, w0=12.25625070029055, w1=-61.00693206512542\n",
      "Gradient Descent(2304/9999): loss=4765.211248412479, w0=21.45505070029055, w1=-55.07473206512542\n",
      "Gradient Descent(2305/9999): loss=13074.7370200028, w0=9.48615070029055, w1=-64.73043206512541\n",
      "Gradient Descent(2306/9999): loss=4604.950283841174, w0=20.72775070029055, w1=-60.84983206512541\n",
      "Gradient Descent(2307/9999): loss=7335.257797802757, w0=20.72775070029055, w1=-60.84983206512541\n",
      "Gradient Descent(2308/9999): loss=7335.257797802757, w0=20.72775070029055, w1=-60.84983206512541\n",
      "Gradient Descent(2309/9999): loss=7335.257797802757, w0=10.634950700290549, w1=-66.9969320651254\n",
      "Gradient Descent(2310/9999): loss=5059.7886147679155, w0=10.634950700290549, w1=-66.9969320651254\n",
      "Gradient Descent(2311/9999): loss=5059.7886147679155, w0=10.634950700290549, w1=-66.9969320651254\n",
      "Gradient Descent(2312/9999): loss=5059.7886147679155, w0=10.634950700290549, w1=-66.9969320651254\n",
      "Gradient Descent(2313/9999): loss=5059.7886147679155, w0=10.634950700290549, w1=-66.9969320651254\n",
      "Gradient Descent(2314/9999): loss=5059.7886147679155, w0=18.21215070029055, w1=-63.787132065125405\n",
      "Gradient Descent(2315/9999): loss=4858.142392512538, w0=30.278916085844084, w1=-54.783032065125404\n",
      "Gradient Descent(2316/9999): loss=16923.99517686144, w0=18.21215070029055, w1=-61.6791320651254\n",
      "Gradient Descent(2317/9999): loss=10869.035400600587, w0=5.125750700290549, w1=-70.0940320651254\n",
      "Gradient Descent(2318/9999): loss=4982.4332134858805, w0=5.125750700290549, w1=-70.0940320651254\n",
      "Gradient Descent(2319/9999): loss=4982.4332134858805, w0=16.42815070029055, w1=-67.3091320651254\n",
      "Gradient Descent(2320/9999): loss=8144.9725898141605, w0=2.0740507002905506, w1=-74.97503206512539\n",
      "Gradient Descent(2321/9999): loss=4974.230263539156, w0=2.0740507002905506, w1=-74.97503206512539\n",
      "Gradient Descent(2322/9999): loss=4974.230263539156, w0=2.0740507002905506, w1=-74.97503206512539\n",
      "Gradient Descent(2323/9999): loss=4974.230263539156, w0=2.0740507002905506, w1=-74.97503206512539\n",
      "Gradient Descent(2324/9999): loss=4974.230263539156, w0=2.0740507002905506, w1=-74.97503206512539\n",
      "Gradient Descent(2325/9999): loss=4974.230263539156, w0=2.0740507002905506, w1=-74.97503206512539\n",
      "Gradient Descent(2326/9999): loss=4974.230263539156, w0=2.0740507002905506, w1=-74.97503206512539\n",
      "Gradient Descent(2327/9999): loss=4974.230263539156, w0=16.67215070029055, w1=-73.6301320651254\n",
      "Gradient Descent(2328/9999): loss=6456.915208612449, w0=16.67215070029055, w1=-73.6301320651254\n",
      "Gradient Descent(2329/9999): loss=6456.915208612449, w0=1.4016507002905492, w1=-78.3087320651254\n",
      "Gradient Descent(2330/9999): loss=5699.947825531755, w0=1.4016507002905492, w1=-78.3087320651254\n",
      "Gradient Descent(2331/9999): loss=5699.947825531755, w0=13.59315070029055, w1=-75.0865320651254\n",
      "Gradient Descent(2332/9999): loss=5546.267049697421, w0=13.59315070029055, w1=-75.0865320651254\n",
      "Gradient Descent(2333/9999): loss=5546.267049697421, w0=13.59315070029055, w1=-75.0865320651254\n",
      "Gradient Descent(2334/9999): loss=5546.267049697421, w0=13.59315070029055, w1=-75.0865320651254\n",
      "Gradient Descent(2335/9999): loss=5546.267049697421, w0=-0.02144929970945242, w1=-76.6837320651254\n",
      "Gradient Descent(2336/9999): loss=5790.986547638883, w0=-0.02144929970945242, w1=-76.6837320651254\n",
      "Gradient Descent(2337/9999): loss=5790.986547638883, w0=11.825350700290548, w1=-74.5159320651254\n",
      "Gradient Descent(2338/9999): loss=4466.365531129305, w0=11.825350700290548, w1=-74.5159320651254\n",
      "Gradient Descent(2339/9999): loss=4466.365531129305, w0=23.89211608584408, w1=-47.248332065125396\n",
      "Gradient Descent(2340/9999): loss=17016.098627252046, w0=23.89211608584408, w1=-47.248332065125396\n",
      "Gradient Descent(2341/9999): loss=17016.098627252046, w0=-8.527983914155918, w1=-50.9489320651254\n",
      "Gradient Descent(2342/9999): loss=5466.388264619306, w0=2.9097160858440834, w1=-45.3282320651254\n",
      "Gradient Descent(2343/9999): loss=13930.734934199032, w0=-8.048283914155917, w1=-46.5986320651254\n",
      "Gradient Descent(2344/9999): loss=5214.02163309535, w0=2.6764160858440853, w1=-42.5789320651254\n",
      "Gradient Descent(2345/9999): loss=12264.298079981772, w0=-9.390349299709449, w1=-47.7013320651254\n",
      "Gradient Descent(2346/9999): loss=5370.326889614169, w0=-17.84954929970945, w1=-48.0103320651254\n",
      "Gradient Descent(2347/9999): loss=5802.4994844197445, w0=-5.782783914155917, w1=-30.373932065125395\n",
      "Gradient Descent(2348/9999): loss=13492.230162271828, w0=-5.782783914155917, w1=-30.373932065125395\n",
      "Gradient Descent(2349/9999): loss=13492.230162271828, w0=-5.782783914155917, w1=-30.373932065125395\n",
      "Gradient Descent(2350/9999): loss=13492.230162271828, w0=-5.782783914155917, w1=-30.373932065125395\n",
      "Gradient Descent(2351/9999): loss=13492.230162271828, w0=-5.782783914155917, w1=-30.373932065125395\n",
      "Gradient Descent(2352/9999): loss=13492.230162271828, w0=-12.96798391415592, w1=-32.68703206512539\n",
      "Gradient Descent(2353/9999): loss=6076.370777507764, w0=-12.96798391415592, w1=-32.68703206512539\n",
      "Gradient Descent(2354/9999): loss=6076.370777507764, w0=-0.8826839141559191, w1=-32.32693206512539\n",
      "Gradient Descent(2355/9999): loss=11077.615831777406, w0=-0.8826839141559191, w1=-32.32693206512539\n",
      "Gradient Descent(2356/9999): loss=11077.615831777406, w0=-6.07578391415592, w1=-36.89753206512539\n",
      "Gradient Descent(2357/9999): loss=5160.255173682907, w0=-6.07578391415592, w1=-36.89753206512539\n",
      "Gradient Descent(2358/9999): loss=5160.255173682907, w0=-6.07578391415592, w1=-36.89753206512539\n",
      "Gradient Descent(2359/9999): loss=5160.255173682907, w0=-6.07578391415592, w1=-36.89753206512539\n",
      "Gradient Descent(2360/9999): loss=5160.255173682907, w0=-6.07578391415592, w1=-36.89753206512539\n",
      "Gradient Descent(2361/9999): loss=5160.255173682907, w0=-6.07578391415592, w1=-36.89753206512539\n",
      "Gradient Descent(2362/9999): loss=5160.255173682907, w0=-6.07578391415592, w1=-36.89753206512539\n",
      "Gradient Descent(2363/9999): loss=5160.255173682907, w0=-6.07578391415592, w1=-36.89753206512539\n",
      "Gradient Descent(2364/9999): loss=5160.255173682907, w0=-6.07578391415592, w1=-36.89753206512539\n",
      "Gradient Descent(2365/9999): loss=5160.255173682907, w0=-6.07578391415592, w1=-36.89753206512539\n",
      "Gradient Descent(2366/9999): loss=5160.255173682907, w0=-6.07578391415592, w1=-36.89753206512539\n",
      "Gradient Descent(2367/9999): loss=5160.255173682907, w0=-6.07578391415592, w1=-36.89753206512539\n",
      "Gradient Descent(2368/9999): loss=5160.255173682907, w0=-6.07578391415592, w1=-36.89753206512539\n",
      "Gradient Descent(2369/9999): loss=5160.255173682907, w0=-6.07578391415592, w1=-36.89753206512539\n",
      "Gradient Descent(2370/9999): loss=5160.255173682907, w0=-6.07578391415592, w1=-36.89753206512539\n",
      "Gradient Descent(2371/9999): loss=5160.255173682907, w0=-6.07578391415592, w1=-36.89753206512539\n",
      "Gradient Descent(2372/9999): loss=5160.255173682907, w0=7.886416085844083, w1=-36.55393206512539\n",
      "Gradient Descent(2373/9999): loss=15124.527027672137, w0=7.886416085844083, w1=-36.55393206512539\n",
      "Gradient Descent(2374/9999): loss=15124.527027672137, w0=-5.355083914155918, w1=-41.68753206512539\n",
      "Gradient Descent(2375/9999): loss=5473.401305710444, w0=-5.355083914155918, w1=-41.68753206512539\n",
      "Gradient Descent(2376/9999): loss=5473.401305710444, w0=-5.355083914155918, w1=-41.68753206512539\n",
      "Gradient Descent(2377/9999): loss=5473.401305710444, w0=-5.355083914155918, w1=-41.68753206512539\n",
      "Gradient Descent(2378/9999): loss=5473.401305710444, w0=-5.355083914155918, w1=-41.68753206512539\n",
      "Gradient Descent(2379/9999): loss=5473.401305710444, w0=6.7116814713976165, w1=-37.77823206512539\n",
      "Gradient Descent(2380/9999): loss=15155.551489903977, w0=6.7116814713976165, w1=-37.77823206512539\n",
      "Gradient Descent(2381/9999): loss=15155.551489903977, w0=-0.15391852860238409, w1=-40.30763206512539\n",
      "Gradient Descent(2382/9999): loss=5184.394385652797, w0=-0.15391852860238409, w1=-40.30763206512539\n",
      "Gradient Descent(2383/9999): loss=5184.394385652797, w0=-0.15391852860238409, w1=-40.30763206512539\n",
      "Gradient Descent(2384/9999): loss=5184.394385652797, w0=12.006081471397616, w1=-37.24323206512539\n",
      "Gradient Descent(2385/9999): loss=16555.581214007303, w0=4.532481471397615, w1=-43.12323206512539\n",
      "Gradient Descent(2386/9999): loss=7518.87338029019, w0=-3.759018528602386, w1=-46.96093206512539\n",
      "Gradient Descent(2387/9999): loss=5174.734835354004, w0=9.657881471397612, w1=-44.68753206512539\n",
      "Gradient Descent(2388/9999): loss=13194.481207513905, w0=-6.622018528602389, w1=-46.27203206512539\n",
      "Gradient Descent(2389/9999): loss=5094.958802616969, w0=-6.622018528602389, w1=-46.27203206512539\n",
      "Gradient Descent(2390/9999): loss=5094.958802616969, w0=-6.622018528602389, w1=-46.27203206512539\n",
      "Gradient Descent(2391/9999): loss=5094.958802616969, w0=1.242581471397611, w1=-42.355232065125385\n",
      "Gradient Descent(2392/9999): loss=7239.732977107422, w0=1.242581471397611, w1=-42.355232065125385\n",
      "Gradient Descent(2393/9999): loss=7239.732977107422, w0=1.242581471397611, w1=-42.355232065125385\n",
      "Gradient Descent(2394/9999): loss=7239.732977107422, w0=-10.824183857844911, w1=-51.72943202137955\n",
      "Gradient Descent(2395/9999): loss=5802.4994844197445, w0=-10.824183857844911, w1=-51.72943202137955\n",
      "Gradient Descent(2396/9999): loss=5802.4994844197445, w0=-10.824183857844911, w1=-51.72943202137955\n",
      "Gradient Descent(2397/9999): loss=5802.4994844197445, w0=-10.824183857844911, w1=-51.72943202137955\n",
      "Gradient Descent(2398/9999): loss=5802.4994844197445, w0=0.49551614215508977, w1=-47.46943202137955\n",
      "Gradient Descent(2399/9999): loss=4936.82658993046, w0=0.49551614215508977, w1=-47.46943202137955\n",
      "Gradient Descent(2400/9999): loss=4936.82658993046, w0=0.49551614215508977, w1=-47.46943202137955\n",
      "Gradient Descent(2401/9999): loss=4936.82658993046, w0=9.821216142155091, w1=-44.47963202137955\n",
      "Gradient Descent(2402/9999): loss=15664.655610303187, w0=0.5475161421550894, w1=-47.10543202137955\n",
      "Gradient Descent(2403/9999): loss=4706.85344945649, w0=0.5475161421550894, w1=-47.10543202137955\n",
      "Gradient Descent(2404/9999): loss=4706.85344945649, w0=-7.626283857844911, w1=-49.400932021379546\n",
      "Gradient Descent(2405/9999): loss=5800.328928767056, w0=-7.626283857844911, w1=-49.400932021379546\n",
      "Gradient Descent(2406/9999): loss=5800.328928767056, w0=2.7003161421550903, w1=-47.81393202137954\n",
      "Gradient Descent(2407/9999): loss=4787.194398719272, w0=2.7003161421550903, w1=-47.81393202137954\n",
      "Gradient Descent(2408/9999): loss=4787.194398719272, w0=2.7003161421550903, w1=-47.81393202137954\n",
      "Gradient Descent(2409/9999): loss=4787.194398719272, w0=2.7003161421550903, w1=-47.81393202137954\n",
      "Gradient Descent(2410/9999): loss=4787.194398719272, w0=-9.366449243398444, w1=-53.71863202137954\n",
      "Gradient Descent(2411/9999): loss=5802.4994844197445, w0=-9.366449243398444, w1=-53.71863202137954\n",
      "Gradient Descent(2412/9999): loss=5802.4994844197445, w0=-9.366449243398444, w1=-53.71863202137954\n",
      "Gradient Descent(2413/9999): loss=5802.4994844197445, w0=-9.366449243398444, w1=-53.71863202137954\n",
      "Gradient Descent(2414/9999): loss=5802.4994844197445, w0=-9.366449243398444, w1=-53.71863202137954\n",
      "Gradient Descent(2415/9999): loss=5802.4994844197445, w0=1.0682507566015573, w1=-49.27833202137954\n",
      "Gradient Descent(2416/9999): loss=4766.341809195919, w0=1.0682507566015573, w1=-49.27833202137954\n",
      "Gradient Descent(2417/9999): loss=4766.341809195919, w0=1.0682507566015573, w1=-49.27833202137954\n",
      "Gradient Descent(2418/9999): loss=4766.341809195919, w0=10.044550756601557, w1=-45.33153202137954\n",
      "Gradient Descent(2419/9999): loss=10418.782607639083, w0=10.044550756601557, w1=-45.33153202137954\n",
      "Gradient Descent(2420/9999): loss=10418.782607639083, w0=10.044550756601557, w1=-45.33153202137954\n",
      "Gradient Descent(2421/9999): loss=10418.782607639083, w0=10.044550756601557, w1=-45.33153202137954\n",
      "Gradient Descent(2422/9999): loss=10418.782607639083, w0=10.044550756601557, w1=-45.33153202137954\n",
      "Gradient Descent(2423/9999): loss=10418.782607639083, w0=10.044550756601557, w1=-45.33153202137954\n",
      "Gradient Descent(2424/9999): loss=10418.782607639083, w0=-2.0222146289519767, w1=-53.30163202137954\n",
      "Gradient Descent(2425/9999): loss=4956.068638504768, w0=10.716485371048025, w1=-49.56593202137954\n",
      "Gradient Descent(2426/9999): loss=12276.632950034313, w0=10.716485371048025, w1=-49.56593202137954\n",
      "Gradient Descent(2427/9999): loss=12276.632950034313, w0=10.716485371048025, w1=-49.56593202137954\n",
      "Gradient Descent(2428/9999): loss=12276.632950034313, w0=2.9715853710480244, w1=-53.49423202137954\n",
      "Gradient Descent(2429/9999): loss=4603.469747087165, w0=2.9715853710480244, w1=-53.49423202137954\n",
      "Gradient Descent(2430/9999): loss=4603.469747087165, w0=2.9715853710480244, w1=-53.49423202137954\n",
      "Gradient Descent(2431/9999): loss=4603.469747087165, w0=2.9715853710480244, w1=-53.49423202137954\n",
      "Gradient Descent(2432/9999): loss=4603.469747087165, w0=2.9715853710480244, w1=-53.49423202137954\n",
      "Gradient Descent(2433/9999): loss=4603.469747087165, w0=-12.246514628951978, w1=-57.49303202137954\n",
      "Gradient Descent(2434/9999): loss=5802.4994844197445, w0=-12.246514628951978, w1=-57.49303202137954\n",
      "Gradient Descent(2435/9999): loss=5802.4994844197445, w0=-12.246514628951978, w1=-57.49303202137954\n",
      "Gradient Descent(2436/9999): loss=5802.4994844197445, w0=-12.246514628951978, w1=-57.49303202137954\n",
      "Gradient Descent(2437/9999): loss=5802.4994844197445, w0=-12.246514628951978, w1=-57.49303202137954\n",
      "Gradient Descent(2438/9999): loss=5802.4994844197445, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2439/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2440/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2441/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2442/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2443/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2444/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2445/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2446/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2447/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2448/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2449/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2450/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2451/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2452/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2453/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2454/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2455/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2456/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2457/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2458/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2459/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2460/9999): loss=5222.163685465186, w0=-4.225214628951976, w1=-53.057532021379544\n",
      "Gradient Descent(2461/9999): loss=5222.163685465186, w0=7.4158853710480255, w1=-50.918832021379544\n",
      "Gradient Descent(2462/9999): loss=12928.997745569188, w0=7.4158853710480255, w1=-50.918832021379544\n",
      "Gradient Descent(2463/9999): loss=12928.997745569188, w0=-4.650880014505509, w1=-59.148532021379545\n",
      "Gradient Descent(2464/9999): loss=4712.67141244465, w0=-4.650880014505509, w1=-59.148532021379545\n",
      "Gradient Descent(2465/9999): loss=4712.67141244465, w0=-4.650880014505509, w1=-59.148532021379545\n",
      "Gradient Descent(2466/9999): loss=4712.67141244465, w0=6.651519985494492, w1=-56.363632021379544\n",
      "Gradient Descent(2467/9999): loss=12374.289406586588, w0=6.651519985494492, w1=-56.363632021379544\n",
      "Gradient Descent(2468/9999): loss=12374.289406586588, w0=-2.0717800145055083, w1=-61.552432021379545\n",
      "Gradient Descent(2469/9999): loss=4743.302333367998, w0=-2.0717800145055083, w1=-61.552432021379545\n",
      "Gradient Descent(2470/9999): loss=4743.302333367998, w0=-2.0717800145055083, w1=-61.552432021379545\n",
      "Gradient Descent(2471/9999): loss=4743.302333367998, w0=-10.245580014505508, w1=-63.84793202137954\n",
      "Gradient Descent(2472/9999): loss=5779.473613489904, w0=-10.245580014505508, w1=-63.84793202137954\n",
      "Gradient Descent(2473/9999): loss=5779.473613489904, w0=-10.245580014505508, w1=-63.84793202137954\n",
      "Gradient Descent(2474/9999): loss=5779.473613489904, w0=-10.245580014505508, w1=-63.84793202137954\n",
      "Gradient Descent(2475/9999): loss=5779.473613489904, w0=-10.245580014505508, w1=-63.84793202137954\n",
      "Gradient Descent(2476/9999): loss=5779.473613489904, w0=-10.245580014505508, w1=-63.84793202137954\n",
      "Gradient Descent(2477/9999): loss=5779.473613489904, w0=-10.245580014505508, w1=-63.84793202137954\n",
      "Gradient Descent(2478/9999): loss=5779.473613489904, w0=-10.245580014505508, w1=-63.84793202137954\n",
      "Gradient Descent(2479/9999): loss=5779.473613489904, w0=2.280519985494493, w1=-57.697532021379544\n",
      "Gradient Descent(2480/9999): loss=5923.363762547276, w0=9.630219985494493, w1=-53.50953202137954\n",
      "Gradient Descent(2481/9999): loss=14465.343947851421, w0=9.630219985494493, w1=-53.50953202137954\n",
      "Gradient Descent(2482/9999): loss=14465.343947851421, w0=3.541919985494493, w1=-57.113632021379544\n",
      "Gradient Descent(2483/9999): loss=4559.2898754378275, w0=3.541919985494493, w1=-57.113632021379544\n",
      "Gradient Descent(2484/9999): loss=4559.2898754378275, w0=3.541919985494493, w1=-57.113632021379544\n",
      "Gradient Descent(2485/9999): loss=4559.2898754378275, w0=3.541919985494493, w1=-57.113632021379544\n",
      "Gradient Descent(2486/9999): loss=4559.2898754378275, w0=12.867619985494494, w1=-54.12383202137954\n",
      "Gradient Descent(2487/9999): loss=14479.368431369154, w0=12.867619985494494, w1=-54.12383202137954\n",
      "Gradient Descent(2488/9999): loss=14479.368431369154, w0=12.867619985494494, w1=-54.12383202137954\n",
      "Gradient Descent(2489/9999): loss=14479.368431369154, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2490/9999): loss=4434.32684956551, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2491/9999): loss=4434.32684956551, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2492/9999): loss=4434.32684956551, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2493/9999): loss=4434.32684956551, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2494/9999): loss=4434.32684956551, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2495/9999): loss=4434.32684956551, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2496/9999): loss=4434.32684956551, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2497/9999): loss=4434.32684956551, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2498/9999): loss=4434.32684956551, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2499/9999): loss=4434.32684956551, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2500/9999): loss=4434.32684956551, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2501/9999): loss=4434.32684956551, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2502/9999): loss=4434.32684956551, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2503/9999): loss=4434.32684956551, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2504/9999): loss=4434.32684956551, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2505/9999): loss=4434.32684956551, w0=5.777419985494494, w1=-56.96073202137954\n",
      "Gradient Descent(2506/9999): loss=4434.32684956551, w0=20.822119985494496, w1=-54.13813202137954\n",
      "Gradient Descent(2507/9999): loss=15687.685685477023, w0=13.216019985494494, w1=-57.28733202137954\n",
      "Gradient Descent(2508/9999): loss=4451.874533392196, w0=13.216019985494494, w1=-57.28733202137954\n",
      "Gradient Descent(2509/9999): loss=4451.874533392196, w0=13.216019985494494, w1=-57.28733202137954\n",
      "Gradient Descent(2510/9999): loss=4451.874533392196, w0=13.216019985494494, w1=-57.28733202137954\n",
      "Gradient Descent(2511/9999): loss=4451.874533392196, w0=13.216019985494494, w1=-57.28733202137954\n",
      "Gradient Descent(2512/9999): loss=4451.874533392196, w0=13.216019985494494, w1=-57.28733202137954\n",
      "Gradient Descent(2513/9999): loss=4451.874533392196, w0=13.216019985494494, w1=-57.28733202137954\n",
      "Gradient Descent(2514/9999): loss=4451.874533392196, w0=13.216019985494494, w1=-57.28733202137954\n",
      "Gradient Descent(2515/9999): loss=4451.874533392196, w0=13.216019985494494, w1=-57.28733202137954\n",
      "Gradient Descent(2516/9999): loss=4451.874533392196, w0=22.336019985494495, w1=-53.01393202137954\n",
      "Gradient Descent(2517/9999): loss=12447.653616758405, w0=22.336019985494495, w1=-53.01393202137954\n",
      "Gradient Descent(2518/9999): loss=12447.653616758405, w0=22.336019985494495, w1=-53.01393202137954\n",
      "Gradient Descent(2519/9999): loss=12447.653616758405, w0=22.336019985494495, w1=-53.01393202137954\n",
      "Gradient Descent(2520/9999): loss=12447.653616758405, w0=22.336019985494495, w1=-53.01393202137954\n",
      "Gradient Descent(2521/9999): loss=12447.653616758405, w0=22.336019985494495, w1=-53.01393202137954\n",
      "Gradient Descent(2522/9999): loss=12447.653616758405, w0=4.708219985494495, w1=-63.51203202137954\n",
      "Gradient Descent(2523/9999): loss=4971.096352833254, w0=4.708219985494495, w1=-63.51203202137954\n",
      "Gradient Descent(2524/9999): loss=4971.096352833254, w0=4.708219985494495, w1=-63.51203202137954\n",
      "Gradient Descent(2525/9999): loss=4971.096352833254, w0=4.708219985494495, w1=-63.51203202137954\n",
      "Gradient Descent(2526/9999): loss=4971.096352833254, w0=4.708219985494495, w1=-63.51203202137954\n",
      "Gradient Descent(2527/9999): loss=4971.096352833254, w0=4.708219985494495, w1=-63.51203202137954\n",
      "Gradient Descent(2528/9999): loss=4971.096352833254, w0=13.954319985494495, w1=-57.79063202137954\n",
      "Gradient Descent(2529/9999): loss=5241.588866450486, w0=13.954319985494495, w1=-57.79063202137954\n",
      "Gradient Descent(2530/9999): loss=5241.588866450486, w0=13.954319985494495, w1=-57.79063202137954\n",
      "Gradient Descent(2531/9999): loss=5241.588866450486, w0=13.954319985494495, w1=-57.79063202137954\n",
      "Gradient Descent(2532/9999): loss=5241.588866450486, w0=13.954319985494495, w1=-57.79063202137954\n",
      "Gradient Descent(2533/9999): loss=5241.588866450486, w0=13.954319985494495, w1=-57.79063202137954\n",
      "Gradient Descent(2534/9999): loss=5241.588866450486, w0=13.954319985494495, w1=-57.79063202137954\n",
      "Gradient Descent(2535/9999): loss=5241.588866450486, w0=13.954319985494495, w1=-57.79063202137954\n",
      "Gradient Descent(2536/9999): loss=5241.588866450486, w0=13.954319985494495, w1=-57.79063202137954\n",
      "Gradient Descent(2537/9999): loss=5241.588866450486, w0=24.851719985494494, w1=-52.797232021379536\n",
      "Gradient Descent(2538/9999): loss=16785.83991869624, w0=12.78495459994096, w1=-60.180732021379534\n",
      "Gradient Descent(2539/9999): loss=6435.883149379979, w0=12.78495459994096, w1=-60.180732021379534\n",
      "Gradient Descent(2540/9999): loss=6435.883149379979, w0=12.78495459994096, w1=-60.180732021379534\n",
      "Gradient Descent(2541/9999): loss=6435.883149379979, w0=12.78495459994096, w1=-60.180732021379534\n",
      "Gradient Descent(2542/9999): loss=6435.883149379979, w0=12.78495459994096, w1=-60.180732021379534\n",
      "Gradient Descent(2543/9999): loss=6435.883149379979, w0=12.78495459994096, w1=-60.180732021379534\n",
      "Gradient Descent(2544/9999): loss=6435.883149379979, w0=12.78495459994096, w1=-60.180732021379534\n",
      "Gradient Descent(2545/9999): loss=6435.883149379979, w0=12.78495459994096, w1=-60.180732021379534\n",
      "Gradient Descent(2546/9999): loss=6435.883149379979, w0=12.78495459994096, w1=-60.180732021379534\n",
      "Gradient Descent(2547/9999): loss=6435.883149379979, w0=12.78495459994096, w1=-60.180732021379534\n",
      "Gradient Descent(2548/9999): loss=6435.883149379979, w0=12.78495459994096, w1=-60.180732021379534\n",
      "Gradient Descent(2549/9999): loss=6435.883149379979, w0=-9.458445400059045, w1=-66.21603202137953\n",
      "Gradient Descent(2550/9999): loss=5802.4994844197445, w0=-9.458445400059045, w1=-66.21603202137953\n",
      "Gradient Descent(2551/9999): loss=5802.4994844197445, w0=-9.458445400059045, w1=-66.21603202137953\n",
      "Gradient Descent(2552/9999): loss=5802.4994844197445, w0=2.6083199854944894, w1=-59.399732021379535\n",
      "Gradient Descent(2553/9999): loss=4704.189441450703, w0=2.6083199854944894, w1=-59.399732021379535\n",
      "Gradient Descent(2554/9999): loss=4704.189441450703, w0=-22.860680014505512, w1=-62.791032021379536\n",
      "Gradient Descent(2555/9999): loss=5802.4994844197445, w0=-22.860680014505512, w1=-62.791032021379536\n",
      "Gradient Descent(2556/9999): loss=5802.4994844197445, w0=-22.860680014505512, w1=-62.791032021379536\n",
      "Gradient Descent(2557/9999): loss=5802.4994844197445, w0=-22.860680014505512, w1=-62.791032021379536\n",
      "Gradient Descent(2558/9999): loss=5802.4994844197445, w0=-22.860680014505512, w1=-62.791032021379536\n",
      "Gradient Descent(2559/9999): loss=5802.4994844197445, w0=-22.860680014505512, w1=-62.791032021379536\n",
      "Gradient Descent(2560/9999): loss=5802.4994844197445, w0=-9.556180014505513, w1=-59.128332021379535\n",
      "Gradient Descent(2561/9999): loss=5802.4994844197445, w0=2.5105853710480215, w1=-45.13143202137954\n",
      "Gradient Descent(2562/9999): loss=6141.4035322703785, w0=2.5105853710480215, w1=-45.13143202137954\n",
      "Gradient Descent(2563/9999): loss=6141.4035322703785, w0=2.5105853710480215, w1=-45.13143202137954\n",
      "Gradient Descent(2564/9999): loss=6141.4035322703785, w0=2.5105853710480215, w1=-45.13143202137954\n",
      "Gradient Descent(2565/9999): loss=6141.4035322703785, w0=2.5105853710480215, w1=-45.13143202137954\n",
      "Gradient Descent(2566/9999): loss=6141.4035322703785, w0=-6.587014628951978, w1=-51.40333202137954\n",
      "Gradient Descent(2567/9999): loss=5733.432875036799, w0=5.280085371048022, w1=-51.10663202137954\n",
      "Gradient Descent(2568/9999): loss=4792.873307766284, w0=5.280085371048022, w1=-51.10663202137954\n",
      "Gradient Descent(2569/9999): loss=4792.873307766284, w0=-10.527414628951977, w1=-52.28983202137954\n",
      "Gradient Descent(2570/9999): loss=5802.4994844197445, w0=-10.527414628951977, w1=-52.28983202137954\n",
      "Gradient Descent(2571/9999): loss=5802.4994844197445, w0=-10.527414628951977, w1=-52.28983202137954\n",
      "Gradient Descent(2572/9999): loss=5802.4994844197445, w0=-2.1743146289519757, w1=-46.92423202137954\n",
      "Gradient Descent(2573/9999): loss=4780.733150849328, w0=-2.1743146289519757, w1=-46.92423202137954\n",
      "Gradient Descent(2574/9999): loss=4780.733150849328, w0=-2.1743146289519757, w1=-46.92423202137954\n",
      "Gradient Descent(2575/9999): loss=4780.733150849328, w0=-2.1743146289519757, w1=-46.92423202137954\n",
      "Gradient Descent(2576/9999): loss=4780.733150849328, w0=-2.1743146289519757, w1=-46.92423202137954\n",
      "Gradient Descent(2577/9999): loss=4780.733150849328, w0=-2.1743146289519757, w1=-46.92423202137954\n",
      "Gradient Descent(2578/9999): loss=4780.733150849328, w0=-2.1743146289519757, w1=-46.92423202137954\n",
      "Gradient Descent(2579/9999): loss=4780.733150849328, w0=-2.1743146289519757, w1=-46.92423202137954\n",
      "Gradient Descent(2580/9999): loss=4780.733150849328, w0=13.570385371048026, w1=-43.157432021379535\n",
      "Gradient Descent(2581/9999): loss=16157.94718429581, w0=-0.7283146289519742, w1=-50.69243202137953\n",
      "Gradient Descent(2582/9999): loss=4708.007262860966, w0=-0.7283146289519742, w1=-50.69243202137953\n",
      "Gradient Descent(2583/9999): loss=4708.007262860966, w0=-0.7283146289519742, w1=-50.69243202137953\n",
      "Gradient Descent(2584/9999): loss=4708.007262860966, w0=-0.7283146289519742, w1=-50.69243202137953\n",
      "Gradient Descent(2585/9999): loss=4708.007262860966, w0=-0.7283146289519742, w1=-50.69243202137953\n",
      "Gradient Descent(2586/9999): loss=4708.007262860966, w0=-0.7283146289519742, w1=-50.69243202137953\n",
      "Gradient Descent(2587/9999): loss=4708.007262860966, w0=-0.7283146289519742, w1=-50.69243202137953\n",
      "Gradient Descent(2588/9999): loss=4708.007262860966, w0=-0.7283146289519742, w1=-50.69243202137953\n",
      "Gradient Descent(2589/9999): loss=4708.007262860966, w0=-0.7283146289519742, w1=-50.69243202137953\n",
      "Gradient Descent(2590/9999): loss=4708.007262860966, w0=-0.7283146289519742, w1=-50.69243202137953\n",
      "Gradient Descent(2591/9999): loss=4708.007262860966, w0=11.33845075660156, w1=-38.04053202137953\n",
      "Gradient Descent(2592/9999): loss=16198.679775100742, w0=-3.993449243398439, w1=-46.977832021379534\n",
      "Gradient Descent(2593/9999): loss=4662.462240332999, w0=-3.993449243398439, w1=-46.977832021379534\n",
      "Gradient Descent(2594/9999): loss=4662.462240332999, w0=-3.993449243398439, w1=-46.977832021379534\n",
      "Gradient Descent(2595/9999): loss=4662.462240332999, w0=-3.993449243398439, w1=-46.977832021379534\n",
      "Gradient Descent(2596/9999): loss=4662.462240332999, w0=-3.993449243398439, w1=-46.977832021379534\n",
      "Gradient Descent(2597/9999): loss=4662.462240332999, w0=-3.993449243398439, w1=-46.977832021379534\n",
      "Gradient Descent(2598/9999): loss=4662.462240332999, w0=-3.993449243398439, w1=-46.977832021379534\n",
      "Gradient Descent(2599/9999): loss=4662.462240332999, w0=-3.993449243398439, w1=-46.977832021379534\n",
      "Gradient Descent(2600/9999): loss=4662.462240332999, w0=8.073316142155095, w1=-38.646932021379534\n",
      "Gradient Descent(2601/9999): loss=16410.747594816712, w0=1.823316142155095, w1=-43.055732021379534\n",
      "Gradient Descent(2602/9999): loss=9751.13181909925, w0=-5.187983857844905, w1=-49.00853202137954\n",
      "Gradient Descent(2603/9999): loss=5008.106937246885, w0=-5.187983857844905, w1=-49.00853202137954\n",
      "Gradient Descent(2604/9999): loss=5008.106937246885, w0=-5.187983857844905, w1=-49.00853202137954\n",
      "Gradient Descent(2605/9999): loss=5008.106937246885, w0=-5.187983857844905, w1=-49.00853202137954\n",
      "Gradient Descent(2606/9999): loss=5008.106937246885, w0=5.413416142155095, w1=-44.37503202137954\n",
      "Gradient Descent(2607/9999): loss=10546.250614254117, w0=-10.004383857844905, w1=-47.76393202137954\n",
      "Gradient Descent(2608/9999): loss=5721.908094221828, w0=-10.004383857844905, w1=-47.76393202137954\n",
      "Gradient Descent(2609/9999): loss=5721.908094221828, w0=-10.004383857844905, w1=-47.76393202137954\n",
      "Gradient Descent(2610/9999): loss=5721.908094221828, w0=-10.004383857844905, w1=-47.76393202137954\n",
      "Gradient Descent(2611/9999): loss=5721.908094221828, w0=-10.004383857844905, w1=-47.76393202137954\n",
      "Gradient Descent(2612/9999): loss=5721.908094221828, w0=2.3971161421550953, w1=-44.211632021379536\n",
      "Gradient Descent(2613/9999): loss=8228.12890189715, w0=2.3971161421550953, w1=-44.211632021379536\n",
      "Gradient Descent(2614/9999): loss=8228.12890189715, w0=2.3971161421550953, w1=-44.211632021379536\n",
      "Gradient Descent(2615/9999): loss=8228.12890189715, w0=-9.669649243398439, w1=-50.62733202137954\n",
      "Gradient Descent(2616/9999): loss=5307.764467487983, w0=-9.669649243398439, w1=-50.62733202137954\n",
      "Gradient Descent(2617/9999): loss=5307.764467487983, w0=-9.669649243398439, w1=-50.62733202137954\n",
      "Gradient Descent(2618/9999): loss=5307.764467487983, w0=-9.669649243398439, w1=-50.62733202137954\n",
      "Gradient Descent(2619/9999): loss=5307.764467487983, w0=-9.669649243398439, w1=-50.62733202137954\n",
      "Gradient Descent(2620/9999): loss=5307.764467487983, w0=-9.669649243398439, w1=-50.62733202137954\n",
      "Gradient Descent(2621/9999): loss=5307.764467487983, w0=2.4182507566015605, w1=-46.26543202137954\n",
      "Gradient Descent(2622/9999): loss=15530.978788817622, w0=-5.04874924339844, w1=-52.67403202137954\n",
      "Gradient Descent(2623/9999): loss=7208.901042595942, w0=7.018016142155094, w1=-45.74163202137954\n",
      "Gradient Descent(2624/9999): loss=16355.510176711909, w0=-5.04874924339844, w1=-53.04133202137954\n",
      "Gradient Descent(2625/9999): loss=4517.37594229812, w0=-5.04874924339844, w1=-53.04133202137954\n",
      "Gradient Descent(2626/9999): loss=4517.37594229812, w0=-5.04874924339844, w1=-53.04133202137954\n",
      "Gradient Descent(2627/9999): loss=4517.37594229812, w0=8.76205075660156, w1=-47.583832021379536\n",
      "Gradient Descent(2628/9999): loss=16417.424675450377, w0=-3.3047146289519738, w1=-55.71853202137954\n",
      "Gradient Descent(2629/9999): loss=5132.950614006586, w0=-12.609614628951974, w1=-57.81783202137954\n",
      "Gradient Descent(2630/9999): loss=5779.572065132972, w0=-12.609614628951974, w1=-57.81783202137954\n",
      "Gradient Descent(2631/9999): loss=5779.572065132972, w0=-12.609614628951974, w1=-57.81783202137954\n",
      "Gradient Descent(2632/9999): loss=5779.572065132972, w0=-12.609614628951974, w1=-57.81783202137954\n",
      "Gradient Descent(2633/9999): loss=5779.572065132972, w0=-2.452514628951974, w1=-55.09403202137953\n",
      "Gradient Descent(2634/9999): loss=4646.38494732087, w0=-2.452514628951974, w1=-55.09403202137953\n",
      "Gradient Descent(2635/9999): loss=4646.38494732087, w0=-2.452514628951974, w1=-55.09403202137953\n",
      "Gradient Descent(2636/9999): loss=4646.38494732087, w0=-2.452514628951974, w1=-55.09403202137953\n",
      "Gradient Descent(2637/9999): loss=4646.38494732087, w0=-2.452514628951974, w1=-55.09403202137953\n",
      "Gradient Descent(2638/9999): loss=4646.38494732087, w0=-2.452514628951974, w1=-55.09403202137953\n",
      "Gradient Descent(2639/9999): loss=4646.38494732087, w0=-2.452514628951974, w1=-55.09403202137953\n",
      "Gradient Descent(2640/9999): loss=4646.38494732087, w0=-2.452514628951974, w1=-55.09403202137953\n",
      "Gradient Descent(2641/9999): loss=4646.38494732087, w0=-2.452514628951974, w1=-55.09403202137953\n",
      "Gradient Descent(2642/9999): loss=4646.38494732087, w0=-2.452514628951974, w1=-55.09403202137953\n",
      "Gradient Descent(2643/9999): loss=4646.38494732087, w0=-2.452514628951974, w1=-55.09403202137953\n",
      "Gradient Descent(2644/9999): loss=4646.38494732087, w0=-2.452514628951974, w1=-55.09403202137953\n",
      "Gradient Descent(2645/9999): loss=4646.38494732087, w0=-2.452514628951974, w1=-55.09403202137953\n",
      "Gradient Descent(2646/9999): loss=4646.38494732087, w0=-2.452514628951974, w1=-55.09403202137953\n",
      "Gradient Descent(2647/9999): loss=4646.38494732087, w0=-2.452514628951974, w1=-55.09403202137953\n",
      "Gradient Descent(2648/9999): loss=4646.38494732087, w0=-10.969314628951974, w1=-57.13443202137953\n",
      "Gradient Descent(2649/9999): loss=5480.35445181022, w0=-10.969314628951974, w1=-57.13443202137953\n",
      "Gradient Descent(2650/9999): loss=5480.35445181022, w0=-10.969314628951974, w1=-57.13443202137953\n",
      "Gradient Descent(2651/9999): loss=5480.35445181022, w0=1.7693853710480276, w1=-53.39873202137953\n",
      "Gradient Descent(2652/9999): loss=7091.161168610462, w0=1.7693853710480276, w1=-53.39873202137953\n",
      "Gradient Descent(2653/9999): loss=7091.161168610462, w0=-8.427914628951973, w1=-54.46313202137953\n",
      "Gradient Descent(2654/9999): loss=5563.36597179792, w0=-8.427914628951973, w1=-54.46313202137953\n",
      "Gradient Descent(2655/9999): loss=5563.36597179792, w0=-8.427914628951973, w1=-54.46313202137953\n",
      "Gradient Descent(2656/9999): loss=5563.36597179792, w0=-8.427914628951973, w1=-54.46313202137953\n",
      "Gradient Descent(2657/9999): loss=5563.36597179792, w0=-8.427914628951973, w1=-54.46313202137953\n",
      "Gradient Descent(2658/9999): loss=5563.36597179792, w0=-8.427914628951973, w1=-54.46313202137953\n",
      "Gradient Descent(2659/9999): loss=5563.36597179792, w0=-8.427914628951973, w1=-54.46313202137953\n",
      "Gradient Descent(2660/9999): loss=5563.36597179792, w0=0.6239853710480272, w1=-49.07053202137953\n",
      "Gradient Descent(2661/9999): loss=4422.6899839133985, w0=0.6239853710480272, w1=-49.07053202137953\n",
      "Gradient Descent(2662/9999): loss=4422.6899839133985, w0=0.6239853710480272, w1=-49.07053202137953\n",
      "Gradient Descent(2663/9999): loss=4422.6899839133985, w0=0.6239853710480272, w1=-49.07053202137953\n",
      "Gradient Descent(2664/9999): loss=4422.6899839133985, w0=12.690750756601561, w1=-40.066432021379526\n",
      "Gradient Descent(2665/9999): loss=16820.378034610956, w0=3.3858507566015614, w1=-42.165732021379526\n",
      "Gradient Descent(2666/9999): loss=6183.005651313843, w0=3.3858507566015614, w1=-42.165732021379526\n",
      "Gradient Descent(2667/9999): loss=6183.005651313843, w0=3.3858507566015614, w1=-42.165732021379526\n",
      "Gradient Descent(2668/9999): loss=6183.005651313843, w0=3.3858507566015614, w1=-42.165732021379526\n",
      "Gradient Descent(2669/9999): loss=6183.005651313843, w0=-4.9056492433984396, w1=-46.003432021379524\n",
      "Gradient Descent(2670/9999): loss=4993.60783845053, w0=-4.9056492433984396, w1=-46.003432021379524\n",
      "Gradient Descent(2671/9999): loss=4993.60783845053, w0=-4.9056492433984396, w1=-46.003432021379524\n",
      "Gradient Descent(2672/9999): loss=4993.60783845053, w0=-4.9056492433984396, w1=-46.003432021379524\n",
      "Gradient Descent(2673/9999): loss=4993.60783845053, w0=7.99835075660156, w1=-44.900732021379525\n",
      "Gradient Descent(2674/9999): loss=12771.173766534743, w0=-7.061349243398441, w1=-51.72293202137953\n",
      "Gradient Descent(2675/9999): loss=5111.170793386214, w0=-7.061349243398441, w1=-51.72293202137953\n",
      "Gradient Descent(2676/9999): loss=5111.170793386214, w0=-7.061349243398441, w1=-51.72293202137953\n",
      "Gradient Descent(2677/9999): loss=5111.170793386214, w0=-7.061349243398441, w1=-51.72293202137953\n",
      "Gradient Descent(2678/9999): loss=5111.170793386214, w0=5.005416142155093, w1=-37.726032021379524\n",
      "Gradient Descent(2679/9999): loss=14690.006943648154, w0=-7.061349243398441, w1=-46.04123202137953\n",
      "Gradient Descent(2680/9999): loss=4575.216341424852, w0=-7.061349243398441, w1=-46.04123202137953\n",
      "Gradient Descent(2681/9999): loss=4575.216341424852, w0=-7.061349243398441, w1=-46.04123202137953\n",
      "Gradient Descent(2682/9999): loss=4575.216341424852, w0=1.8254507566015583, w1=-42.80243202137953\n",
      "Gradient Descent(2683/9999): loss=14421.732056426174, w0=-12.65284924339844, w1=-54.12093202137953\n",
      "Gradient Descent(2684/9999): loss=5629.805452454996, w0=-12.65284924339844, w1=-54.12093202137953\n",
      "Gradient Descent(2685/9999): loss=5629.805452454996, w0=-1.4198492433984402, w1=-52.08873202137953\n",
      "Gradient Descent(2686/9999): loss=5086.942216121091, w0=-1.4198492433984402, w1=-52.08873202137953\n",
      "Gradient Descent(2687/9999): loss=5086.942216121091, w0=-1.4198492433984402, w1=-52.08873202137953\n",
      "Gradient Descent(2688/9999): loss=5086.942216121091, w0=-1.4198492433984402, w1=-52.08873202137953\n",
      "Gradient Descent(2689/9999): loss=5086.942216121091, w0=-1.4198492433984402, w1=-52.08873202137953\n",
      "Gradient Descent(2690/9999): loss=5086.942216121091, w0=-1.4198492433984402, w1=-52.08873202137953\n",
      "Gradient Descent(2691/9999): loss=5086.942216121091, w0=-1.4198492433984402, w1=-52.08873202137953\n",
      "Gradient Descent(2692/9999): loss=5086.942216121091, w0=-1.4198492433984402, w1=-52.08873202137953\n",
      "Gradient Descent(2693/9999): loss=5086.942216121091, w0=-1.4198492433984402, w1=-52.08873202137953\n",
      "Gradient Descent(2694/9999): loss=5086.942216121091, w0=-1.4198492433984402, w1=-52.08873202137953\n",
      "Gradient Descent(2695/9999): loss=5086.942216121091, w0=-1.4198492433984402, w1=-52.08873202137953\n",
      "Gradient Descent(2696/9999): loss=5086.942216121091, w0=-1.4198492433984402, w1=-52.08873202137953\n",
      "Gradient Descent(2697/9999): loss=5086.942216121091, w0=9.049150756601561, w1=-46.780432021379525\n",
      "Gradient Descent(2698/9999): loss=15760.142735195139, w0=9.049150756601561, w1=-46.780432021379525\n",
      "Gradient Descent(2699/9999): loss=15760.142735195139, w0=9.049150756601561, w1=-46.780432021379525\n",
      "Gradient Descent(2700/9999): loss=15760.142735195139, w0=-2.29484924339844, w1=-51.43443202137952\n",
      "Gradient Descent(2701/9999): loss=4719.90708071285, w0=-2.29484924339844, w1=-51.43443202137952\n",
      "Gradient Descent(2702/9999): loss=4719.90708071285, w0=-7.72824924339844, w1=-55.79133202137952\n",
      "Gradient Descent(2703/9999): loss=5547.568519808814, w0=-7.72824924339844, w1=-55.79133202137952\n",
      "Gradient Descent(2704/9999): loss=5547.568519808814, w0=-7.72824924339844, w1=-55.79133202137952\n",
      "Gradient Descent(2705/9999): loss=5547.568519808814, w0=0.9119507566015601, w1=-52.930632021379516\n",
      "Gradient Descent(2706/9999): loss=4654.677458986847, w0=0.9119507566015601, w1=-52.930632021379516\n",
      "Gradient Descent(2707/9999): loss=4654.677458986847, w0=0.9119507566015601, w1=-52.930632021379516\n",
      "Gradient Descent(2708/9999): loss=4654.677458986847, w0=0.9119507566015601, w1=-52.930632021379516\n",
      "Gradient Descent(2709/9999): loss=4654.677458986847, w0=0.9119507566015601, w1=-52.930632021379516\n",
      "Gradient Descent(2710/9999): loss=4654.677458986847, w0=0.9119507566015601, w1=-52.930632021379516\n",
      "Gradient Descent(2711/9999): loss=4654.677458986847, w0=0.9119507566015601, w1=-52.930632021379516\n",
      "Gradient Descent(2712/9999): loss=4654.677458986847, w0=0.9119507566015601, w1=-52.930632021379516\n",
      "Gradient Descent(2713/9999): loss=4654.677458986847, w0=0.9119507566015601, w1=-52.930632021379516\n",
      "Gradient Descent(2714/9999): loss=4654.677458986847, w0=0.9119507566015601, w1=-52.930632021379516\n",
      "Gradient Descent(2715/9999): loss=4654.677458986847, w0=10.235450756601562, w1=-48.32173202137952\n",
      "Gradient Descent(2716/9999): loss=15324.033155310075, w0=-0.23144924339843875, w1=-53.85863202137952\n",
      "Gradient Descent(2717/9999): loss=4625.11031428334, w0=-0.23144924339843875, w1=-53.85863202137952\n",
      "Gradient Descent(2718/9999): loss=4625.11031428334, w0=-0.23144924339843875, w1=-53.85863202137952\n",
      "Gradient Descent(2719/9999): loss=4625.11031428334, w0=-0.23144924339843875, w1=-53.85863202137952\n",
      "Gradient Descent(2720/9999): loss=4625.11031428334, w0=-0.23144924339843875, w1=-53.85863202137952\n",
      "Gradient Descent(2721/9999): loss=4625.11031428334, w0=-10.204249243398438, w1=-57.14003202137952\n",
      "Gradient Descent(2722/9999): loss=5767.815032426339, w0=-10.204249243398438, w1=-57.14003202137952\n",
      "Gradient Descent(2723/9999): loss=5767.815032426339, w0=4.520750756601563, w1=-54.04143202137952\n",
      "Gradient Descent(2724/9999): loss=4880.877764157325, w0=-4.673549243398437, w1=-56.91473202137952\n",
      "Gradient Descent(2725/9999): loss=5618.301672098081, w0=-4.673549243398437, w1=-56.91473202137952\n",
      "Gradient Descent(2726/9999): loss=5618.301672098081, w0=-4.673549243398437, w1=-56.91473202137952\n",
      "Gradient Descent(2727/9999): loss=5618.301672098081, w0=-4.673549243398437, w1=-56.91473202137952\n",
      "Gradient Descent(2728/9999): loss=5618.301672098081, w0=6.055950756601565, w1=-54.86203202137952\n",
      "Gradient Descent(2729/9999): loss=4469.28578707726, w0=6.055950756601565, w1=-54.86203202137952\n",
      "Gradient Descent(2730/9999): loss=4469.28578707726, w0=6.055950756601565, w1=-54.86203202137952\n",
      "Gradient Descent(2731/9999): loss=4469.28578707726, w0=-9.751549243398435, w1=-56.04523202137952\n",
      "Gradient Descent(2732/9999): loss=5802.4994844197445, w0=-9.751549243398435, w1=-56.04523202137952\n",
      "Gradient Descent(2733/9999): loss=5802.4994844197445, w0=-9.751549243398435, w1=-56.04523202137952\n",
      "Gradient Descent(2734/9999): loss=5802.4994844197445, w0=-9.751549243398435, w1=-56.04523202137952\n",
      "Gradient Descent(2735/9999): loss=5802.4994844197445, w0=-9.751549243398435, w1=-56.04523202137952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(2736/9999): loss=5802.4994844197445, w0=-9.751549243398435, w1=-56.04523202137952\n",
      "Gradient Descent(2737/9999): loss=5802.4994844197445, w0=-9.751549243398435, w1=-56.04523202137952\n",
      "Gradient Descent(2738/9999): loss=5802.4994844197445, w0=-9.751549243398435, w1=-56.04523202137952\n",
      "Gradient Descent(2739/9999): loss=5802.4994844197445, w0=2.9580507566015672, w1=-54.23163202137952\n",
      "Gradient Descent(2740/9999): loss=4749.172515120368, w0=2.9580507566015672, w1=-54.23163202137952\n",
      "Gradient Descent(2741/9999): loss=4749.172515120368, w0=2.9580507566015672, w1=-54.23163202137952\n",
      "Gradient Descent(2742/9999): loss=4749.172515120368, w0=13.332550756601568, w1=-50.40123202137952\n",
      "Gradient Descent(2743/9999): loss=10604.885435446071, w0=13.332550756601568, w1=-50.40123202137952\n",
      "Gradient Descent(2744/9999): loss=10604.885435446071, w0=3.7097507566015686, w1=-57.20743202137952\n",
      "Gradient Descent(2745/9999): loss=4743.318137735692, w0=3.7097507566015686, w1=-57.20743202137952\n",
      "Gradient Descent(2746/9999): loss=4743.318137735692, w0=3.7097507566015686, w1=-57.20743202137952\n",
      "Gradient Descent(2747/9999): loss=4743.318137735692, w0=3.7097507566015686, w1=-57.20743202137952\n",
      "Gradient Descent(2748/9999): loss=4743.318137735692, w0=3.7097507566015686, w1=-57.20743202137952\n",
      "Gradient Descent(2749/9999): loss=4743.318137735692, w0=3.7097507566015686, w1=-57.20743202137952\n",
      "Gradient Descent(2750/9999): loss=4743.318137735692, w0=15.012150756601569, w1=-54.42253202137952\n",
      "Gradient Descent(2751/9999): loss=10225.099947634015, w0=15.012150756601569, w1=-54.42253202137952\n",
      "Gradient Descent(2752/9999): loss=10225.099947634015, w0=5.574650756601569, w1=-60.614432021379514\n",
      "Gradient Descent(2753/9999): loss=4540.463487056406, w0=16.594250756601568, w1=-57.212532021379516\n",
      "Gradient Descent(2754/9999): loss=13316.10808269523, w0=4.527485371048034, w1=-65.41333202137952\n",
      "Gradient Descent(2755/9999): loss=4599.084410361139, w0=4.527485371048034, w1=-65.41333202137952\n",
      "Gradient Descent(2756/9999): loss=4599.084410361139, w0=4.527485371048034, w1=-65.41333202137952\n",
      "Gradient Descent(2757/9999): loss=4599.084410361139, w0=4.527485371048034, w1=-65.41333202137952\n",
      "Gradient Descent(2758/9999): loss=4599.084410361139, w0=4.527485371048034, w1=-65.41333202137952\n",
      "Gradient Descent(2759/9999): loss=4599.084410361139, w0=4.527485371048034, w1=-65.41333202137952\n",
      "Gradient Descent(2760/9999): loss=4599.084410361139, w0=4.527485371048034, w1=-65.41333202137952\n",
      "Gradient Descent(2761/9999): loss=4599.084410361139, w0=4.527485371048034, w1=-65.41333202137952\n",
      "Gradient Descent(2762/9999): loss=4599.084410361139, w0=19.572185371048036, w1=-62.590732021379516\n",
      "Gradient Descent(2763/9999): loss=10421.95916700217, w0=5.654885371048035, w1=-69.99073202137951\n",
      "Gradient Descent(2764/9999): loss=4739.688221103794, w0=5.654885371048035, w1=-69.99073202137951\n",
      "Gradient Descent(2765/9999): loss=4739.688221103794, w0=5.654885371048035, w1=-69.99073202137951\n",
      "Gradient Descent(2766/9999): loss=4739.688221103794, w0=5.654885371048035, w1=-69.99073202137951\n",
      "Gradient Descent(2767/9999): loss=4739.688221103794, w0=5.654885371048035, w1=-69.99073202137951\n",
      "Gradient Descent(2768/9999): loss=4739.688221103794, w0=5.654885371048035, w1=-69.99073202137951\n",
      "Gradient Descent(2769/9999): loss=4739.688221103794, w0=18.076785371048036, w1=-67.68403202137951\n",
      "Gradient Descent(2770/9999): loss=8488.672398360799, w0=6.689685371048034, w1=-72.2640320213795\n",
      "Gradient Descent(2771/9999): loss=4276.381725193502, w0=6.689685371048034, w1=-72.2640320213795\n",
      "Gradient Descent(2772/9999): loss=4276.381725193502, w0=6.689685371048034, w1=-72.2640320213795\n",
      "Gradient Descent(2773/9999): loss=4276.381725193502, w0=6.689685371048034, w1=-72.2640320213795\n",
      "Gradient Descent(2774/9999): loss=4276.381725193502, w0=6.689685371048034, w1=-72.2640320213795\n",
      "Gradient Descent(2775/9999): loss=4276.381725193502, w0=6.689685371048034, w1=-72.2640320213795\n",
      "Gradient Descent(2776/9999): loss=4276.381725193502, w0=6.689685371048034, w1=-72.2640320213795\n",
      "Gradient Descent(2777/9999): loss=4276.381725193502, w0=6.689685371048034, w1=-72.2640320213795\n",
      "Gradient Descent(2778/9999): loss=4276.381725193502, w0=6.689685371048034, w1=-72.2640320213795\n",
      "Gradient Descent(2779/9999): loss=4276.381725193502, w0=6.689685371048034, w1=-72.2640320213795\n",
      "Gradient Descent(2780/9999): loss=4276.381725193502, w0=6.689685371048034, w1=-72.2640320213795\n",
      "Gradient Descent(2781/9999): loss=4276.381725193502, w0=18.756450756601566, w1=-59.232132021379506\n",
      "Gradient Descent(2782/9999): loss=15591.908066845483, w0=18.756450756601566, w1=-59.232132021379506\n",
      "Gradient Descent(2783/9999): loss=15591.908066845483, w0=4.732150756601566, w1=-65.6938320213795\n",
      "Gradient Descent(2784/9999): loss=4463.867683117677, w0=4.732150756601566, w1=-65.6938320213795\n",
      "Gradient Descent(2785/9999): loss=4463.867683117677, w0=4.732150756601566, w1=-65.6938320213795\n",
      "Gradient Descent(2786/9999): loss=4463.867683117677, w0=4.732150756601566, w1=-65.6938320213795\n",
      "Gradient Descent(2787/9999): loss=4463.867683117677, w0=4.732150756601566, w1=-65.6938320213795\n",
      "Gradient Descent(2788/9999): loss=4463.867683117677, w0=-3.3862492433984333, w1=-67.00093202137951\n",
      "Gradient Descent(2789/9999): loss=5503.163122585569, w0=-3.3862492433984333, w1=-67.00093202137951\n",
      "Gradient Descent(2790/9999): loss=5503.163122585569, w0=-3.3862492433984333, w1=-67.00093202137951\n",
      "Gradient Descent(2791/9999): loss=5503.163122585569, w0=-3.3862492433984333, w1=-67.00093202137951\n",
      "Gradient Descent(2792/9999): loss=5503.163122585569, w0=-3.3862492433984333, w1=-67.00093202137951\n",
      "Gradient Descent(2793/9999): loss=5503.163122585569, w0=-3.3862492433984333, w1=-67.00093202137951\n",
      "Gradient Descent(2794/9999): loss=5503.163122585569, w0=-3.3862492433984333, w1=-67.00093202137951\n",
      "Gradient Descent(2795/9999): loss=5503.163122585569, w0=8.382050756601567, w1=-65.16933202137952\n",
      "Gradient Descent(2796/9999): loss=5511.2062011307535, w0=0.30845075660156596, w1=-67.17673202137952\n",
      "Gradient Descent(2797/9999): loss=4524.87561589595, w0=0.30845075660156596, w1=-67.17673202137952\n",
      "Gradient Descent(2798/9999): loss=4524.87561589595, w0=14.730750756601566, w1=-63.87423202137952\n",
      "Gradient Descent(2799/9999): loss=13186.914370552393, w0=-9.870249243398433, w1=-66.86863202137953\n",
      "Gradient Descent(2800/9999): loss=4762.987501794902, w0=-9.870249243398433, w1=-66.86863202137953\n",
      "Gradient Descent(2801/9999): loss=4762.987501794902, w0=-9.870249243398433, w1=-66.86863202137953\n",
      "Gradient Descent(2802/9999): loss=4762.987501794902, w0=-9.870249243398433, w1=-66.86863202137953\n",
      "Gradient Descent(2803/9999): loss=4762.987501794902, w0=-9.870249243398433, w1=-66.86863202137953\n",
      "Gradient Descent(2804/9999): loss=4762.987501794902, w0=-9.870249243398433, w1=-66.86863202137953\n",
      "Gradient Descent(2805/9999): loss=4762.987501794902, w0=-9.870249243398433, w1=-66.86863202137953\n",
      "Gradient Descent(2806/9999): loss=4762.987501794902, w0=-17.948049243398437, w1=-67.32753202137953\n",
      "Gradient Descent(2807/9999): loss=5802.4994844197445, w0=-17.948049243398437, w1=-67.32753202137953\n",
      "Gradient Descent(2808/9999): loss=5802.4994844197445, w0=-17.948049243398437, w1=-67.32753202137953\n",
      "Gradient Descent(2809/9999): loss=5802.4994844197445, w0=-17.948049243398437, w1=-67.32753202137953\n",
      "Gradient Descent(2810/9999): loss=5802.4994844197445, w0=-17.948049243398437, w1=-67.32753202137953\n",
      "Gradient Descent(2811/9999): loss=5802.4994844197445, w0=-17.948049243398437, w1=-67.32753202137953\n",
      "Gradient Descent(2812/9999): loss=5802.4994844197445, w0=-17.948049243398437, w1=-67.32753202137953\n",
      "Gradient Descent(2813/9999): loss=5802.4994844197445, w0=-17.948049243398437, w1=-67.32753202137953\n",
      "Gradient Descent(2814/9999): loss=5802.4994844197445, w0=-5.679449243398436, w1=-60.723532021379526\n",
      "Gradient Descent(2815/9999): loss=4599.236678509544, w0=-5.679449243398436, w1=-60.723532021379526\n",
      "Gradient Descent(2816/9999): loss=4599.236678509544, w0=-22.362749243398433, w1=-63.89483202137953\n",
      "Gradient Descent(2817/9999): loss=5802.4994844197445, w0=-10.295983857844899, w1=-51.171932021379526\n",
      "Gradient Descent(2818/9999): loss=5021.603278472205, w0=-10.295983857844899, w1=-51.171932021379526\n",
      "Gradient Descent(2819/9999): loss=5021.603278472205, w0=-3.1248838578448987, w1=-47.82443202137952\n",
      "Gradient Descent(2820/9999): loss=6766.541247902713, w0=-3.1248838578448987, w1=-47.82443202137952\n",
      "Gradient Descent(2821/9999): loss=6766.541247902713, w0=-3.1248838578448987, w1=-47.82443202137952\n",
      "Gradient Descent(2822/9999): loss=6766.541247902713, w0=-11.2986838578449, w1=-50.11993202137952\n",
      "Gradient Descent(2823/9999): loss=4975.693207798503, w0=-11.2986838578449, w1=-50.11993202137952\n",
      "Gradient Descent(2824/9999): loss=4975.693207798503, w0=-11.2986838578449, w1=-50.11993202137952\n",
      "Gradient Descent(2825/9999): loss=4975.693207798503, w0=-11.2986838578449, w1=-50.11993202137952\n",
      "Gradient Descent(2826/9999): loss=4975.693207798503, w0=-11.2986838578449, w1=-50.11993202137952\n",
      "Gradient Descent(2827/9999): loss=4975.693207798503, w0=-11.2986838578449, w1=-50.11993202137952\n",
      "Gradient Descent(2828/9999): loss=4975.693207798503, w0=-11.2986838578449, w1=-50.11993202137952\n",
      "Gradient Descent(2829/9999): loss=4975.693207798503, w0=-11.2986838578449, w1=-50.11993202137952\n",
      "Gradient Descent(2830/9999): loss=4975.693207798503, w0=-11.2986838578449, w1=-50.11993202137952\n",
      "Gradient Descent(2831/9999): loss=4975.693207798503, w0=-11.2986838578449, w1=-50.11993202137952\n",
      "Gradient Descent(2832/9999): loss=4975.693207798503, w0=-11.2986838578449, w1=-50.11993202137952\n",
      "Gradient Descent(2833/9999): loss=4975.693207798503, w0=1.578716142155102, w1=-49.28353202137952\n",
      "Gradient Descent(2834/9999): loss=5763.649963394507, w0=-10.488049243398432, w1=-55.126732021379524\n",
      "Gradient Descent(2835/9999): loss=5583.753710586263, w0=-10.488049243398432, w1=-55.126732021379524\n",
      "Gradient Descent(2836/9999): loss=5583.753710586263, w0=-10.488049243398432, w1=-55.126732021379524\n",
      "Gradient Descent(2837/9999): loss=5583.753710586263, w0=-10.488049243398432, w1=-55.126732021379524\n",
      "Gradient Descent(2838/9999): loss=5583.753710586263, w0=-10.488049243398432, w1=-55.126732021379524\n",
      "Gradient Descent(2839/9999): loss=5583.753710586263, w0=-10.488049243398432, w1=-55.126732021379524\n",
      "Gradient Descent(2840/9999): loss=5583.753710586263, w0=-10.488049243398432, w1=-55.126732021379524\n",
      "Gradient Descent(2841/9999): loss=5583.753710586263, w0=-10.488049243398432, w1=-55.126732021379524\n",
      "Gradient Descent(2842/9999): loss=5583.753710586263, w0=1.850550756601569, w1=-54.64423202137952\n",
      "Gradient Descent(2843/9999): loss=6565.467968283117, w0=1.850550756601569, w1=-54.64423202137952\n",
      "Gradient Descent(2844/9999): loss=6565.467968283117, w0=1.850550756601569, w1=-54.64423202137952\n",
      "Gradient Descent(2845/9999): loss=6565.467968283117, w0=-6.7810492433984315, w1=-57.33193202137952\n",
      "Gradient Descent(2846/9999): loss=4815.791495565211, w0=-6.7810492433984315, w1=-57.33193202137952\n",
      "Gradient Descent(2847/9999): loss=4815.791495565211, w0=-6.7810492433984315, w1=-57.33193202137952\n",
      "Gradient Descent(2848/9999): loss=4815.791495565211, w0=3.365650756601571, w1=-55.25823202137952\n",
      "Gradient Descent(2849/9999): loss=8051.564429981511, w0=3.365650756601571, w1=-55.25823202137952\n",
      "Gradient Descent(2850/9999): loss=8051.564429981511, w0=-4.892949243398428, w1=-58.72613202137952\n",
      "Gradient Descent(2851/9999): loss=4451.259312344526, w0=-4.892949243398428, w1=-58.72613202137952\n",
      "Gradient Descent(2852/9999): loss=4451.259312344526, w0=7.173816142155106, w1=-39.898732021379516\n",
      "Gradient Descent(2853/9999): loss=16187.143351074465, w0=-0.8514838578448938, w1=-46.07453202137952\n",
      "Gradient Descent(2854/9999): loss=7380.166769981588, w0=-0.8514838578448938, w1=-46.07453202137952\n",
      "Gradient Descent(2855/9999): loss=7380.166769981588, w0=-0.8514838578448938, w1=-46.07453202137952\n",
      "Gradient Descent(2856/9999): loss=7380.166769981588, w0=-9.478983857844895, w1=-47.963132021379515\n",
      "Gradient Descent(2857/9999): loss=5285.553825986975, w0=-9.478983857844895, w1=-47.963132021379515\n",
      "Gradient Descent(2858/9999): loss=5285.553825986975, w0=-9.478983857844895, w1=-47.963132021379515\n",
      "Gradient Descent(2859/9999): loss=5285.553825986975, w0=-9.478983857844895, w1=-47.963132021379515\n",
      "Gradient Descent(2860/9999): loss=5285.553825986975, w0=-9.478983857844895, w1=-47.963132021379515\n",
      "Gradient Descent(2861/9999): loss=5285.553825986975, w0=-2.2513838578448935, w1=-47.66483202137952\n",
      "Gradient Descent(2862/9999): loss=4755.444346986905, w0=8.215316142155107, w1=-42.15803202137952\n",
      "Gradient Descent(2863/9999): loss=15551.513684055546, w0=8.215316142155107, w1=-42.15803202137952\n",
      "Gradient Descent(2864/9999): loss=15551.513684055546, w0=0.12871614215510618, w1=-45.16203202137952\n",
      "Gradient Descent(2865/9999): loss=5931.595566777648, w0=0.12871614215510618, w1=-45.16203202137952\n",
      "Gradient Descent(2866/9999): loss=5931.595566777648, w0=0.12871614215510618, w1=-45.16203202137952\n",
      "Gradient Descent(2867/9999): loss=5931.595566777648, w0=0.12871614215510618, w1=-45.16203202137952\n",
      "Gradient Descent(2868/9999): loss=5931.595566777648, w0=-11.938049243398428, w1=-53.77873202137952\n",
      "Gradient Descent(2869/9999): loss=5802.4994844197445, w0=-11.938049243398428, w1=-53.77873202137952\n",
      "Gradient Descent(2870/9999): loss=5802.4994844197445, w0=-11.938049243398428, w1=-53.77873202137952\n",
      "Gradient Descent(2871/9999): loss=5802.4994844197445, w0=-11.938049243398428, w1=-53.77873202137952\n",
      "Gradient Descent(2872/9999): loss=5802.4994844197445, w0=-11.938049243398428, w1=-53.77873202137952\n",
      "Gradient Descent(2873/9999): loss=5802.4994844197445, w0=-11.938049243398428, w1=-53.77873202137952\n",
      "Gradient Descent(2874/9999): loss=5802.4994844197445, w0=-11.938049243398428, w1=-53.77873202137952\n",
      "Gradient Descent(2875/9999): loss=5802.4994844197445, w0=-11.938049243398428, w1=-53.77873202137952\n",
      "Gradient Descent(2876/9999): loss=5802.4994844197445, w0=-11.938049243398428, w1=-53.77873202137952\n",
      "Gradient Descent(2877/9999): loss=5802.4994844197445, w0=-11.938049243398428, w1=-53.77873202137952\n",
      "Gradient Descent(2878/9999): loss=5802.4994844197445, w0=-11.938049243398428, w1=-53.77873202137952\n",
      "Gradient Descent(2879/9999): loss=5802.4994844197445, w0=-11.938049243398428, w1=-53.77873202137952\n",
      "Gradient Descent(2880/9999): loss=5802.4994844197445, w0=-11.938049243398428, w1=-53.77873202137952\n",
      "Gradient Descent(2881/9999): loss=5802.4994844197445, w0=-11.938049243398428, w1=-53.77873202137952\n",
      "Gradient Descent(2882/9999): loss=5802.4994844197445, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2883/9999): loss=4924.750338829074, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2884/9999): loss=4924.750338829074, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2885/9999): loss=4924.750338829074, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2886/9999): loss=4924.750338829074, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2887/9999): loss=4924.750338829074, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2888/9999): loss=4924.750338829074, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2889/9999): loss=4924.750338829074, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2890/9999): loss=4924.750338829074, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2891/9999): loss=4924.750338829074, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2892/9999): loss=4924.750338829074, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2893/9999): loss=4924.750338829074, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2894/9999): loss=4924.750338829074, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2895/9999): loss=4924.750338829074, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2896/9999): loss=4924.750338829074, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2897/9999): loss=4924.750338829074, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2898/9999): loss=4924.750338829074, w0=-3.080649243398428, w1=-50.65263202137952\n",
      "Gradient Descent(2899/9999): loss=4924.750338829074, w0=6.101650756601572, w1=-46.18563202137952\n",
      "Gradient Descent(2900/9999): loss=11373.782255642742, w0=6.101650756601572, w1=-46.18563202137952\n",
      "Gradient Descent(2901/9999): loss=11373.782255642742, w0=6.101650756601572, w1=-46.18563202137952\n",
      "Gradient Descent(2902/9999): loss=11373.782255642742, w0=6.101650756601572, w1=-46.18563202137952\n",
      "Gradient Descent(2903/9999): loss=11373.782255642742, w0=-5.965114628951962, w1=-50.24523202137952\n",
      "Gradient Descent(2904/9999): loss=4710.500558425888, w0=-5.965114628951962, w1=-50.24523202137952\n",
      "Gradient Descent(2905/9999): loss=4710.500558425888, w0=-5.965114628951962, w1=-50.24523202137952\n",
      "Gradient Descent(2906/9999): loss=4710.500558425888, w0=6.101650756601572, w1=-38.15803202137952\n",
      "Gradient Descent(2907/9999): loss=15530.671484297733, w0=6.101650756601572, w1=-38.15803202137952\n",
      "Gradient Descent(2908/9999): loss=15530.671484297733, w0=0.05975075660157181, w1=-42.13093202137952\n",
      "Gradient Descent(2909/9999): loss=6762.667837567834, w0=-19.674849243398427, w1=-45.85263202137952\n",
      "Gradient Descent(2910/9999): loss=5802.4994844197445, w0=-19.674849243398427, w1=-45.85263202137952\n",
      "Gradient Descent(2911/9999): loss=5802.4994844197445, w0=-19.674849243398427, w1=-45.85263202137952\n",
      "Gradient Descent(2912/9999): loss=5802.4994844197445, w0=-4.860849243398427, w1=-42.66293202137952\n",
      "Gradient Descent(2913/9999): loss=4841.295669524096, w0=-4.860849243398427, w1=-42.66293202137952\n",
      "Gradient Descent(2914/9999): loss=4841.295669524096, w0=-4.860849243398427, w1=-42.66293202137952\n",
      "Gradient Descent(2915/9999): loss=4841.295669524096, w0=-4.860849243398427, w1=-42.66293202137952\n",
      "Gradient Descent(2916/9999): loss=4841.295669524096, w0=-4.860849243398427, w1=-42.66293202137952\n",
      "Gradient Descent(2917/9999): loss=4841.295669524096, w0=-4.860849243398427, w1=-42.66293202137952\n",
      "Gradient Descent(2918/9999): loss=4841.295669524096, w0=-4.860849243398427, w1=-42.66293202137952\n",
      "Gradient Descent(2919/9999): loss=4841.295669524096, w0=-4.860849243398427, w1=-42.66293202137952\n",
      "Gradient Descent(2920/9999): loss=4841.295669524096, w0=-4.860849243398427, w1=-42.66293202137952\n",
      "Gradient Descent(2921/9999): loss=4841.295669524096, w0=-4.860849243398427, w1=-42.66293202137952\n",
      "Gradient Descent(2922/9999): loss=4841.295669524096, w0=-4.860849243398427, w1=-42.66293202137952\n",
      "Gradient Descent(2923/9999): loss=4841.295669524096, w0=-4.860849243398427, w1=-42.66293202137952\n",
      "Gradient Descent(2924/9999): loss=4841.295669524096, w0=4.021150756601573, w1=-40.11763202137952\n",
      "Gradient Descent(2925/9999): loss=10710.808092599495, w0=4.021150756601573, w1=-40.11763202137952\n",
      "Gradient Descent(2926/9999): loss=10710.808092599495, w0=4.021150756601573, w1=-40.11763202137952\n",
      "Gradient Descent(2927/9999): loss=10710.808092599495, w0=-9.361749243398428, w1=-48.65423202137952\n",
      "Gradient Descent(2928/9999): loss=5802.4994844197445, w0=2.705016142155106, w1=-35.03593202137952\n",
      "Gradient Descent(2929/9999): loss=7034.403168402876, w0=2.705016142155106, w1=-35.03593202137952\n",
      "Gradient Descent(2930/9999): loss=7034.403168402876, w0=9.956016142155107, w1=-30.133332021379523\n",
      "Gradient Descent(2931/9999): loss=15195.786561988802, w0=9.956016142155107, w1=-30.133332021379523\n",
      "Gradient Descent(2932/9999): loss=15195.786561988802, w0=-2.110749243398427, w1=-35.91213202137952\n",
      "Gradient Descent(2933/9999): loss=5004.70784671778, w0=9.657550756601573, w1=-34.08053202137952\n",
      "Gradient Descent(2934/9999): loss=15576.924966932364, w0=9.657550756601573, w1=-34.08053202137952\n",
      "Gradient Descent(2935/9999): loss=15576.924966932364, w0=9.657550756601573, w1=-34.08053202137952\n",
      "Gradient Descent(2936/9999): loss=15576.924966932364, w0=-3.4412492433984276, w1=-42.81403202137952\n",
      "Gradient Descent(2937/9999): loss=4846.6543112578875, w0=-3.4412492433984276, w1=-42.81403202137952\n",
      "Gradient Descent(2938/9999): loss=4846.6543112578875, w0=5.792350756601573, w1=-39.15503202137952\n",
      "Gradient Descent(2939/9999): loss=11606.421074224181, w0=-6.274414628951961, w1=-45.41753202137952\n",
      "Gradient Descent(2940/9999): loss=4709.863506024314, w0=-6.274414628951961, w1=-45.41753202137952\n",
      "Gradient Descent(2941/9999): loss=4709.863506024314, w0=-6.274414628951961, w1=-45.41753202137952\n",
      "Gradient Descent(2942/9999): loss=4709.863506024314, w0=-6.274414628951961, w1=-45.41753202137952\n",
      "Gradient Descent(2943/9999): loss=4709.863506024314, w0=-16.65001462895196, w1=-46.06463202137952\n",
      "Gradient Descent(2944/9999): loss=5802.4994844197445, w0=-16.65001462895196, w1=-46.06463202137952\n",
      "Gradient Descent(2945/9999): loss=5802.4994844197445, w0=-16.65001462895196, w1=-46.06463202137952\n",
      "Gradient Descent(2946/9999): loss=5802.4994844197445, w0=-16.65001462895196, w1=-46.06463202137952\n",
      "Gradient Descent(2947/9999): loss=5802.4994844197445, w0=-16.65001462895196, w1=-46.06463202137952\n",
      "Gradient Descent(2948/9999): loss=5802.4994844197445, w0=-16.65001462895196, w1=-46.06463202137952\n",
      "Gradient Descent(2949/9999): loss=5802.4994844197445, w0=-16.65001462895196, w1=-46.06463202137952\n",
      "Gradient Descent(2950/9999): loss=5802.4994844197445, w0=-5.125214628951962, w1=-43.51793202137952\n",
      "Gradient Descent(2951/9999): loss=5233.163202678109, w0=-5.125214628951962, w1=-43.51793202137952\n",
      "Gradient Descent(2952/9999): loss=5233.163202678109, w0=-5.125214628951962, w1=-43.51793202137952\n",
      "Gradient Descent(2953/9999): loss=5233.163202678109, w0=-5.125214628951962, w1=-43.51793202137952\n",
      "Gradient Descent(2954/9999): loss=5233.163202678109, w0=-5.125214628951962, w1=-43.51793202137952\n",
      "Gradient Descent(2955/9999): loss=5233.163202678109, w0=-17.191980014505496, w1=-48.64033202137952\n",
      "Gradient Descent(2956/9999): loss=5802.4994844197445, w0=-17.191980014505496, w1=-48.64033202137952\n",
      "Gradient Descent(2957/9999): loss=5802.4994844197445, w0=-5.125214628951962, w1=-25.21313202137952\n",
      "Gradient Descent(2958/9999): loss=9456.596166856107, w0=-5.125214628951962, w1=-25.21313202137952\n",
      "Gradient Descent(2959/9999): loss=9456.596166856107, w0=-24.627614628951964, w1=-28.58213202137952\n",
      "Gradient Descent(2960/9999): loss=5802.4994844197445, w0=-24.627614628951964, w1=-28.58213202137952\n",
      "Gradient Descent(2961/9999): loss=5802.4994844197445, w0=-13.737914628951962, w1=-20.846032021379518\n",
      "Gradient Descent(2962/9999): loss=5387.783301298941, w0=-13.737914628951962, w1=-20.846032021379518\n",
      "Gradient Descent(2963/9999): loss=5387.783301298941, w0=-13.737914628951962, w1=-20.846032021379518\n",
      "Gradient Descent(2964/9999): loss=5387.783301298941, w0=-13.737914628951962, w1=-20.846032021379518\n",
      "Gradient Descent(2965/9999): loss=5387.783301298941, w0=-13.737914628951962, w1=-20.846032021379518\n",
      "Gradient Descent(2966/9999): loss=5387.783301298941, w0=-2.539114628951962, w1=-14.642032021379517\n",
      "Gradient Descent(2967/9999): loss=15693.92613182854, w0=-10.164114628951962, w1=-23.25823202137952\n",
      "Gradient Descent(2968/9999): loss=5808.243332625195, w0=-22.230880014505495, w1=-30.29173202137952\n",
      "Gradient Descent(2969/9999): loss=5814.012419884664, w0=-22.230880014505495, w1=-30.29173202137952\n",
      "Gradient Descent(2970/9999): loss=5814.012419884664, w0=-22.230880014505495, w1=-30.29173202137952\n",
      "Gradient Descent(2971/9999): loss=5814.012419884664, w0=-8.820180014505494, w1=-29.83333202137952\n",
      "Gradient Descent(2972/9999): loss=5819.042615547854, w0=-8.820180014505494, w1=-29.83333202137952\n",
      "Gradient Descent(2973/9999): loss=5819.042615547854, w0=-8.820180014505494, w1=-29.83333202137952\n",
      "Gradient Descent(2974/9999): loss=5819.042615547854, w0=-8.820180014505494, w1=-29.83333202137952\n",
      "Gradient Descent(2975/9999): loss=5819.042615547854, w0=-8.820180014505494, w1=-29.83333202137952\n",
      "Gradient Descent(2976/9999): loss=5819.042615547854, w0=-8.820180014505494, w1=-29.83333202137952\n",
      "Gradient Descent(2977/9999): loss=5819.042615547854, w0=-8.820180014505494, w1=-29.83333202137952\n",
      "Gradient Descent(2978/9999): loss=5819.042615547854, w0=-8.820180014505494, w1=-29.83333202137952\n",
      "Gradient Descent(2979/9999): loss=5819.042615547854, w0=-8.820180014505494, w1=-29.83333202137952\n",
      "Gradient Descent(2980/9999): loss=5819.042615547854, w0=-25.498080014505497, w1=-29.88993202137952\n",
      "Gradient Descent(2981/9999): loss=5802.4994844197445, w0=-25.498080014505497, w1=-29.88993202137952\n",
      "Gradient Descent(2982/9999): loss=5802.4994844197445, w0=-25.498080014505497, w1=-29.88993202137952\n",
      "Gradient Descent(2983/9999): loss=5802.4994844197445, w0=-25.498080014505497, w1=-29.88993202137952\n",
      "Gradient Descent(2984/9999): loss=5802.4994844197445, w0=-25.498080014505497, w1=-29.88993202137952\n",
      "Gradient Descent(2985/9999): loss=5802.4994844197445, w0=-25.498080014505497, w1=-29.88993202137952\n",
      "Gradient Descent(2986/9999): loss=5802.4994844197445, w0=-12.727180014505496, w1=-23.492832021379517\n",
      "Gradient Descent(2987/9999): loss=5810.185456705904, w0=-12.727180014505496, w1=-23.492832021379517\n",
      "Gradient Descent(2988/9999): loss=5810.185456705904, w0=-12.727180014505496, w1=-23.492832021379517\n",
      "Gradient Descent(2989/9999): loss=5810.185456705904, w0=-12.727180014505496, w1=-23.492832021379517\n",
      "Gradient Descent(2990/9999): loss=5810.185456705904, w0=-0.20128001450549604, w1=-21.853332021379515\n",
      "Gradient Descent(2991/9999): loss=15945.603938390497, w0=-0.20128001450549604, w1=-21.853332021379515\n",
      "Gradient Descent(2992/9999): loss=15945.603938390497, w0=-0.20128001450549604, w1=-21.853332021379515\n",
      "Gradient Descent(2993/9999): loss=15945.603938390497, w0=-13.983180014505496, w1=-24.508832021379515\n",
      "Gradient Descent(2994/9999): loss=5071.925958593116, w0=-13.983180014505496, w1=-24.508832021379515\n",
      "Gradient Descent(2995/9999): loss=5071.925958593116, w0=-13.983180014505496, w1=-24.508832021379515\n",
      "Gradient Descent(2996/9999): loss=5071.925958593116, w0=-13.983180014505496, w1=-24.508832021379515\n",
      "Gradient Descent(2997/9999): loss=5071.925958593116, w0=-13.983180014505496, w1=-24.508832021379515\n",
      "Gradient Descent(2998/9999): loss=5071.925958593116, w0=-13.983180014505496, w1=-24.508832021379515\n",
      "Gradient Descent(2999/9999): loss=5071.925958593116, w0=-13.983180014505496, w1=-24.508832021379515\n",
      "Gradient Descent(3000/9999): loss=5071.925958593116, w0=-13.983180014505496, w1=-24.508832021379515\n",
      "Gradient Descent(3001/9999): loss=5071.925958593116, w0=-13.983180014505496, w1=-24.508832021379515\n",
      "Gradient Descent(3002/9999): loss=5071.925958593116, w0=-13.983180014505496, w1=-24.508832021379515\n",
      "Gradient Descent(3003/9999): loss=5071.925958593116, w0=-3.587680014505496, w1=-21.302632021379516\n",
      "Gradient Descent(3004/9999): loss=15086.028816691909, w0=-16.297580014505495, w1=-28.975932021379517\n",
      "Gradient Descent(3005/9999): loss=4952.658656705156, w0=-1.0775800145054966, w1=-21.08653202137952\n",
      "Gradient Descent(3006/9999): loss=15975.251965194213, w0=-10.736780014505499, w1=-28.083732021379518\n",
      "Gradient Descent(3007/9999): loss=5309.258146557764, w0=-10.736780014505499, w1=-28.083732021379518\n",
      "Gradient Descent(3008/9999): loss=5309.258146557764, w0=-10.736780014505499, w1=-28.083732021379518\n",
      "Gradient Descent(3009/9999): loss=5309.258146557764, w0=-10.736780014505499, w1=-28.083732021379518\n",
      "Gradient Descent(3010/9999): loss=5309.258146557764, w0=-10.736780014505499, w1=-28.083732021379518\n",
      "Gradient Descent(3011/9999): loss=5309.258146557764, w0=-10.736780014505499, w1=-28.083732021379518\n",
      "Gradient Descent(3012/9999): loss=5309.258146557764, w0=-0.5587800145054977, w1=-22.263032021379516\n",
      "Gradient Descent(3013/9999): loss=14752.687378656272, w0=-12.625545400059032, w1=-29.520732021379516\n",
      "Gradient Descent(3014/9999): loss=5143.092745040652, w0=-12.625545400059032, w1=-29.520732021379516\n",
      "Gradient Descent(3015/9999): loss=5143.092745040652, w0=-12.625545400059032, w1=-29.520732021379516\n",
      "Gradient Descent(3016/9999): loss=5143.092745040652, w0=-12.62554540022019, w1=-29.52073202146886\n",
      "Gradient Descent(3017/9999): loss=5143.092745108559, w0=-12.62554540022019, w1=-29.52073202146886\n",
      "Gradient Descent(3018/9999): loss=5143.092745108559, w0=-12.62554540022019, w1=-29.52073202146886\n",
      "Gradient Descent(3019/9999): loss=5143.092745108559, w0=-12.62554540022019, w1=-29.52073202146886\n",
      "Gradient Descent(3020/9999): loss=5143.092745108559, w0=-12.62554540022019, w1=-29.52073202146886\n",
      "Gradient Descent(3021/9999): loss=5143.092745108559, w0=-12.62554540022019, w1=-29.52073202146886\n",
      "Gradient Descent(3022/9999): loss=5143.092745108559, w0=-12.62554540022019, w1=-29.52073202146886\n",
      "Gradient Descent(3023/9999): loss=5143.092745108559, w0=-12.62554540022019, w1=-29.52073202146886\n",
      "Gradient Descent(3024/9999): loss=5143.092745108559, w0=8.818154599779813, w1=-22.92083202146886\n",
      "Gradient Descent(3025/9999): loss=17039.124498112185, w0=8.818154599779813, w1=-22.92083202146886\n",
      "Gradient Descent(3026/9999): loss=17039.124498112185, w0=2.1775545997798122, w1=-28.55863202146886\n",
      "Gradient Descent(3027/9999): loss=15257.658276408218, w0=-5.752845400220188, w1=-35.86943202146886\n",
      "Gradient Descent(3028/9999): loss=4909.372797023569, w0=-5.752845400220188, w1=-35.86943202146886\n",
      "Gradient Descent(3029/9999): loss=4909.372797023569, w0=-5.752845400220188, w1=-35.86943202146886\n",
      "Gradient Descent(3030/9999): loss=4909.372797023569, w0=-5.752845400220188, w1=-35.86943202146886\n",
      "Gradient Descent(3031/9999): loss=4909.372797023569, w0=-5.752845400220188, w1=-35.86943202146886\n",
      "Gradient Descent(3032/9999): loss=4909.372797023569, w0=-5.752845400220188, w1=-35.86943202146886\n",
      "Gradient Descent(3033/9999): loss=4909.372797023569, w0=-5.752845400220188, w1=-35.86943202146886\n",
      "Gradient Descent(3034/9999): loss=4909.372797023569, w0=-5.752845400220188, w1=-35.86943202146886\n",
      "Gradient Descent(3035/9999): loss=4909.372797023569, w0=-5.752845400220188, w1=-35.86943202146886\n",
      "Gradient Descent(3036/9999): loss=4909.372797023569, w0=8.48855459977981, w1=-33.75603202146886\n",
      "Gradient Descent(3037/9999): loss=16094.9069238933, w0=-3.5782107857737238, w1=-43.413432021468864\n",
      "Gradient Descent(3038/9999): loss=5292.131655614243, w0=-3.5782107857737238, w1=-43.413432021468864\n",
      "Gradient Descent(3039/9999): loss=5292.131655614243, w0=-3.5782107857737238, w1=-43.413432021468864\n",
      "Gradient Descent(3040/9999): loss=5292.131655614243, w0=-3.5782107857737238, w1=-43.413432021468864\n",
      "Gradient Descent(3041/9999): loss=5292.131655614243, w0=-3.5782107857737238, w1=-43.413432021468864\n",
      "Gradient Descent(3042/9999): loss=5292.131655614243, w0=-3.5782107857737238, w1=-43.413432021468864\n",
      "Gradient Descent(3043/9999): loss=5292.131655614243, w0=-3.5782107857737238, w1=-43.413432021468864\n",
      "Gradient Descent(3044/9999): loss=5292.131655614243, w0=-3.5782107857737238, w1=-43.413432021468864\n",
      "Gradient Descent(3045/9999): loss=5292.131655614243, w0=-3.5782107857737238, w1=-43.413432021468864\n",
      "Gradient Descent(3046/9999): loss=5292.131655614243, w0=-3.5782107857737238, w1=-43.413432021468864\n",
      "Gradient Descent(3047/9999): loss=5292.131655614243, w0=-12.645610785773723, w1=-44.43193202146887\n",
      "Gradient Descent(3048/9999): loss=5633.819857227476, w0=-12.645610785773723, w1=-44.43193202146887\n",
      "Gradient Descent(3049/9999): loss=5633.819857227476, w0=-12.645610785773723, w1=-44.43193202146887\n",
      "Gradient Descent(3050/9999): loss=5633.819857227476, w0=-12.645610785773723, w1=-44.43193202146887\n",
      "Gradient Descent(3051/9999): loss=5633.819857227476, w0=-1.2079107857737217, w1=-38.81123202146887\n",
      "Gradient Descent(3052/9999): loss=5756.9040966175135, w0=-1.2079107857737217, w1=-38.81123202146887\n",
      "Gradient Descent(3053/9999): loss=5756.9040966175135, w0=-1.2079107857737217, w1=-38.81123202146887\n",
      "Gradient Descent(3054/9999): loss=5756.9040966175135, w0=-1.2079107857737217, w1=-38.81123202146887\n",
      "Gradient Descent(3055/9999): loss=5756.9040966175135, w0=-1.2079107857737217, w1=-38.81123202146887\n",
      "Gradient Descent(3056/9999): loss=5756.9040966175135, w0=-1.2079107857737217, w1=-38.81123202146887\n",
      "Gradient Descent(3057/9999): loss=5756.9040966175135, w0=-1.2079107857737217, w1=-38.81123202146887\n",
      "Gradient Descent(3058/9999): loss=5756.9040966175135, w0=-1.2079107857737217, w1=-38.81123202146887\n",
      "Gradient Descent(3059/9999): loss=5756.9040966175135, w0=-1.2079107857737217, w1=-38.81123202146887\n",
      "Gradient Descent(3060/9999): loss=5756.9040966175135, w0=-1.2079107857737217, w1=-38.81123202146887\n",
      "Gradient Descent(3061/9999): loss=5756.9040966175135, w0=-13.274676171327256, w1=-44.59003202146887\n",
      "Gradient Descent(3062/9999): loss=5744.935165519467, w0=-13.274676171327256, w1=-44.59003202146887\n",
      "Gradient Descent(3063/9999): loss=5744.935165519467, w0=-13.274676171327256, w1=-44.59003202146887\n",
      "Gradient Descent(3064/9999): loss=5744.935165519467, w0=-13.274676171327256, w1=-44.59003202146887\n",
      "Gradient Descent(3065/9999): loss=5744.935165519467, w0=-3.3785761713272553, w1=-38.56473202146887\n",
      "Gradient Descent(3066/9999): loss=4803.1460843150235, w0=-3.3785761713272553, w1=-38.56473202146887\n",
      "Gradient Descent(3067/9999): loss=4803.1460843150235, w0=-3.3785761713272553, w1=-38.56473202146887\n",
      "Gradient Descent(3068/9999): loss=4803.1460843150235, w0=-3.3785761713272553, w1=-38.56473202146887\n",
      "Gradient Descent(3069/9999): loss=4803.1460843150235, w0=-3.3785761713272553, w1=-38.56473202146887\n",
      "Gradient Descent(3070/9999): loss=4803.1460843150235, w0=-3.3785761713272553, w1=-38.56473202146887\n",
      "Gradient Descent(3071/9999): loss=4803.1460843150235, w0=-12.216576171327254, w1=-42.60433202146887\n",
      "Gradient Descent(3072/9999): loss=5652.23037741386, w0=-12.216576171327254, w1=-42.60433202146887\n",
      "Gradient Descent(3073/9999): loss=5652.23037741386, w0=-12.216576171327254, w1=-42.60433202146887\n",
      "Gradient Descent(3074/9999): loss=5652.23037741386, w0=-12.216576171327254, w1=-42.60433202146887\n",
      "Gradient Descent(3075/9999): loss=5652.23037741386, w0=2.884123828672747, w1=-41.00553202146887\n",
      "Gradient Descent(3076/9999): loss=14494.999888654409, w0=-6.183276171327252, w1=-42.02403202146888\n",
      "Gradient Descent(3077/9999): loss=4598.411005622091, w0=-6.183276171327252, w1=-42.02403202146888\n",
      "Gradient Descent(3078/9999): loss=4598.411005622091, w0=3.534623828672748, w1=-38.18333202146888\n",
      "Gradient Descent(3079/9999): loss=13510.398381730382, w0=3.534623828672748, w1=-38.18333202146888\n",
      "Gradient Descent(3080/9999): loss=13510.398381730382, w0=3.534623828672748, w1=-38.18333202146888\n",
      "Gradient Descent(3081/9999): loss=13510.398381730382, w0=3.534623828672748, w1=-38.18333202146888\n",
      "Gradient Descent(3082/9999): loss=13510.398381730382, w0=-8.532141556880786, w1=-47.38283202146888\n",
      "Gradient Descent(3083/9999): loss=4765.799382906529, w0=-8.532141556880786, w1=-47.38283202146888\n",
      "Gradient Descent(3084/9999): loss=4765.799382906529, w0=-8.532141556880786, w1=-47.38283202146888\n",
      "Gradient Descent(3085/9999): loss=4765.799382906529, w0=-8.532141556880786, w1=-47.38283202146888\n",
      "Gradient Descent(3086/9999): loss=4765.799382906529, w0=-8.532141556880786, w1=-47.38283202146888\n",
      "Gradient Descent(3087/9999): loss=4765.799382906529, w0=3.0153584431192133, w1=-43.82843202146888\n",
      "Gradient Descent(3088/9999): loss=12858.648539670163, w0=3.0153584431192133, w1=-43.82843202146888\n",
      "Gradient Descent(3089/9999): loss=12858.648539670163, w0=-6.8646415568807875, w1=-51.97913202146888\n",
      "Gradient Descent(3090/9999): loss=4700.801857849619, w0=-6.8646415568807875, w1=-51.97913202146888\n",
      "Gradient Descent(3091/9999): loss=4700.801857849619, w0=-6.8646415568807875, w1=-51.97913202146888\n",
      "Gradient Descent(3092/9999): loss=4700.801857849619, w0=-6.8646415568807875, w1=-51.97913202146888\n",
      "Gradient Descent(3093/9999): loss=4700.801857849619, w0=-17.156441556880786, w1=-52.467732021468876\n",
      "Gradient Descent(3094/9999): loss=5802.4994844197445, w0=-17.156441556880786, w1=-52.467732021468876\n",
      "Gradient Descent(3095/9999): loss=5802.4994844197445, w0=-17.156441556880786, w1=-52.467732021468876\n",
      "Gradient Descent(3096/9999): loss=5802.4994844197445, w0=-17.156441556880786, w1=-52.467732021468876\n",
      "Gradient Descent(3097/9999): loss=5802.4994844197445, w0=-17.156441556880786, w1=-52.467732021468876\n",
      "Gradient Descent(3098/9999): loss=5802.4994844197445, w0=-17.156441556880786, w1=-52.467732021468876\n",
      "Gradient Descent(3099/9999): loss=5802.4994844197445, w0=-17.156441556880786, w1=-52.467732021468876\n",
      "Gradient Descent(3100/9999): loss=5802.4994844197445, w0=-17.156441556880786, w1=-52.467732021468876\n",
      "Gradient Descent(3101/9999): loss=5802.4994844197445, w0=-17.156441556880786, w1=-52.467732021468876\n",
      "Gradient Descent(3102/9999): loss=5802.4994844197445, w0=-17.156441556880786, w1=-52.467732021468876\n",
      "Gradient Descent(3103/9999): loss=5802.4994844197445, w0=-17.156441556880786, w1=-52.467732021468876\n",
      "Gradient Descent(3104/9999): loss=5802.4994844197445, w0=-17.156441556880786, w1=-52.467732021468876\n",
      "Gradient Descent(3105/9999): loss=5802.4994844197445, w0=-17.156441556880786, w1=-52.467732021468876\n",
      "Gradient Descent(3106/9999): loss=5802.4994844197445, w0=-17.156441556880786, w1=-52.467732021468876\n",
      "Gradient Descent(3107/9999): loss=5802.4994844197445, w0=-8.318341556880785, w1=-46.43143202146888\n",
      "Gradient Descent(3108/9999): loss=5517.057997236081, w0=-8.318341556880785, w1=-46.43143202146888\n",
      "Gradient Descent(3109/9999): loss=5517.057997236081, w0=-8.318341556880785, w1=-46.43143202146888\n",
      "Gradient Descent(3110/9999): loss=5517.057997236081, w0=-8.318341556880785, w1=-46.43143202146888\n",
      "Gradient Descent(3111/9999): loss=5517.057997236081, w0=-8.318341556880785, w1=-46.43143202146888\n",
      "Gradient Descent(3112/9999): loss=5517.057997236081, w0=5.291458443119215, w1=-38.477132021468876\n",
      "Gradient Descent(3113/9999): loss=16564.120020499297, w0=5.291458443119215, w1=-38.477132021468876\n",
      "Gradient Descent(3114/9999): loss=16564.120020499297, w0=-5.012741556880787, w1=-43.52963202146888\n",
      "Gradient Descent(3115/9999): loss=5139.844674513711, w0=-5.012741556880787, w1=-43.52963202146888\n",
      "Gradient Descent(3116/9999): loss=5139.844674513711, w0=5.980458443119215, w1=-39.69773202146888\n",
      "Gradient Descent(3117/9999): loss=16417.50165052657, w0=-3.136241556880785, w1=-47.22323202146888\n",
      "Gradient Descent(3118/9999): loss=5168.401133932487, w0=-12.286241556880785, w1=-50.84903202146888\n",
      "Gradient Descent(3119/9999): loss=5550.734827461782, w0=-12.286241556880785, w1=-50.84903202146888\n",
      "Gradient Descent(3120/9999): loss=5550.734827461782, w0=-12.286241556880785, w1=-50.84903202146888\n",
      "Gradient Descent(3121/9999): loss=5550.734827461782, w0=-12.286241556880785, w1=-50.84903202146888\n",
      "Gradient Descent(3122/9999): loss=5550.734827461782, w0=-12.286241556880785, w1=-50.84903202146888\n",
      "Gradient Descent(3123/9999): loss=5550.734827461782, w0=1.2668584431192151, w1=-49.88763202146888\n",
      "Gradient Descent(3124/9999): loss=8854.203194882211, w0=1.2668584431192151, w1=-49.88763202146888\n",
      "Gradient Descent(3125/9999): loss=8854.203194882211, w0=1.2668584431192151, w1=-49.88763202146888\n",
      "Gradient Descent(3126/9999): loss=8854.203194882211, w0=1.2668584431192151, w1=-49.88763202146888\n",
      "Gradient Descent(3127/9999): loss=8854.203194882211, w0=-6.991741556880784, w1=-53.35553202146888\n",
      "Gradient Descent(3128/9999): loss=4617.795782734254, w0=-6.991741556880784, w1=-53.35553202146888\n",
      "Gradient Descent(3129/9999): loss=4617.795782734254, w0=-6.991741556880784, w1=-53.35553202146888\n",
      "Gradient Descent(3130/9999): loss=4617.795782734254, w0=-6.991741556880784, w1=-53.35553202146888\n",
      "Gradient Descent(3131/9999): loss=4617.795782734254, w0=-6.991741556880784, w1=-53.35553202146888\n",
      "Gradient Descent(3132/9999): loss=4617.795782734254, w0=-6.991741556880784, w1=-53.35553202146888\n",
      "Gradient Descent(3133/9999): loss=4617.795782734254, w0=-20.17964155688078, w1=-56.981032021468884\n",
      "Gradient Descent(3134/9999): loss=5802.4994844197445, w0=-11.297641556880782, w1=-54.43573202146889\n",
      "Gradient Descent(3135/9999): loss=4625.939232190738, w0=-2.487741556880783, w1=-53.89323202146889\n",
      "Gradient Descent(3136/9999): loss=7257.68944970425, w0=-7.6068415568807835, w1=-61.07203202146889\n",
      "Gradient Descent(3137/9999): loss=5082.751751397767, w0=-7.6068415568807835, w1=-61.07203202146889\n",
      "Gradient Descent(3138/9999): loss=5082.751751397767, w0=4.459923828672751, w1=-57.16803202146889\n",
      "Gradient Descent(3139/9999): loss=8095.012558079459, w0=4.459923828672751, w1=-57.16803202146889\n",
      "Gradient Descent(3140/9999): loss=8095.012558079459, w0=4.459923828672751, w1=-57.16803202146889\n",
      "Gradient Descent(3141/9999): loss=8095.012558079459, w0=-5.379976171327249, w1=-61.69583202146889\n",
      "Gradient Descent(3142/9999): loss=4962.055057011499, w0=-5.379976171327249, w1=-61.69583202146889\n",
      "Gradient Descent(3143/9999): loss=4962.055057011499, w0=5.743423828672751, w1=-59.34313202146889\n",
      "Gradient Descent(3144/9999): loss=6740.166457415579, w0=-0.60987617132725, w1=-63.76913202146889\n",
      "Gradient Descent(3145/9999): loss=4374.895486791488, w0=-0.60987617132725, w1=-63.76913202146889\n",
      "Gradient Descent(3146/9999): loss=4374.895486791488, w0=-0.60987617132725, w1=-63.76913202146889\n",
      "Gradient Descent(3147/9999): loss=4374.895486791488, w0=10.114823828672751, w1=-59.74943202146889\n",
      "Gradient Descent(3148/9999): loss=10604.173567052476, w0=-6.408076171327252, w1=-67.26633202146888\n",
      "Gradient Descent(3149/9999): loss=4488.59300062704, w0=-6.408076171327252, w1=-67.26633202146888\n",
      "Gradient Descent(3150/9999): loss=4488.59300062704, w0=0.1407238286727477, w1=-64.07323202146888\n",
      "Gradient Descent(3151/9999): loss=9114.600865225375, w0=0.1407238286727477, w1=-64.07323202146888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(3152/9999): loss=9114.600865225375, w0=0.1407238286727477, w1=-64.07323202146888\n",
      "Gradient Descent(3153/9999): loss=9114.600865225375, w0=0.1407238286727477, w1=-64.07323202146888\n",
      "Gradient Descent(3154/9999): loss=9114.600865225375, w0=-11.926041556880786, w1=-70.89653202146889\n",
      "Gradient Descent(3155/9999): loss=4708.7525646256145, w0=-11.926041556880786, w1=-70.89653202146889\n",
      "Gradient Descent(3156/9999): loss=4708.7525646256145, w0=-11.926041556880786, w1=-70.89653202146889\n",
      "Gradient Descent(3157/9999): loss=4708.7525646256145, w0=-11.926041556880786, w1=-70.89653202146889\n",
      "Gradient Descent(3158/9999): loss=4708.7525646256145, w0=0.1407238286727477, w1=-61.396732021468885\n",
      "Gradient Descent(3159/9999): loss=8831.42754751196, w0=0.1407238286727477, w1=-61.396732021468885\n",
      "Gradient Descent(3160/9999): loss=8831.42754751196, w0=0.1407238286727477, w1=-61.396732021468885\n",
      "Gradient Descent(3161/9999): loss=8831.42754751196, w0=-8.216476171327253, w1=-62.10853202146888\n",
      "Gradient Descent(3162/9999): loss=4774.905402534425, w0=-8.216476171327253, w1=-62.10853202146888\n",
      "Gradient Descent(3163/9999): loss=4774.905402534425, w0=-8.216476171327253, w1=-62.10853202146888\n",
      "Gradient Descent(3164/9999): loss=4774.905402534425, w0=-8.216476171327253, w1=-62.10853202146888\n",
      "Gradient Descent(3165/9999): loss=4774.905402534425, w0=-8.216476171327253, w1=-62.10853202146888\n",
      "Gradient Descent(3166/9999): loss=4774.905402534425, w0=-27.718876171327253, w1=-65.47753202146887\n",
      "Gradient Descent(3167/9999): loss=5802.4994844197445, w0=-27.718876171327253, w1=-65.47753202146887\n",
      "Gradient Descent(3168/9999): loss=5802.4994844197445, w0=-27.718876171327253, w1=-65.47753202146887\n",
      "Gradient Descent(3169/9999): loss=5802.4994844197445, w0=-27.718876171327253, w1=-65.47753202146887\n",
      "Gradient Descent(3170/9999): loss=5802.4994844197445, w0=-27.718876171327253, w1=-65.47753202146887\n",
      "Gradient Descent(3171/9999): loss=5802.4994844197445, w0=-27.718876171327253, w1=-65.47753202146887\n",
      "Gradient Descent(3172/9999): loss=5802.4994844197445, w0=-27.718876171327253, w1=-65.47753202146887\n",
      "Gradient Descent(3173/9999): loss=5802.4994844197445, w0=-17.28707617132725, w1=-61.10453202146888\n",
      "Gradient Descent(3174/9999): loss=5523.723155390329, w0=-17.28707617132725, w1=-61.10453202146888\n",
      "Gradient Descent(3175/9999): loss=5523.723155390329, w0=-4.74297617132725, w1=-58.322332021468874\n",
      "Gradient Descent(3176/9999): loss=8236.468092936248, w0=-13.84057617132725, w1=-64.59423202146887\n",
      "Gradient Descent(3177/9999): loss=4967.877846234916, w0=-13.84057617132725, w1=-64.59423202146887\n",
      "Gradient Descent(3178/9999): loss=4967.877846234916, w0=-13.84057617132725, w1=-64.59423202146887\n",
      "Gradient Descent(3179/9999): loss=4967.877846234916, w0=-13.84057617132725, w1=-64.59423202146887\n",
      "Gradient Descent(3180/9999): loss=4967.877846234916, w0=-13.84057617132725, w1=-64.59423202146887\n",
      "Gradient Descent(3181/9999): loss=4967.877846234916, w0=-13.84057617132725, w1=-64.59423202146887\n",
      "Gradient Descent(3182/9999): loss=4967.877846234916, w0=-13.84057617132725, w1=-64.59423202146887\n",
      "Gradient Descent(3183/9999): loss=4967.877846234916, w0=-2.2199761713272483, w1=-60.66013202146887\n",
      "Gradient Descent(3184/9999): loss=8453.771168467705, w0=-12.48247617132725, w1=-67.40613202146886\n",
      "Gradient Descent(3185/9999): loss=5144.064288544556, w0=-0.3400761713272491, w1=-64.49103202146887\n",
      "Gradient Descent(3186/9999): loss=7889.945841378718, w0=-0.3400761713272491, w1=-64.49103202146887\n",
      "Gradient Descent(3187/9999): loss=7889.945841378718, w0=9.837923828672752, w1=-58.670332021468866\n",
      "Gradient Descent(3188/9999): loss=15747.07904171174, w0=-2.2288415568807824, w1=-63.744832021468866\n",
      "Gradient Descent(3189/9999): loss=7499.042238920313, w0=-2.2288415568807824, w1=-63.744832021468866\n",
      "Gradient Descent(3190/9999): loss=7499.042238920313, w0=-10.584441556880783, w1=-68.96773202146886\n",
      "Gradient Descent(3191/9999): loss=4693.318992158901, w0=-10.584441556880783, w1=-68.96773202146886\n",
      "Gradient Descent(3192/9999): loss=4693.318992158901, w0=-10.584441556880783, w1=-68.96773202146886\n",
      "Gradient Descent(3193/9999): loss=4693.318992158901, w0=-10.584441556880783, w1=-68.96773202146886\n",
      "Gradient Descent(3194/9999): loss=4693.318992158901, w0=-10.584441556880783, w1=-68.96773202146886\n",
      "Gradient Descent(3195/9999): loss=4693.318992158901, w0=-10.584441556880783, w1=-68.96773202146886\n",
      "Gradient Descent(3196/9999): loss=4693.318992158901, w0=-10.584441556880783, w1=-68.96773202146886\n",
      "Gradient Descent(3197/9999): loss=4693.318992158901, w0=-10.584441556880783, w1=-68.96773202146886\n",
      "Gradient Descent(3198/9999): loss=4693.318992158901, w0=-10.584441556880783, w1=-68.96773202146886\n",
      "Gradient Descent(3199/9999): loss=4693.318992158901, w0=-10.584441556880783, w1=-68.96773202146886\n",
      "Gradient Descent(3200/9999): loss=4693.318992158901, w0=1.2623584431192167, w1=-66.79993202146886\n",
      "Gradient Descent(3201/9999): loss=7421.788421594564, w0=-6.911441556880783, w1=-69.09543202146887\n",
      "Gradient Descent(3202/9999): loss=4597.621433271698, w0=-6.911441556880783, w1=-69.09543202146887\n",
      "Gradient Descent(3203/9999): loss=4597.621433271698, w0=-6.911441556880783, w1=-69.09543202146887\n",
      "Gradient Descent(3204/9999): loss=4597.621433271698, w0=-6.911441556880783, w1=-69.09543202146887\n",
      "Gradient Descent(3205/9999): loss=4597.621433271698, w0=-6.911441556880783, w1=-69.09543202146887\n",
      "Gradient Descent(3206/9999): loss=4597.621433271698, w0=-6.911441556880783, w1=-69.09543202146887\n",
      "Gradient Descent(3207/9999): loss=4597.621433271698, w0=-6.911441556880783, w1=-69.09543202146887\n",
      "Gradient Descent(3208/9999): loss=4597.621433271698, w0=5.155323828672751, w1=-60.00003202146887\n",
      "Gradient Descent(3209/9999): loss=6109.039736343493, w0=5.155323828672751, w1=-60.00003202146887\n",
      "Gradient Descent(3210/9999): loss=6109.039736343493, w0=-14.416976171327248, w1=-65.08693202146887\n",
      "Gradient Descent(3211/9999): loss=5802.4994844197445, w0=-14.416976171327248, w1=-65.08693202146887\n",
      "Gradient Descent(3212/9999): loss=5802.4994844197445, w0=-4.8936761713272485, w1=-60.26653202146887\n",
      "Gradient Descent(3213/9999): loss=4838.047277520356, w0=-4.8936761713272485, w1=-60.26653202146887\n",
      "Gradient Descent(3214/9999): loss=4838.047277520356, w0=7.848323828672752, w1=-56.12393202146887\n",
      "Gradient Descent(3215/9999): loss=9272.1278496774, w0=-5.600676171327249, w1=-56.792732021468865\n",
      "Gradient Descent(3216/9999): loss=5363.789497757946, w0=-5.600676171327249, w1=-56.792732021468865\n",
      "Gradient Descent(3217/9999): loss=5363.789497757946, w0=-5.600676171327249, w1=-56.792732021468865\n",
      "Gradient Descent(3218/9999): loss=5363.789497757946, w0=-5.600676171327249, w1=-56.792732021468865\n",
      "Gradient Descent(3219/9999): loss=5363.789497757946, w0=-5.600676171327249, w1=-56.792732021468865\n",
      "Gradient Descent(3220/9999): loss=5363.789497757946, w0=6.466089214226285, w1=-46.751832021468864\n",
      "Gradient Descent(3221/9999): loss=6131.856212173429, w0=6.466089214226285, w1=-46.751832021468864\n",
      "Gradient Descent(3222/9999): loss=6131.856212173429, w0=6.466089214226285, w1=-46.751832021468864\n",
      "Gradient Descent(3223/9999): loss=6131.856212173429, w0=6.466089214226285, w1=-46.751832021468864\n",
      "Gradient Descent(3224/9999): loss=6131.856212173429, w0=6.466089214226285, w1=-46.751832021468864\n",
      "Gradient Descent(3225/9999): loss=6131.856212173429, w0=6.466089214226285, w1=-46.751832021468864\n",
      "Gradient Descent(3226/9999): loss=6131.856212173429, w0=6.466089214226285, w1=-46.751832021468864\n",
      "Gradient Descent(3227/9999): loss=6131.856212173429, w0=6.466089214226285, w1=-46.751832021468864\n",
      "Gradient Descent(3228/9999): loss=6131.856212173429, w0=6.466089214226285, w1=-46.751832021468864\n",
      "Gradient Descent(3229/9999): loss=6131.856212173429, w0=-5.600676171327249, w1=-53.190832021468864\n",
      "Gradient Descent(3230/9999): loss=5284.938195390649, w0=-5.600676171327249, w1=-53.190832021468864\n",
      "Gradient Descent(3231/9999): loss=5284.938195390649, w0=3.838523828672752, w1=-53.15563202146886\n",
      "Gradient Descent(3232/9999): loss=7167.619735478314, w0=-6.999476171327249, w1=-57.393732021468864\n",
      "Gradient Descent(3233/9999): loss=5054.124174142555, w0=-6.999476171327249, w1=-57.393732021468864\n",
      "Gradient Descent(3234/9999): loss=5054.124174142555, w0=-6.999476171327249, w1=-57.393732021468864\n",
      "Gradient Descent(3235/9999): loss=5054.124174142555, w0=-6.999476171327249, w1=-57.393732021468864\n",
      "Gradient Descent(3236/9999): loss=5054.124174142555, w0=-6.999476171327249, w1=-57.393732021468864\n",
      "Gradient Descent(3237/9999): loss=5054.124174142555, w0=-6.999476171327249, w1=-57.393732021468864\n",
      "Gradient Descent(3238/9999): loss=5054.124174142555, w0=-6.999476171327249, w1=-57.393732021468864\n",
      "Gradient Descent(3239/9999): loss=5054.124174142555, w0=-6.999476171327249, w1=-57.393732021468864\n",
      "Gradient Descent(3240/9999): loss=5054.124174142555, w0=-6.999476171327249, w1=-57.393732021468864\n",
      "Gradient Descent(3241/9999): loss=5054.124174142555, w0=-6.999476171327249, w1=-57.393732021468864\n",
      "Gradient Descent(3242/9999): loss=5054.124174142555, w0=-6.999476171327249, w1=-57.393732021468864\n",
      "Gradient Descent(3243/9999): loss=5054.124174142555, w0=2.788223828672752, w1=-52.954732021468864\n",
      "Gradient Descent(3244/9999): loss=7036.064617731852, w0=2.788223828672752, w1=-52.954732021468864\n",
      "Gradient Descent(3245/9999): loss=7036.064617731852, w0=0.5644238286727519, w1=-59.51823202146886\n",
      "Gradient Descent(3246/9999): loss=4647.333773818122, w0=0.5644238286727519, w1=-59.51823202146886\n",
      "Gradient Descent(3247/9999): loss=4647.333773818122, w0=9.567023828672752, w1=-56.947032021468864\n",
      "Gradient Descent(3248/9999): loss=8360.493719401027, w0=19.569823828672753, w1=-50.99923202146886\n",
      "Gradient Descent(3249/9999): loss=16653.055462606164, w0=19.569823828672753, w1=-50.99923202146886\n",
      "Gradient Descent(3250/9999): loss=16653.055462606164, w0=6.109123828672752, w1=-54.553632021468864\n",
      "Gradient Descent(3251/9999): loss=5332.001361906008, w0=6.109123828672752, w1=-54.553632021468864\n",
      "Gradient Descent(3252/9999): loss=5332.001361906008, w0=-2.8440761713272487, w1=-58.64853202146887\n",
      "Gradient Descent(3253/9999): loss=5050.1978345963, w0=9.07172382867275, w1=-56.141632021468865\n",
      "Gradient Descent(3254/9999): loss=9396.081451191358, w0=-1.1907761713272507, w1=-62.88763202146887\n",
      "Gradient Descent(3255/9999): loss=5006.733168766028, w0=-1.1907761713272507, w1=-62.88763202146887\n",
      "Gradient Descent(3256/9999): loss=5006.733168766028, w0=-1.1907761713272507, w1=-62.88763202146887\n",
      "Gradient Descent(3257/9999): loss=5006.733168766028, w0=10.12892382867275, w1=-58.62763202146887\n",
      "Gradient Descent(3258/9999): loss=7135.813091393078, w0=-0.5977761713272507, w1=-63.69203202146887\n",
      "Gradient Descent(3259/9999): loss=4996.600359738082, w0=-0.5977761713272507, w1=-63.69203202146887\n",
      "Gradient Descent(3260/9999): loss=4996.600359738082, w0=-0.5977761713272507, w1=-63.69203202146887\n",
      "Gradient Descent(3261/9999): loss=4996.600359738082, w0=-0.5977761713272507, w1=-63.69203202146887\n",
      "Gradient Descent(3262/9999): loss=4996.600359738082, w0=-0.5977761713272507, w1=-63.69203202146887\n",
      "Gradient Descent(3263/9999): loss=4996.600359738082, w0=-12.372676171327251, w1=-66.44763202146886\n",
      "Gradient Descent(3264/9999): loss=5802.4994844197445, w0=-12.372676171327251, w1=-66.44763202146886\n",
      "Gradient Descent(3265/9999): loss=5802.4994844197445, w0=-0.3059107857737171, w1=-52.450732021468866\n",
      "Gradient Descent(3266/9999): loss=4535.043282266195, w0=-0.3059107857737171, w1=-52.450732021468866\n",
      "Gradient Descent(3267/9999): loss=4535.043282266195, w0=-0.3059107857737171, w1=-52.450732021468866\n",
      "Gradient Descent(3268/9999): loss=4535.043282266195, w0=-0.3059107857737171, w1=-52.450732021468866\n",
      "Gradient Descent(3269/9999): loss=4535.043282266195, w0=-0.3059107857737171, w1=-52.450732021468866\n",
      "Gradient Descent(3270/9999): loss=4535.043282266195, w0=-0.3059107857737171, w1=-52.450732021468866\n",
      "Gradient Descent(3271/9999): loss=4535.043282266195, w0=-0.3059107857737171, w1=-52.450732021468866\n",
      "Gradient Descent(3272/9999): loss=4535.043282266195, w0=-0.3059107857737171, w1=-52.450732021468866\n",
      "Gradient Descent(3273/9999): loss=4535.043282266195, w0=-0.3059107857737171, w1=-52.450732021468866\n",
      "Gradient Descent(3274/9999): loss=4535.043282266195, w0=-0.3059107857737171, w1=-52.450732021468866\n",
      "Gradient Descent(3275/9999): loss=4535.043282266195, w0=7.443589214226284, w1=-47.65843202146887\n",
      "Gradient Descent(3276/9999): loss=10083.868873725067, w0=7.443589214226284, w1=-47.65843202146887\n",
      "Gradient Descent(3277/9999): loss=10083.868873725067, w0=7.443589214226284, w1=-47.65843202146887\n",
      "Gradient Descent(3278/9999): loss=10083.868873725067, w0=7.443589214226284, w1=-47.65843202146887\n",
      "Gradient Descent(3279/9999): loss=10083.868873725067, w0=-0.7302107857737159, w1=-49.953932021468866\n",
      "Gradient Descent(3280/9999): loss=4563.873286298831, w0=-0.7302107857737159, w1=-49.953932021468866\n",
      "Gradient Descent(3281/9999): loss=4563.873286298831, w0=-0.7302107857737159, w1=-49.953932021468866\n",
      "Gradient Descent(3282/9999): loss=4563.873286298831, w0=-0.7302107857737159, w1=-49.953932021468866\n",
      "Gradient Descent(3283/9999): loss=4563.873286298831, w0=11.336554599779818, w1=-34.87373202146886\n",
      "Gradient Descent(3284/9999): loss=16555.546241936783, w0=-0.7302107857737159, w1=-42.14573202146886\n",
      "Gradient Descent(3285/9999): loss=7136.950968817973, w0=-10.552310785773717, w1=-49.95073202146886\n",
      "Gradient Descent(3286/9999): loss=5779.473613489904, w0=-10.552310785773717, w1=-49.95073202146886\n",
      "Gradient Descent(3287/9999): loss=5779.473613489904, w0=-10.552310785773717, w1=-49.95073202146886\n",
      "Gradient Descent(3288/9999): loss=5779.473613489904, w0=5.192389214226285, w1=-46.18393202146886\n",
      "Gradient Descent(3289/9999): loss=8415.907437233995, w0=5.192389214226285, w1=-46.18393202146886\n",
      "Gradient Descent(3290/9999): loss=8415.907437233995, w0=5.192389214226285, w1=-46.18393202146886\n",
      "Gradient Descent(3291/9999): loss=8415.907437233995, w0=5.192389214226285, w1=-46.18393202146886\n",
      "Gradient Descent(3292/9999): loss=8415.907437233995, w0=-7.135310785773715, w1=-54.01903202146886\n",
      "Gradient Descent(3293/9999): loss=5411.00652827334, w0=-7.135310785773715, w1=-54.01903202146886\n",
      "Gradient Descent(3294/9999): loss=5411.00652827334, w0=2.740689214226286, w1=-48.28073202146886\n",
      "Gradient Descent(3295/9999): loss=5113.404802438588, w0=2.740689214226286, w1=-48.28073202146886\n",
      "Gradient Descent(3296/9999): loss=5113.404802438588, w0=2.740689214226286, w1=-48.28073202146886\n",
      "Gradient Descent(3297/9999): loss=5113.404802438588, w0=2.740689214226286, w1=-48.28073202146886\n",
      "Gradient Descent(3298/9999): loss=5113.404802438588, w0=2.740689214226286, w1=-48.28073202146886\n",
      "Gradient Descent(3299/9999): loss=5113.404802438588, w0=2.740689214226286, w1=-48.28073202146886\n",
      "Gradient Descent(3300/9999): loss=5113.404802438588, w0=2.740689214226286, w1=-48.28073202146886\n",
      "Gradient Descent(3301/9999): loss=5113.404802438588, w0=-17.299124714134084, w1=-57.048550611412516\n",
      "Gradient Descent(3302/9999): loss=5802.4994844197445, w0=-5.745124714134082, w1=-53.10685061141252\n",
      "Gradient Descent(3303/9999): loss=5183.293605948853, w0=-5.745124714134082, w1=-53.10685061141252\n",
      "Gradient Descent(3304/9999): loss=5183.293605948853, w0=7.94747528586592, w1=-43.15505061141252\n",
      "Gradient Descent(3305/9999): loss=16384.46435894041, w0=7.94747528586592, w1=-43.15505061141252\n",
      "Gradient Descent(3306/9999): loss=16384.46435894041, w0=-1.3843247141340793, w1=-50.24485061141252\n",
      "Gradient Descent(3307/9999): loss=8629.736956195868, w0=-14.689924714134081, w1=-52.76245061141252\n",
      "Gradient Descent(3308/9999): loss=5504.389305327177, w0=-14.689924714134081, w1=-52.76245061141252\n",
      "Gradient Descent(3309/9999): loss=5504.389305327177, w0=-6.0332247141340805, w1=-50.42155061141252\n",
      "Gradient Descent(3310/9999): loss=6198.143786991775, w0=-6.0332247141340805, w1=-50.42155061141252\n",
      "Gradient Descent(3311/9999): loss=6198.143786991775, w0=6.033540671419454, w1=-45.14565061141252\n",
      "Gradient Descent(3312/9999): loss=14037.025271591714, w0=-7.7483593285805465, w1=-47.801150611412524\n",
      "Gradient Descent(3313/9999): loss=4781.288190196926, w0=-7.7483593285805465, w1=-47.801150611412524\n",
      "Gradient Descent(3314/9999): loss=4781.288190196926, w0=2.6196406714194556, w1=-41.42375061141252\n",
      "Gradient Descent(3315/9999): loss=10625.551199517147, w0=2.6196406714194556, w1=-41.42375061141252\n",
      "Gradient Descent(3316/9999): loss=10625.551199517147, w0=-6.685259328580544, w1=-43.52305061141252\n",
      "Gradient Descent(3317/9999): loss=5779.470559720741, w0=-6.685259328580544, w1=-43.52305061141252\n",
      "Gradient Descent(3318/9999): loss=5779.470559720741, w0=3.315640671419457, w1=-38.027650611412525\n",
      "Gradient Descent(3319/9999): loss=11328.116895650921, w0=3.315640671419457, w1=-38.027650611412525\n",
      "Gradient Descent(3320/9999): loss=11328.116895650921, w0=3.315640671419457, w1=-38.027650611412525\n",
      "Gradient Descent(3321/9999): loss=11328.116895650921, w0=-2.7171593285805438, w1=-41.05795061141252\n",
      "Gradient Descent(3322/9999): loss=4755.26262031612, w0=-2.7171593285805438, w1=-41.05795061141252\n",
      "Gradient Descent(3323/9999): loss=4755.26262031612, w0=-2.7171593285805438, w1=-41.05795061141252\n",
      "Gradient Descent(3324/9999): loss=4755.26262031612, w0=5.965140671419456, w1=-34.738450611412524\n",
      "Gradient Descent(3325/9999): loss=11137.630134611783, w0=-6.101624714134078, w1=-42.142550611412524\n",
      "Gradient Descent(3326/9999): loss=5403.34069682229, w0=-6.101624714134078, w1=-42.142550611412524\n",
      "Gradient Descent(3327/9999): loss=5403.34069682229, w0=-6.101624714134078, w1=-42.142550611412524\n",
      "Gradient Descent(3328/9999): loss=5403.34069682229, w0=-6.101624714134078, w1=-42.142550611412524\n",
      "Gradient Descent(3329/9999): loss=5403.34069682229, w0=-6.101624714134078, w1=-42.142550611412524\n",
      "Gradient Descent(3330/9999): loss=5403.34069682229, w0=-6.101624714134078, w1=-42.142550611412524\n",
      "Gradient Descent(3331/9999): loss=5403.34069682229, w0=-6.101624714134078, w1=-42.142550611412524\n",
      "Gradient Descent(3332/9999): loss=5403.34069682229, w0=-6.101624714134078, w1=-42.142550611412524\n",
      "Gradient Descent(3333/9999): loss=5403.34069682229, w0=-6.101624714134078, w1=-42.142550611412524\n",
      "Gradient Descent(3334/9999): loss=5403.34069682229, w0=-6.101624714134078, w1=-42.142550611412524\n",
      "Gradient Descent(3335/9999): loss=5403.34069682229, w0=-6.101624714134078, w1=-42.142550611412524\n",
      "Gradient Descent(3336/9999): loss=5403.34069682229, w0=7.543675285865922, w1=-38.436050611412526\n",
      "Gradient Descent(3337/9999): loss=11543.818415738246, w0=7.543675285865922, w1=-38.436050611412526\n",
      "Gradient Descent(3338/9999): loss=11543.818415738246, w0=-6.403034813909417, w1=-48.34182137110828\n",
      "Gradient Descent(3339/9999): loss=5646.027429898357, w0=6.236565186090584, w1=-44.433121371108285\n",
      "Gradient Descent(3340/9999): loss=7285.888755632452, w0=6.236565186090584, w1=-44.433121371108285\n",
      "Gradient Descent(3341/9999): loss=7285.888755632452, w0=6.236565186090584, w1=-44.433121371108285\n",
      "Gradient Descent(3342/9999): loss=7285.888755632452, w0=6.236565186090584, w1=-44.433121371108285\n",
      "Gradient Descent(3343/9999): loss=7285.888755632452, w0=6.236565186090584, w1=-44.433121371108285\n",
      "Gradient Descent(3344/9999): loss=7285.888755632452, w0=-1.8801348139094154, w1=-48.226521371108284\n",
      "Gradient Descent(3345/9999): loss=5002.869530268343, w0=-1.8801348139094154, w1=-48.226521371108284\n",
      "Gradient Descent(3346/9999): loss=5002.869530268343, w0=-1.8801348139094154, w1=-48.226521371108284\n",
      "Gradient Descent(3347/9999): loss=5002.869530268343, w0=-1.8801348139094154, w1=-48.226521371108284\n",
      "Gradient Descent(3348/9999): loss=5002.869530268343, w0=-1.8801348139094154, w1=-48.226521371108284\n",
      "Gradient Descent(3349/9999): loss=5002.869530268343, w0=-1.8801348139094154, w1=-48.226521371108284\n",
      "Gradient Descent(3350/9999): loss=5002.869530268343, w0=-1.8801348139094154, w1=-48.226521371108284\n",
      "Gradient Descent(3351/9999): loss=5002.869530268343, w0=10.279865186090586, w1=-45.162121371108285\n",
      "Gradient Descent(3352/9999): loss=13649.11687695069, w0=-7.3518348139094165, w1=-58.13062137110828\n",
      "Gradient Descent(3353/9999): loss=5687.370129138809, w0=2.6556651860905838, w1=-57.29812137110828\n",
      "Gradient Descent(3354/9999): loss=5747.709876387202, w0=2.6556651860905838, w1=-57.29812137110828\n",
      "Gradient Descent(3355/9999): loss=5747.709876387202, w0=2.6556651860905838, w1=-57.29812137110828\n",
      "Gradient Descent(3356/9999): loss=5747.709876387202, w0=-6.087834813909417, w1=-60.76072137110828\n",
      "Gradient Descent(3357/9999): loss=4827.472428253389, w0=-6.087834813909417, w1=-60.76072137110828\n",
      "Gradient Descent(3358/9999): loss=4827.472428253389, w0=4.280165186090585, w1=-54.38332137110828\n",
      "Gradient Descent(3359/9999): loss=7088.533528535731, w0=4.280165186090585, w1=-54.38332137110828\n",
      "Gradient Descent(3360/9999): loss=7088.533528535731, w0=4.280165186090585, w1=-54.38332137110828\n",
      "Gradient Descent(3361/9999): loss=7088.533528535731, w0=4.280165186090585, w1=-54.38332137110828\n",
      "Gradient Descent(3362/9999): loss=7088.533528535731, w0=-8.286734813909415, w1=-57.07852137110828\n",
      "Gradient Descent(3363/9999): loss=5435.45829683161, w0=-8.286734813909415, w1=-57.07852137110828\n",
      "Gradient Descent(3364/9999): loss=5435.45829683161, w0=-8.286734813909415, w1=-57.07852137110828\n",
      "Gradient Descent(3365/9999): loss=5435.45829683161, w0=-8.286734813909415, w1=-57.07852137110828\n",
      "Gradient Descent(3366/9999): loss=5435.45829683161, w0=-8.286734813909415, w1=-57.07852137110828\n",
      "Gradient Descent(3367/9999): loss=5435.45829683161, w0=-8.286734813909415, w1=-57.07852137110828\n",
      "Gradient Descent(3368/9999): loss=5435.45829683161, w0=-8.286734813909415, w1=-57.07852137110828\n",
      "Gradient Descent(3369/9999): loss=5435.45829683161, w0=-8.286734813909415, w1=-57.07852137110828\n",
      "Gradient Descent(3370/9999): loss=5435.45829683161, w0=11.382765186090584, w1=-55.23472137110828\n",
      "Gradient Descent(3371/9999): loss=16351.660884748537, w0=-13.838734813909419, w1=-62.87352137110828\n",
      "Gradient Descent(3372/9999): loss=4804.006571904985, w0=-13.838734813909419, w1=-62.87352137110828\n",
      "Gradient Descent(3373/9999): loss=4804.006571904985, w0=-21.912334813909418, w1=-64.88092137110829\n",
      "Gradient Descent(3374/9999): loss=5737.9379177643805, w0=-21.912334813909418, w1=-64.88092137110829\n",
      "Gradient Descent(3375/9999): loss=5737.9379177643805, w0=-21.912334813909418, w1=-64.88092137110829\n",
      "Gradient Descent(3376/9999): loss=5737.9379177643805, w0=-21.912334813909418, w1=-64.88092137110829\n",
      "Gradient Descent(3377/9999): loss=5737.9379177643805, w0=-21.912334813909418, w1=-64.88092137110829\n",
      "Gradient Descent(3378/9999): loss=5737.9379177643805, w0=-21.912334813909418, w1=-64.88092137110829\n",
      "Gradient Descent(3379/9999): loss=5737.9379177643805, w0=-21.912334813909418, w1=-64.88092137110829\n",
      "Gradient Descent(3380/9999): loss=5737.9379177643805, w0=-21.912334813909418, w1=-64.88092137110829\n",
      "Gradient Descent(3381/9999): loss=5737.9379177643805, w0=-21.912334813909418, w1=-64.88092137110829\n",
      "Gradient Descent(3382/9999): loss=5737.9379177643805, w0=-21.912334813909418, w1=-64.88092137110829\n",
      "Gradient Descent(3383/9999): loss=5737.9379177643805, w0=-21.912334813909418, w1=-64.88092137110829\n",
      "Gradient Descent(3384/9999): loss=5737.9379177643805, w0=-21.912334813909418, w1=-64.88092137110829\n",
      "Gradient Descent(3385/9999): loss=5737.9379177643805, w0=-21.912334813909418, w1=-64.88092137110829\n",
      "Gradient Descent(3386/9999): loss=5737.9379177643805, w0=-13.924934813909417, w1=-61.25572137110829\n",
      "Gradient Descent(3387/9999): loss=4877.972244927094, w0=-1.8581694283558825, w1=-52.07382137110829\n",
      "Gradient Descent(3388/9999): loss=12767.76798289789, w0=-1.8581694283558825, w1=-52.07382137110829\n",
      "Gradient Descent(3389/9999): loss=12767.76798289789, w0=-1.8581694283558825, w1=-52.07382137110829\n",
      "Gradient Descent(3390/9999): loss=12767.76798289789, w0=-10.148969428355882, w1=-58.70692137110829\n",
      "Gradient Descent(3391/9999): loss=4856.86889609326, w0=-10.148969428355882, w1=-58.70692137110829\n",
      "Gradient Descent(3392/9999): loss=4856.86889609326, w0=-18.91576942835588, w1=-62.150621371108286\n",
      "Gradient Descent(3393/9999): loss=5802.4994844197445, w0=-7.505269428355879, w1=-60.05912137110829\n",
      "Gradient Descent(3394/9999): loss=5490.901296427044, w0=-0.24696942835587876, w1=-55.80482137110829\n",
      "Gradient Descent(3395/9999): loss=13296.71005756812, w0=-12.313734813909413, w1=-62.61472137110829\n",
      "Gradient Descent(3396/9999): loss=4606.170001789273, w0=-12.313734813909413, w1=-62.61472137110829\n",
      "Gradient Descent(3397/9999): loss=4606.170001789273, w0=-12.313734813909413, w1=-62.61472137110829\n",
      "Gradient Descent(3398/9999): loss=4606.170001789273, w0=-12.313734813909413, w1=-62.61472137110829\n",
      "Gradient Descent(3399/9999): loss=4606.170001789273, w0=-12.313734813909413, w1=-62.61472137110829\n",
      "Gradient Descent(3400/9999): loss=4606.170001789273, w0=-12.313734813909413, w1=-62.61472137110829\n",
      "Gradient Descent(3401/9999): loss=4606.170001789273, w0=-12.313734813909413, w1=-62.61472137110829\n",
      "Gradient Descent(3402/9999): loss=4606.170001789273, w0=-12.313734813909413, w1=-62.61472137110829\n",
      "Gradient Descent(3403/9999): loss=4606.170001789273, w0=-12.313734813909413, w1=-62.61472137110829\n",
      "Gradient Descent(3404/9999): loss=4606.170001789273, w0=-12.313734813909413, w1=-62.61472137110829\n",
      "Gradient Descent(3405/9999): loss=4606.170001789273, w0=-12.313734813909413, w1=-62.61472137110829\n",
      "Gradient Descent(3406/9999): loss=4606.170001789273, w0=-12.313734813909413, w1=-62.61472137110829\n",
      "Gradient Descent(3407/9999): loss=4606.170001789273, w0=-12.313734813909413, w1=-62.61472137110829\n",
      "Gradient Descent(3408/9999): loss=4606.170001789273, w0=-28.12123481390941, w1=-63.79792137110829\n",
      "Gradient Descent(3409/9999): loss=5802.4994844197445, w0=-28.12123481390941, w1=-63.79792137110829\n",
      "Gradient Descent(3410/9999): loss=5802.4994844197445, w0=-28.12123481390941, w1=-63.79792137110829\n",
      "Gradient Descent(3411/9999): loss=5802.4994844197445, w0=-28.12123481390941, w1=-63.79792137110829\n",
      "Gradient Descent(3412/9999): loss=5802.4994844197445, w0=-28.12123481390941, w1=-63.79792137110829\n",
      "Gradient Descent(3413/9999): loss=5802.4994844197445, w0=-28.12123481390941, w1=-63.79792137110829\n",
      "Gradient Descent(3414/9999): loss=5802.4994844197445, w0=-28.12123481390941, w1=-63.79792137110829\n",
      "Gradient Descent(3415/9999): loss=5802.4994844197445, w0=-28.12123481390941, w1=-63.79792137110829\n",
      "Gradient Descent(3416/9999): loss=5802.4994844197445, w0=-28.12123481390941, w1=-63.79792137110829\n",
      "Gradient Descent(3417/9999): loss=5802.4994844197445, w0=-28.12123481390941, w1=-63.79792137110829\n",
      "Gradient Descent(3418/9999): loss=5802.4994844197445, w0=-28.12123481390941, w1=-63.79792137110829\n",
      "Gradient Descent(3419/9999): loss=5802.4994844197445, w0=-28.12123481390941, w1=-63.79792137110829\n",
      "Gradient Descent(3420/9999): loss=5802.4994844197445, w0=-28.12123481390941, w1=-63.79792137110829\n",
      "Gradient Descent(3421/9999): loss=5802.4994844197445, w0=-19.14493481390941, w1=-59.851121371108285\n",
      "Gradient Descent(3422/9999): loss=5802.4994844197445, w0=-19.14493481390941, w1=-59.851121371108285\n",
      "Gradient Descent(3423/9999): loss=5802.4994844197445, w0=-19.14493481390941, w1=-59.851121371108285\n",
      "Gradient Descent(3424/9999): loss=5802.4994844197445, w0=-19.14493481390941, w1=-59.851121371108285\n",
      "Gradient Descent(3425/9999): loss=5802.4994844197445, w0=-19.14493481390941, w1=-59.851121371108285\n",
      "Gradient Descent(3426/9999): loss=5802.4994844197445, w0=-19.14493481390941, w1=-59.851121371108285\n",
      "Gradient Descent(3427/9999): loss=5802.4994844197445, w0=-19.14493481390941, w1=-59.851121371108285\n",
      "Gradient Descent(3428/9999): loss=5802.4994844197445, w0=-19.14493481390941, w1=-59.851121371108285\n",
      "Gradient Descent(3429/9999): loss=5802.4994844197445, w0=-8.814534813909408, w1=-59.522821371108286\n",
      "Gradient Descent(3430/9999): loss=4834.4616884379475, w0=-8.814534813909408, w1=-59.522821371108286\n",
      "Gradient Descent(3431/9999): loss=4834.4616884379475, w0=-8.814534813909408, w1=-59.522821371108286\n",
      "Gradient Descent(3432/9999): loss=4834.4616884379475, w0=-8.814534813909408, w1=-59.522821371108286\n",
      "Gradient Descent(3433/9999): loss=4834.4616884379475, w0=-8.814534813909408, w1=-59.522821371108286\n",
      "Gradient Descent(3434/9999): loss=4834.4616884379475, w0=-8.814534813909408, w1=-59.522821371108286\n",
      "Gradient Descent(3435/9999): loss=4834.4616884379475, w0=-8.814534813909408, w1=-59.522821371108286\n",
      "Gradient Descent(3436/9999): loss=4834.4616884379475, w0=-8.814534813909408, w1=-59.522821371108286\n",
      "Gradient Descent(3437/9999): loss=4834.4616884379475, w0=-8.814534813909408, w1=-59.522821371108286\n",
      "Gradient Descent(3438/9999): loss=4834.4616884379475, w0=-8.814534813909408, w1=-59.522821371108286\n",
      "Gradient Descent(3439/9999): loss=4834.4616884379475, w0=-8.814534813909408, w1=-59.522821371108286\n",
      "Gradient Descent(3440/9999): loss=4834.4616884379475, w0=-8.814534813909408, w1=-59.522821371108286\n",
      "Gradient Descent(3441/9999): loss=4834.4616884379475, w0=-8.814534813909408, w1=-59.522821371108286\n",
      "Gradient Descent(3442/9999): loss=4834.4616884379475, w0=-17.581334813909407, w1=-62.966521371108286\n",
      "Gradient Descent(3443/9999): loss=5802.497924427262, w0=-17.581334813909407, w1=-62.966521371108286\n",
      "Gradient Descent(3444/9999): loss=5802.497924427262, w0=-17.581334813909407, w1=-62.966521371108286\n",
      "Gradient Descent(3445/9999): loss=5802.497924427262, w0=-17.581334813909407, w1=-62.966521371108286\n",
      "Gradient Descent(3446/9999): loss=5802.497924427262, w0=-6.843834813909407, w1=-62.59952137110829\n",
      "Gradient Descent(3447/9999): loss=5279.252999464314, w0=2.9955651860905927, w1=-58.20512137110829\n",
      "Gradient Descent(3448/9999): loss=13289.245784264282, w0=2.9955651860905927, w1=-58.20512137110829\n",
      "Gradient Descent(3449/9999): loss=13289.245784264282, w0=2.9955651860905927, w1=-58.20512137110829\n",
      "Gradient Descent(3450/9999): loss=13289.245784264282, w0=-6.232434813909407, w1=-58.41252137110829\n",
      "Gradient Descent(3451/9999): loss=6131.467670443382, w0=-16.845234813909407, w1=-63.310121371108295\n",
      "Gradient Descent(3452/9999): loss=5157.6279184731375, w0=-6.610034813909406, w1=-57.684521371108296\n",
      "Gradient Descent(3453/9999): loss=7008.897376389563, w0=-6.610034813909406, w1=-57.684521371108296\n",
      "Gradient Descent(3454/9999): loss=7008.897376389563, w0=-6.610034813909406, w1=-57.684521371108296\n",
      "Gradient Descent(3455/9999): loss=7008.897376389563, w0=-6.610034813909406, w1=-57.684521371108296\n",
      "Gradient Descent(3456/9999): loss=7008.897376389563, w0=-6.610034813909406, w1=-57.684521371108296\n",
      "Gradient Descent(3457/9999): loss=7008.897376389563, w0=-6.610034813909406, w1=-57.684521371108296\n",
      "Gradient Descent(3458/9999): loss=7008.897376389563, w0=-24.074234813909406, w1=-59.236721371108295\n",
      "Gradient Descent(3459/9999): loss=5781.850691970825, w0=-24.074234813909406, w1=-59.236721371108295\n",
      "Gradient Descent(3460/9999): loss=5781.850691970825, w0=-24.074234813909406, w1=-59.236721371108295\n",
      "Gradient Descent(3461/9999): loss=5781.850691970825, w0=-24.074234813909406, w1=-59.236721371108295\n",
      "Gradient Descent(3462/9999): loss=5781.850691970825, w0=-24.074234813909406, w1=-59.236721371108295\n",
      "Gradient Descent(3463/9999): loss=5781.850691970825, w0=-24.074234813909406, w1=-59.236721371108295\n",
      "Gradient Descent(3464/9999): loss=5781.850691970825, w0=-27.838134813909406, w1=-62.195621371108295\n",
      "Gradient Descent(3465/9999): loss=5802.4994844197445, w0=-17.442634813909407, w1=-58.98942137110829\n",
      "Gradient Descent(3466/9999): loss=5378.865084082186, w0=-17.44263481400793, w1=-58.989421371109785\n",
      "Gradient Descent(3467/9999): loss=5378.86508411349, w0=-17.44263481400793, w1=-58.989421371109785\n",
      "Gradient Descent(3468/9999): loss=5378.86508411349, w0=-17.44263481400793, w1=-58.989421371109785\n",
      "Gradient Descent(3469/9999): loss=5378.86508411349, w0=-4.934534814007931, w1=-54.81182137110979\n",
      "Gradient Descent(3470/9999): loss=7880.147564661171, w0=-17.78593481400793, w1=-55.584021371109785\n",
      "Gradient Descent(3471/9999): loss=5545.256479535428, w0=-17.78593481400793, w1=-55.584021371109785\n",
      "Gradient Descent(3472/9999): loss=5545.256479535428, w0=-4.19783481400793, w1=-55.046821371109786\n",
      "Gradient Descent(3473/9999): loss=8011.317537520188, w0=-4.19783481400793, w1=-55.046821371109786\n",
      "Gradient Descent(3474/9999): loss=8011.317537520188, w0=-4.19783481400793, w1=-55.046821371109786\n",
      "Gradient Descent(3475/9999): loss=8011.317537520188, w0=-4.19783481400793, w1=-55.046821371109786\n",
      "Gradient Descent(3476/9999): loss=8011.317537520188, w0=-4.19783481400793, w1=-55.046821371109786\n",
      "Gradient Descent(3477/9999): loss=8011.317537520188, w0=-4.19783481400793, w1=-55.046821371109786\n",
      "Gradient Descent(3478/9999): loss=8011.317537520188, w0=-4.19783481400793, w1=-55.046821371109786\n",
      "Gradient Descent(3479/9999): loss=8011.317537520188, w0=-16.07053481400793, w1=-58.254021371109786\n",
      "Gradient Descent(3480/9999): loss=4618.902861418763, w0=-16.07053481400793, w1=-58.254021371109786\n",
      "Gradient Descent(3481/9999): loss=4618.902861418763, w0=-16.07053481400793, w1=-58.254021371109786\n",
      "Gradient Descent(3482/9999): loss=4618.902861418763, w0=-4.277934814007931, w1=-54.37012137110979\n",
      "Gradient Descent(3483/9999): loss=7873.500954403608, w0=-4.277934814007931, w1=-54.37012137110979\n",
      "Gradient Descent(3484/9999): loss=7873.500954403608, w0=-11.618734814007933, w1=-56.88252137110979\n",
      "Gradient Descent(3485/9999): loss=4710.425482473279, w0=-11.618734814007933, w1=-56.88252137110979\n",
      "Gradient Descent(3486/9999): loss=4710.425482473279, w0=-11.618734814007933, w1=-56.88252137110979\n",
      "Gradient Descent(3487/9999): loss=4710.425482473279, w0=-11.618734814007933, w1=-56.88252137110979\n",
      "Gradient Descent(3488/9999): loss=4710.425482473279, w0=-11.618734814007933, w1=-56.88252137110979\n",
      "Gradient Descent(3489/9999): loss=4710.425482473279, w0=-11.618734814007933, w1=-56.88252137110979\n",
      "Gradient Descent(3490/9999): loss=4710.425482473279, w0=-11.618734814007933, w1=-56.88252137110979\n",
      "Gradient Descent(3491/9999): loss=4710.425482473279, w0=-11.618734814007933, w1=-56.88252137110979\n",
      "Gradient Descent(3492/9999): loss=4710.425482473279, w0=-11.618734814007933, w1=-56.88252137110979\n",
      "Gradient Descent(3493/9999): loss=4710.425482473279, w0=-11.618734814007933, w1=-56.88252137110979\n",
      "Gradient Descent(3494/9999): loss=4710.425482473279, w0=-1.7793348140079335, w1=-52.48812137110979\n",
      "Gradient Descent(3495/9999): loss=6810.609973345896, w0=-1.7793348140079335, w1=-52.48812137110979\n",
      "Gradient Descent(3496/9999): loss=6810.609973345896, w0=-1.7793348140079335, w1=-52.48812137110979\n",
      "Gradient Descent(3497/9999): loss=6810.609973345896, w0=-1.7793348140079335, w1=-52.48812137110979\n",
      "Gradient Descent(3498/9999): loss=6810.609973345896, w0=-1.7793348140079335, w1=-52.48812137110979\n",
      "Gradient Descent(3499/9999): loss=6810.609973345896, w0=-1.7793348140079335, w1=-52.48812137110979\n",
      "Gradient Descent(3500/9999): loss=6810.609973345896, w0=-1.7793348140079335, w1=-52.48812137110979\n",
      "Gradient Descent(3501/9999): loss=6810.609973345896, w0=-13.846100199561468, w1=-61.18972137110979\n",
      "Gradient Descent(3502/9999): loss=5802.4994844197445, w0=-1.6931001995614672, w1=-56.83292137110979\n",
      "Gradient Descent(3503/9999): loss=4422.063089967239, w0=-1.6931001995614672, w1=-56.83292137110979\n",
      "Gradient Descent(3504/9999): loss=4422.063089967239, w0=-1.6931001995614672, w1=-56.83292137110979\n",
      "Gradient Descent(3505/9999): loss=4422.063089967239, w0=-1.6931001995614672, w1=-56.83292137110979\n",
      "Gradient Descent(3506/9999): loss=4422.063089967239, w0=-1.6931001995614672, w1=-56.83292137110979\n",
      "Gradient Descent(3507/9999): loss=4422.063089967239, w0=-1.6931001995614672, w1=-56.83292137110979\n",
      "Gradient Descent(3508/9999): loss=4422.063089967239, w0=-1.6931001995614672, w1=-56.83292137110979\n",
      "Gradient Descent(3509/9999): loss=4422.063089967239, w0=-1.6931001995614672, w1=-56.83292137110979\n",
      "Gradient Descent(3510/9999): loss=4422.063089967239, w0=-1.6931001995614672, w1=-56.83292137110979\n",
      "Gradient Descent(3511/9999): loss=4422.063089967239, w0=-1.6931001995614672, w1=-56.83292137110979\n",
      "Gradient Descent(3512/9999): loss=4422.063089967239, w0=-1.6931001995614672, w1=-56.83292137110979\n",
      "Gradient Descent(3513/9999): loss=4422.063089967239, w0=-1.6931001995614672, w1=-56.83292137110979\n",
      "Gradient Descent(3514/9999): loss=4422.063089967239, w0=13.438399800438534, w1=-49.99502137110979\n",
      "Gradient Descent(3515/9999): loss=15692.361823379495, w0=13.438399800438534, w1=-49.99502137110979\n",
      "Gradient Descent(3516/9999): loss=15692.361823379495, w0=13.438399800438534, w1=-49.99502137110979\n",
      "Gradient Descent(3517/9999): loss=15692.361823379495, w0=2.183699800438532, w1=-56.7231213711098\n",
      "Gradient Descent(3518/9999): loss=4369.832274735914, w0=2.183699800438532, w1=-56.7231213711098\n",
      "Gradient Descent(3519/9999): loss=4369.832274735914, w0=-9.883065585115002, w1=-62.627821371109796\n",
      "Gradient Descent(3520/9999): loss=5802.4994844197445, w0=-9.883065585115002, w1=-62.627821371109796\n",
      "Gradient Descent(3521/9999): loss=5802.4994844197445, w0=-9.883065585115002, w1=-62.627821371109796\n",
      "Gradient Descent(3522/9999): loss=5802.4994844197445, w0=-9.883065585115002, w1=-62.627821371109796\n",
      "Gradient Descent(3523/9999): loss=5802.4994844197445, w0=-9.883065585115002, w1=-62.627821371109796\n",
      "Gradient Descent(3524/9999): loss=5802.4994844197445, w0=-9.883065585115002, w1=-62.627821371109796\n",
      "Gradient Descent(3525/9999): loss=5802.4994844197445, w0=-9.883065585115002, w1=-62.627821371109796\n",
      "Gradient Descent(3526/9999): loss=5802.4994844197445, w0=2.183699800438532, w1=-51.59062137110979\n",
      "Gradient Descent(3527/9999): loss=5730.456423297464, w0=2.183699800438532, w1=-51.59062137110979\n",
      "Gradient Descent(3528/9999): loss=5730.456423297464, w0=2.183699800438532, w1=-51.59062137110979\n",
      "Gradient Descent(3529/9999): loss=5730.456423297464, w0=2.183699800438532, w1=-51.59062137110979\n",
      "Gradient Descent(3530/9999): loss=5730.456423297464, w0=2.183699800438532, w1=-51.59062137110979\n",
      "Gradient Descent(3531/9999): loss=5730.456423297464, w0=2.183699800438532, w1=-51.59062137110979\n",
      "Gradient Descent(3532/9999): loss=5730.456423297464, w0=2.183699800438532, w1=-51.59062137110979\n",
      "Gradient Descent(3533/9999): loss=5730.456423297464, w0=2.183699800438532, w1=-51.59062137110979\n",
      "Gradient Descent(3534/9999): loss=5730.456423297464, w0=2.183699800438532, w1=-51.59062137110979\n",
      "Gradient Descent(3535/9999): loss=5730.456423297464, w0=-1.1164001995614679, w1=-59.25372137110979\n",
      "Gradient Descent(3536/9999): loss=5618.416267295238, w0=-1.1164001995614679, w1=-59.25372137110979\n",
      "Gradient Descent(3537/9999): loss=5618.416267295238, w0=5.643799800438533, w1=-53.84512137110979\n",
      "Gradient Descent(3538/9999): loss=4313.131698559557, w0=5.643799800438533, w1=-53.84512137110979\n",
      "Gradient Descent(3539/9999): loss=4313.131698559557, w0=5.643799800438533, w1=-53.84512137110979\n",
      "Gradient Descent(3540/9999): loss=4313.131698559557, w0=5.643799800438533, w1=-53.84512137110979\n",
      "Gradient Descent(3541/9999): loss=4313.131698559557, w0=5.643799800438533, w1=-53.84512137110979\n",
      "Gradient Descent(3542/9999): loss=4313.131698559557, w0=16.954599800438533, w1=-46.544921371109794\n",
      "Gradient Descent(3543/9999): loss=15461.45447168031, w0=4.887834414884999, w1=-56.478821371109795\n",
      "Gradient Descent(3544/9999): loss=4488.761170604419, w0=18.776934414884998, w1=-47.46292137110979\n",
      "Gradient Descent(3545/9999): loss=16797.35284022538, w0=6.087134414884998, w1=-54.70692137110979\n",
      "Gradient Descent(3546/9999): loss=5277.698420690422, w0=-8.114565585115002, w1=-55.492921371109794\n",
      "Gradient Descent(3547/9999): loss=5790.986548954825, w0=3.3172344148849984, w1=-46.8913213711098\n",
      "Gradient Descent(3548/9999): loss=9028.271681672693, w0=-4.138765585115002, w1=-52.398321371109795\n",
      "Gradient Descent(3549/9999): loss=4558.7417050529475, w0=-4.138765585115002, w1=-52.398321371109795\n",
      "Gradient Descent(3550/9999): loss=4558.7417050529475, w0=-4.138765585115002, w1=-52.398321371109795\n",
      "Gradient Descent(3551/9999): loss=4558.7417050529475, w0=7.927999800438532, w1=-33.038121371109796\n",
      "Gradient Descent(3552/9999): loss=13940.567716255522, w0=7.927999800438532, w1=-33.038121371109796\n",
      "Gradient Descent(3553/9999): loss=13940.567716255522, w0=7.927999800438532, w1=-33.038121371109796\n",
      "Gradient Descent(3554/9999): loss=13940.567716255522, w0=7.927999800438532, w1=-33.038121371109796\n",
      "Gradient Descent(3555/9999): loss=13940.567716255522, w0=0.6141998004385316, w1=-38.9523213711098\n",
      "Gradient Descent(3556/9999): loss=4427.828051227846, w0=0.6141998004385316, w1=-38.9523213711098\n",
      "Gradient Descent(3557/9999): loss=4427.828051227846, w0=0.6141998004385316, w1=-38.9523213711098\n",
      "Gradient Descent(3558/9999): loss=4427.828051227846, w0=0.6141998004385316, w1=-38.9523213711098\n",
      "Gradient Descent(3559/9999): loss=4427.828051227846, w0=0.6141998004385316, w1=-38.9523213711098\n",
      "Gradient Descent(3560/9999): loss=4427.828051227846, w0=0.6141998004385316, w1=-38.9523213711098\n",
      "Gradient Descent(3561/9999): loss=4427.828051227846, w0=12.0514998004355, w1=-34.98942137111085\n",
      "Gradient Descent(3562/9999): loss=15621.315022679068, w0=12.0514998004355, w1=-34.98942137111085\n",
      "Gradient Descent(3563/9999): loss=15621.315022679068, w0=3.1319998004355014, w1=-42.10422137111085\n",
      "Gradient Descent(3564/9999): loss=4649.141778812616, w0=11.989399800435502, w1=-38.97812137111085\n",
      "Gradient Descent(3565/9999): loss=10809.703235906481, w0=11.989399800435502, w1=-38.97812137111085\n",
      "Gradient Descent(3566/9999): loss=10809.703235906481, w0=11.989399800435502, w1=-38.97812137111085\n",
      "Gradient Descent(3567/9999): loss=10809.703235906481, w0=2.5229998004355014, w1=-41.427021371110854\n",
      "Gradient Descent(3568/9999): loss=4901.281936645382, w0=2.5229998004355014, w1=-41.427021371110854\n",
      "Gradient Descent(3569/9999): loss=4901.281936645382, w0=14.676099800435503, w1=-37.33882137111085\n",
      "Gradient Descent(3570/9999): loss=13860.343468574538, w0=14.676099800435503, w1=-37.33882137111085\n",
      "Gradient Descent(3571/9999): loss=13860.343468574538, w0=2.6093344148819693, w1=-46.247721371110856\n",
      "Gradient Descent(3572/9999): loss=4629.588779507221, w0=2.6093344148819693, w1=-46.247721371110856\n",
      "Gradient Descent(3573/9999): loss=4629.588779507221, w0=2.6093344148819693, w1=-46.247721371110856\n",
      "Gradient Descent(3574/9999): loss=4629.588779507221, w0=2.6093344148819693, w1=-46.247721371110856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(3575/9999): loss=4629.588779507221, w0=2.6093344148819693, w1=-46.247721371110856\n",
      "Gradient Descent(3576/9999): loss=4629.588779507221, w0=2.6093344148819693, w1=-46.247721371110856\n",
      "Gradient Descent(3577/9999): loss=4629.588779507221, w0=2.6093344148819693, w1=-46.247721371110856\n",
      "Gradient Descent(3578/9999): loss=4629.588779507221, w0=2.6093344148819693, w1=-46.247721371110856\n",
      "Gradient Descent(3579/9999): loss=4629.588779507221, w0=2.6093344148819693, w1=-46.247721371110856\n",
      "Gradient Descent(3580/9999): loss=4629.588779507221, w0=13.602534414881971, w1=-42.41582137111086\n",
      "Gradient Descent(3581/9999): loss=13910.134384519737, w0=6.96193441488197, w1=-48.05362137111086\n",
      "Gradient Descent(3582/9999): loss=4443.14865271312, w0=6.96193441488197, w1=-48.05362137111086\n",
      "Gradient Descent(3583/9999): loss=4443.14865271312, w0=6.96193441488197, w1=-48.05362137111086\n",
      "Gradient Descent(3584/9999): loss=4443.14865271312, w0=6.96193441488197, w1=-48.05362137111086\n",
      "Gradient Descent(3585/9999): loss=4443.14865271312, w0=6.96193441488197, w1=-48.05362137111086\n",
      "Gradient Descent(3586/9999): loss=4443.14865271312, w0=6.96193441488197, w1=-48.05362137111086\n",
      "Gradient Descent(3587/9999): loss=4443.14865271312, w0=19.028699800435504, w1=-39.049521371110856\n",
      "Gradient Descent(3588/9999): loss=16912.482208067762, w0=19.028699800435504, w1=-39.049521371110856\n",
      "Gradient Descent(3589/9999): loss=16912.482208067762, w0=6.96193441488197, w1=-46.87562137111086\n",
      "Gradient Descent(3590/9999): loss=8213.591295002476, w0=6.96193441488197, w1=-46.87562137111086\n",
      "Gradient Descent(3591/9999): loss=8213.591295002476, w0=6.96193441488197, w1=-46.87562137111086\n",
      "Gradient Descent(3592/9999): loss=8213.591295002476, w0=-5.805065585118031, w1=-51.819021371110864\n",
      "Gradient Descent(3593/9999): loss=5641.36182018951, w0=-5.805065585118031, w1=-51.819021371110864\n",
      "Gradient Descent(3594/9999): loss=5641.36182018951, w0=3.091934414881969, w1=-51.37012137111086\n",
      "Gradient Descent(3595/9999): loss=6247.450686783548, w0=3.091934414881969, w1=-51.37012137111086\n",
      "Gradient Descent(3596/9999): loss=6247.450686783548, w0=-8.18196558511803, w1=-54.495021371110866\n",
      "Gradient Descent(3597/9999): loss=5354.242218782891, w0=-8.18196558511803, w1=-54.495021371110866\n",
      "Gradient Descent(3598/9999): loss=5354.242218782891, w0=1.1437344148819708, w1=-51.50522137111086\n",
      "Gradient Descent(3599/9999): loss=6762.801956511925, w0=-8.75226558511803, w1=-54.395921371110866\n",
      "Gradient Descent(3600/9999): loss=4855.41115487268, w0=1.982434414881972, w1=-54.12612137111087\n",
      "Gradient Descent(3601/9999): loss=7686.623134773512, w0=-10.084330970671562, w1=-64.16332137111087\n",
      "Gradient Descent(3602/9999): loss=5802.4994844197445, w0=-10.084330970671562, w1=-64.16332137111087\n",
      "Gradient Descent(3603/9999): loss=5802.4994844197445, w0=-2.574230970671562, w1=-63.13752137111087\n",
      "Gradient Descent(3604/9999): loss=5282.118245107295, w0=-2.574230970671562, w1=-63.13752137111087\n",
      "Gradient Descent(3605/9999): loss=5282.118245107295, w0=-2.574230970671562, w1=-63.13752137111087\n",
      "Gradient Descent(3606/9999): loss=5282.118245107295, w0=12.465669029328438, w1=-55.36662137111087\n",
      "Gradient Descent(3607/9999): loss=11928.568994913832, w0=12.465669029328438, w1=-55.36662137111087\n",
      "Gradient Descent(3608/9999): loss=11928.568994913832, w0=5.111269029328438, w1=-59.559621371110865\n",
      "Gradient Descent(3609/9999): loss=5266.720449175207, w0=5.111269029328438, w1=-59.559621371110865\n",
      "Gradient Descent(3610/9999): loss=5266.720449175207, w0=5.111269029328438, w1=-59.559621371110865\n",
      "Gradient Descent(3611/9999): loss=5266.720449175207, w0=5.111269029328438, w1=-59.559621371110865\n",
      "Gradient Descent(3612/9999): loss=5266.720449175207, w0=5.111269029328438, w1=-59.559621371110865\n",
      "Gradient Descent(3613/9999): loss=5266.720449175207, w0=5.111269029328438, w1=-59.559621371110865\n",
      "Gradient Descent(3614/9999): loss=5266.720449175207, w0=-9.090430970671562, w1=-60.345621371110866\n",
      "Gradient Descent(3615/9999): loss=5790.986548954825, w0=-9.090430970671562, w1=-60.345621371110866\n",
      "Gradient Descent(3616/9999): loss=5790.986548954825, w0=-9.090430970671562, w1=-60.345621371110866\n",
      "Gradient Descent(3617/9999): loss=5790.986548954825, w0=-9.090430970671562, w1=-60.345621371110866\n",
      "Gradient Descent(3618/9999): loss=5790.986548954825, w0=-9.090430970671562, w1=-60.345621371110866\n",
      "Gradient Descent(3619/9999): loss=5790.986548954825, w0=-9.090430970671562, w1=-60.345621371110866\n",
      "Gradient Descent(3620/9999): loss=5790.986548954825, w0=-9.090430970671562, w1=-60.345621371110866\n",
      "Gradient Descent(3621/9999): loss=5790.986548954825, w0=-9.090430970671562, w1=-60.345621371110866\n",
      "Gradient Descent(3622/9999): loss=5790.986548954825, w0=1.539069029328438, w1=-57.24702137111087\n",
      "Gradient Descent(3623/9999): loss=4541.021283047939, w0=-6.538730970671564, w1=-57.70592137111087\n",
      "Gradient Descent(3624/9999): loss=5802.4994844197445, w0=-6.538730970671564, w1=-57.70592137111087\n",
      "Gradient Descent(3625/9999): loss=5802.4994844197445, w0=0.7392690293284367, w1=-54.44082137111087\n",
      "Gradient Descent(3626/9999): loss=4584.129787249018, w0=0.7392690293284367, w1=-54.44082137111087\n",
      "Gradient Descent(3627/9999): loss=4584.129787249018, w0=0.7392690293284367, w1=-54.44082137111087\n",
      "Gradient Descent(3628/9999): loss=4584.129787249018, w0=0.7392690293284367, w1=-54.44082137111087\n",
      "Gradient Descent(3629/9999): loss=4584.129787249018, w0=0.7392690293284367, w1=-54.44082137111087\n",
      "Gradient Descent(3630/9999): loss=4584.129787249018, w0=0.7392690293284367, w1=-54.44082137111087\n",
      "Gradient Descent(3631/9999): loss=4584.129787249018, w0=0.7392690293284367, w1=-54.44082137111087\n",
      "Gradient Descent(3632/9999): loss=4584.129787249018, w0=0.7392690293284367, w1=-54.44082137111087\n",
      "Gradient Descent(3633/9999): loss=4584.129787249018, w0=0.7392690293284367, w1=-54.44082137111087\n",
      "Gradient Descent(3634/9999): loss=4584.129787249018, w0=0.7392690293284367, w1=-54.44082137111087\n",
      "Gradient Descent(3635/9999): loss=4584.129787249018, w0=0.7392690293284367, w1=-54.44082137111087\n",
      "Gradient Descent(3636/9999): loss=4584.129787249018, w0=0.7392690293284367, w1=-54.44082137111087\n",
      "Gradient Descent(3637/9999): loss=4584.129787249018, w0=0.7392690293284367, w1=-54.44082137111087\n",
      "Gradient Descent(3638/9999): loss=4584.129787249018, w0=0.7392690293284367, w1=-54.44082137111087\n",
      "Gradient Descent(3639/9999): loss=4584.129787249018, w0=0.7392690293284367, w1=-54.44082137111087\n",
      "Gradient Descent(3640/9999): loss=4584.129787249018, w0=-13.100130970671565, w1=-55.65182137111087\n",
      "Gradient Descent(3641/9999): loss=5802.4994844197445, w0=-13.100130970671565, w1=-55.65182137111087\n",
      "Gradient Descent(3642/9999): loss=5802.4994844197445, w0=-0.36143097067156305, w1=-51.91612137111087\n",
      "Gradient Descent(3643/9999): loss=4776.868607820656, w0=-0.36143097067156305, w1=-51.91612137111087\n",
      "Gradient Descent(3644/9999): loss=4776.868607820656, w0=-0.36143097067156305, w1=-51.91612137111087\n",
      "Gradient Descent(3645/9999): loss=4776.868607820656, w0=-0.36143097067156305, w1=-51.91612137111087\n",
      "Gradient Descent(3646/9999): loss=4776.868607820656, w0=-0.36143097067156305, w1=-51.91612137111087\n",
      "Gradient Descent(3647/9999): loss=4776.868607820656, w0=9.614769029328437, w1=-47.309021371110866\n",
      "Gradient Descent(3648/9999): loss=13242.204355343707, w0=9.614769029328437, w1=-47.309021371110866\n",
      "Gradient Descent(3649/9999): loss=13242.204355343707, w0=9.614769029328437, w1=-47.309021371110866\n",
      "Gradient Descent(3650/9999): loss=13242.204355343707, w0=2.348469029328437, w1=-49.07382137111087\n",
      "Gradient Descent(3651/9999): loss=4355.115993402222, w0=2.348469029328437, w1=-49.07382137111087\n",
      "Gradient Descent(3652/9999): loss=4355.115993402222, w0=2.348469029328437, w1=-49.07382137111087\n",
      "Gradient Descent(3653/9999): loss=4355.115993402222, w0=12.716569029328436, w1=-43.831021371110864\n",
      "Gradient Descent(3654/9999): loss=15373.708737920466, w0=12.716569029328436, w1=-43.831021371110864\n",
      "Gradient Descent(3655/9999): loss=15373.708737920466, w0=1.073869029328435, w1=-53.04152137111087\n",
      "Gradient Descent(3656/9999): loss=4500.041228283895, w0=1.073869029328435, w1=-53.04152137111087\n",
      "Gradient Descent(3657/9999): loss=4500.041228283895, w0=1.073869029328435, w1=-53.04152137111087\n",
      "Gradient Descent(3658/9999): loss=4500.041228283895, w0=1.073869029328435, w1=-53.04152137111087\n",
      "Gradient Descent(3659/9999): loss=4500.041228283895, w0=1.073869029328435, w1=-53.04152137111087\n",
      "Gradient Descent(3660/9999): loss=4500.041228283895, w0=1.073869029328435, w1=-53.04152137111087\n",
      "Gradient Descent(3661/9999): loss=4500.041228283895, w0=1.073869029328435, w1=-53.04152137111087\n",
      "Gradient Descent(3662/9999): loss=4500.041228283895, w0=1.073869029328435, w1=-53.04152137111087\n",
      "Gradient Descent(3663/9999): loss=4500.041228283895, w0=1.073869029328435, w1=-53.04152137111087\n",
      "Gradient Descent(3664/9999): loss=4500.041228283895, w0=1.073869029328435, w1=-53.04152137111087\n",
      "Gradient Descent(3665/9999): loss=4500.041228283895, w0=1.073869029328435, w1=-53.04152137111087\n",
      "Gradient Descent(3666/9999): loss=4500.041228283895, w0=1.073869029328435, w1=-53.04152137111087\n",
      "Gradient Descent(3667/9999): loss=4500.041228283895, w0=1.073869029328435, w1=-53.04152137111087\n",
      "Gradient Descent(3668/9999): loss=4500.041228283895, w0=1.073869029328435, w1=-53.04152137111087\n",
      "Gradient Descent(3669/9999): loss=4500.041228283895, w0=1.073869029328435, w1=-53.04152137111087\n",
      "Gradient Descent(3670/9999): loss=4500.041228283895, w0=-5.710130970671566, w1=-53.91162137111087\n",
      "Gradient Descent(3671/9999): loss=5779.473613484941, w0=-5.710130970671566, w1=-53.91162137111087\n",
      "Gradient Descent(3672/9999): loss=5779.473613484941, w0=-5.710130970671566, w1=-53.91162137111087\n",
      "Gradient Descent(3673/9999): loss=5779.473613484941, w0=6.111369029328435, w1=-51.78972137111087\n",
      "Gradient Descent(3674/9999): loss=6623.339117462927, w0=6.111369029328435, w1=-51.78972137111087\n",
      "Gradient Descent(3675/9999): loss=6623.339117462927, w0=6.111369029328435, w1=-51.78972137111087\n",
      "Gradient Descent(3676/9999): loss=6623.339117462927, w0=6.111369029328435, w1=-51.78972137111087\n",
      "Gradient Descent(3677/9999): loss=6623.339117462927, w0=-1.2656309706715652, w1=-56.90562137111087\n",
      "Gradient Descent(3678/9999): loss=5251.259417171669, w0=-1.2656309706715652, w1=-56.90562137111087\n",
      "Gradient Descent(3679/9999): loss=5251.259417171669, w0=-1.2656309706715652, w1=-56.90562137111087\n",
      "Gradient Descent(3680/9999): loss=5251.259417171669, w0=-1.2656309706715652, w1=-56.90562137111087\n",
      "Gradient Descent(3681/9999): loss=5251.259417171669, w0=9.060969029328437, w1=-55.318621371110865\n",
      "Gradient Descent(3682/9999): loss=4929.803301243362, w0=9.060969029328437, w1=-55.318621371110865\n",
      "Gradient Descent(3683/9999): loss=4929.803301243362, w0=9.060969029328437, w1=-55.318621371110865\n",
      "Gradient Descent(3684/9999): loss=4929.803301243362, w0=9.060969029328437, w1=-55.318621371110865\n",
      "Gradient Descent(3685/9999): loss=4929.803301243362, w0=9.060969029328437, w1=-55.318621371110865\n",
      "Gradient Descent(3686/9999): loss=4929.803301243362, w0=9.060969029328437, w1=-55.318621371110865\n",
      "Gradient Descent(3687/9999): loss=4929.803301243362, w0=9.060969029328437, w1=-55.318621371110865\n",
      "Gradient Descent(3688/9999): loss=4929.803301243362, w0=9.060969029328437, w1=-55.318621371110865\n",
      "Gradient Descent(3689/9999): loss=4929.803301243362, w0=-1.5518309706715634, w1=-60.21622137111086\n",
      "Gradient Descent(3690/9999): loss=5491.6502268669265, w0=-1.5518309706715634, w1=-60.21622137111086\n",
      "Gradient Descent(3691/9999): loss=5491.6502268669265, w0=-1.5518309706715634, w1=-60.21622137111086\n",
      "Gradient Descent(3692/9999): loss=5491.6502268669265, w0=-1.5518309706715634, w1=-60.21622137111086\n",
      "Gradient Descent(3693/9999): loss=5491.6502268669265, w0=-1.5518309706715634, w1=-60.21622137111086\n",
      "Gradient Descent(3694/9999): loss=5491.6502268669265, w0=-1.5518309706715634, w1=-60.21622137111086\n",
      "Gradient Descent(3695/9999): loss=5491.6502268669265, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3696/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3697/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3698/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3699/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3700/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3701/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3702/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3703/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3704/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3705/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3706/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3707/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3708/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3709/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3710/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3711/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3712/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3713/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3714/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3715/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3716/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3717/9999): loss=5450.320836776673, w0=9.767869029328438, w1=-55.956221371110864\n",
      "Gradient Descent(3718/9999): loss=5450.320836776673, w0=-1.224230970671563, w1=-58.520921371110866\n",
      "Gradient Descent(3719/9999): loss=4835.434168796963, w0=-1.224230970671563, w1=-58.520921371110866\n",
      "Gradient Descent(3720/9999): loss=4835.434168796963, w0=-1.224230970671563, w1=-58.520921371110866\n",
      "Gradient Descent(3721/9999): loss=4835.434168796963, w0=-1.224230970671563, w1=-58.520921371110866\n",
      "Gradient Descent(3722/9999): loss=4835.434168796963, w0=-1.224230970671563, w1=-58.520921371110866\n",
      "Gradient Descent(3723/9999): loss=4835.434168796963, w0=-1.224230970671563, w1=-58.520921371110866\n",
      "Gradient Descent(3724/9999): loss=4835.434168796963, w0=-1.224230970671563, w1=-58.520921371110866\n",
      "Gradient Descent(3725/9999): loss=4835.434168796963, w0=-1.224230970671563, w1=-58.520921371110866\n",
      "Gradient Descent(3726/9999): loss=4835.434168796963, w0=-1.224230970671563, w1=-58.520921371110866\n",
      "Gradient Descent(3727/9999): loss=4835.434168796963, w0=-1.8760976011862571, w1=-58.62640583276267\n",
      "Gradient Descent(3728/9999): loss=5087.277413964281, w0=-1.8760976011862571, w1=-58.62640583276267\n",
      "Gradient Descent(3729/9999): loss=5087.277413964281, w0=-1.8760976011862571, w1=-58.62640583276267\n",
      "Gradient Descent(3730/9999): loss=5087.277413964281, w0=-1.8760976011862571, w1=-58.62640583276267\n",
      "Gradient Descent(3731/9999): loss=5087.277413964281, w0=-1.8760976011862571, w1=-58.62640583276267\n",
      "Gradient Descent(3732/9999): loss=5087.277413964281, w0=-1.8760976011862571, w1=-58.62640583276267\n",
      "Gradient Descent(3733/9999): loss=5087.277413964281, w0=-1.8760976011862571, w1=-58.62640583276267\n",
      "Gradient Descent(3734/9999): loss=5087.277413964281, w0=-1.8760976011862571, w1=-58.62640583276267\n",
      "Gradient Descent(3735/9999): loss=5087.277413964281, w0=-1.8760976011862571, w1=-58.62640583276267\n",
      "Gradient Descent(3736/9999): loss=5087.277413964281, w0=7.990502398813743, w1=-55.98900583276267\n",
      "Gradient Descent(3737/9999): loss=4614.932441943549, w0=-5.315097601186259, w1=-58.50660583276267\n",
      "Gradient Descent(3738/9999): loss=5802.4994844197445, w0=-5.315097601186259, w1=-58.50660583276267\n",
      "Gradient Descent(3739/9999): loss=5802.4994844197445, w0=8.23570239881374, w1=-47.71720583276267\n",
      "Gradient Descent(3740/9999): loss=4696.124010681523, w0=8.23570239881374, w1=-47.71720583276267\n",
      "Gradient Descent(3741/9999): loss=4696.124010681523, w0=8.23570239881374, w1=-47.71720583276267\n",
      "Gradient Descent(3742/9999): loss=4696.124010681523, w0=20.761802398813742, w1=-41.566805832762675\n",
      "Gradient Descent(3743/9999): loss=16359.861305751592, w0=-8.491197601186258, w1=-48.34660583276268\n",
      "Gradient Descent(3744/9999): loss=4927.043684895743, w0=4.218402398813744, w1=-46.533005832762676\n",
      "Gradient Descent(3745/9999): loss=10691.654584376003, w0=4.218402398813744, w1=-46.533005832762676\n",
      "Gradient Descent(3746/9999): loss=10691.654584376003, w0=4.218402398813744, w1=-46.533005832762676\n",
      "Gradient Descent(3747/9999): loss=10691.654584376003, w0=4.218402398813744, w1=-46.533005832762676\n",
      "Gradient Descent(3748/9999): loss=10691.654584376003, w0=4.218402398813744, w1=-46.533005832762676\n",
      "Gradient Descent(3749/9999): loss=10691.654584376003, w0=4.218402398813744, w1=-46.533005832762676\n",
      "Gradient Descent(3750/9999): loss=10691.654584376003, w0=4.218402398813744, w1=-46.533005832762676\n",
      "Gradient Descent(3751/9999): loss=10691.654584376003, w0=-5.4970976011862565, w1=-51.330505832762675\n",
      "Gradient Descent(3752/9999): loss=4870.106467580748, w0=-5.4970976011862565, w1=-51.330505832762675\n",
      "Gradient Descent(3753/9999): loss=4870.106467580748, w0=-5.4970976011862565, w1=-51.330505832762675\n",
      "Gradient Descent(3754/9999): loss=4870.106467580748, w0=-5.4970976011862565, w1=-51.330505832762675\n",
      "Gradient Descent(3755/9999): loss=4870.106467580748, w0=-5.4970976011862565, w1=-51.330505832762675\n",
      "Gradient Descent(3756/9999): loss=4870.106467580748, w0=-5.4970976011862565, w1=-51.330505832762675\n",
      "Gradient Descent(3757/9999): loss=4870.106467580748, w0=-5.4970976011862565, w1=-51.330505832762675\n",
      "Gradient Descent(3758/9999): loss=4870.106467580748, w0=-5.4970976011862565, w1=-51.330505832762675\n",
      "Gradient Descent(3759/9999): loss=4870.106467580748, w0=7.4069023988137435, w1=-50.22780583276268\n",
      "Gradient Descent(3760/9999): loss=10416.598406768597, w0=7.4069023988137435, w1=-50.22780583276268\n",
      "Gradient Descent(3761/9999): loss=10416.598406768597, w0=-4.659862986739791, w1=-58.76410583276268\n",
      "Gradient Descent(3762/9999): loss=4501.537860928898, w0=-4.659862986739791, w1=-58.76410583276268\n",
      "Gradient Descent(3763/9999): loss=4501.537860928898, w0=-4.659862986739791, w1=-58.76410583276268\n",
      "Gradient Descent(3764/9999): loss=4501.537860928898, w0=-4.659862986739791, w1=-58.76410583276268\n",
      "Gradient Descent(3765/9999): loss=4501.537860928898, w0=-4.659862986739791, w1=-58.76410583276268\n",
      "Gradient Descent(3766/9999): loss=4501.537860928898, w0=-4.659862986739791, w1=-58.76410583276268\n",
      "Gradient Descent(3767/9999): loss=4501.537860928898, w0=-4.659862986739791, w1=-58.76410583276268\n",
      "Gradient Descent(3768/9999): loss=4501.537860928898, w0=5.80413701326021, w1=-51.62000583276268\n",
      "Gradient Descent(3769/9999): loss=9452.402884473944, w0=5.80413701326021, w1=-51.62000583276268\n",
      "Gradient Descent(3770/9999): loss=9452.402884473944, w0=-5.5398629867397915, w1=-56.27400583276268\n",
      "Gradient Descent(3771/9999): loss=4622.091647098328, w0=-5.5398629867397915, w1=-56.27400583276268\n",
      "Gradient Descent(3772/9999): loss=4622.091647098328, w0=-5.5398629867397915, w1=-56.27400583276268\n",
      "Gradient Descent(3773/9999): loss=4622.091647098328, w0=4.248737013260211, w1=-54.50720583276268\n",
      "Gradient Descent(3774/9999): loss=9352.437964577539, w0=4.248737013260211, w1=-54.50720583276268\n",
      "Gradient Descent(3775/9999): loss=9352.437964577539, w0=4.248737013260211, w1=-54.50720583276268\n",
      "Gradient Descent(3776/9999): loss=9352.437964577539, w0=4.248737013260211, w1=-54.50720583276268\n",
      "Gradient Descent(3777/9999): loss=9352.437964577539, w0=-16.53596298673979, w1=-65.88460583276267\n",
      "Gradient Descent(3778/9999): loss=5802.4994844197445, w0=-7.302362986739789, w1=-62.225605832762675\n",
      "Gradient Descent(3779/9999): loss=4671.032412661176, w0=-7.302362986739789, w1=-62.225605832762675\n",
      "Gradient Descent(3780/9999): loss=4671.032412661176, w0=5.065737013260211, w1=-55.13110583276267\n",
      "Gradient Descent(3781/9999): loss=11907.686962862052, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3782/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3783/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3784/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3785/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3786/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3787/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3788/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3789/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3790/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3791/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3792/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3793/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3794/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3795/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3796/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3797/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3798/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3799/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3800/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3801/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3802/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3803/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3804/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3805/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3806/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3807/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3808/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3809/9999): loss=4697.8091925979425, w0=-8.77366298673979, w1=-56.34210583276267\n",
      "Gradient Descent(3810/9999): loss=4697.8091925979425, w0=-1.522662986739789, w1=-51.43950583276267\n",
      "Gradient Descent(3811/9999): loss=8323.506997617877, w0=-1.522662986739789, w1=-51.43950583276267\n",
      "Gradient Descent(3812/9999): loss=8323.506997617877, w0=-1.522662986739789, w1=-51.43950583276267\n",
      "Gradient Descent(3813/9999): loss=8323.506997617877, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3814/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3815/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3816/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3817/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3818/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3819/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3820/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3821/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3822/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3823/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3824/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3825/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3826/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3827/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3828/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3829/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3830/9999): loss=5595.248385133926, w0=-9.013662986739789, w1=-60.32180583276267\n",
      "Gradient Descent(3831/9999): loss=5595.248385133926, w0=-0.3569629867397879, w1=-57.98090583276267\n",
      "Gradient Descent(3832/9999): loss=4451.420939030552, w0=-0.3569629867397879, w1=-57.98090583276267\n",
      "Gradient Descent(3833/9999): loss=4451.420939030552, w0=11.709802398813746, w1=-46.943705832762674\n",
      "Gradient Descent(3834/9999): loss=16256.242414289936, w0=-0.3569629867397879, w1=-55.464905832762675\n",
      "Gradient Descent(3835/9999): loss=8532.920897895807, w0=-0.3569629867397879, w1=-55.464905832762675\n",
      "Gradient Descent(3836/9999): loss=8532.920897895807, w0=-0.3569629867397879, w1=-55.464905832762675\n",
      "Gradient Descent(3837/9999): loss=8532.920897895807, w0=-0.3569629867397879, w1=-55.464905832762675\n",
      "Gradient Descent(3838/9999): loss=8532.920897895807, w0=-12.423728372293322, w1=-62.10110583276268\n",
      "Gradient Descent(3839/9999): loss=4575.859405437816, w0=-12.423728372293322, w1=-62.10110583276268\n",
      "Gradient Descent(3840/9999): loss=4575.859405437816, w0=-12.423728372293322, w1=-62.10110583276268\n",
      "Gradient Descent(3841/9999): loss=4575.859405437816, w0=-12.423728372293322, w1=-62.10110583276268\n",
      "Gradient Descent(3842/9999): loss=4575.859405437816, w0=-12.423728372293322, w1=-62.10110583276268\n",
      "Gradient Descent(3843/9999): loss=4575.859405437816, w0=-12.423728372293322, w1=-62.10110583276268\n",
      "Gradient Descent(3844/9999): loss=4575.859405437816, w0=-12.423728372293322, w1=-62.10110583276268\n",
      "Gradient Descent(3845/9999): loss=4575.859405437816, w0=1.918071627706679, w1=-55.17800583276268\n",
      "Gradient Descent(3846/9999): loss=7103.5305805125245, w0=-6.027828372293322, w1=-59.31740583276268\n",
      "Gradient Descent(3847/9999): loss=4514.966512718119, w0=-6.027828372293322, w1=-59.31740583276268\n",
      "Gradient Descent(3848/9999): loss=4514.966512718119, w0=7.89967162770668, w1=-51.22420583276268\n",
      "Gradient Descent(3849/9999): loss=13081.460456002333, w0=0.17347162770667968, w1=-57.99240583276268\n",
      "Gradient Descent(3850/9999): loss=4640.69985610314, w0=0.17347162770667968, w1=-57.99240583276268\n",
      "Gradient Descent(3851/9999): loss=4640.69985610314, w0=0.17347162770667968, w1=-57.99240583276268\n",
      "Gradient Descent(3852/9999): loss=4640.69985610314, w0=0.17347162770667968, w1=-57.99240583276268\n",
      "Gradient Descent(3853/9999): loss=4640.69985610314, w0=0.17347162770667968, w1=-57.99240583276268\n",
      "Gradient Descent(3854/9999): loss=4640.69985610314, w0=10.408671627706681, w1=-52.36680583276268\n",
      "Gradient Descent(3855/9999): loss=14686.740289260793, w0=10.408671627706681, w1=-52.36680583276268\n",
      "Gradient Descent(3856/9999): loss=14686.740289260793, w0=3.405271627706682, w1=-59.54710583276268\n",
      "Gradient Descent(3857/9999): loss=5484.4311975301935, w0=3.405271627706682, w1=-59.54710583276268\n",
      "Gradient Descent(3858/9999): loss=5484.4311975301935, w0=3.405271627706682, w1=-59.54710583276268\n",
      "Gradient Descent(3859/9999): loss=5484.4311975301935, w0=3.405271627706682, w1=-59.54710583276268\n",
      "Gradient Descent(3860/9999): loss=5484.4311975301935, w0=-11.466528372293318, w1=-59.66780583276268\n",
      "Gradient Descent(3861/9999): loss=5802.4994844197445, w0=-11.466528372293318, w1=-59.66780583276268\n",
      "Gradient Descent(3862/9999): loss=5802.4994844197445, w0=-1.071028372293318, w1=-56.46160583276268\n",
      "Gradient Descent(3863/9999): loss=4583.1315357994445, w0=-1.071028372293318, w1=-56.46160583276268\n",
      "Gradient Descent(3864/9999): loss=4583.1315357994445, w0=-1.071028372293318, w1=-56.46160583276268\n",
      "Gradient Descent(3865/9999): loss=4583.1315357994445, w0=-1.071028372293318, w1=-56.46160583276268\n",
      "Gradient Descent(3866/9999): loss=4583.1315357994445, w0=-1.071028372293318, w1=-56.46160583276268\n",
      "Gradient Descent(3867/9999): loss=4583.1315357994445, w0=-1.071028372293318, w1=-56.46160583276268\n",
      "Gradient Descent(3868/9999): loss=4583.1315357994445, w0=-1.071028372293318, w1=-56.46160583276268\n",
      "Gradient Descent(3869/9999): loss=4583.1315357994445, w0=-1.071028372293318, w1=-56.46160583276268\n",
      "Gradient Descent(3870/9999): loss=4583.1315357994445, w0=-1.071028372293318, w1=-56.46160583276268\n",
      "Gradient Descent(3871/9999): loss=4583.1315357994445, w0=-1.071028372293318, w1=-56.46160583276268\n",
      "Gradient Descent(3872/9999): loss=4583.1315357994445, w0=11.698571627706682, w1=-50.76320583276268\n",
      "Gradient Descent(3873/9999): loss=14653.405784531522, w0=5.931171627706682, w1=-54.98290583276268\n",
      "Gradient Descent(3874/9999): loss=5571.024169872087, w0=-7.857928372293317, w1=-59.808305832762684\n",
      "Gradient Descent(3875/9999): loss=5307.443261846674, w0=-0.2807283722933178, w1=-56.59850583276268\n",
      "Gradient Descent(3876/9999): loss=4708.8042129953965, w0=-0.2807283722933178, w1=-56.59850583276268\n",
      "Gradient Descent(3877/9999): loss=4708.8042129953965, w0=-0.2807283722933178, w1=-56.59850583276268\n",
      "Gradient Descent(3878/9999): loss=4708.8042129953965, w0=-0.2807283722933178, w1=-56.59850583276268\n",
      "Gradient Descent(3879/9999): loss=4708.8042129953965, w0=-0.2807283722933178, w1=-56.59850583276268\n",
      "Gradient Descent(3880/9999): loss=4708.8042129953965, w0=-0.2807283722933178, w1=-56.59850583276268\n",
      "Gradient Descent(3881/9999): loss=4708.8042129953965, w0=-0.2807283722933178, w1=-56.59850583276268\n",
      "Gradient Descent(3882/9999): loss=4708.8042129953965, w0=-0.2807283722933178, w1=-56.59850583276268\n",
      "Gradient Descent(3883/9999): loss=4708.8042129953965, w0=-0.2807283722933178, w1=-56.59850583276268\n",
      "Gradient Descent(3884/9999): loss=4708.8042129953965, w0=-0.2807283722933178, w1=-56.59850583276268\n",
      "Gradient Descent(3885/9999): loss=4708.8042129953965, w0=10.551171627706683, w1=-49.64130583276268\n",
      "Gradient Descent(3886/9999): loss=15196.161757989159, w0=5.7065716277066825, w1=-54.373005832762686\n",
      "Gradient Descent(3887/9999): loss=4521.24323070199, w0=5.7065716277066825, w1=-54.373005832762686\n",
      "Gradient Descent(3888/9999): loss=4521.24323070199, w0=-6.748428372293318, w1=-57.17590583276269\n",
      "Gradient Descent(3889/9999): loss=5802.4994844197445, w0=-6.748428372293318, w1=-57.17590583276269\n",
      "Gradient Descent(3890/9999): loss=5802.4994844197445, w0=5.073071627706683, w1=-55.054005832762684\n",
      "Gradient Descent(3891/9999): loss=4354.694590931229, w0=5.073071627706683, w1=-55.054005832762684\n",
      "Gradient Descent(3892/9999): loss=4354.694590931229, w0=14.337171627706685, w1=-48.600505832762686\n",
      "Gradient Descent(3893/9999): loss=13557.911236637112, w0=14.337171627706685, w1=-48.600505832762686\n",
      "Gradient Descent(3894/9999): loss=13557.911236637112, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3895/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3896/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3897/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3898/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3899/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3900/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3901/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3902/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3903/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3904/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3905/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3906/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3907/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3908/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3909/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3910/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3911/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3912/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3913/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3914/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3915/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3916/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3917/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3918/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3919/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3920/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3921/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3922/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3923/9999): loss=4454.519554845282, w0=2.2704062421531503, w1=-57.384505832762684\n",
      "Gradient Descent(3924/9999): loss=4454.519554845282, w0=10.45430624215315, w1=-55.832105832762686\n",
      "Gradient Descent(3925/9999): loss=12088.20831768351, w0=10.45430624215315, w1=-55.832105832762686\n",
      "Gradient Descent(3926/9999): loss=12088.20831768351, w0=10.45430624215315, w1=-55.832105832762686\n",
      "Gradient Descent(3927/9999): loss=12088.20831768351, w0=10.45430624215315, w1=-55.832105832762686\n",
      "Gradient Descent(3928/9999): loss=12088.20831768351, w0=10.45430624215315, w1=-55.832105832762686\n",
      "Gradient Descent(3929/9999): loss=12088.20831768351, w0=-5.617693757846849, w1=-62.133905832762686\n",
      "Gradient Descent(3930/9999): loss=4463.875757179509, w0=-5.617693757846849, w1=-62.133905832762686\n",
      "Gradient Descent(3931/9999): loss=4463.875757179509, w0=-5.617693757846849, w1=-62.133905832762686\n",
      "Gradient Descent(3932/9999): loss=4463.875757179509, w0=-5.617693757846849, w1=-62.133905832762686\n",
      "Gradient Descent(3933/9999): loss=4463.875757179509, w0=-19.06669375784685, w1=-62.80270583276268\n",
      "Gradient Descent(3934/9999): loss=5802.4994844197445, w0=-19.06669375784685, w1=-62.80270583276268\n",
      "Gradient Descent(3935/9999): loss=5802.4994844197445, w0=-19.06669375784685, w1=-62.80270583276268\n",
      "Gradient Descent(3936/9999): loss=5802.4994844197445, w0=-19.06669375784685, w1=-62.80270583276268\n",
      "Gradient Descent(3937/9999): loss=5802.4994844197445, w0=-19.06669375784685, w1=-62.80270583276268\n",
      "Gradient Descent(3938/9999): loss=5802.4994844197445, w0=-19.06669375784685, w1=-62.80270583276268\n",
      "Gradient Descent(3939/9999): loss=5802.4994844197445, w0=-19.06669375784685, w1=-62.80270583276268\n",
      "Gradient Descent(3940/9999): loss=5802.4994844197445, w0=-19.06669375784685, w1=-62.80270583276268\n",
      "Gradient Descent(3941/9999): loss=5802.4994844197445, w0=-19.06669375784685, w1=-62.80270583276268\n",
      "Gradient Descent(3942/9999): loss=5802.4994844197445, w0=-19.06669375784685, w1=-62.80270583276268\n",
      "Gradient Descent(3943/9999): loss=5802.4994844197445, w0=-8.820693757846849, w1=-58.62460583276268\n",
      "Gradient Descent(3944/9999): loss=4623.7970705879625, w0=5.438027298030963, w1=-55.953050681084214\n",
      "Gradient Descent(3945/9999): loss=12200.86033538814, w0=5.438027298030963, w1=-55.953050681084214\n",
      "Gradient Descent(3946/9999): loss=12200.86033538814, w0=5.438027298030963, w1=-55.953050681084214\n",
      "Gradient Descent(3947/9999): loss=12200.86033538814, w0=-8.765672701969038, w1=-67.25955068108422\n",
      "Gradient Descent(3948/9999): loss=4543.5887200218385, w0=-8.765672701969038, w1=-67.25955068108422\n",
      "Gradient Descent(3949/9999): loss=4543.5887200218385, w0=-8.765672701969038, w1=-67.25955068108422\n",
      "Gradient Descent(3950/9999): loss=4543.5887200218385, w0=-8.765672701969038, w1=-67.25955068108422\n",
      "Gradient Descent(3951/9999): loss=4543.5887200218385, w0=-8.765672701969038, w1=-67.25955068108422\n",
      "Gradient Descent(3952/9999): loss=4543.5887200218385, w0=-8.765672701969038, w1=-67.25955068108422\n",
      "Gradient Descent(3953/9999): loss=4543.5887200218385, w0=-8.765672701969038, w1=-67.25955068108422\n",
      "Gradient Descent(3954/9999): loss=4543.5887200218385, w0=-8.765672701969038, w1=-67.25955068108422\n",
      "Gradient Descent(3955/9999): loss=4543.5887200218385, w0=-8.765672701969038, w1=-67.25955068108422\n",
      "Gradient Descent(3956/9999): loss=4543.5887200218385, w0=-8.765672701969038, w1=-67.25955068108422\n",
      "Gradient Descent(3957/9999): loss=4543.5887200218385, w0=-8.765672701969038, w1=-67.25955068108422\n",
      "Gradient Descent(3958/9999): loss=4543.5887200218385, w0=-8.765672701969038, w1=-67.25955068108422\n",
      "Gradient Descent(3959/9999): loss=4543.5887200218385, w0=-8.765672701969038, w1=-67.25955068108422\n",
      "Gradient Descent(3960/9999): loss=4543.5887200218385, w0=-8.765672701969038, w1=-67.25955068108422\n",
      "Gradient Descent(3961/9999): loss=4543.5887200218385, w0=-8.765672701969038, w1=-67.25955068108422\n",
      "Gradient Descent(3962/9999): loss=4543.5887200218385, w0=3.3010926835844963, w1=-48.432150681084224\n",
      "Gradient Descent(3963/9999): loss=12926.042053845427, w0=-4.629307316415504, w1=-55.742950681084224\n",
      "Gradient Descent(3964/9999): loss=4511.514443423552, w0=-4.629307316415504, w1=-55.742950681084224\n",
      "Gradient Descent(3965/9999): loss=4511.514443423552, w0=-4.629307316415504, w1=-55.742950681084224\n",
      "Gradient Descent(3966/9999): loss=4511.514443423552, w0=-4.629307316415504, w1=-55.742950681084224\n",
      "Gradient Descent(3967/9999): loss=4511.514443423552, w0=-4.629307316415504, w1=-55.742950681084224\n",
      "Gradient Descent(3968/9999): loss=4511.514443423552, w0=-4.629307316415504, w1=-55.742950681084224\n",
      "Gradient Descent(3969/9999): loss=4511.514443423552, w0=-4.629307316415504, w1=-55.742950681084224\n",
      "Gradient Descent(3970/9999): loss=4511.514443423552, w0=-4.629307316415504, w1=-55.742950681084224\n",
      "Gradient Descent(3971/9999): loss=4511.514443423552, w0=-4.629307316415504, w1=-55.742950681084224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(3972/9999): loss=4511.514443423552, w0=-4.629307316415504, w1=-55.742950681084224\n",
      "Gradient Descent(3973/9999): loss=4511.514443423552, w0=4.672292683584496, w1=-47.74785068108422\n",
      "Gradient Descent(3974/9999): loss=16164.503904351957, w0=-9.966207316415504, w1=-53.60305068108423\n",
      "Gradient Descent(3975/9999): loss=6556.517245949859, w0=-21.127507316415503, w1=-58.14765068108423\n",
      "Gradient Descent(3976/9999): loss=5790.9865486290855, w0=-9.3618073164155, w1=-54.94825068108423\n",
      "Gradient Descent(3977/9999): loss=5310.879842211249, w0=-16.9077073164155, w1=-57.01525068108423\n",
      "Gradient Descent(3978/9999): loss=5596.687299179946, w0=-24.9855073164155, w1=-57.47415068108423\n",
      "Gradient Descent(3979/9999): loss=5802.4994844197445, w0=-9.6487073164155, w1=-55.29385068108423\n",
      "Gradient Descent(3980/9999): loss=4721.795401377973, w0=3.4996926835845024, w1=-49.69405068108423\n",
      "Gradient Descent(3981/9999): loss=10344.937759735214, w0=3.4996926835845024, w1=-49.69405068108423\n",
      "Gradient Descent(3982/9999): loss=10344.937759735214, w0=-8.567072701969032, w1=-57.20675068108423\n",
      "Gradient Descent(3983/9999): loss=4505.028597477272, w0=-8.567072701969032, w1=-57.20675068108423\n",
      "Gradient Descent(3984/9999): loss=4505.028597477272, w0=-8.567072701969032, w1=-57.20675068108423\n",
      "Gradient Descent(3985/9999): loss=4505.028597477272, w0=1.590027298030968, w1=-54.48295068108423\n",
      "Gradient Descent(3986/9999): loss=10796.926731229232, w0=1.590027298030968, w1=-54.48295068108423\n",
      "Gradient Descent(3987/9999): loss=10796.926731229232, w0=1.590027298030968, w1=-54.48295068108423\n",
      "Gradient Descent(3988/9999): loss=10796.926731229232, w0=-8.382772701969031, w1=-57.76435068108423\n",
      "Gradient Descent(3989/9999): loss=4404.173913610831, w0=-8.382772701969031, w1=-57.76435068108423\n",
      "Gradient Descent(3990/9999): loss=4404.173913610831, w0=-8.382772701969031, w1=-57.76435068108423\n",
      "Gradient Descent(3991/9999): loss=4404.173913610831, w0=-8.382772701969031, w1=-57.76435068108423\n",
      "Gradient Descent(3992/9999): loss=4404.173913610831, w0=-8.382772701969031, w1=-57.76435068108423\n",
      "Gradient Descent(3993/9999): loss=4404.173913610831, w0=-8.382772701969031, w1=-57.76435068108423\n",
      "Gradient Descent(3994/9999): loss=4404.173913610831, w0=-8.382772701969031, w1=-57.76435068108423\n",
      "Gradient Descent(3995/9999): loss=4404.173913610831, w0=-8.382772701969031, w1=-57.76435068108423\n",
      "Gradient Descent(3996/9999): loss=4404.173913610831, w0=-8.382772701969031, w1=-57.76435068108423\n",
      "Gradient Descent(3997/9999): loss=4404.173913610831, w0=-8.382772701969031, w1=-57.76435068108423\n",
      "Gradient Descent(3998/9999): loss=4404.173913610831, w0=-8.382772701969031, w1=-57.76435068108423\n",
      "Gradient Descent(3999/9999): loss=4404.173913610831, w0=-8.382772701969031, w1=-57.76435068108423\n",
      "Gradient Descent(4000/9999): loss=4404.173913610831, w0=-8.382772701969031, w1=-57.76435068108423\n",
      "Gradient Descent(4001/9999): loss=4404.173913610831, w0=-8.382772701969031, w1=-57.76435068108423\n",
      "Gradient Descent(4002/9999): loss=4404.173913610831, w0=-8.382772719610859, w1=-57.764350686038696\n",
      "Gradient Descent(4003/9999): loss=4404.173895816587, w0=-8.382772719610859, w1=-57.764350686038696\n",
      "Gradient Descent(4004/9999): loss=4404.173895816587, w0=-8.38277229946848, w1=-57.764350656809874\n",
      "Gradient Descent(4005/9999): loss=4404.174206960852, w0=-8.38277229946848, w1=-57.764350656809874\n",
      "Gradient Descent(4006/9999): loss=4404.174206960852, w0=-8.38277229946848, w1=-57.764350656809874\n",
      "Gradient Descent(4007/9999): loss=4404.174206960852, w0=-8.38277229946848, w1=-57.764350656809874\n",
      "Gradient Descent(4008/9999): loss=4404.174206960852, w0=-8.38277229946848, w1=-57.764350656809874\n",
      "Gradient Descent(4009/9999): loss=4404.174206960852, w0=2.51462770053152, w1=-52.77095065680987\n",
      "Gradient Descent(4010/9999): loss=13376.07725984274, w0=-5.47037229946848, w1=-54.605550656809875\n",
      "Gradient Descent(4011/9999): loss=6684.199298191679, w0=-5.47037229946848, w1=-54.605550656809875\n",
      "Gradient Descent(4012/9999): loss=6684.199298191679, w0=-5.47037229946848, w1=-54.605550656809875\n",
      "Gradient Descent(4013/9999): loss=6684.199298191679, w0=-5.47037229946848, w1=-54.605550656809875\n",
      "Gradient Descent(4014/9999): loss=6684.199298191679, w0=-5.47037229946848, w1=-54.605550656809875\n",
      "Gradient Descent(4015/9999): loss=6684.199298191679, w0=-12.82477229946848, w1=-58.79855065680987\n",
      "Gradient Descent(4016/9999): loss=4600.33445039114, w0=-12.82477229946848, w1=-58.79855065680987\n",
      "Gradient Descent(4017/9999): loss=4600.33445039114, w0=-12.82477229946848, w1=-58.79855065680987\n",
      "Gradient Descent(4018/9999): loss=4600.33445039114, w0=-5.546772299468479, w1=-55.533450656809876\n",
      "Gradient Descent(4019/9999): loss=9542.200723560174, w0=-20.17287229946848, w1=-58.11125065680988\n",
      "Gradient Descent(4020/9999): loss=4850.229969304017, w0=-20.17287229946848, w1=-58.11125065680988\n",
      "Gradient Descent(4021/9999): loss=4850.229969304017, w0=-20.17287229946848, w1=-58.11125065680988\n",
      "Gradient Descent(4022/9999): loss=4850.229969304017, w0=-27.43917229946848, w1=-59.87605065680988\n",
      "Gradient Descent(4023/9999): loss=5802.4994844197445, w0=-27.43917229946848, w1=-59.87605065680988\n",
      "Gradient Descent(4024/9999): loss=5802.4994844197445, w0=-27.43917229946848, w1=-59.87605065680988\n",
      "Gradient Descent(4025/9999): loss=5802.4994844197445, w0=-27.43917229946848, w1=-59.87605065680988\n",
      "Gradient Descent(4026/9999): loss=5802.4994844197445, w0=-17.65057229946848, w1=-58.10925065680988\n",
      "Gradient Descent(4027/9999): loss=4732.28444347754, w0=-17.65057229946848, w1=-58.10925065680988\n",
      "Gradient Descent(4028/9999): loss=4732.28444347754, w0=-17.65057229946848, w1=-58.10925065680988\n",
      "Gradient Descent(4029/9999): loss=4732.28444347754, w0=-5.583806913914945, w1=-46.681550656809875\n",
      "Gradient Descent(4030/9999): loss=10213.192995893169, w0=-16.233406913914948, w1=-48.73325065680987\n",
      "Gradient Descent(4031/9999): loss=4849.632649054669, w0=-16.233406913914948, w1=-48.73325065680987\n",
      "Gradient Descent(4032/9999): loss=4849.632649054669, w0=-16.233406913914948, w1=-48.73325065680987\n",
      "Gradient Descent(4033/9999): loss=4849.632649054669, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4034/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4035/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4036/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4037/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4038/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4039/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4040/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4041/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4042/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4043/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4044/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4045/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4046/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4047/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4048/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4049/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4050/9999): loss=5802.4994844197445, w0=-23.713806913914947, w1=-50.82865065680987\n",
      "Gradient Descent(4051/9999): loss=5802.4994844197445, w0=-9.726906913914947, w1=-42.35555065680987\n",
      "Gradient Descent(4052/9999): loss=9613.235192874121, w0=-21.793672299468483, w1=-48.01675065680987\n",
      "Gradient Descent(4053/9999): loss=5513.132213853077, w0=-21.793672299468483, w1=-48.01675065680987\n",
      "Gradient Descent(4054/9999): loss=5513.132213853077, w0=-21.793672299468483, w1=-48.01675065680987\n",
      "Gradient Descent(4055/9999): loss=5513.132213853077, w0=-21.793672299468483, w1=-48.01675065680987\n",
      "Gradient Descent(4056/9999): loss=5513.132213853077, w0=-21.793672299468483, w1=-48.01675065680987\n",
      "Gradient Descent(4057/9999): loss=5513.132213853077, w0=-21.793672299468483, w1=-48.01675065680987\n",
      "Gradient Descent(4058/9999): loss=5513.132213853077, w0=-21.793672299468483, w1=-48.01675065680987\n",
      "Gradient Descent(4059/9999): loss=5513.132213853077, w0=-21.793672299468483, w1=-48.01675065680987\n",
      "Gradient Descent(4060/9999): loss=5513.132213853077, w0=-21.793672299468483, w1=-48.01675065680987\n",
      "Gradient Descent(4061/9999): loss=5513.132213853077, w0=-21.793672299468483, w1=-48.01675065680987\n",
      "Gradient Descent(4062/9999): loss=5513.132213853077, w0=-21.793672299468483, w1=-48.01675065680987\n",
      "Gradient Descent(4063/9999): loss=5513.132213853077, w0=-21.793672299468483, w1=-48.01675065680987\n",
      "Gradient Descent(4064/9999): loss=5513.132213853077, w0=-21.793672299468483, w1=-48.01675065680987\n",
      "Gradient Descent(4065/9999): loss=5513.132213853077, w0=-21.793672299468483, w1=-48.01675065680987\n",
      "Gradient Descent(4066/9999): loss=5513.132213853077, w0=-21.793672299468483, w1=-48.01675065680987\n",
      "Gradient Descent(4067/9999): loss=5513.132213853077, w0=-21.793672299468483, w1=-48.01675065680987\n",
      "Gradient Descent(4068/9999): loss=5513.132213853077, w0=-10.045172299468483, w1=-46.58225065680987\n",
      "Gradient Descent(4069/9999): loss=9070.24705285308, w0=-13.736972299468484, w1=-53.32305065680987\n",
      "Gradient Descent(4070/9999): loss=4763.12453779901, w0=-13.736972299468484, w1=-53.32305065680987\n",
      "Gradient Descent(4071/9999): loss=4763.12453779901, w0=-21.705472299468482, w1=-54.07365065680987\n",
      "Gradient Descent(4072/9999): loss=5802.4994844197445, w0=-21.705472299468482, w1=-54.07365065680987\n",
      "Gradient Descent(4073/9999): loss=5802.4994844197445, w0=-21.705472299468482, w1=-54.07365065680987\n",
      "Gradient Descent(4074/9999): loss=5802.4994844197445, w0=-21.705472299468482, w1=-54.07365065680987\n",
      "Gradient Descent(4075/9999): loss=5802.4994844197445, w0=-8.853672299468482, w1=-52.594550656809865\n",
      "Gradient Descent(4076/9999): loss=4545.984393955779, w0=-8.853672299468482, w1=-52.594550656809865\n",
      "Gradient Descent(4077/9999): loss=4545.984393955779, w0=-8.853672299468482, w1=-52.594550656809865\n",
      "Gradient Descent(4078/9999): loss=4545.984393955779, w0=-8.853672299468482, w1=-52.594550656809865\n",
      "Gradient Descent(4079/9999): loss=4545.984393955779, w0=-8.853672299468482, w1=-52.594550656809865\n",
      "Gradient Descent(4080/9999): loss=4545.984393955779, w0=-8.853672299468482, w1=-52.594550656809865\n",
      "Gradient Descent(4081/9999): loss=4545.984393955779, w0=-8.853672299468482, w1=-52.594550656809865\n",
      "Gradient Descent(4082/9999): loss=4545.984393955779, w0=-8.853672299468482, w1=-52.594550656809865\n",
      "Gradient Descent(4083/9999): loss=4545.984393955779, w0=4.753627700531517, w1=-47.417750656809865\n",
      "Gradient Descent(4084/9999): loss=12718.798813672132, w0=4.753627700531517, w1=-47.417750656809865\n",
      "Gradient Descent(4085/9999): loss=12718.798813672132, w0=-4.5921722994684835, w1=-48.77535065680986\n",
      "Gradient Descent(4086/9999): loss=4724.733309706673, w0=-4.5921722994684835, w1=-48.77535065680986\n",
      "Gradient Descent(4087/9999): loss=4724.733309706673, w0=-4.5921722994684835, w1=-48.77535065680986\n",
      "Gradient Descent(4088/9999): loss=4724.733309706673, w0=-4.5921722994684835, w1=-48.77535065680986\n",
      "Gradient Descent(4089/9999): loss=4724.733309706673, w0=-4.5921722994684835, w1=-48.77535065680986\n",
      "Gradient Descent(4090/9999): loss=4724.733309706673, w0=-4.5921722994684835, w1=-48.77535065680986\n",
      "Gradient Descent(4091/9999): loss=4724.733309706673, w0=-13.472772299468483, w1=-52.419450656809865\n",
      "Gradient Descent(4092/9999): loss=5802.4994844197445, w0=-13.472772299468483, w1=-52.419450656809865\n",
      "Gradient Descent(4093/9999): loss=5802.4994844197445, w0=-13.472772299468483, w1=-52.419450656809865\n",
      "Gradient Descent(4094/9999): loss=5802.4994844197445, w0=-13.472772299468483, w1=-52.419450656809865\n",
      "Gradient Descent(4095/9999): loss=5802.4994844197445, w0=-13.472772299468483, w1=-52.419450656809865\n",
      "Gradient Descent(4096/9999): loss=5802.4994844197445, w0=-13.472772299468483, w1=-52.419450656809865\n",
      "Gradient Descent(4097/9999): loss=5802.4994844197445, w0=-3.524572299468481, w1=-47.601150656809864\n",
      "Gradient Descent(4098/9999): loss=4433.7889540949145, w0=-3.524572299468481, w1=-47.601150656809864\n",
      "Gradient Descent(4099/9999): loss=4433.7889540949145, w0=-3.524572299468481, w1=-47.601150656809864\n",
      "Gradient Descent(4100/9999): loss=4433.7889540949145, w0=-3.524572299468481, w1=-47.601150656809864\n",
      "Gradient Descent(4101/9999): loss=4433.7889540949145, w0=-3.524572299468481, w1=-47.601150656809864\n",
      "Gradient Descent(4102/9999): loss=4433.7889540949145, w0=-3.524572299468481, w1=-47.601150656809864\n",
      "Gradient Descent(4103/9999): loss=4433.7889540949145, w0=-3.524572299468481, w1=-47.601150656809864\n",
      "Gradient Descent(4104/9999): loss=4433.7889540949145, w0=7.120227700531519, w1=-43.493050656809864\n",
      "Gradient Descent(4105/9999): loss=11847.154103751745, w0=7.120227700531519, w1=-43.493050656809864\n",
      "Gradient Descent(4106/9999): loss=11847.154103751745, w0=-1.9067722994684804, w1=-50.389950656809866\n",
      "Gradient Descent(4107/9999): loss=4462.226985628781, w0=-1.9067722994684804, w1=-50.389950656809866\n",
      "Gradient Descent(4108/9999): loss=4462.226985628781, w0=-1.9067722994684804, w1=-50.389950656809866\n",
      "Gradient Descent(4109/9999): loss=4462.226985628781, w0=5.16622770053152, w1=-47.817750656809864\n",
      "Gradient Descent(4110/9999): loss=9066.799674107046, w0=-5.12557229946848, w1=-48.30635065680986\n",
      "Gradient Descent(4111/9999): loss=4805.312453269895, w0=-5.12557229946848, w1=-48.30635065680986\n",
      "Gradient Descent(4112/9999): loss=4805.312453269895, w0=-5.12557229946848, w1=-48.30635065680986\n",
      "Gradient Descent(4113/9999): loss=4805.312453269895, w0=-5.12557229946848, w1=-48.30635065680986\n",
      "Gradient Descent(4114/9999): loss=4805.312453269895, w0=-5.12557229946848, w1=-48.30635065680986\n",
      "Gradient Descent(4115/9999): loss=4805.312453269895, w0=-5.12557229946848, w1=-48.30635065680986\n",
      "Gradient Descent(4116/9999): loss=4805.312453269895, w0=-5.12557229946848, w1=-48.30635065680986\n",
      "Gradient Descent(4117/9999): loss=4805.312453269895, w0=-5.12557229946848, w1=-48.30635065680986\n",
      "Gradient Descent(4118/9999): loss=4805.312453269895, w0=-5.12557229946848, w1=-48.30635065680986\n",
      "Gradient Descent(4119/9999): loss=4805.312453269895, w0=-5.12557229946848, w1=-48.30635065680986\n",
      "Gradient Descent(4120/9999): loss=4805.312453269895, w0=-5.12557229946848, w1=-48.30635065680986\n",
      "Gradient Descent(4121/9999): loss=4805.312453269895, w0=-5.12557229946848, w1=-48.30635065680986\n",
      "Gradient Descent(4122/9999): loss=4805.312453269895, w0=8.68522770053152, w1=-42.84885065680986\n",
      "Gradient Descent(4123/9999): loss=15329.840582827728, w0=1.8639277005315193, w1=-48.93005065680986\n",
      "Gradient Descent(4124/9999): loss=5159.781986904432, w0=1.8639277005315193, w1=-48.93005065680986\n",
      "Gradient Descent(4125/9999): loss=5159.781986904432, w0=-8.73367229946848, w1=-53.51355065680986\n",
      "Gradient Descent(4126/9999): loss=5729.461574814537, w0=-8.73367229946848, w1=-53.51355065680986\n",
      "Gradient Descent(4127/9999): loss=5729.461574814537, w0=-8.73367229946848, w1=-53.51355065680986\n",
      "Gradient Descent(4128/9999): loss=5729.461574814537, w0=-8.73367229946848, w1=-53.51355065680986\n",
      "Gradient Descent(4129/9999): loss=5729.461574814537, w0=-8.73367229946848, w1=-53.51355065680986\n",
      "Gradient Descent(4130/9999): loss=5729.461574814537, w0=3.345721418605754, w1=-53.15362664351449\n",
      "Gradient Descent(4131/9999): loss=4564.412157969714, w0=3.345721418605754, w1=-53.15362664351449\n",
      "Gradient Descent(4132/9999): loss=4564.412157969714, w0=3.345721418605754, w1=-53.15362664351449\n",
      "Gradient Descent(4133/9999): loss=4564.412157969714, w0=3.345721418605754, w1=-53.15362664351449\n",
      "Gradient Descent(4134/9999): loss=4564.412157969714, w0=3.345721418605754, w1=-53.15362664351449\n",
      "Gradient Descent(4135/9999): loss=4564.412157969714, w0=3.345721418605754, w1=-53.15362664351449\n",
      "Gradient Descent(4136/9999): loss=4564.412157969714, w0=3.345721418605754, w1=-53.15362664351449\n",
      "Gradient Descent(4137/9999): loss=4564.412157969714, w0=-2.7375785813942466, w1=-54.445226643514495\n",
      "Gradient Descent(4138/9999): loss=4962.167998919547, w0=-2.7375785813942466, w1=-54.445226643514495\n",
      "Gradient Descent(4139/9999): loss=4962.167998919547, w0=-2.7375785813942466, w1=-54.445226643514495\n",
      "Gradient Descent(4140/9999): loss=4962.167998919547, w0=-2.7375785813942466, w1=-54.445226643514495\n",
      "Gradient Descent(4141/9999): loss=4962.167998919547, w0=-2.7375785813942466, w1=-54.445226643514495\n",
      "Gradient Descent(4142/9999): loss=4962.167998919547, w0=-2.7375785813942466, w1=-54.445226643514495\n",
      "Gradient Descent(4143/9999): loss=4962.167998919547, w0=-2.7375785813942466, w1=-54.445226643514495\n",
      "Gradient Descent(4144/9999): loss=4962.167998919547, w0=8.461221418605753, w1=-48.241226643514494\n",
      "Gradient Descent(4145/9999): loss=9203.899887546915, w0=-3.6055439669477813, w1=-55.7340266435145\n",
      "Gradient Descent(4146/9999): loss=4895.500076000035, w0=-3.6055439669477813, w1=-55.7340266435145\n",
      "Gradient Descent(4147/9999): loss=4895.500076000035, w0=-3.6055439669477813, w1=-55.7340266435145\n",
      "Gradient Descent(4148/9999): loss=4895.500076000035, w0=-3.6055439669477813, w1=-55.7340266435145\n",
      "Gradient Descent(4149/9999): loss=4895.500076000035, w0=-3.6055439669477813, w1=-55.7340266435145\n",
      "Gradient Descent(4150/9999): loss=4895.500076000035, w0=-3.6055439669477813, w1=-55.7340266435145\n",
      "Gradient Descent(4151/9999): loss=4895.500076000035, w0=-3.6055439669477813, w1=-55.7340266435145\n",
      "Gradient Descent(4152/9999): loss=4895.500076000035, w0=-3.6055439669477813, w1=-55.7340266435145\n",
      "Gradient Descent(4153/9999): loss=4895.500076000035, w0=-3.6055439669477813, w1=-55.7340266435145\n",
      "Gradient Descent(4154/9999): loss=4895.500076000035, w0=-3.6055439669477813, w1=-55.7340266435145\n",
      "Gradient Descent(4155/9999): loss=4895.500076000035, w0=-3.6055439669477813, w1=-55.7340266435145\n",
      "Gradient Descent(4156/9999): loss=4895.500076000035, w0=4.06925603305222, w1=-52.9305266435145\n",
      "Gradient Descent(4157/9999): loss=5136.046186225531, w0=4.06925603305222, w1=-52.9305266435145\n",
      "Gradient Descent(4158/9999): loss=5136.046186225531, w0=4.06925603305222, w1=-52.9305266435145\n",
      "Gradient Descent(4159/9999): loss=5136.046186225531, w0=14.90115603305222, w1=-45.9733266435145\n",
      "Gradient Descent(4160/9999): loss=16118.435071528678, w0=6.75735603305222, w1=-53.1369266435145\n",
      "Gradient Descent(4161/9999): loss=8110.881089820683, w0=-5.309409352501314, w1=-59.9468266435145\n",
      "Gradient Descent(4162/9999): loss=5721.908936165302, w0=7.347690647498686, w1=-56.418026643514494\n",
      "Gradient Descent(4163/9999): loss=5525.42560840569, w0=7.347690647498686, w1=-56.418026643514494\n",
      "Gradient Descent(4164/9999): loss=5525.42560840569, w0=7.347690647498686, w1=-56.418026643514494\n",
      "Gradient Descent(4165/9999): loss=5525.42560840569, w0=7.347690647498686, w1=-56.418026643514494\n",
      "Gradient Descent(4166/9999): loss=5525.42560840569, w0=7.347690647498686, w1=-56.418026643514494\n",
      "Gradient Descent(4167/9999): loss=5525.42560840569, w0=7.347690647498686, w1=-56.418026643514494\n",
      "Gradient Descent(4168/9999): loss=5525.42560840569, w0=7.347690647498686, w1=-56.418026643514494\n",
      "Gradient Descent(4169/9999): loss=5525.42560840569, w0=7.347690647498686, w1=-56.418026643514494\n",
      "Gradient Descent(4170/9999): loss=5525.42560840569, w0=7.347690647498686, w1=-56.418026643514494\n",
      "Gradient Descent(4171/9999): loss=5525.42560840569, w0=-0.7259093525013149, w1=-58.42542664351449\n",
      "Gradient Descent(4172/9999): loss=4432.487022354699, w0=-0.7259093525013149, w1=-58.42542664351449\n",
      "Gradient Descent(4173/9999): loss=4432.487022354699, w0=-0.7259093525013149, w1=-58.42542664351449\n",
      "Gradient Descent(4174/9999): loss=4432.487022354699, w0=-14.179409352501315, w1=-59.92092664351449\n",
      "Gradient Descent(4175/9999): loss=5802.4994844197445, w0=-6.287109352501314, w1=-56.69752664351449\n",
      "Gradient Descent(4176/9999): loss=5802.499076134078, w0=-6.287109352501314, w1=-56.69752664351449\n",
      "Gradient Descent(4177/9999): loss=5802.499076134078, w0=2.7765906474986863, w1=-55.697126643514494\n",
      "Gradient Descent(4178/9999): loss=4340.2573056555175, w0=2.7765906474986863, w1=-55.697126643514494\n",
      "Gradient Descent(4179/9999): loss=4340.2573056555175, w0=13.673990647498686, w1=-50.70372664351449\n",
      "Gradient Descent(4180/9999): loss=14820.831431836628, w0=-0.2393093525013139, w1=-56.640026643514496\n",
      "Gradient Descent(4181/9999): loss=4674.787942961099, w0=-0.2393093525013139, w1=-56.640026643514496\n",
      "Gradient Descent(4182/9999): loss=4674.787942961099, w0=-0.2393093525013139, w1=-56.640026643514496\n",
      "Gradient Descent(4183/9999): loss=4674.787942961099, w0=13.453290647498688, w1=-46.6882266435145\n",
      "Gradient Descent(4184/9999): loss=16405.896410676083, w0=13.453290647498688, w1=-46.6882266435145\n",
      "Gradient Descent(4185/9999): loss=16405.896410676083, w0=13.453290647498688, w1=-46.6882266435145\n",
      "Gradient Descent(4186/9999): loss=16405.896410676083, w0=1.3865252619451542, w1=-55.193526643514495\n",
      "Gradient Descent(4187/9999): loss=7208.087664066793, w0=1.3865252619451542, w1=-55.193526643514495\n",
      "Gradient Descent(4188/9999): loss=7208.087664066793, w0=1.3865252619451542, w1=-55.193526643514495\n",
      "Gradient Descent(4189/9999): loss=7208.087664066793, w0=1.3865252619451542, w1=-55.193526643514495\n",
      "Gradient Descent(4190/9999): loss=7208.087664066793, w0=1.3865252619451542, w1=-55.193526643514495\n",
      "Gradient Descent(4191/9999): loss=7208.087664066793, w0=1.3865252619451542, w1=-55.193526643514495\n",
      "Gradient Descent(4192/9999): loss=7208.087664066793, w0=1.3865252619451542, w1=-55.193526643514495\n",
      "Gradient Descent(4193/9999): loss=7208.087664066793, w0=-20.091374738054853, w1=-63.6450266435145\n",
      "Gradient Descent(4194/9999): loss=5802.4994844197445, w0=-20.091374738054853, w1=-63.6450266435145\n",
      "Gradient Descent(4195/9999): loss=5802.4994844197445, w0=-20.091374738054853, w1=-63.6450266435145\n",
      "Gradient Descent(4196/9999): loss=5802.4994844197445, w0=-20.091374738054853, w1=-63.6450266435145\n",
      "Gradient Descent(4197/9999): loss=5802.4994844197445, w0=-20.091374738054853, w1=-63.6450266435145\n",
      "Gradient Descent(4198/9999): loss=5802.4994844197445, w0=-11.708974738054852, w1=-61.0367266435145\n",
      "Gradient Descent(4199/9999): loss=4844.744903609476, w0=-0.24427473805485178, w1=-57.4762266435145\n",
      "Gradient Descent(4200/9999): loss=7857.521948553169, w0=-0.24427473805485178, w1=-57.4762266435145\n",
      "Gradient Descent(4201/9999): loss=7857.521948553169, w0=-0.24427473805485178, w1=-57.4762266435145\n",
      "Gradient Descent(4202/9999): loss=7857.521948553169, w0=-0.24427473805485178, w1=-57.4762266435145\n",
      "Gradient Descent(4203/9999): loss=7857.521948553169, w0=-0.24427473805485178, w1=-57.4762266435145\n",
      "Gradient Descent(4204/9999): loss=7857.521948553169, w0=-6.352574738054852, w1=-61.9700266435145\n",
      "Gradient Descent(4205/9999): loss=4723.726874456723, w0=-6.352574738054852, w1=-61.9700266435145\n",
      "Gradient Descent(4206/9999): loss=4723.726874456723, w0=-6.352574738054852, w1=-61.9700266435145\n",
      "Gradient Descent(4207/9999): loss=4723.726874456723, w0=-6.352574738054852, w1=-61.9700266435145\n",
      "Gradient Descent(4208/9999): loss=4723.726874456723, w0=-14.86287473805485, w1=-63.8773266435145\n",
      "Gradient Descent(4209/9999): loss=5802.4994844197445, w0=0.0038252619451508707, w1=-53.3421266435145\n",
      "Gradient Descent(4210/9999): loss=5645.406960520669, w0=0.0038252619451508707, w1=-53.3421266435145\n",
      "Gradient Descent(4211/9999): loss=5645.406960520669, w0=0.0038252619451508707, w1=-53.3421266435145\n",
      "Gradient Descent(4212/9999): loss=5645.406960520669, w0=12.070590647498685, w1=-40.6902266435145\n",
      "Gradient Descent(4213/9999): loss=16198.67977696984, w0=0.0038252619451508707, w1=-48.694626643514496\n",
      "Gradient Descent(4214/9999): loss=4730.54857508306, w0=0.0038252619451508707, w1=-48.694626643514496\n",
      "Gradient Descent(4215/9999): loss=4730.54857508306, w0=10.60522526194515, w1=-44.0611266435145\n",
      "Gradient Descent(4216/9999): loss=10882.738734860668, w0=10.60522526194515, w1=-44.0611266435145\n",
      "Gradient Descent(4217/9999): loss=10882.738734860668, w0=10.60522526194515, w1=-44.0611266435145\n",
      "Gradient Descent(4218/9999): loss=10882.738734860668, w0=10.60522526194515, w1=-44.0611266435145\n",
      "Gradient Descent(4219/9999): loss=10882.738734860668, w0=-0.5930747380548489, w1=-51.3518266435145\n",
      "Gradient Descent(4220/9999): loss=4771.90987728891, w0=-0.5930747380548489, w1=-51.3518266435145\n",
      "Gradient Descent(4221/9999): loss=4771.90987728891, w0=-0.5930747380548489, w1=-51.3518266435145\n",
      "Gradient Descent(4222/9999): loss=4771.90987728891, w0=-0.5930747380548489, w1=-51.3518266435145\n",
      "Gradient Descent(4223/9999): loss=4771.90987728891, w0=-0.5930747380548489, w1=-51.3518266435145\n",
      "Gradient Descent(4224/9999): loss=4771.90987728891, w0=9.409725261945152, w1=-45.4040266435145\n",
      "Gradient Descent(4225/9999): loss=8184.773494359919, w0=9.409725261945152, w1=-45.4040266435145\n",
      "Gradient Descent(4226/9999): loss=8184.773494359919, w0=9.409725261945152, w1=-45.4040266435145\n",
      "Gradient Descent(4227/9999): loss=8184.773494359919, w0=9.409725261945152, w1=-45.4040266435145\n",
      "Gradient Descent(4228/9999): loss=8184.773494359919, w0=9.409725261945152, w1=-45.4040266435145\n",
      "Gradient Descent(4229/9999): loss=8184.773494359919, w0=2.1769252619451507, w1=-46.6822266435145\n",
      "Gradient Descent(4230/9999): loss=4572.8653118589355, w0=10.89582526194515, w1=-46.6362266435145\n",
      "Gradient Descent(4231/9999): loss=8522.555640704184, w0=-2.065074738054852, w1=-48.978826643514495\n",
      "Gradient Descent(4232/9999): loss=4889.005475264002, w0=-2.065074738054852, w1=-48.978826643514495\n",
      "Gradient Descent(4233/9999): loss=4889.005475264002, w0=11.485725261945147, w1=-38.189426643514494\n",
      "Gradient Descent(4234/9999): loss=11753.458304002834, w0=11.485725261945147, w1=-38.189426643514494\n",
      "Gradient Descent(4235/9999): loss=11753.458304002834, w0=-18.822774738054854, w1=-47.0106266435145\n",
      "Gradient Descent(4236/9999): loss=5802.4994844197445, w0=-6.1947747380548535, w1=-45.3848266435145\n",
      "Gradient Descent(4237/9999): loss=5728.263275090446, w0=-6.1947747380548535, w1=-45.3848266435145\n",
      "Gradient Descent(4238/9999): loss=5728.263275090446, w0=-6.1947747380548535, w1=-45.3848266435145\n",
      "Gradient Descent(4239/9999): loss=5728.263275090446, w0=-6.1947747380548535, w1=-45.3848266435145\n",
      "Gradient Descent(4240/9999): loss=5728.263275090446, w0=4.601625261945147, w1=-44.2397266435145\n",
      "Gradient Descent(4241/9999): loss=8055.620964575255, w0=16.668390647498683, w1=-30.2428266435145\n",
      "Gradient Descent(4242/9999): loss=17016.098627252046, w0=-11.227309352501319, w1=-40.091726643514505\n",
      "Gradient Descent(4243/9999): loss=5790.986548954824, w0=-11.227309352501319, w1=-40.091726643514505\n",
      "Gradient Descent(4244/9999): loss=5790.986548954824, w0=-11.227309352501319, w1=-40.091726643514505\n",
      "Gradient Descent(4245/9999): loss=5790.986548954824, w0=-11.227309352501319, w1=-40.091726643514505\n",
      "Gradient Descent(4246/9999): loss=5790.986548954824, w0=-11.227309352501319, w1=-40.091726643514505\n",
      "Gradient Descent(4247/9999): loss=5790.986548954824, w0=3.873390647498683, w1=-38.49292664351451\n",
      "Gradient Descent(4248/9999): loss=13974.06254475472, w0=3.873390647498683, w1=-38.49292664351451\n",
      "Gradient Descent(4249/9999): loss=13974.06254475472, w0=3.873390647498683, w1=-38.49292664351451\n",
      "Gradient Descent(4250/9999): loss=13974.06254475472, w0=3.873390647498683, w1=-38.49292664351451\n",
      "Gradient Descent(4251/9999): loss=13974.06254475472, w0=-8.193374737676471, w1=-51.96422664309209\n",
      "Gradient Descent(4252/9999): loss=5359.8054796331635, w0=-18.06297473767647, w1=-52.30332664309209\n",
      "Gradient Descent(4253/9999): loss=5802.4994844197445, w0=-18.06297473767647, w1=-52.30332664309209\n",
      "Gradient Descent(4254/9999): loss=5802.4994844197445, w0=-18.06297473767647, w1=-52.30332664309209\n",
      "Gradient Descent(4255/9999): loss=5802.4994844197445, w0=-18.06297473767647, w1=-52.30332664309209\n",
      "Gradient Descent(4256/9999): loss=5802.4994844197445, w0=-18.06297473767647, w1=-52.30332664309209\n",
      "Gradient Descent(4257/9999): loss=5802.4994844197445, w0=-18.06297473767647, w1=-52.30332664309209\n",
      "Gradient Descent(4258/9999): loss=5802.4994844197445, w0=-6.760574737676469, w1=-49.51842664309209\n",
      "Gradient Descent(4259/9999): loss=4926.49490141812, w0=-6.760574737676469, w1=-49.51842664309209\n",
      "Gradient Descent(4260/9999): loss=4926.49490141812, w0=-6.760574737676469, w1=-49.51842664309209\n",
      "Gradient Descent(4261/9999): loss=4926.49490141812, w0=-6.760574737676469, w1=-49.51842664309209\n",
      "Gradient Descent(4262/9999): loss=4926.49490141812, w0=2.943625262323531, w1=-43.69482664309209\n",
      "Gradient Descent(4263/9999): loss=13137.923191955215, w0=-9.123140123230003, w1=-51.40392664309209\n",
      "Gradient Descent(4264/9999): loss=5330.855580833602, w0=-9.123140123230003, w1=-51.40392664309209\n",
      "Gradient Descent(4265/9999): loss=5330.855580833602, w0=-9.123140123230003, w1=-51.40392664309209\n",
      "Gradient Descent(4266/9999): loss=5330.855580833602, w0=-9.123140123230003, w1=-51.40392664309209\n",
      "Gradient Descent(4267/9999): loss=5330.855580833602, w0=-9.123140123230003, w1=-51.40392664309209\n",
      "Gradient Descent(4268/9999): loss=5330.855580833602, w0=-9.123140123230003, w1=-51.40392664309209\n",
      "Gradient Descent(4269/9999): loss=5330.855580833602, w0=-9.123140123230003, w1=-51.40392664309209\n",
      "Gradient Descent(4270/9999): loss=5330.855580833602, w0=-9.123140123230003, w1=-51.40392664309209\n",
      "Gradient Descent(4271/9999): loss=5330.855580833602, w0=-9.123140123230003, w1=-51.40392664309209\n",
      "Gradient Descent(4272/9999): loss=5330.855580833602, w0=-9.123140123230003, w1=-51.40392664309209\n",
      "Gradient Descent(4273/9999): loss=5330.855580833602, w0=-21.18990550878354, w1=-57.21702664309209\n",
      "Gradient Descent(4274/9999): loss=5802.4994844197445, w0=-21.18990550878354, w1=-57.21702664309209\n",
      "Gradient Descent(4275/9999): loss=5802.4994844197445, w0=-11.743505508783539, w1=-53.74392664309209\n",
      "Gradient Descent(4276/9999): loss=5073.150709667257, w0=-11.743505508783539, w1=-53.74392664309209\n",
      "Gradient Descent(4277/9999): loss=5073.150709667257, w0=-11.743505508783539, w1=-53.74392664309209\n",
      "Gradient Descent(4278/9999): loss=5073.150709667257, w0=-11.743505508783539, w1=-53.74392664309209\n",
      "Gradient Descent(4279/9999): loss=5073.150709667257, w0=-11.743505508783539, w1=-53.74392664309209\n",
      "Gradient Descent(4280/9999): loss=5073.150709667257, w0=-11.743505508783539, w1=-53.74392664309209\n",
      "Gradient Descent(4281/9999): loss=5073.150709667257, w0=-11.743505508783539, w1=-53.74392664309209\n",
      "Gradient Descent(4282/9999): loss=5073.150709667257, w0=-11.743505508783539, w1=-53.74392664309209\n",
      "Gradient Descent(4283/9999): loss=5073.150709667257, w0=-11.743505508783539, w1=-53.74392664309209\n",
      "Gradient Descent(4284/9999): loss=5073.150709667257, w0=-11.743505508783539, w1=-53.74392664309209\n",
      "Gradient Descent(4285/9999): loss=5073.150709667257, w0=-16.277405508783538, w1=-58.114326643092085\n",
      "Gradient Descent(4286/9999): loss=5802.4994844197445, w0=-16.277405508783538, w1=-58.114326643092085\n",
      "Gradient Descent(4287/9999): loss=5802.4994844197445, w0=-16.277405508783538, w1=-58.114326643092085\n",
      "Gradient Descent(4288/9999): loss=5802.4994844197445, w0=-16.277405508783538, w1=-58.114326643092085\n",
      "Gradient Descent(4289/9999): loss=5802.4994844197445, w0=-16.277405508783538, w1=-58.114326643092085\n",
      "Gradient Descent(4290/9999): loss=5802.4994844197445, w0=-5.481005508783538, w1=-56.969226643092085\n",
      "Gradient Descent(4291/9999): loss=4903.52625330246, w0=-5.481005508783538, w1=-56.969226643092085\n",
      "Gradient Descent(4292/9999): loss=4903.52625330246, w0=-5.481005508783538, w1=-56.969226643092085\n",
      "Gradient Descent(4293/9999): loss=4903.52625330246, w0=-9.244905508783539, w1=-59.928126643092085\n",
      "Gradient Descent(4294/9999): loss=5790.986030176556, w0=-9.244905508783539, w1=-59.928126643092085\n",
      "Gradient Descent(4295/9999): loss=5790.986030176556, w0=-9.244905508783539, w1=-59.928126643092085\n",
      "Gradient Descent(4296/9999): loss=5790.986030176556, w0=-9.244905508783539, w1=-59.928126643092085\n",
      "Gradient Descent(4297/9999): loss=5790.986030176556, w0=-9.244905508783539, w1=-59.928126643092085\n",
      "Gradient Descent(4298/9999): loss=5790.986030176556, w0=-9.244905508783539, w1=-59.928126643092085\n",
      "Gradient Descent(4299/9999): loss=5790.986030176556, w0=-9.244905508783539, w1=-59.928126643092085\n",
      "Gradient Descent(4300/9999): loss=5790.986030176556, w0=2.497294491216463, w1=-59.03142664309208\n",
      "Gradient Descent(4301/9999): loss=5996.7810151524445, w0=2.497294491216463, w1=-59.03142664309208\n",
      "Gradient Descent(4302/9999): loss=5996.7810151524445, w0=2.497294491216463, w1=-59.03142664309208\n",
      "Gradient Descent(4303/9999): loss=5996.7810151524445, w0=2.497294491216463, w1=-59.03142664309208\n",
      "Gradient Descent(4304/9999): loss=5996.7810151524445, w0=2.497294491216463, w1=-59.03142664309208\n",
      "Gradient Descent(4305/9999): loss=5996.7810151524445, w0=2.497294491216463, w1=-59.03142664309208\n",
      "Gradient Descent(4306/9999): loss=5996.7810151524445, w0=2.497294491216463, w1=-59.03142664309208\n",
      "Gradient Descent(4307/9999): loss=5996.7810151524445, w0=2.497294491216463, w1=-59.03142664309208\n",
      "Gradient Descent(4308/9999): loss=5996.7810151524445, w0=2.497294491216463, w1=-59.03142664309208\n",
      "Gradient Descent(4309/9999): loss=5996.7810151524445, w0=2.497294491216463, w1=-59.03142664309208\n",
      "Gradient Descent(4310/9999): loss=5996.7810151524445, w0=2.497294491216463, w1=-59.03142664309208\n",
      "Gradient Descent(4311/9999): loss=5996.7810151524445, w0=2.497294491216463, w1=-59.03142664309208\n",
      "Gradient Descent(4312/9999): loss=5996.7810151524445, w0=-7.789105508783537, w1=-63.571926643092084\n",
      "Gradient Descent(4313/9999): loss=5087.298213840704, w0=-7.789105508783537, w1=-63.571926643092084\n",
      "Gradient Descent(4314/9999): loss=5087.298213840704, w0=-7.789105508783537, w1=-63.571926643092084\n",
      "Gradient Descent(4315/9999): loss=5087.298213840704, w0=6.808994491216463, w1=-62.22702664309208\n",
      "Gradient Descent(4316/9999): loss=6685.502115734369, w0=6.808994491216463, w1=-62.22702664309208\n",
      "Gradient Descent(4317/9999): loss=6685.502115734369, w0=18.207694491216465, w1=-54.90062664309208\n",
      "Gradient Descent(4318/9999): loss=16252.043518680792, w0=6.140929105662931, w1=-62.31972664309208\n",
      "Gradient Descent(4319/9999): loss=5099.498434738654, w0=6.140929105662931, w1=-62.31972664309208\n",
      "Gradient Descent(4320/9999): loss=5099.498434738654, w0=6.140929105662931, w1=-62.31972664309208\n",
      "Gradient Descent(4321/9999): loss=5099.498434738654, w0=6.140929105662931, w1=-62.31972664309208\n",
      "Gradient Descent(4322/9999): loss=5099.498434738654, w0=17.37702910566293, w1=-55.86352664309208\n",
      "Gradient Descent(4323/9999): loss=15703.980799100917, w0=11.31852910566293, w1=-62.64622664309208\n",
      "Gradient Descent(4324/9999): loss=8580.14777559941, w0=1.1887291056629312, w1=-69.31142664309208\n",
      "Gradient Descent(4325/9999): loss=4617.13972252538, w0=1.1887291056629312, w1=-69.31142664309208\n",
      "Gradient Descent(4326/9999): loss=4617.13972252538, w0=13.012329105662932, w1=-66.28062664309208\n",
      "Gradient Descent(4327/9999): loss=5898.070039152169, w0=3.5952291056629306, w1=-67.15492664309208\n",
      "Gradient Descent(4328/9999): loss=4823.902573511822, w0=3.5952291056629306, w1=-67.15492664309208\n",
      "Gradient Descent(4329/9999): loss=4823.902573511822, w0=3.5952291056629306, w1=-67.15492664309208\n",
      "Gradient Descent(4330/9999): loss=4823.902573511822, w0=12.783929105662931, w1=-63.720526643092086\n",
      "Gradient Descent(4331/9999): loss=5632.514997536252, w0=12.783929105662931, w1=-63.720526643092086\n",
      "Gradient Descent(4332/9999): loss=5632.514997536252, w0=12.783929105662931, w1=-63.720526643092086\n",
      "Gradient Descent(4333/9999): loss=5632.514997536252, w0=12.783929105662931, w1=-63.720526643092086\n",
      "Gradient Descent(4334/9999): loss=5632.514997536252, w0=12.783929105662931, w1=-63.720526643092086\n",
      "Gradient Descent(4335/9999): loss=5632.514997536252, w0=12.783929105662931, w1=-63.720526643092086\n",
      "Gradient Descent(4336/9999): loss=5632.514997536252, w0=12.783929105662931, w1=-63.720526643092086\n",
      "Gradient Descent(4337/9999): loss=5632.514997536252, w0=12.783929105662931, w1=-63.720526643092086\n",
      "Gradient Descent(4338/9999): loss=5632.514997536252, w0=12.783929105662931, w1=-63.720526643092086\n",
      "Gradient Descent(4339/9999): loss=5632.514997536252, w0=26.711429105662933, w1=-55.62732664309208\n",
      "Gradient Descent(4340/9999): loss=16808.833563544256, w0=18.254429105662936, w1=-58.909326643092086\n",
      "Gradient Descent(4341/9999): loss=9513.186058462315, w0=30.32119449121647, w1=-46.25742664309209\n",
      "Gradient Descent(4342/9999): loss=17096.689175506486, w0=18.254429105662936, w1=-53.97312664309209\n",
      "Gradient Descent(4343/9999): loss=13454.918172250826, w0=18.254429105662936, w1=-53.97312664309209\n",
      "Gradient Descent(4344/9999): loss=13454.918172250826, w0=18.254429105662936, w1=-53.97312664309209\n",
      "Gradient Descent(4345/9999): loss=13454.918172250826, w0=18.254429105662936, w1=-53.97312664309209\n",
      "Gradient Descent(4346/9999): loss=13454.918172250826, w0=10.611829105662935, w1=-57.59062664309209\n",
      "Gradient Descent(4347/9999): loss=4656.006820890545, w0=10.611829105662935, w1=-57.59062664309209\n",
      "Gradient Descent(4348/9999): loss=4656.006820890545, w0=1.4447291056629332, w1=-60.81712664309209\n",
      "Gradient Descent(4349/9999): loss=5617.711222947983, w0=11.742729105662935, w1=-56.53382664309209\n",
      "Gradient Descent(4350/9999): loss=4656.67703461771, w0=11.742729105662935, w1=-56.53382664309209\n",
      "Gradient Descent(4351/9999): loss=4656.67703461771, w0=0.14292910566293493, w1=-57.17922664309209\n",
      "Gradient Descent(4352/9999): loss=5710.395962839359, w0=0.14292910566293493, w1=-57.17922664309209\n",
      "Gradient Descent(4353/9999): loss=5710.395962839359, w0=14.867929105662936, w1=-54.080626643092096\n",
      "Gradient Descent(4354/9999): loss=4835.11353846854, w0=-0.4710708943370623, w1=-61.922426643092095\n",
      "Gradient Descent(4355/9999): loss=5802.4994844197445, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4356/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4357/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4358/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4359/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4360/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4361/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4362/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4363/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4364/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4365/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4366/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4367/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4368/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4369/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4370/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4371/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4372/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4373/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4374/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4375/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4376/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4377/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4378/9999): loss=4766.335292576714, w0=9.67562910566294, w1=-59.094926643092094\n",
      "Gradient Descent(4379/9999): loss=4766.335292576714, w0=21.17302910566294, w1=-52.0175266430921\n",
      "Gradient Descent(4380/9999): loss=13664.851094891372, w0=21.17302910566294, w1=-52.0175266430921\n",
      "Gradient Descent(4381/9999): loss=13664.851094891372, w0=21.17302910566294, w1=-52.0175266430921\n",
      "Gradient Descent(4382/9999): loss=13664.851094891372, w0=9.106263720109407, w1=-60.7160266430921\n",
      "Gradient Descent(4383/9999): loss=4435.26405948842, w0=9.106263720109407, w1=-60.7160266430921\n",
      "Gradient Descent(4384/9999): loss=4435.26405948842, w0=9.106263720109407, w1=-60.7160266430921\n",
      "Gradient Descent(4385/9999): loss=4435.26405948842, w0=-2.6686362798905936, w1=-63.4716266430921\n",
      "Gradient Descent(4386/9999): loss=5802.4994844197445, w0=-2.6686362798905936, w1=-63.4716266430921\n",
      "Gradient Descent(4387/9999): loss=5802.4994844197445, w0=-2.6686362798905936, w1=-63.4716266430921\n",
      "Gradient Descent(4388/9999): loss=5802.4994844197445, w0=-2.6686362798905936, w1=-63.4716266430921\n",
      "Gradient Descent(4389/9999): loss=5802.4994844197445, w0=-2.6686362798905936, w1=-63.4716266430921\n",
      "Gradient Descent(4390/9999): loss=5802.4994844197445, w0=-2.6686362798905936, w1=-63.4716266430921\n",
      "Gradient Descent(4391/9999): loss=5802.4994844197445, w0=-2.6686362798905936, w1=-63.4716266430921\n",
      "Gradient Descent(4392/9999): loss=5802.4994844197445, w0=9.39812910566294, w1=-44.6442266430921\n",
      "Gradient Descent(4393/9999): loss=4420.36227550733, w0=9.39812910566294, w1=-44.6442266430921\n",
      "Gradient Descent(4394/9999): loss=4420.36227550733, w0=9.39812910566294, w1=-44.6442266430921\n",
      "Gradient Descent(4395/9999): loss=4420.36227550733, w0=21.464894491216477, w1=-35.4623266430921\n",
      "Gradient Descent(4396/9999): loss=16149.3433700074, w0=9.398129105662942, w1=-42.5702266430921\n",
      "Gradient Descent(4397/9999): loss=4436.918132738743, w0=9.398129105662942, w1=-42.5702266430921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(4398/9999): loss=4436.918132738743, w0=9.398129105662942, w1=-42.5702266430921\n",
      "Gradient Descent(4399/9999): loss=4436.918132738743, w0=9.398129105662942, w1=-42.5702266430921\n",
      "Gradient Descent(4400/9999): loss=4436.918132738743, w0=9.398129105662942, w1=-42.5702266430921\n",
      "Gradient Descent(4401/9999): loss=4436.918132738743, w0=9.398129105662942, w1=-42.5702266430921\n",
      "Gradient Descent(4402/9999): loss=4436.918132738743, w0=9.398129105662942, w1=-42.5702266430921\n",
      "Gradient Descent(4403/9999): loss=4436.918132738743, w0=9.398129105662942, w1=-42.5702266430921\n",
      "Gradient Descent(4404/9999): loss=4436.918132738743, w0=18.37442910566294, w1=-38.623426643092095\n",
      "Gradient Descent(4405/9999): loss=14426.35543988127, w0=0.1750291056629365, w1=-45.0531266430921\n",
      "Gradient Descent(4406/9999): loss=5802.4994844197445, w0=0.1750291056629365, w1=-45.0531266430921\n",
      "Gradient Descent(4407/9999): loss=5802.4994844197445, w0=11.399829105662937, w1=-37.4480266430921\n",
      "Gradient Descent(4408/9999): loss=4836.175483112234, w0=11.399829105662937, w1=-37.4480266430921\n",
      "Gradient Descent(4409/9999): loss=4836.175483112234, w0=11.399829105662937, w1=-37.4480266430921\n",
      "Gradient Descent(4410/9999): loss=4836.175483112234, w0=11.399829105662937, w1=-37.4480266430921\n",
      "Gradient Descent(4411/9999): loss=4836.175483112234, w0=11.399829105662937, w1=-37.4480266430921\n",
      "Gradient Descent(4412/9999): loss=4836.175483112234, w0=11.399829105662937, w1=-37.4480266430921\n",
      "Gradient Descent(4413/9999): loss=4836.175483112234, w0=11.399829105662937, w1=-37.4480266430921\n",
      "Gradient Descent(4414/9999): loss=4836.175483112234, w0=11.399829105662937, w1=-37.4480266430921\n",
      "Gradient Descent(4415/9999): loss=4836.175483112234, w0=11.399829105662937, w1=-37.4480266430921\n",
      "Gradient Descent(4416/9999): loss=4836.175483112234, w0=23.46659449121647, w1=-27.1244266430921\n",
      "Gradient Descent(4417/9999): loss=14308.544037039239, w0=11.399829105662935, w1=-34.2563266430921\n",
      "Gradient Descent(4418/9999): loss=4720.8783183848645, w0=11.399829105662935, w1=-34.2563266430921\n",
      "Gradient Descent(4419/9999): loss=4720.8783183848645, w0=23.46659449121647, w1=-20.2594266430921\n",
      "Gradient Descent(4420/9999): loss=16937.919126074343, w0=12.26829449121647, w1=-27.550126643092103\n",
      "Gradient Descent(4421/9999): loss=8288.052606559984, w0=12.26829449121647, w1=-27.550126643092103\n",
      "Gradient Descent(4422/9999): loss=8288.052606559984, w0=12.26829449121647, w1=-27.550126643092103\n",
      "Gradient Descent(4423/9999): loss=8288.052606559984, w0=2.247494491216468, w1=-31.6925266430921\n",
      "Gradient Descent(4424/9999): loss=5652.863288561493, w0=2.247494491216468, w1=-31.6925266430921\n",
      "Gradient Descent(4425/9999): loss=5652.863288561493, w0=2.247494491216468, w1=-31.6925266430921\n",
      "Gradient Descent(4426/9999): loss=5652.863288561493, w0=2.247494491216468, w1=-31.6925266430921\n",
      "Gradient Descent(4427/9999): loss=5652.863288561493, w0=2.247494491216468, w1=-31.6925266430921\n",
      "Gradient Descent(4428/9999): loss=5652.863288561493, w0=15.71319449121647, w1=-24.589626643092103\n",
      "Gradient Descent(4429/9999): loss=14488.45742580964, w0=-6.965005508783534, w1=-34.143626643092105\n",
      "Gradient Descent(4430/9999): loss=5802.4994844197445, w0=-6.965005508783534, w1=-34.143626643092105\n",
      "Gradient Descent(4431/9999): loss=5802.4994844197445, w0=-6.965005508783534, w1=-34.143626643092105\n",
      "Gradient Descent(4432/9999): loss=5802.4994844197445, w0=4.667494491216466, w1=-30.309626643092106\n",
      "Gradient Descent(4433/9999): loss=4777.243498533121, w0=4.667494491216466, w1=-30.309626643092106\n",
      "Gradient Descent(4434/9999): loss=4777.243498533121, w0=-9.114405508783534, w1=-32.965126643092105\n",
      "Gradient Descent(4435/9999): loss=5802.4994844197445, w0=-9.114405508783534, w1=-32.965126643092105\n",
      "Gradient Descent(4436/9999): loss=5802.4994844197445, w0=-9.114405508783534, w1=-32.965126643092105\n",
      "Gradient Descent(4437/9999): loss=5802.4994844197445, w0=-9.114405508783534, w1=-32.965126643092105\n",
      "Gradient Descent(4438/9999): loss=5802.4994844197445, w0=-9.114405508783534, w1=-32.965126643092105\n",
      "Gradient Descent(4439/9999): loss=5802.4994844197445, w0=0.7652944912164674, w1=-32.79992664309211\n",
      "Gradient Descent(4440/9999): loss=4767.956424568869, w0=0.7652944912164674, w1=-32.79992664309211\n",
      "Gradient Descent(4441/9999): loss=4767.956424568869, w0=9.575194491216466, w1=-32.25742664309211\n",
      "Gradient Descent(4442/9999): loss=10398.995178168283, w0=9.575194491216466, w1=-32.25742664309211\n",
      "Gradient Descent(4443/9999): loss=10398.995178168283, w0=-9.927205508783535, w1=-35.62642664309211\n",
      "Gradient Descent(4444/9999): loss=5802.4994844197445, w0=-9.927205508783535, w1=-35.62642664309211\n",
      "Gradient Descent(4445/9999): loss=5802.4994844197445, w0=1.865394491216465, w1=-31.74252664309211\n",
      "Gradient Descent(4446/9999): loss=5345.654585700979, w0=1.865394491216465, w1=-31.74252664309211\n",
      "Gradient Descent(4447/9999): loss=5345.654585700979, w0=1.865394491216465, w1=-31.74252664309211\n",
      "Gradient Descent(4448/9999): loss=5345.654585700979, w0=13.303094491216466, w1=-26.12182664309211\n",
      "Gradient Descent(4449/9999): loss=11517.316568026967, w0=13.303094491216466, w1=-26.12182664309211\n",
      "Gradient Descent(4450/9999): loss=11517.316568026967, w0=13.303094491216466, w1=-26.12182664309211\n",
      "Gradient Descent(4451/9999): loss=11517.316568026967, w0=-2.0359055087835323, w1=-33.96362664309211\n",
      "Gradient Descent(4452/9999): loss=5802.4994844197445, w0=6.861094491216468, w1=-33.51472664309211\n",
      "Gradient Descent(4453/9999): loss=4546.182140773112, w0=6.861094491216468, w1=-33.51472664309211\n",
      "Gradient Descent(4454/9999): loss=4546.182140773112, w0=6.861094491216468, w1=-33.51472664309211\n",
      "Gradient Descent(4455/9999): loss=4546.182140773112, w0=15.205894491216467, w1=-30.77042664309211\n",
      "Gradient Descent(4456/9999): loss=15666.229745238677, w0=15.205894491216467, w1=-30.77042664309211\n",
      "Gradient Descent(4457/9999): loss=15666.229745238677, w0=4.480794491216466, w1=-37.22162664309211\n",
      "Gradient Descent(4458/9999): loss=4503.00421660973, w0=4.480794491216466, w1=-37.22162664309211\n",
      "Gradient Descent(4459/9999): loss=4503.00421660973, w0=4.480794491216466, w1=-37.22162664309211\n",
      "Gradient Descent(4460/9999): loss=4503.00421660973, w0=4.480794491216466, w1=-37.22162664309211\n",
      "Gradient Descent(4461/9999): loss=4503.00421660973, w0=15.679594491216466, w1=-31.017626643092107\n",
      "Gradient Descent(4462/9999): loss=16348.348370398173, w0=15.679594491216466, w1=-31.017626643092107\n",
      "Gradient Descent(4463/9999): loss=16348.348370398173, w0=3.6128291056629322, w1=-39.25352664309211\n",
      "Gradient Descent(4464/9999): loss=5358.158543300096, w0=3.6128291056629322, w1=-39.25352664309211\n",
      "Gradient Descent(4465/9999): loss=5358.158543300096, w0=-4.0297708943370685, w1=-42.87102664309211\n",
      "Gradient Descent(4466/9999): loss=5779.548872141095, w0=-4.0297708943370685, w1=-42.87102664309211\n",
      "Gradient Descent(4467/9999): loss=5779.548872141095, w0=3.319929105662932, w1=-38.683026643092106\n",
      "Gradient Descent(4468/9999): loss=4817.343238228799, w0=3.319929105662932, w1=-38.683026643092106\n",
      "Gradient Descent(4469/9999): loss=4817.343238228799, w0=13.583029105662934, w1=-32.034426643092104\n",
      "Gradient Descent(4470/9999): loss=15870.880453401605, w0=4.357929105662933, w1=-32.58202664309211\n",
      "Gradient Descent(4471/9999): loss=5116.095300342236, w0=4.357929105662933, w1=-32.58202664309211\n",
      "Gradient Descent(4472/9999): loss=5116.095300342236, w0=4.357929105662933, w1=-32.58202664309211\n",
      "Gradient Descent(4473/9999): loss=5116.095300342236, w0=4.357929105662933, w1=-32.58202664309211\n",
      "Gradient Descent(4474/9999): loss=5116.095300342236, w0=4.357929105662933, w1=-32.58202664309211\n",
      "Gradient Descent(4475/9999): loss=5116.095300342236, w0=4.357929105662933, w1=-32.58202664309211\n",
      "Gradient Descent(4476/9999): loss=5116.095300342236, w0=-6.986470894337067, w1=-36.916326643092106\n",
      "Gradient Descent(4477/9999): loss=5802.4994844197445, w0=-6.986470894337067, w1=-36.916326643092106\n",
      "Gradient Descent(4478/9999): loss=5802.4994844197445, w0=5.764329105662933, w1=-31.315326643092106\n",
      "Gradient Descent(4479/9999): loss=4539.199224403896, w0=5.764329105662933, w1=-31.315326643092106\n",
      "Gradient Descent(4480/9999): loss=4539.199224403896, w0=5.764329105662933, w1=-31.315326643092106\n",
      "Gradient Descent(4481/9999): loss=4539.199224403896, w0=5.764329105662933, w1=-31.315326643092106\n",
      "Gradient Descent(4482/9999): loss=4539.199224403896, w0=5.764329105662933, w1=-31.315326643092106\n",
      "Gradient Descent(4483/9999): loss=4539.199224403896, w0=-9.107470894337068, w1=-31.436026643092106\n",
      "Gradient Descent(4484/9999): loss=5802.4994844197445, w0=-9.107470894337068, w1=-31.436026643092106\n",
      "Gradient Descent(4485/9999): loss=5802.4994844197445, w0=-9.107470894337068, w1=-31.436026643092106\n",
      "Gradient Descent(4486/9999): loss=5802.4994844197445, w0=3.769929105662934, w1=-30.599626643092105\n",
      "Gradient Descent(4487/9999): loss=5145.555250914648, w0=3.769929105662934, w1=-30.599626643092105\n",
      "Gradient Descent(4488/9999): loss=5145.555250914648, w0=3.769929105662934, w1=-30.599626643092105\n",
      "Gradient Descent(4489/9999): loss=5145.555250914648, w0=3.769929105662934, w1=-30.599626643092105\n",
      "Gradient Descent(4490/9999): loss=5145.555250914648, w0=3.769929105662934, w1=-30.599626643092105\n",
      "Gradient Descent(4491/9999): loss=5145.555250914648, w0=3.769929105662934, w1=-30.599626643092105\n",
      "Gradient Descent(4492/9999): loss=5145.555250914648, w0=3.769929105662934, w1=-30.599626643092105\n",
      "Gradient Descent(4493/9999): loss=5145.555250914648, w0=3.769929105662934, w1=-30.599626643092105\n",
      "Gradient Descent(4494/9999): loss=5145.555250914648, w0=3.769929105662934, w1=-30.599626643092105\n",
      "Gradient Descent(4495/9999): loss=5145.555250914648, w0=3.769929105662934, w1=-30.599626643092105\n",
      "Gradient Descent(4496/9999): loss=5145.555250914648, w0=3.769929105662934, w1=-30.599626643092105\n",
      "Gradient Descent(4497/9999): loss=5145.555250914648, w0=3.769929105662934, w1=-30.599626643092105\n",
      "Gradient Descent(4498/9999): loss=5145.555250914648, w0=3.769929105662934, w1=-30.599626643092105\n",
      "Gradient Descent(4499/9999): loss=5145.555250914648, w0=14.173029105662936, w1=-25.104426643092104\n",
      "Gradient Descent(4500/9999): loss=13996.701093437106, w0=14.173029105662936, w1=-25.104426643092104\n",
      "Gradient Descent(4501/9999): loss=13996.701093437106, w0=2.1062637201094017, w1=-35.5057266430921\n",
      "Gradient Descent(4502/9999): loss=4744.765854575189, w0=2.1062637201094017, w1=-35.5057266430921\n",
      "Gradient Descent(4503/9999): loss=4744.765854575189, w0=2.1062637201094017, w1=-35.5057266430921\n",
      "Gradient Descent(4504/9999): loss=4744.765854575189, w0=2.1062637201094017, w1=-35.5057266430921\n",
      "Gradient Descent(4505/9999): loss=4744.765854575189, w0=-21.1200362798906, w1=-38.08332664309211\n",
      "Gradient Descent(4506/9999): loss=5802.4994844197445, w0=-21.1200362798906, w1=-38.08332664309211\n",
      "Gradient Descent(4507/9999): loss=5802.4994844197445, w0=-9.053270894337064, w1=-28.98792664309211\n",
      "Gradient Descent(4508/9999): loss=5802.4994844197445, w0=-9.053270894337064, w1=-28.98792664309211\n",
      "Gradient Descent(4509/9999): loss=5802.4994844197445, w0=2.8150291056629353, w1=-28.34342664309211\n",
      "Gradient Descent(4510/9999): loss=4921.422576344819, w0=2.8150291056629353, w1=-28.34342664309211\n",
      "Gradient Descent(4511/9999): loss=4921.422576344819, w0=13.218129105662937, w1=-22.848226643092108\n",
      "Gradient Descent(4512/9999): loss=14673.309300845787, w0=5.178329105662938, w1=-30.54302664309211\n",
      "Gradient Descent(4513/9999): loss=4824.417854369145, w0=5.178329105662938, w1=-30.54302664309211\n",
      "Gradient Descent(4514/9999): loss=4824.417854369145, w0=5.178329105662938, w1=-30.54302664309211\n",
      "Gradient Descent(4515/9999): loss=4824.417854369145, w0=5.178329105662938, w1=-30.54302664309211\n",
      "Gradient Descent(4516/9999): loss=4824.417854369145, w0=5.178329105662938, w1=-30.54302664309211\n",
      "Gradient Descent(4517/9999): loss=4824.417854369145, w0=5.178329105662938, w1=-30.54302664309211\n",
      "Gradient Descent(4518/9999): loss=4824.417854369145, w0=5.178329105662938, w1=-30.54302664309211\n",
      "Gradient Descent(4519/9999): loss=4824.417854369145, w0=5.178329105662938, w1=-30.54302664309211\n",
      "Gradient Descent(4520/9999): loss=4824.417854369145, w0=15.823129105662938, w1=-26.43492664309211\n",
      "Gradient Descent(4521/9999): loss=10678.073571786957, w0=5.627929105662936, w1=-32.86712664309211\n",
      "Gradient Descent(4522/9999): loss=4810.569670261673, w0=5.627929105662936, w1=-32.86712664309211\n",
      "Gradient Descent(4523/9999): loss=4810.569670261673, w0=14.268129105662936, w1=-30.006426643092105\n",
      "Gradient Descent(4524/9999): loss=11503.544875654696, w0=3.6766291056629345, w1=-37.642126643092105\n",
      "Gradient Descent(4525/9999): loss=4705.061950761101, w0=12.021429105662934, w1=-34.8978266430921\n",
      "Gradient Descent(4526/9999): loss=10177.27196847263, w0=12.021429105662934, w1=-34.8978266430921\n",
      "Gradient Descent(4527/9999): loss=10177.27196847263, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4528/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4529/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4530/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4531/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4532/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4533/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4534/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4535/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4536/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4537/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4538/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4539/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4540/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4541/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4542/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4543/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4544/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4545/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4546/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4547/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4548/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4549/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4550/9999): loss=4901.058552934606, w0=-0.045336279890600295, w1=-41.8216266430921\n",
      "Gradient Descent(4551/9999): loss=4901.058552934606, w0=9.955563720109401, w1=-36.3262266430921\n",
      "Gradient Descent(4552/9999): loss=13206.711713609637, w0=9.955563720109401, w1=-36.3262266430921\n",
      "Gradient Descent(4553/9999): loss=13206.711713609637, w0=-2.111201665444133, w1=-43.0134266430921\n",
      "Gradient Descent(4554/9999): loss=4559.102448219763, w0=9.955563720109401, w1=-30.9262266430921\n",
      "Gradient Descent(4555/9999): loss=16095.339631396333, w0=3.8970637201094007, w1=-37.7089266430921\n",
      "Gradient Descent(4556/9999): loss=8098.290195731648, w0=3.8970637201094007, w1=-37.7089266430921\n",
      "Gradient Descent(4557/9999): loss=8098.290195731648, w0=-5.805836279890599, w1=-43.2066266430921\n",
      "Gradient Descent(4558/9999): loss=5801.123261923522, w0=-5.805836279890599, w1=-43.2066266430921\n",
      "Gradient Descent(4559/9999): loss=5801.123261923522, w0=-5.805836279890599, w1=-43.2066266430921\n",
      "Gradient Descent(4560/9999): loss=5801.123261923522, w0=-5.805836279890599, w1=-43.2066266430921\n",
      "Gradient Descent(4561/9999): loss=5801.123261923522, w0=-5.805836279890599, w1=-43.2066266430921\n",
      "Gradient Descent(4562/9999): loss=5801.123261923522, w0=-5.805836279890599, w1=-43.2066266430921\n",
      "Gradient Descent(4563/9999): loss=5801.123261923522, w0=-5.805836279890599, w1=-43.2066266430921\n",
      "Gradient Descent(4564/9999): loss=5801.123261923522, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4565/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4566/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4567/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4568/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4569/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4570/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4571/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4572/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4573/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4574/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4575/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4576/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4577/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4578/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4579/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4580/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4581/9999): loss=4692.741542176773, w0=4.568663720109402, w1=-39.3762266430921\n",
      "Gradient Descent(4582/9999): loss=4692.741542176773, w0=-4.8235362798905985, w1=-40.561826643092104\n",
      "Gradient Descent(4583/9999): loss=5583.754103510453, w0=-4.8235362798905985, w1=-40.561826643092104\n",
      "Gradient Descent(4584/9999): loss=5583.754103510453, w0=-4.8235362798905985, w1=-40.561826643092104\n",
      "Gradient Descent(4585/9999): loss=5583.754103510453, w0=7.243229105662936, w1=-17.1346266430921\n",
      "Gradient Descent(4586/9999): loss=13711.992039067753, w0=7.243229105662936, w1=-17.1346266430921\n",
      "Gradient Descent(4587/9999): loss=13711.992039067753, w0=-1.0832708943370655, w1=-18.9808266430921\n",
      "Gradient Descent(4588/9999): loss=5243.418233799065, w0=-1.0832708943370655, w1=-18.9808266430921\n",
      "Gradient Descent(4589/9999): loss=5243.418233799065, w0=-1.0832708943370655, w1=-18.9808266430921\n",
      "Gradient Descent(4590/9999): loss=5243.418233799065, w0=-1.0832708943370655, w1=-18.9808266430921\n",
      "Gradient Descent(4591/9999): loss=5243.418233799065, w0=-1.0832708943370655, w1=-18.9808266430921\n",
      "Gradient Descent(4592/9999): loss=5243.418233799065, w0=-1.0832708943370655, w1=-18.9808266430921\n",
      "Gradient Descent(4593/9999): loss=5243.418233799065, w0=-1.0832708943370655, w1=-18.9808266430921\n",
      "Gradient Descent(4594/9999): loss=5243.418233799065, w0=-1.0832708943370655, w1=-18.9808266430921\n",
      "Gradient Descent(4595/9999): loss=5243.418233799065, w0=12.286229105662935, w1=-14.985226643092101\n",
      "Gradient Descent(4596/9999): loss=15830.266291079544, w0=-1.3470708943370653, w1=-23.835326643092102\n",
      "Gradient Descent(4597/9999): loss=4898.86350619173, w0=-1.3470708943370653, w1=-23.835326643092102\n",
      "Gradient Descent(4598/9999): loss=4898.86350619173, w0=-1.3470708943370653, w1=-23.835326643092102\n",
      "Gradient Descent(4599/9999): loss=4898.86350619173, w0=-1.3470708943370653, w1=-23.835326643092102\n",
      "Gradient Descent(4600/9999): loss=4898.86350619173, w0=9.555829105662935, w1=-23.510326643092103\n",
      "Gradient Descent(4601/9999): loss=15414.25544374061, w0=-2.5109362798905988, w1=-36.138026643092104\n",
      "Gradient Descent(4602/9999): loss=5698.883065235463, w0=12.389063720109402, w1=-31.377626643092103\n",
      "Gradient Descent(4603/9999): loss=8595.415390665039, w0=12.389063720109402, w1=-31.377626643092103\n",
      "Gradient Descent(4604/9999): loss=8595.415390665039, w0=12.389063720109402, w1=-31.377626643092103\n",
      "Gradient Descent(4605/9999): loss=8595.415390665039, w0=12.389063720109402, w1=-31.377626643092103\n",
      "Gradient Descent(4606/9999): loss=8595.415390665039, w0=12.389063720109402, w1=-31.377626643092103\n",
      "Gradient Descent(4607/9999): loss=8595.415390665039, w0=12.389063720109402, w1=-31.377626643092103\n",
      "Gradient Descent(4608/9999): loss=8595.415390665039, w0=12.389063720109402, w1=-31.377626643092103\n",
      "Gradient Descent(4609/9999): loss=8595.415390665039, w0=12.389063720109402, w1=-31.377626643092103\n",
      "Gradient Descent(4610/9999): loss=8595.415390665039, w0=0.3222983345558674, w1=-38.9879266430921\n",
      "Gradient Descent(4611/9999): loss=5422.572771582459, w0=10.505698334555868, w1=-35.529926643092104\n",
      "Gradient Descent(4612/9999): loss=13956.74402287241, w0=-5.9285016654441325, w1=-42.401926643092104\n",
      "Gradient Descent(4613/9999): loss=5802.4994844197445, w0=2.9288983345558677, w1=-39.2758266430921\n",
      "Gradient Descent(4614/9999): loss=4469.914980535248, w0=2.9288983345558677, w1=-39.2758266430921\n",
      "Gradient Descent(4615/9999): loss=4469.914980535248, w0=2.9288983345558677, w1=-39.2758266430921\n",
      "Gradient Descent(4616/9999): loss=4469.914980535248, w0=-9.922501665444134, w1=-40.0480266430921\n",
      "Gradient Descent(4617/9999): loss=5802.4994844197445, w0=-9.922501665444134, w1=-40.0480266430921\n",
      "Gradient Descent(4618/9999): loss=5802.4994844197445, w0=-9.922501665444134, w1=-40.0480266430921\n",
      "Gradient Descent(4619/9999): loss=5802.4994844197445, w0=-1.200401665444133, w1=-38.2254266430921\n",
      "Gradient Descent(4620/9999): loss=4702.148670921649, w0=-1.200401665444133, w1=-38.2254266430921\n",
      "Gradient Descent(4621/9999): loss=4702.148670921649, w0=-1.200401665444133, w1=-38.2254266430921\n",
      "Gradient Descent(4622/9999): loss=4702.148670921649, w0=-1.200401665444133, w1=-38.2254266430921\n",
      "Gradient Descent(4623/9999): loss=4702.148670921649, w0=-1.200401665444133, w1=-38.2254266430921\n",
      "Gradient Descent(4624/9999): loss=4702.148670921649, w0=11.94799833455587, w1=-32.6256266430921\n",
      "Gradient Descent(4625/9999): loss=13770.870048930685, w0=3.845198334555869, w1=-40.852026643092096\n",
      "Gradient Descent(4626/9999): loss=4736.233764873781, w0=16.56849833455587, w1=-36.7947266430921\n",
      "Gradient Descent(4627/9999): loss=11415.482770535367, w0=16.56849833455587, w1=-36.7947266430921\n",
      "Gradient Descent(4628/9999): loss=11415.482770535367, w0=16.56849833455587, w1=-36.7947266430921\n",
      "Gradient Descent(4629/9999): loss=11415.482770535367, w0=6.192498334555868, w1=-41.7805266430921\n",
      "Gradient Descent(4630/9999): loss=4898.783297602465, w0=6.192498334555868, w1=-41.7805266430921\n",
      "Gradient Descent(4631/9999): loss=4898.783297602465, w0=6.192498334555868, w1=-41.7805266430921\n",
      "Gradient Descent(4632/9999): loss=4898.783297602465, w0=6.192498334555868, w1=-41.7805266430921\n",
      "Gradient Descent(4633/9999): loss=4898.783297602465, w0=17.02439833455587, w1=-34.8233266430921\n",
      "Gradient Descent(4634/9999): loss=11995.421810797026, w0=1.8062983345558674, w1=-38.822126643092105\n",
      "Gradient Descent(4635/9999): loss=5756.447751666916, w0=1.8062983345558674, w1=-38.822126643092105\n",
      "Gradient Descent(4636/9999): loss=5756.447751666916, w0=1.8062983345558674, w1=-38.822126643092105\n",
      "Gradient Descent(4637/9999): loss=5756.447751666916, w0=1.8062983345558674, w1=-38.822126643092105\n",
      "Gradient Descent(4638/9999): loss=5756.447751666916, w0=13.461398334555868, w1=-38.099926643092104\n",
      "Gradient Descent(4639/9999): loss=8763.99483940091, w0=1.3946329490023341, w1=-45.71902664309211\n",
      "Gradient Descent(4640/9999): loss=4762.007479295407, w0=1.3946329490023341, w1=-45.71902664309211\n",
      "Gradient Descent(4641/9999): loss=4762.007479295407, w0=1.3946329490023341, w1=-45.71902664309211\n",
      "Gradient Descent(4642/9999): loss=4762.007479295407, w0=13.162932949002334, w1=-43.887426643092105\n",
      "Gradient Descent(4643/9999): loss=12293.047178186825, w0=1.0961675634488, w1=-49.49302664309211\n",
      "Gradient Descent(4644/9999): loss=5802.4994844197445, w0=1.0961675634488, w1=-49.49302664309211\n",
      "Gradient Descent(4645/9999): loss=5802.4994844197445, w0=14.561867563448802, w1=-42.39012664309211\n",
      "Gradient Descent(4646/9999): loss=5597.965626590983, w0=14.561867563448802, w1=-42.39012664309211\n",
      "Gradient Descent(4647/9999): loss=5597.965626590983, w0=25.732767563448803, w1=-35.42712664309211\n",
      "Gradient Descent(4648/9999): loss=16912.482208067762, w0=13.666002177895269, w1=-44.403926643092106\n",
      "Gradient Descent(4649/9999): loss=5255.292591372776, w0=13.666002177895269, w1=-44.403926643092106\n",
      "Gradient Descent(4650/9999): loss=5255.292591372776, w0=13.666002177895269, w1=-44.403926643092106\n",
      "Gradient Descent(4651/9999): loss=5255.292591372776, w0=13.666002177895269, w1=-44.403926643092106\n",
      "Gradient Descent(4652/9999): loss=5255.292591372776, w0=13.666002177895269, w1=-44.403926643092106\n",
      "Gradient Descent(4653/9999): loss=5255.292591372776, w0=13.666002177895269, w1=-44.403926643092106\n",
      "Gradient Descent(4654/9999): loss=5255.292591372776, w0=-13.13449782210473, w1=-55.399426643092106\n",
      "Gradient Descent(4655/9999): loss=5802.4994844197445, w0=-2.729597822104731, w1=-55.108726643092105\n",
      "Gradient Descent(4656/9999): loss=5790.986548954824, w0=-2.729597822104731, w1=-55.108726643092105\n",
      "Gradient Descent(4657/9999): loss=5790.986548954824, w0=-2.729597822104731, w1=-55.108726643092105\n",
      "Gradient Descent(4658/9999): loss=5790.986548954824, w0=7.50560217789527, w1=-49.483126643092106\n",
      "Gradient Descent(4659/9999): loss=5479.419461267378, w0=-1.7693978221047306, w1=-54.005526643092104\n",
      "Gradient Descent(4660/9999): loss=5595.008657104631, w0=-1.7693978221047306, w1=-54.005526643092104\n",
      "Gradient Descent(4661/9999): loss=5595.008657104631, w0=-1.7693978221047306, w1=-54.005526643092104\n",
      "Gradient Descent(4662/9999): loss=5595.008657104631, w0=-1.7693978221047306, w1=-54.005526643092104\n",
      "Gradient Descent(4663/9999): loss=5595.008657104631, w0=10.39060217789527, w1=-50.941126643092105\n",
      "Gradient Descent(4664/9999): loss=9057.947211795945, w0=10.39060217789527, w1=-50.941126643092105\n",
      "Gradient Descent(4665/9999): loss=9057.947211795945, w0=10.39060217789527, w1=-50.941126643092105\n",
      "Gradient Descent(4666/9999): loss=9057.947211795945, w0=10.39060217789527, w1=-50.941126643092105\n",
      "Gradient Descent(4667/9999): loss=9057.947211795945, w0=10.39060217789527, w1=-50.941126643092105\n",
      "Gradient Descent(4668/9999): loss=9057.947211795945, w0=10.39060217789527, w1=-50.941126643092105\n",
      "Gradient Descent(4669/9999): loss=9057.947211795945, w0=-3.811097822104731, w1=-51.727126643092106\n",
      "Gradient Descent(4670/9999): loss=5367.574788893554, w0=8.255667563448803, w1=-44.91082664309211\n",
      "Gradient Descent(4671/9999): loss=7797.015049647178, w0=8.255667563448803, w1=-44.91082664309211\n",
      "Gradient Descent(4672/9999): loss=7797.015049647178, w0=8.255667563448803, w1=-44.91082664309211\n",
      "Gradient Descent(4673/9999): loss=7797.015049647178, w0=8.255667563448803, w1=-44.91082664309211\n",
      "Gradient Descent(4674/9999): loss=7797.015049647178, w0=8.255667563448803, w1=-44.91082664309211\n",
      "Gradient Descent(4675/9999): loss=7797.015049647178, w0=8.255667563448803, w1=-44.91082664309211\n",
      "Gradient Descent(4676/9999): loss=7797.015049647178, w0=8.255667563448803, w1=-44.91082664309211\n",
      "Gradient Descent(4677/9999): loss=7797.015049647178, w0=8.255667563448803, w1=-44.91082664309211\n",
      "Gradient Descent(4678/9999): loss=7797.015049647178, w0=-3.1473324365511974, w1=-48.34942664309211\n",
      "Gradient Descent(4679/9999): loss=5790.986548954824, w0=-3.1473324365511974, w1=-48.34942664309211\n",
      "Gradient Descent(4680/9999): loss=5790.986548954824, w0=-3.1473324365511974, w1=-48.34942664309211\n",
      "Gradient Descent(4681/9999): loss=5790.986548954824, w0=-3.1473324365511974, w1=-48.34942664309211\n",
      "Gradient Descent(4682/9999): loss=5790.986548954824, w0=9.591367563448804, w1=-44.61372664309211\n",
      "Gradient Descent(4683/9999): loss=5820.8075926726315, w0=-0.6059324365511962, w1=-45.67812664309211\n",
      "Gradient Descent(4684/9999): loss=5802.4994844197445, w0=-0.6059324365511962, w1=-45.67812664309211\n",
      "Gradient Descent(4685/9999): loss=5802.4994844197445, w0=-0.6059324365511962, w1=-45.67812664309211\n",
      "Gradient Descent(4686/9999): loss=5802.4994844197445, w0=-0.6059324365511962, w1=-45.67812664309211\n",
      "Gradient Descent(4687/9999): loss=5802.4994844197445, w0=10.225967563448805, w1=-38.720926643092106\n",
      "Gradient Descent(4688/9999): loss=5120.7908620339185, w0=10.225967563448805, w1=-38.720926643092106\n",
      "Gradient Descent(4689/9999): loss=5120.7908620339185, w0=10.225967563448805, w1=-38.720926643092106\n",
      "Gradient Descent(4690/9999): loss=5120.7908620339185, w0=10.225967563448805, w1=-38.720926643092106\n",
      "Gradient Descent(4691/9999): loss=5120.7908620339185, w0=10.225967563448805, w1=-38.720926643092106\n",
      "Gradient Descent(4692/9999): loss=5120.7908620339185, w0=2.4010675634488052, w1=-45.836726643092106\n",
      "Gradient Descent(4693/9999): loss=5802.4994844197445, w0=11.689267563448807, w1=-45.741226643092105\n",
      "Gradient Descent(4694/9999): loss=4772.741687758657, w0=11.689267563448807, w1=-45.741226643092105\n",
      "Gradient Descent(4695/9999): loss=4772.741687758657, w0=11.689267563448807, w1=-45.741226643092105\n",
      "Gradient Descent(4696/9999): loss=4772.741687758657, w0=11.689267563448807, w1=-45.741226643092105\n",
      "Gradient Descent(4697/9999): loss=4772.741687758657, w0=11.689267563448807, w1=-45.741226643092105\n",
      "Gradient Descent(4698/9999): loss=4772.741687758657, w0=23.071467563448806, w1=-40.357626643092104\n",
      "Gradient Descent(4699/9999): loss=13287.534618229376, w0=23.071467563448806, w1=-40.357626643092104\n",
      "Gradient Descent(4700/9999): loss=13287.534618229376, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4701/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4702/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4703/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4704/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4705/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4706/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4707/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4708/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4709/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4710/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4711/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4712/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4713/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4714/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4715/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4716/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4717/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4718/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4719/9999): loss=4396.215554484865, w0=14.184367563448804, w1=-47.483726643092105\n",
      "Gradient Descent(4720/9999): loss=4396.215554484865, w0=4.792167563448803, w1=-48.669326643092106\n",
      "Gradient Descent(4721/9999): loss=5802.4994844197445, w0=16.781467563448803, w1=-48.381026643092106\n",
      "Gradient Descent(4722/9999): loss=4380.119853885639, w0=7.355067563448804, w1=-51.03932664309211\n",
      "Gradient Descent(4723/9999): loss=5802.4994844197445, w0=18.737267563448803, w1=-45.65572664309211\n",
      "Gradient Descent(4724/9999): loss=5071.911360403454, w0=18.737267563448803, w1=-45.65572664309211\n",
      "Gradient Descent(4725/9999): loss=5071.911360403454, w0=18.737267563448803, w1=-45.65572664309211\n",
      "Gradient Descent(4726/9999): loss=5071.911360403454, w0=18.737004297298395, w1=-45.65588826486353\n",
      "Gradient Descent(4727/9999): loss=5072.095807281009, w0=18.737004297298395, w1=-45.65588826486353\n",
      "Gradient Descent(4728/9999): loss=5072.095807281009, w0=18.737004297298395, w1=-45.65588826486353\n",
      "Gradient Descent(4729/9999): loss=5072.095807281009, w0=18.737004297298395, w1=-45.65588826486353\n",
      "Gradient Descent(4730/9999): loss=5072.095807281009, w0=18.737004297298395, w1=-45.65588826486353\n",
      "Gradient Descent(4731/9999): loss=5072.095807281009, w0=18.737004297298395, w1=-45.65588826486353\n",
      "Gradient Descent(4732/9999): loss=5072.095807281009, w0=-8.368695702701608, w1=-56.19858826486353\n",
      "Gradient Descent(4733/9999): loss=5802.4994844197445, w0=13.075004297298396, w1=-49.59868826486353\n",
      "Gradient Descent(4734/9999): loss=4774.948475549128, w0=26.379504297298396, w1=-45.93598826486353\n",
      "Gradient Descent(4735/9999): loss=14664.722549811398, w0=26.379504297298396, w1=-45.93598826486353\n",
      "Gradient Descent(4736/9999): loss=14664.722549811398, w0=14.312738911744862, w1=-52.76368826486353\n",
      "Gradient Descent(4737/9999): loss=4663.391019041218, w0=14.312738911744862, w1=-52.76368826486353\n",
      "Gradient Descent(4738/9999): loss=4663.391019041218, w0=14.312738911744862, w1=-52.76368826486353\n",
      "Gradient Descent(4739/9999): loss=4663.391019041218, w0=14.312738911744862, w1=-52.76368826486353\n",
      "Gradient Descent(4740/9999): loss=4663.391019041218, w0=14.312738911744862, w1=-52.76368826486353\n",
      "Gradient Descent(4741/9999): loss=4663.391019041218, w0=14.312738911744862, w1=-52.76368826486353\n",
      "Gradient Descent(4742/9999): loss=4663.391019041218, w0=14.312738911744862, w1=-52.76368826486353\n",
      "Gradient Descent(4743/9999): loss=4663.391019041218, w0=14.312738911744862, w1=-52.76368826486353\n",
      "Gradient Descent(4744/9999): loss=4663.391019041218, w0=14.312738911744862, w1=-52.76368826486353\n",
      "Gradient Descent(4745/9999): loss=4663.391019041218, w0=14.312738911744862, w1=-52.76368826486353\n",
      "Gradient Descent(4746/9999): loss=4663.391019041218, w0=14.312738911744862, w1=-52.76368826486353\n",
      "Gradient Descent(4747/9999): loss=4663.391019041218, w0=14.312738911744862, w1=-52.76368826486353\n",
      "Gradient Descent(4748/9999): loss=4663.391019041218, w0=14.312738911744862, w1=-52.76368826486353\n",
      "Gradient Descent(4749/9999): loss=4663.391019041218, w0=14.312738913640679, w1=-52.7636882641726\n",
      "Gradient Descent(4750/9999): loss=4663.391019344807, w0=14.312738913640679, w1=-52.7636882641726\n",
      "Gradient Descent(4751/9999): loss=4663.391019344807, w0=6.971938913640678, w1=-55.2760882641726\n",
      "Gradient Descent(4752/9999): loss=5802.4994844197445, w0=6.971938913640678, w1=-55.2760882641726\n",
      "Gradient Descent(4753/9999): loss=5802.4994844197445, w0=6.971938913640678, w1=-55.2760882641726\n",
      "Gradient Descent(4754/9999): loss=5802.4994844197445, w0=6.971938913640678, w1=-55.2760882641726\n",
      "Gradient Descent(4755/9999): loss=5802.4994844197445, w0=6.971938913640678, w1=-55.2760882641726\n",
      "Gradient Descent(4756/9999): loss=5802.4994844197445, w0=19.03870429919421, w1=-42.9733882641726\n",
      "Gradient Descent(4757/9999): loss=4401.992194814908, w0=19.03870429919421, w1=-42.9733882641726\n",
      "Gradient Descent(4758/9999): loss=4401.992194814908, w0=19.03870429919421, w1=-42.9733882641726\n",
      "Gradient Descent(4759/9999): loss=4401.992194814908, w0=32.35620429919422, w1=-33.5761882641726\n",
      "Gradient Descent(4760/9999): loss=16336.579734749153, w0=18.518504299194216, w1=-43.3341882641726\n",
      "Gradient Descent(4761/9999): loss=4697.302122144726, w0=18.518504299194216, w1=-43.3341882641726\n",
      "Gradient Descent(4762/9999): loss=4697.302122144726, w0=18.518504299194216, w1=-43.3341882641726\n",
      "Gradient Descent(4763/9999): loss=4697.302122144726, w0=18.518504299194216, w1=-43.3341882641726\n",
      "Gradient Descent(4764/9999): loss=4697.302122144726, w0=34.32770429919422, w1=-39.441288264172606\n",
      "Gradient Descent(4765/9999): loss=16060.369818821906, w0=34.32770429919422, w1=-39.441288264172606\n",
      "Gradient Descent(4766/9999): loss=16060.369818821906, w0=34.32770429919422, w1=-39.441288264172606\n",
      "Gradient Descent(4767/9999): loss=16060.369818821906, w0=22.260938913640683, w1=-46.39428826417261\n",
      "Gradient Descent(4768/9999): loss=4233.0752018557905, w0=22.260938913640683, w1=-46.39428826417261\n",
      "Gradient Descent(4769/9999): loss=4233.0752018557905, w0=22.260938913640683, w1=-46.39428826417261\n",
      "Gradient Descent(4770/9999): loss=4233.0752018557905, w0=22.260938913640683, w1=-46.39428826417261\n",
      "Gradient Descent(4771/9999): loss=4233.0752018557905, w0=22.260938913640683, w1=-46.39428826417261\n",
      "Gradient Descent(4772/9999): loss=4233.0752018557905, w0=22.260938913640683, w1=-46.39428826417261\n",
      "Gradient Descent(4773/9999): loss=4233.0752018557905, w0=9.347438913640683, w1=-50.14068826417261\n",
      "Gradient Descent(4774/9999): loss=5802.4994844197445, w0=9.347438913640683, w1=-50.14068826417261\n",
      "Gradient Descent(4775/9999): loss=5802.4994844197445, w0=9.347438913640683, w1=-50.14068826417261\n",
      "Gradient Descent(4776/9999): loss=5802.4994844197445, w0=9.347438913640683, w1=-50.14068826417261\n",
      "Gradient Descent(4777/9999): loss=5802.4994844197445, w0=9.347438913640683, w1=-50.14068826417261\n",
      "Gradient Descent(4778/9999): loss=5802.4994844197445, w0=9.347438913640683, w1=-50.14068826417261\n",
      "Gradient Descent(4779/9999): loss=5802.4994844197445, w0=23.964138913640685, w1=-49.99558826417261\n",
      "Gradient Descent(4780/9999): loss=4758.7108577117415, w0=23.964138913640685, w1=-49.99558826417261\n",
      "Gradient Descent(4781/9999): loss=4758.7108577117415, w0=23.964138913640685, w1=-49.99558826417261\n",
      "Gradient Descent(4782/9999): loss=4758.7108577117415, w0=23.964138913640685, w1=-49.99558826417261\n",
      "Gradient Descent(4783/9999): loss=4758.7108577117415, w0=23.964138913640685, w1=-49.99558826417261\n",
      "Gradient Descent(4784/9999): loss=4758.7108577117415, w0=16.080338913640684, w1=-52.69788826417261\n",
      "Gradient Descent(4785/9999): loss=5802.4994844197445, w0=32.91173891364069, w1=-50.09508826417261\n",
      "Gradient Descent(4786/9999): loss=11059.758566070097, w0=16.70143891364069, w1=-58.190888264172614\n",
      "Gradient Descent(4787/9999): loss=5790.986548979277, w0=16.70143891364069, w1=-58.190888264172614\n",
      "Gradient Descent(4788/9999): loss=5790.986548979277, w0=16.70143891364069, w1=-58.190888264172614\n",
      "Gradient Descent(4789/9999): loss=5790.986548979277, w0=16.70143891364069, w1=-58.190888264172614\n",
      "Gradient Descent(4790/9999): loss=5790.986548979277, w0=28.27273891364069, w1=-55.811888264172616\n",
      "Gradient Descent(4791/9999): loss=4362.1250693344355, w0=28.27273891364069, w1=-55.811888264172616\n",
      "Gradient Descent(4792/9999): loss=4362.1250693344355, w0=28.27273891364069, w1=-55.811888264172616\n",
      "Gradient Descent(4793/9999): loss=4362.1250693344355, w0=28.27273891364069, w1=-55.811888264172616\n",
      "Gradient Descent(4794/9999): loss=4362.1250693344355, w0=16.86973891364069, w1=-59.25048826417262\n",
      "Gradient Descent(4795/9999): loss=5802.4994844197445, w0=16.86973891364069, w1=-59.25048826417262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(4796/9999): loss=5802.4994844197445, w0=29.14273891364069, w1=-57.77318826417262\n",
      "Gradient Descent(4797/9999): loss=4293.991639785818, w0=29.14273891364069, w1=-57.77318826417262\n",
      "Gradient Descent(4798/9999): loss=4293.991639785818, w0=43.12963891364069, w1=-49.300088264172615\n",
      "Gradient Descent(4799/9999): loss=16236.151593064626, w0=43.12963891364069, w1=-49.300088264172615\n",
      "Gradient Descent(4800/9999): loss=16236.151593064626, w0=31.062873528087156, w1=-56.186188264172614\n",
      "Gradient Descent(4801/9999): loss=5676.723955389042, w0=31.062873528087156, w1=-56.186188264172614\n",
      "Gradient Descent(4802/9999): loss=5676.723955389042, w0=31.062873528087156, w1=-56.186188264172614\n",
      "Gradient Descent(4803/9999): loss=5676.723955389042, w0=31.062873528087156, w1=-56.186188264172614\n",
      "Gradient Descent(4804/9999): loss=5676.723955389042, w0=31.062873528087156, w1=-56.186188264172614\n",
      "Gradient Descent(4805/9999): loss=5676.723955389042, w0=21.288473528087156, w1=-58.29178826417262\n",
      "Gradient Descent(4806/9999): loss=4800.874217594529, w0=21.288473528087156, w1=-58.29178826417262\n",
      "Gradient Descent(4807/9999): loss=4800.874217594529, w0=21.288473528087156, w1=-58.29178826417262\n",
      "Gradient Descent(4808/9999): loss=4800.874217594529, w0=30.264773528087154, w1=-54.34498826417261\n",
      "Gradient Descent(4809/9999): loss=5718.182537941292, w0=30.264773528087154, w1=-54.34498826417261\n",
      "Gradient Descent(4810/9999): loss=5718.182537941292, w0=13.741873528087151, w1=-61.86188826417261\n",
      "Gradient Descent(4811/9999): loss=5696.240015209674, w0=13.741873528087151, w1=-61.86188826417261\n",
      "Gradient Descent(4812/9999): loss=5696.240015209674, w0=24.233073528087154, w1=-59.245688264172614\n",
      "Gradient Descent(4813/9999): loss=4783.996364336088, w0=35.78057352808715, w1=-55.69128826417261\n",
      "Gradient Descent(4814/9999): loss=16128.916484110938, w0=35.78057352808715, w1=-55.69128826417261\n",
      "Gradient Descent(4815/9999): loss=16128.916484110938, w0=28.782073528087153, w1=-59.419988264172616\n",
      "Gradient Descent(4816/9999): loss=7136.690408456172, w0=19.631673528087155, w1=-62.73448826417262\n",
      "Gradient Descent(4817/9999): loss=4398.371794571699, w0=19.631673528087155, w1=-62.73448826417262\n",
      "Gradient Descent(4818/9999): loss=4398.371794571699, w0=19.631673528087155, w1=-62.73448826417262\n",
      "Gradient Descent(4819/9999): loss=4398.371794571699, w0=19.631673528087155, w1=-62.73448826417262\n",
      "Gradient Descent(4820/9999): loss=4398.371794571699, w0=19.631673528087155, w1=-62.73448826417262\n",
      "Gradient Descent(4821/9999): loss=4398.371794571699, w0=19.631673528087155, w1=-62.73448826417262\n",
      "Gradient Descent(4822/9999): loss=4398.371794571699, w0=19.631673528087155, w1=-62.73448826417262\n",
      "Gradient Descent(4823/9999): loss=4398.371794571699, w0=19.631673528087155, w1=-62.73448826417262\n",
      "Gradient Descent(4824/9999): loss=4398.371794571699, w0=19.631673528087155, w1=-62.73448826417262\n",
      "Gradient Descent(4825/9999): loss=4398.371794571699, w0=19.631673528087155, w1=-62.73448826417262\n",
      "Gradient Descent(4826/9999): loss=4398.371794571699, w0=19.631673528087155, w1=-62.73448826417262\n",
      "Gradient Descent(4827/9999): loss=4398.371794571699, w0=19.631673528087155, w1=-62.73448826417262\n",
      "Gradient Descent(4828/9999): loss=4398.371794571699, w0=19.631673528087155, w1=-62.73448826417262\n",
      "Gradient Descent(4829/9999): loss=4398.371794571699, w0=19.631673528087155, w1=-62.73448826417262\n",
      "Gradient Descent(4830/9999): loss=4398.371794571699, w0=34.22977352808716, w1=-61.389588264172616\n",
      "Gradient Descent(4831/9999): loss=9383.974688756709, w0=27.876473528087157, w1=-65.81558826417262\n",
      "Gradient Descent(4832/9999): loss=4293.112898112022, w0=27.876473528087157, w1=-65.81558826417262\n",
      "Gradient Descent(4833/9999): loss=4293.112898112022, w0=36.852773528087155, w1=-61.868788264172615\n",
      "Gradient Descent(4834/9999): loss=12013.106241530566, w0=36.852773528087155, w1=-61.868788264172615\n",
      "Gradient Descent(4835/9999): loss=12013.106241530566, w0=36.852773528087155, w1=-61.868788264172615\n",
      "Gradient Descent(4836/9999): loss=12013.106241530566, w0=28.386373528087155, w1=-65.60418826417262\n",
      "Gradient Descent(4837/9999): loss=4190.473219511019, w0=28.386373528087155, w1=-65.60418826417262\n",
      "Gradient Descent(4838/9999): loss=4190.473219511019, w0=28.386373528087155, w1=-65.60418826417262\n",
      "Gradient Descent(4839/9999): loss=4190.473219511019, w0=28.386373528087155, w1=-65.60418826417262\n",
      "Gradient Descent(4840/9999): loss=4190.473219511019, w0=28.386373528087155, w1=-65.60418826417262\n",
      "Gradient Descent(4841/9999): loss=4190.473219511019, w0=28.386373528087155, w1=-65.60418826417262\n",
      "Gradient Descent(4842/9999): loss=4190.473219511019, w0=28.386373528087155, w1=-65.60418826417262\n",
      "Gradient Descent(4843/9999): loss=4190.473219511019, w0=41.93137352808716, w1=-62.75488826417262\n",
      "Gradient Descent(4844/9999): loss=13506.405139128148, w0=24.097573528087157, w1=-70.67978826417261\n",
      "Gradient Descent(4845/9999): loss=4352.995898924082, w0=24.097573528087157, w1=-70.67978826417261\n",
      "Gradient Descent(4846/9999): loss=4352.995898924082, w0=24.097573528087157, w1=-70.67978826417261\n",
      "Gradient Descent(4847/9999): loss=4352.995898924082, w0=24.097573528087157, w1=-70.67978826417261\n",
      "Gradient Descent(4848/9999): loss=4352.995898924082, w0=36.16433891364069, w1=-57.647888264172614\n",
      "Gradient Descent(4849/9999): loss=15466.86231350909, w0=28.97913891364069, w1=-59.96098826417261\n",
      "Gradient Descent(4850/9999): loss=4428.623174305588, w0=28.97913891364069, w1=-59.96098826417261\n",
      "Gradient Descent(4851/9999): loss=4428.623174305588, w0=28.97913891364069, w1=-59.96098826417261\n",
      "Gradient Descent(4852/9999): loss=4428.623174305588, w0=20.860738913640688, w1=-61.26808826417261\n",
      "Gradient Descent(4853/9999): loss=5536.308575820403, w0=20.860738913640688, w1=-61.26808826417261\n",
      "Gradient Descent(4854/9999): loss=5536.308575820403, w0=20.860738913640688, w1=-61.26808826417261\n",
      "Gradient Descent(4855/9999): loss=5536.308575820403, w0=20.860738913640688, w1=-61.26808826417261\n",
      "Gradient Descent(4856/9999): loss=5536.308575820403, w0=20.860738913640688, w1=-61.26808826417261\n",
      "Gradient Descent(4857/9999): loss=5536.308575820403, w0=20.860738913640688, w1=-61.26808826417261\n",
      "Gradient Descent(4858/9999): loss=5536.308575820403, w0=31.12383891364069, w1=-54.61948826417261\n",
      "Gradient Descent(4859/9999): loss=4497.150050811906, w0=31.12383891364069, w1=-54.61948826417261\n",
      "Gradient Descent(4860/9999): loss=4497.150050811906, w0=40.28523891364069, w1=-47.044888264172606\n",
      "Gradient Descent(4861/9999): loss=16425.706495812017, w0=33.28183891364069, w1=-54.22518826417261\n",
      "Gradient Descent(4862/9999): loss=7080.45061790978, w0=33.28183891364069, w1=-54.22518826417261\n",
      "Gradient Descent(4863/9999): loss=7080.45061790978, w0=45.95613891364069, w1=-48.77868826417261\n",
      "Gradient Descent(4864/9999): loss=16785.849179262448, w0=38.548038913640696, w1=-52.49168826417261\n",
      "Gradient Descent(4865/9999): loss=8630.253298067593, w0=38.548038913640696, w1=-52.49168826417261\n",
      "Gradient Descent(4866/9999): loss=8630.253298067593, w0=38.548038913640696, w1=-52.49168826417261\n",
      "Gradient Descent(4867/9999): loss=8630.253298067593, w0=29.7557389136407, w1=-55.20868826417261\n",
      "Gradient Descent(4868/9999): loss=4743.425293947455, w0=41.8981389136407, w1=-52.293588264172605\n",
      "Gradient Descent(4869/9999): loss=10786.901320348195, w0=29.0095389136407, w1=-52.334688264172605\n",
      "Gradient Descent(4870/9999): loss=5194.483308252778, w0=29.0095389136407, w1=-52.334688264172605\n",
      "Gradient Descent(4871/9999): loss=5194.483308252778, w0=29.0095389136407, w1=-52.334688264172605\n",
      "Gradient Descent(4872/9999): loss=5194.483308252778, w0=29.0095389136407, w1=-52.334688264172605\n",
      "Gradient Descent(4873/9999): loss=5194.483308252778, w0=29.0095389136407, w1=-52.334688264172605\n",
      "Gradient Descent(4874/9999): loss=5194.483308252778, w0=29.0095389136407, w1=-52.334688264172605\n",
      "Gradient Descent(4875/9999): loss=5194.483308252778, w0=39.1929389136407, w1=-48.87668826417261\n",
      "Gradient Descent(4876/9999): loss=12142.675070385274, w0=39.1929389136407, w1=-48.87668826417261\n",
      "Gradient Descent(4877/9999): loss=12142.675070385274, w0=22.515038913640698, w1=-48.93328826417261\n",
      "Gradient Descent(4878/9999): loss=5525.646962887123, w0=22.515038913640698, w1=-48.93328826417261\n",
      "Gradient Descent(4879/9999): loss=5525.646962887123, w0=22.515038913640698, w1=-48.93328826417261\n",
      "Gradient Descent(4880/9999): loss=5525.646962887123, w0=22.515038913640698, w1=-48.93328826417261\n",
      "Gradient Descent(4881/9999): loss=5525.646962887123, w0=22.515038913640698, w1=-48.93328826417261\n",
      "Gradient Descent(4882/9999): loss=5525.646962887123, w0=31.5197389136407, w1=-44.67318826417261\n",
      "Gradient Descent(4883/9999): loss=7717.022744821589, w0=19.452973528087167, w1=-52.14498826417261\n",
      "Gradient Descent(4884/9999): loss=4681.858941853985, w0=36.42867352808717, w1=-47.81998826417261\n",
      "Gradient Descent(4885/9999): loss=15367.905440901104, w0=21.790173528087166, w1=-53.675188264172604\n",
      "Gradient Descent(4886/9999): loss=4465.194503192897, w0=34.73287352808717, w1=-45.7884882641726\n",
      "Gradient Descent(4887/9999): loss=15858.738886835015, w0=34.73287352808717, w1=-45.7884882641726\n",
      "Gradient Descent(4888/9999): loss=15858.738886835015, w0=20.835573528087167, w1=-55.7938882641726\n",
      "Gradient Descent(4889/9999): loss=4427.621524875056, w0=20.835573528087167, w1=-55.7938882641726\n",
      "Gradient Descent(4890/9999): loss=4427.621524875056, w0=20.835573528087167, w1=-55.7938882641726\n",
      "Gradient Descent(4891/9999): loss=4427.621524875056, w0=20.835573528087167, w1=-55.7938882641726\n",
      "Gradient Descent(4892/9999): loss=4427.621524875056, w0=20.835573528087167, w1=-55.7938882641726\n",
      "Gradient Descent(4893/9999): loss=4427.621524875056, w0=9.060673528087166, w1=-58.5494882641726\n",
      "Gradient Descent(4894/9999): loss=5802.4994844197445, w0=9.060673528087166, w1=-58.5494882641726\n",
      "Gradient Descent(4895/9999): loss=5802.4994844197445, w0=9.060673528087166, w1=-58.5494882641726\n",
      "Gradient Descent(4896/9999): loss=5802.4994844197445, w0=9.060673528087166, w1=-58.5494882641726\n",
      "Gradient Descent(4897/9999): loss=5802.4994844197445, w0=19.601473528087165, w1=-57.656588264172605\n",
      "Gradient Descent(4898/9999): loss=4601.803060369982, w0=19.601473528087165, w1=-57.656588264172605\n",
      "Gradient Descent(4899/9999): loss=4601.803060369982, w0=19.601473528087165, w1=-57.656588264172605\n",
      "Gradient Descent(4900/9999): loss=4601.803060369982, w0=19.601473528087165, w1=-57.656588264172605\n",
      "Gradient Descent(4901/9999): loss=4601.803060369982, w0=19.601473528087165, w1=-57.656588264172605\n",
      "Gradient Descent(4902/9999): loss=4601.803060369982, w0=19.601473528087165, w1=-57.656588264172605\n",
      "Gradient Descent(4903/9999): loss=4601.803060369982, w0=19.601473528087165, w1=-57.656588264172605\n",
      "Gradient Descent(4904/9999): loss=4601.803060369982, w0=19.601473528087165, w1=-57.656588264172605\n",
      "Gradient Descent(4905/9999): loss=4601.803060369982, w0=9.723473528087165, w1=-58.128588264172606\n",
      "Gradient Descent(4906/9999): loss=5802.4994844197445, w0=21.110273528087166, w1=-58.0171882641726\n",
      "Gradient Descent(4907/9999): loss=4499.965820419364, w0=21.110273528087166, w1=-58.0171882641726\n",
      "Gradient Descent(4908/9999): loss=4499.965820419364, w0=21.110273528087166, w1=-58.0171882641726\n",
      "Gradient Descent(4909/9999): loss=4499.965820419364, w0=21.110273528087166, w1=-58.0171882641726\n",
      "Gradient Descent(4910/9999): loss=4499.965820419364, w0=21.110273528087166, w1=-58.0171882641726\n",
      "Gradient Descent(4911/9999): loss=4499.965820419364, w0=21.110273528087166, w1=-58.0171882641726\n",
      "Gradient Descent(4912/9999): loss=4499.965820419364, w0=21.110273528087166, w1=-58.0171882641726\n",
      "Gradient Descent(4913/9999): loss=4499.965820419364, w0=21.110273528087166, w1=-58.0171882641726\n",
      "Gradient Descent(4914/9999): loss=4499.965820419364, w0=30.411873528087167, w1=-50.0220882641726\n",
      "Gradient Descent(4915/9999): loss=15884.656838821002, w0=19.414973528087167, w1=-51.9509882641726\n",
      "Gradient Descent(4916/9999): loss=6229.025812855554, w0=19.414973528087167, w1=-51.9509882641726\n",
      "Gradient Descent(4917/9999): loss=6229.025812855554, w0=19.414973528087167, w1=-51.9509882641726\n",
      "Gradient Descent(4918/9999): loss=6229.025812855554, w0=19.414973528087167, w1=-51.9509882641726\n",
      "Gradient Descent(4919/9999): loss=6229.025812855554, w0=19.414973528087167, w1=-51.9509882641726\n",
      "Gradient Descent(4920/9999): loss=6229.025812855554, w0=7.1703735280871665, w1=-57.1727882641726\n",
      "Gradient Descent(4921/9999): loss=5698.994467415038, w0=7.1703735280871665, w1=-57.1727882641726\n",
      "Gradient Descent(4922/9999): loss=5698.994467415038, w0=7.1703735280871665, w1=-57.1727882641726\n",
      "Gradient Descent(4923/9999): loss=5698.994467415038, w0=19.939973528087165, w1=-51.4743882641726\n",
      "Gradient Descent(4924/9999): loss=6288.460448081492, w0=19.939973528087165, w1=-51.4743882641726\n",
      "Gradient Descent(4925/9999): loss=6288.460448081492, w0=0.107773528087165, w1=-59.2512882641726\n",
      "Gradient Descent(4926/9999): loss=5802.4994844197445, w0=0.107773528087165, w1=-59.2512882641726\n",
      "Gradient Descent(4927/9999): loss=5802.4994844197445, w0=8.419773528087166, w1=-55.452788264172604\n",
      "Gradient Descent(4928/9999): loss=5169.998505079335, w0=19.857073528087167, w1=-51.489888264172606\n",
      "Gradient Descent(4929/9999): loss=9036.27146085371, w0=31.9238389136407, w1=-38.83798826417261\n",
      "Gradient Descent(4930/9999): loss=16923.99514353268, w0=31.9238389136407, w1=-38.83798826417261\n",
      "Gradient Descent(4931/9999): loss=16923.99514353268, w0=24.0989389136407, w1=-45.95378826417261\n",
      "Gradient Descent(4932/9999): loss=7524.4482722554185, w0=15.925138913640701, w1=-48.249288264172606\n",
      "Gradient Descent(4933/9999): loss=4856.133680257632, w0=15.925138913640701, w1=-48.249288264172606\n",
      "Gradient Descent(4934/9999): loss=4856.133680257632, w0=15.925138913640701, w1=-48.249288264172606\n",
      "Gradient Descent(4935/9999): loss=4856.133680257632, w0=15.925138913640701, w1=-48.249288264172606\n",
      "Gradient Descent(4936/9999): loss=4856.133680257632, w0=15.925138913640701, w1=-48.249288264172606\n",
      "Gradient Descent(4937/9999): loss=4856.133680257632, w0=15.925138913640701, w1=-48.249288264172606\n",
      "Gradient Descent(4938/9999): loss=4856.133680257632, w0=15.925138913640701, w1=-48.249288264172606\n",
      "Gradient Descent(4939/9999): loss=4856.133680257632, w0=23.526738913640703, w1=-44.025188264172606\n",
      "Gradient Descent(4940/9999): loss=5605.729775501107, w0=23.526738913640703, w1=-44.025188264172606\n",
      "Gradient Descent(4941/9999): loss=5605.729775501107, w0=23.526738913640703, w1=-44.025188264172606\n",
      "Gradient Descent(4942/9999): loss=5605.729775501107, w0=23.526738913640703, w1=-44.025188264172606\n",
      "Gradient Descent(4943/9999): loss=5605.729775501107, w0=23.526738913640703, w1=-44.025188264172606\n",
      "Gradient Descent(4944/9999): loss=5605.729775501107, w0=15.067538913640702, w1=-44.3341882641726\n",
      "Gradient Descent(4945/9999): loss=5081.3147142674625, w0=24.976138913640703, w1=-40.2050882641726\n",
      "Gradient Descent(4946/9999): loss=13988.879320205757, w0=4.274438913640701, w1=-47.7593882641726\n",
      "Gradient Descent(4947/9999): loss=5790.982023611865, w0=13.720838913640701, w1=-44.2862882641726\n",
      "Gradient Descent(4948/9999): loss=6454.84018732708, w0=13.720838913640701, w1=-44.2862882641726\n",
      "Gradient Descent(4949/9999): loss=6454.84018732708, w0=-3.425761086359298, w1=-55.1690882641726\n",
      "Gradient Descent(4950/9999): loss=5802.4994844197445, w0=-3.425761086359298, w1=-55.1690882641726\n",
      "Gradient Descent(4951/9999): loss=5802.4994844197445, w0=-3.425761086359298, w1=-55.1690882641726\n",
      "Gradient Descent(4952/9999): loss=5802.4994844197445, w0=10.868138913640703, w1=-54.4138882641726\n",
      "Gradient Descent(4953/9999): loss=4612.911312505003, w0=10.868138913640703, w1=-54.4138882641726\n",
      "Gradient Descent(4954/9999): loss=4612.911312505003, w0=19.019238913640706, w1=-52.1559882641726\n",
      "Gradient Descent(4955/9999): loss=6296.162251899885, w0=26.883838913640705, w1=-48.2391882641726\n",
      "Gradient Descent(4956/9999): loss=14730.245070512712, w0=19.584438913640703, w1=-50.6163882641726\n",
      "Gradient Descent(4957/9999): loss=5771.6462086716765, w0=19.584438913640703, w1=-50.6163882641726\n",
      "Gradient Descent(4958/9999): loss=5771.6462086716765, w0=19.584438913640703, w1=-50.6163882641726\n",
      "Gradient Descent(4959/9999): loss=5771.6462086716765, w0=19.584438913640703, w1=-50.6163882641726\n",
      "Gradient Descent(4960/9999): loss=5771.6462086716765, w0=19.584438913640703, w1=-50.6163882641726\n",
      "Gradient Descent(4961/9999): loss=5771.6462086716765, w0=19.584438913640703, w1=-50.6163882641726\n",
      "Gradient Descent(4962/9999): loss=5771.6462086716765, w0=9.880038913640703, w1=-52.1810882641726\n",
      "Gradient Descent(4963/9999): loss=5622.860926473993, w0=9.880038913640703, w1=-52.1810882641726\n",
      "Gradient Descent(4964/9999): loss=5622.860926473993, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4965/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4966/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4967/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4968/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4969/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4970/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4971/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4972/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4973/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4974/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4975/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4976/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4977/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4978/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4979/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4980/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4981/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4982/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4983/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4984/9999): loss=6562.175151558251, w0=24.14473891364071, w1=-50.3053882641726\n",
      "Gradient Descent(4985/9999): loss=6562.175151558251, w0=12.077973528087174, w1=-57.338888264172596\n",
      "Gradient Descent(4986/9999): loss=4574.501155259376, w0=12.077973528087174, w1=-57.338888264172596\n",
      "Gradient Descent(4987/9999): loss=4574.501155259376, w0=12.077973528087174, w1=-57.338888264172596\n",
      "Gradient Descent(4988/9999): loss=4574.501155259376, w0=12.077973528087174, w1=-57.338888264172596\n",
      "Gradient Descent(4989/9999): loss=4574.501155259376, w0=12.077973528087174, w1=-57.338888264172596\n",
      "Gradient Descent(4990/9999): loss=4574.501155259376, w0=12.077973528087174, w1=-57.338888264172596\n",
      "Gradient Descent(4991/9999): loss=4574.501155259376, w0=12.077973528087174, w1=-57.338888264172596\n",
      "Gradient Descent(4992/9999): loss=4574.501155259376, w0=12.077973528087174, w1=-57.338888264172596\n",
      "Gradient Descent(4993/9999): loss=4574.501155259376, w0=12.077973528087174, w1=-57.338888264172596\n",
      "Gradient Descent(4994/9999): loss=4574.501155259376, w0=24.14473891364071, w1=-38.5114882641726\n",
      "Gradient Descent(4995/9999): loss=14978.13582253039, w0=17.986338913640708, w1=-43.8468882641726\n",
      "Gradient Descent(4996/9999): loss=4220.120675147574, w0=17.986338913640708, w1=-43.8468882641726\n",
      "Gradient Descent(4997/9999): loss=4220.120675147574, w0=27.594138913640705, w1=-41.2212882641726\n",
      "Gradient Descent(4998/9999): loss=15703.915441278237, w0=27.594138913640705, w1=-41.2212882641726\n",
      "Gradient Descent(4999/9999): loss=15703.915441278237, w0=18.518838913640707, w1=-47.7621882641726\n",
      "Gradient Descent(5000/9999): loss=4910.419021104033, w0=18.518838913640707, w1=-47.7621882641726\n",
      "Gradient Descent(5001/9999): loss=4910.419021104033, w0=18.518838913640707, w1=-47.7621882641726\n",
      "Gradient Descent(5002/9999): loss=4910.419021104033, w0=30.58560429919424, w1=-37.4385882641726\n",
      "Gradient Descent(5003/9999): loss=16279.354446718624, w0=30.58560429919424, w1=-37.4385882641726\n",
      "Gradient Descent(5004/9999): loss=16279.354446718624, w0=18.69280429919424, w1=-44.7701882641726\n",
      "Gradient Descent(5005/9999): loss=4260.556447308538, w0=18.69280429919424, w1=-44.7701882641726\n",
      "Gradient Descent(5006/9999): loss=4260.556447308538, w0=18.69280429919424, w1=-44.7701882641726\n",
      "Gradient Descent(5007/9999): loss=4260.556447308538, w0=18.69280429919424, w1=-44.7701882641726\n",
      "Gradient Descent(5008/9999): loss=4260.556447308538, w0=18.69280429919424, w1=-44.7701882641726\n",
      "Gradient Descent(5009/9999): loss=4260.556447308538, w0=9.300604299194239, w1=-45.955788264172604\n",
      "Gradient Descent(5010/9999): loss=5627.498994690711, w0=9.300604299194239, w1=-45.955788264172604\n",
      "Gradient Descent(5011/9999): loss=5627.498994690711, w0=9.300604299194239, w1=-45.955788264172604\n",
      "Gradient Descent(5012/9999): loss=5627.498994690711, w0=9.300604299194239, w1=-45.955788264172604\n",
      "Gradient Descent(5013/9999): loss=5627.498994690711, w0=22.618104299194243, w1=-36.5585882641726\n",
      "Gradient Descent(5014/9999): loss=8973.572409998398, w0=22.618104299194243, w1=-36.5585882641726\n",
      "Gradient Descent(5015/9999): loss=8973.572409998398, w0=10.55133891364071, w1=-44.5629882641726\n",
      "Gradient Descent(5016/9999): loss=5802.4994844197445, w0=10.55133891364071, w1=-44.5629882641726\n",
      "Gradient Descent(5017/9999): loss=5802.4994844197445, w0=19.19153891364071, w1=-41.7022882641726\n",
      "Gradient Descent(5018/9999): loss=4776.401679815571, w0=19.19153891364071, w1=-41.7022882641726\n",
      "Gradient Descent(5019/9999): loss=4776.401679815571, w0=33.08063891364071, w1=-32.6863882641726\n",
      "Gradient Descent(5020/9999): loss=16446.13614054259, w0=33.08063891364071, w1=-32.6863882641726\n",
      "Gradient Descent(5021/9999): loss=16446.13614054259, w0=33.08063891364071, w1=-32.6863882641726\n",
      "Gradient Descent(5022/9999): loss=16446.13614054259, w0=26.88413891364071, w1=-39.7994882641726\n",
      "Gradient Descent(5023/9999): loss=5411.1586897161, w0=13.696238913640713, w1=-43.424988264172605\n",
      "Gradient Descent(5024/9999): loss=5802.4994844197445, w0=13.696238913640713, w1=-43.424988264172605\n",
      "Gradient Descent(5025/9999): loss=5802.4994844197445, w0=13.696238913640713, w1=-43.424988264172605\n",
      "Gradient Descent(5026/9999): loss=5802.4994844197445, w0=13.696238913640713, w1=-43.424988264172605\n",
      "Gradient Descent(5027/9999): loss=5802.4994844197445, w0=13.696238913640713, w1=-43.424988264172605\n",
      "Gradient Descent(5028/9999): loss=5802.4994844197445, w0=27.403038913640714, w1=-42.042288264172605\n",
      "Gradient Descent(5029/9999): loss=5587.826879052599, w0=-0.49266108635928774, w1=-51.891188264172605\n",
      "Gradient Descent(5030/9999): loss=5802.4994844197445, w0=-0.49266108635928774, w1=-51.891188264172605\n",
      "Gradient Descent(5031/9999): loss=5802.4994844197445, w0=-0.49266108635928774, w1=-51.891188264172605\n",
      "Gradient Descent(5032/9999): loss=5802.4994844197445, w0=-0.49266108635928774, w1=-51.891188264172605\n",
      "Gradient Descent(5033/9999): loss=5802.4994844197445, w0=-0.49266108635928774, w1=-51.891188264172605\n",
      "Gradient Descent(5034/9999): loss=5802.4994844197445, w0=-0.49266108635928774, w1=-51.891188264172605\n",
      "Gradient Descent(5035/9999): loss=5802.4994844197445, w0=13.137438913640715, w1=-50.924588264172606\n",
      "Gradient Descent(5036/9999): loss=5767.963148343925, w0=13.137438913640715, w1=-50.924588264172606\n",
      "Gradient Descent(5037/9999): loss=5767.963148343925, w0=28.228938913640715, w1=-44.96678826417261\n",
      "Gradient Descent(5038/9999): loss=11425.787647349774, w0=28.228938913640715, w1=-44.96678826417261\n",
      "Gradient Descent(5039/9999): loss=11425.787647349774, w0=28.228938913640715, w1=-44.96678826417261\n",
      "Gradient Descent(5040/9999): loss=11425.787647349774, w0=16.16217352808718, w1=-51.38248826417261\n",
      "Gradient Descent(5041/9999): loss=4663.194958736365, w0=16.16217352808718, w1=-51.38248826417261\n",
      "Gradient Descent(5042/9999): loss=4663.194958736365, w0=26.02877352808718, w1=-48.74508826417261\n",
      "Gradient Descent(5043/9999): loss=6290.576083697661, w0=34.71107352808718, w1=-42.42558826417261\n",
      "Gradient Descent(5044/9999): loss=16082.903930429791, w0=34.71107352808718, w1=-42.42558826417261\n",
      "Gradient Descent(5045/9999): loss=16082.903930429791, w0=23.985973528087175, w1=-48.87678826417261\n",
      "Gradient Descent(5046/9999): loss=4805.963449195855, w0=23.985973528087175, w1=-48.87678826417261\n",
      "Gradient Descent(5047/9999): loss=4805.963449195855, w0=23.985973528087175, w1=-48.87678826417261\n",
      "Gradient Descent(5048/9999): loss=4805.963449195855, w0=23.985973528087175, w1=-48.87678826417261\n",
      "Gradient Descent(5049/9999): loss=4805.963449195855, w0=23.985973528087175, w1=-48.87678826417261\n",
      "Gradient Descent(5050/9999): loss=4805.963449195855, w0=23.985973528087175, w1=-48.87678826417261\n",
      "Gradient Descent(5051/9999): loss=4805.963449195855, w0=23.985973528087175, w1=-48.87678826417261\n",
      "Gradient Descent(5052/9999): loss=4805.963449195855, w0=35.75167352808718, w1=-45.67738826417261\n",
      "Gradient Descent(5053/9999): loss=16092.331302144921, w0=19.240573528087182, w1=-52.26318826417261\n",
      "Gradient Descent(5054/9999): loss=4572.049541303733, w0=33.168073528087184, w1=-44.16998826417261\n",
      "Gradient Descent(5055/9999): loss=15064.237708696566, w0=33.168073528087184, w1=-44.16998826417261\n",
      "Gradient Descent(5056/9999): loss=15064.237708696566, w0=21.10130814253365, w1=-54.12518826417261\n",
      "Gradient Descent(5057/9999): loss=4452.578282355149, w0=21.10130814253365, w1=-54.12518826417261\n",
      "Gradient Descent(5058/9999): loss=4452.578282355149, w0=21.10130814253365, w1=-54.12518826417261\n",
      "Gradient Descent(5059/9999): loss=4452.578282355149, w0=15.601908142533649, w1=-57.58138826417261\n",
      "Gradient Descent(5060/9999): loss=5710.396146344983, w0=15.601908142533649, w1=-57.58138826417261\n",
      "Gradient Descent(5061/9999): loss=5710.396146344983, w0=15.601908142533649, w1=-57.58138826417261\n",
      "Gradient Descent(5062/9999): loss=5710.396146344983, w0=27.90810814253365, w1=-53.83418826417261\n",
      "Gradient Descent(5063/9999): loss=4454.458980081394, w0=27.90810814253365, w1=-53.83418826417261\n",
      "Gradient Descent(5064/9999): loss=4454.458980081394, w0=27.90810814253365, w1=-53.83418826417261\n",
      "Gradient Descent(5065/9999): loss=4454.458980081394, w0=27.90810814253365, w1=-53.83418826417261\n",
      "Gradient Descent(5066/9999): loss=4454.458980081394, w0=19.83450814253365, w1=-55.84158826417261\n",
      "Gradient Descent(5067/9999): loss=4950.536944197602, w0=19.83450814253365, w1=-55.84158826417261\n",
      "Gradient Descent(5068/9999): loss=4950.536944197602, w0=19.83450814253365, w1=-55.84158826417261\n",
      "Gradient Descent(5069/9999): loss=4950.536944197602, w0=19.83450814253365, w1=-55.84158826417261\n",
      "Gradient Descent(5070/9999): loss=4950.536944197602, w0=19.83450814253365, w1=-55.84158826417261\n",
      "Gradient Descent(5071/9999): loss=4950.536944197602, w0=19.83450814253365, w1=-55.84158826417261\n",
      "Gradient Descent(5072/9999): loss=4950.536944197602, w0=30.30380814253365, w1=-53.421988264172604\n",
      "Gradient Descent(5073/9999): loss=7984.576158909144, w0=30.30380814253365, w1=-53.421988264172604\n",
      "Gradient Descent(5074/9999): loss=7984.576158909144, w0=30.30380814253365, w1=-53.421988264172604\n",
      "Gradient Descent(5075/9999): loss=7984.576158909144, w0=30.30380814253365, w1=-53.421988264172604\n",
      "Gradient Descent(5076/9999): loss=7984.576158909144, w0=12.382608142533648, w1=-55.951788264172606\n",
      "Gradient Descent(5077/9999): loss=5802.499484419739, w0=12.382608142533648, w1=-55.951788264172606\n",
      "Gradient Descent(5078/9999): loss=5802.499484419739, w0=12.382608142533648, w1=-55.951788264172606\n",
      "Gradient Descent(5079/9999): loss=5802.499484419739, w0=12.382608142533648, w1=-55.951788264172606\n",
      "Gradient Descent(5080/9999): loss=5802.499484419739, w0=12.382608142533648, w1=-55.951788264172606\n",
      "Gradient Descent(5081/9999): loss=5802.499484419739, w0=12.382608142533648, w1=-55.951788264172606\n",
      "Gradient Descent(5082/9999): loss=5802.499484419739, w0=12.382608142533648, w1=-55.951788264172606\n",
      "Gradient Descent(5083/9999): loss=5802.499484419739, w0=24.80450814253365, w1=-53.64508826417261\n",
      "Gradient Descent(5084/9999): loss=5486.954413114049, w0=24.80450814253365, w1=-53.64508826417261\n",
      "Gradient Descent(5085/9999): loss=5486.954413114049, w0=14.428508142533648, w1=-58.63088826417261\n",
      "Gradient Descent(5086/9999): loss=5579.821054842119, w0=14.428508142533648, w1=-58.63088826417261\n",
      "Gradient Descent(5087/9999): loss=5579.821054842119, w0=14.428508142533648, w1=-58.63088826417261\n",
      "Gradient Descent(5088/9999): loss=5579.821054842119, w0=14.428508142533648, w1=-58.63088826417261\n",
      "Gradient Descent(5089/9999): loss=5579.821054842119, w0=14.428508142533648, w1=-58.63088826417261\n",
      "Gradient Descent(5090/9999): loss=5579.821054842119, w0=14.428508142533648, w1=-58.63088826417261\n",
      "Gradient Descent(5091/9999): loss=5579.821054842119, w0=14.428508142533648, w1=-58.63088826417261\n",
      "Gradient Descent(5092/9999): loss=5579.821054842119, w0=14.428508142533648, w1=-58.63088826417261\n",
      "Gradient Descent(5093/9999): loss=5579.821054842119, w0=14.428508142533648, w1=-58.63088826417261\n",
      "Gradient Descent(5094/9999): loss=5579.821054842119, w0=14.428508142533648, w1=-58.63088826417261\n",
      "Gradient Descent(5095/9999): loss=5579.821054842119, w0=14.428508142533648, w1=-58.63088826417261\n",
      "Gradient Descent(5096/9999): loss=5579.821054842119, w0=14.428508142533648, w1=-58.63088826417261\n",
      "Gradient Descent(5097/9999): loss=5579.821054842119, w0=14.428508142533648, w1=-58.63088826417261\n",
      "Gradient Descent(5098/9999): loss=5579.821054842119, w0=14.428508142533648, w1=-58.63088826417261\n",
      "Gradient Descent(5099/9999): loss=5579.821054842119, w0=28.11890814253365, w1=-56.77148826417261\n",
      "Gradient Descent(5100/9999): loss=7570.913581923958, w0=28.11890814253365, w1=-56.77148826417261\n",
      "Gradient Descent(5101/9999): loss=7570.913581923958, w0=19.45260814253365, w1=-62.172488264172614\n",
      "Gradient Descent(5102/9999): loss=4898.741603469668, w0=19.45260814253365, w1=-62.172488264172614\n",
      "Gradient Descent(5103/9999): loss=4898.741603469668, w0=19.45260814253365, w1=-62.172488264172614\n",
      "Gradient Descent(5104/9999): loss=4898.741603469668, w0=19.45260814253365, w1=-62.172488264172614\n",
      "Gradient Descent(5105/9999): loss=4898.741603469668, w0=19.45260814253365, w1=-62.172488264172614\n",
      "Gradient Descent(5106/9999): loss=4898.741603469668, w0=19.45260814253365, w1=-62.172488264172614\n",
      "Gradient Descent(5107/9999): loss=4898.741603469668, w0=19.45260814253365, w1=-62.172488264172614\n",
      "Gradient Descent(5108/9999): loss=4898.741603469668, w0=19.45260814253365, w1=-62.172488264172614\n",
      "Gradient Descent(5109/9999): loss=4898.741603469668, w0=19.45260814253365, w1=-62.172488264172614\n",
      "Gradient Descent(5110/9999): loss=4898.741603469668, w0=19.45260814253365, w1=-62.172488264172614\n",
      "Gradient Descent(5111/9999): loss=4898.741603469668, w0=32.048408142533646, w1=-60.672988264172616\n",
      "Gradient Descent(5112/9999): loss=7032.333166069004, w0=20.273508142533643, w1=-63.42858826417262\n",
      "Gradient Descent(5113/9999): loss=4668.3243414842, w0=20.273508142533643, w1=-63.42858826417262\n",
      "Gradient Descent(5114/9999): loss=4668.3243414842, w0=20.273508142533643, w1=-63.42858826417262\n",
      "Gradient Descent(5115/9999): loss=4668.3243414842, w0=20.273508142533643, w1=-63.42858826417262\n",
      "Gradient Descent(5116/9999): loss=4668.3243414842, w0=6.0718081425336425, w1=-64.21458826417262\n",
      "Gradient Descent(5117/9999): loss=5802.4994844197445, w0=6.0718081425336425, w1=-64.21458826417262\n",
      "Gradient Descent(5118/9999): loss=5802.4994844197445, w0=17.116808142533642, w1=-63.16878826417262\n",
      "Gradient Descent(5119/9999): loss=5399.576587997056, w0=17.116808142533642, w1=-63.16878826417262\n",
      "Gradient Descent(5120/9999): loss=5399.576587997056, w0=17.116808142533642, w1=-63.16878826417262\n",
      "Gradient Descent(5121/9999): loss=5399.576587997056, w0=17.116808142533642, w1=-63.16878826417262\n",
      "Gradient Descent(5122/9999): loss=5399.576587997056, w0=17.116808142533642, w1=-63.16878826417262\n",
      "Gradient Descent(5123/9999): loss=5399.576587997056, w0=17.116808142533642, w1=-63.16878826417262\n",
      "Gradient Descent(5124/9999): loss=5399.576587997056, w0=17.116808142533642, w1=-63.16878826417262\n",
      "Gradient Descent(5125/9999): loss=5399.576587997056, w0=17.116808142533642, w1=-63.16878826417262\n",
      "Gradient Descent(5126/9999): loss=5399.576587997056, w0=17.116808142533642, w1=-63.16878826417262\n",
      "Gradient Descent(5127/9999): loss=5399.576587997056, w0=29.183573528087177, w1=-53.12788826417262\n",
      "Gradient Descent(5128/9999): loss=4883.300772392956, w0=16.616673528087176, w1=-55.82308826417262\n",
      "Gradient Descent(5129/9999): loss=5721.9089362618215, w0=16.616673528087176, w1=-55.82308826417262\n",
      "Gradient Descent(5130/9999): loss=5721.9089362618215, w0=16.616673528087176, w1=-55.82308826417262\n",
      "Gradient Descent(5131/9999): loss=5721.9089362618215, w0=16.616673528087176, w1=-55.82308826417262\n",
      "Gradient Descent(5132/9999): loss=5721.9089362618215, w0=31.666773528087177, w1=-53.01168826417262\n",
      "Gradient Descent(5133/9999): loss=6703.614400820559, w0=31.666773528087177, w1=-53.01168826417262\n",
      "Gradient Descent(5134/9999): loss=6703.614400820559, w0=31.666773528087177, w1=-53.01168826417262\n",
      "Gradient Descent(5135/9999): loss=6703.614400820559, w0=31.666773528087177, w1=-53.01168826417262\n",
      "Gradient Descent(5136/9999): loss=6703.614400820559, w0=31.666773528087177, w1=-53.01168826417262\n",
      "Gradient Descent(5137/9999): loss=6703.614400820559, w0=21.693973528087177, w1=-56.29308826417262\n",
      "Gradient Descent(5138/9999): loss=5042.423920705719, w0=33.47627352808718, w1=-53.179588264172615\n",
      "Gradient Descent(5139/9999): loss=8209.303251623003, w0=21.189073528087174, w1=-55.687288264172615\n",
      "Gradient Descent(5140/9999): loss=4772.208400871385, w0=21.189073528087174, w1=-55.687288264172615\n",
      "Gradient Descent(5141/9999): loss=4772.208400871385, w0=21.189073528087174, w1=-55.687288264172615\n",
      "Gradient Descent(5142/9999): loss=4772.208400871385, w0=30.577973528087174, w1=-49.518188264172615\n",
      "Gradient Descent(5143/9999): loss=7538.679002066055, w0=30.577973528087174, w1=-49.518188264172615\n",
      "Gradient Descent(5144/9999): loss=7538.679002066055, w0=30.577973528087174, w1=-49.518188264172615\n",
      "Gradient Descent(5145/9999): loss=7538.679002066055, w0=41.467673528087175, w1=-41.782088264172614\n",
      "Gradient Descent(5146/9999): loss=16900.969272602844, w0=41.467673528087175, w1=-41.782088264172614\n",
      "Gradient Descent(5147/9999): loss=16900.969272602844, w0=29.40090814253364, w1=-49.66488826417262\n",
      "Gradient Descent(5148/9999): loss=6766.7966348712835, w0=14.335708142533639, w1=-53.37828826417262\n",
      "Gradient Descent(5149/9999): loss=5614.31621496753, w0=14.335708142533639, w1=-53.37828826417262\n",
      "Gradient Descent(5150/9999): loss=5614.31621496753, w0=14.335708142533639, w1=-53.37828826417262\n",
      "Gradient Descent(5151/9999): loss=5614.31621496753, w0=14.335708142533639, w1=-53.37828826417262\n",
      "Gradient Descent(5152/9999): loss=5614.31621496753, w0=14.335708142533639, w1=-53.37828826417262\n",
      "Gradient Descent(5153/9999): loss=5614.31621496753, w0=14.335708142533639, w1=-53.37828826417262\n",
      "Gradient Descent(5154/9999): loss=5614.31621496753, w0=14.335708142533639, w1=-53.37828826417262\n",
      "Gradient Descent(5155/9999): loss=5614.31621496753, w0=14.335708142533639, w1=-53.37828826417262\n",
      "Gradient Descent(5156/9999): loss=5614.31621496753, w0=14.335708142533639, w1=-53.37828826417262\n",
      "Gradient Descent(5157/9999): loss=5614.31621496753, w0=22.41320814253364, w1=-50.78198826417262\n",
      "Gradient Descent(5158/9999): loss=4615.573403510141, w0=22.41320814253364, w1=-50.78198826417262\n",
      "Gradient Descent(5159/9999): loss=4615.573403510141, w0=13.18810814253364, w1=-51.32958826417262\n",
      "Gradient Descent(5160/9999): loss=5640.168085768575, w0=13.18810814253364, w1=-51.32958826417262\n",
      "Gradient Descent(5161/9999): loss=5640.168085768575, w0=13.18810814253364, w1=-51.32958826417262\n",
      "Gradient Descent(5162/9999): loss=5640.168085768575, w0=13.18810814253364, w1=-51.32958826417262\n",
      "Gradient Descent(5163/9999): loss=5640.168085768575, w0=24.165708142533642, w1=-47.86598826417262\n",
      "Gradient Descent(5164/9999): loss=5452.779405236845, w0=24.165708142533642, w1=-47.86598826417262\n",
      "Gradient Descent(5165/9999): loss=5452.779405236845, w0=24.165708142533642, w1=-47.86598826417262\n",
      "Gradient Descent(5166/9999): loss=5452.779405236845, w0=24.165708142533642, w1=-47.86598826417262\n",
      "Gradient Descent(5167/9999): loss=5452.779405236845, w0=5.966308142533638, w1=-54.295688264172625\n",
      "Gradient Descent(5168/9999): loss=5802.4994844197445, w0=15.071808142533639, w1=-52.31228826417262\n",
      "Gradient Descent(5169/9999): loss=5721.907458321125, w0=27.59970814253364, w1=-51.291188264172625\n",
      "Gradient Descent(5170/9999): loss=4943.992464734645, w0=27.59970814253364, w1=-51.291188264172625\n",
      "Gradient Descent(5171/9999): loss=4943.992464734645, w0=14.287808142533638, w1=-58.06508826417262\n",
      "Gradient Descent(5172/9999): loss=5802.4994844197445, w0=14.287808142533638, w1=-58.06508826417262\n",
      "Gradient Descent(5173/9999): loss=5802.4994844197445, w0=28.082708142533637, w1=-52.32508826417262\n",
      "Gradient Descent(5174/9999): loss=4239.986917593481, w0=28.082708142533637, w1=-52.32508826417262\n",
      "Gradient Descent(5175/9999): loss=4239.986917593481, w0=28.082708142533637, w1=-52.32508826417262\n",
      "Gradient Descent(5176/9999): loss=4239.986917593481, w0=28.082708142533637, w1=-52.32508826417262\n",
      "Gradient Descent(5177/9999): loss=4239.986917593481, w0=28.082708142533637, w1=-52.32508826417262\n",
      "Gradient Descent(5178/9999): loss=4239.986917593481, w0=28.082708142533637, w1=-52.32508826417262\n",
      "Gradient Descent(5179/9999): loss=4239.986917593481, w0=36.358408142533634, w1=-45.99788826417262\n",
      "Gradient Descent(5180/9999): loss=14856.74267073996, w0=24.2916427569801, w1=-53.640888264172624\n",
      "Gradient Descent(5181/9999): loss=4529.20557422695, w0=24.2916427569801, w1=-53.640888264172624\n",
      "Gradient Descent(5182/9999): loss=4529.20557422695, w0=24.2916427569801, w1=-53.640888264172624\n",
      "Gradient Descent(5183/9999): loss=4529.20557422695, w0=24.2916427569801, w1=-53.640888264172624\n",
      "Gradient Descent(5184/9999): loss=4529.20557422695, w0=24.2916427569801, w1=-53.640888264172624\n",
      "Gradient Descent(5185/9999): loss=4529.20557422695, w0=24.2916427569801, w1=-53.640888264172624\n",
      "Gradient Descent(5186/9999): loss=4529.20557422695, w0=24.2916427569801, w1=-53.640888264172624\n",
      "Gradient Descent(5187/9999): loss=4529.20557422695, w0=24.2916427569801, w1=-53.640888264172624\n",
      "Gradient Descent(5188/9999): loss=4529.20557422695, w0=24.2916427569801, w1=-53.640888264172624\n",
      "Gradient Descent(5189/9999): loss=4529.20557422695, w0=24.2916427569801, w1=-53.640888264172624\n",
      "Gradient Descent(5190/9999): loss=4529.20557422695, w0=24.2916427569801, w1=-53.640888264172624\n",
      "Gradient Descent(5191/9999): loss=4529.20557422695, w0=24.2916427569801, w1=-53.640888264172624\n",
      "Gradient Descent(5192/9999): loss=4529.20557422695, w0=24.2916427569801, w1=-53.640888264172624\n",
      "Gradient Descent(5193/9999): loss=4529.20557422695, w0=24.2916427569801, w1=-53.640888264172624\n",
      "Gradient Descent(5194/9999): loss=4529.20557422695, w0=24.2916427569801, w1=-53.640888264172624\n",
      "Gradient Descent(5195/9999): loss=4529.20557422695, w0=24.2916427569801, w1=-53.640888264172624\n",
      "Gradient Descent(5196/9999): loss=4529.20557422695, w0=37.7573427569801, w1=-46.537988264172625\n",
      "Gradient Descent(5197/9999): loss=16739.788176157588, w0=16.8335427569801, w1=-55.95668826417263\n",
      "Gradient Descent(5198/9999): loss=4932.198332619185, w0=16.8335427569801, w1=-55.95668826417263\n",
      "Gradient Descent(5199/9999): loss=4932.198332619185, w0=16.8335427569801, w1=-55.95668826417263\n",
      "Gradient Descent(5200/9999): loss=4932.198332619185, w0=16.8335427569801, w1=-55.95668826417263\n",
      "Gradient Descent(5201/9999): loss=4932.198332619185, w0=16.8335427569801, w1=-55.95668826417263\n",
      "Gradient Descent(5202/9999): loss=4932.198332619185, w0=16.8335427569801, w1=-55.95668826417263\n",
      "Gradient Descent(5203/9999): loss=4932.198332619185, w0=25.7791427569801, w1=-47.36808826417263\n",
      "Gradient Descent(5204/9999): loss=15979.772091617675, w0=13.712377371426566, w1=-56.81228826417263\n",
      "Gradient Descent(5205/9999): loss=5081.394348745433, w0=13.712377371426566, w1=-56.81228826417263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(5206/9999): loss=5081.394348745433, w0=13.712377371426566, w1=-56.81228826417263\n",
      "Gradient Descent(5207/9999): loss=5081.394348745433, w0=13.712377371426566, w1=-56.81228826417263\n",
      "Gradient Descent(5208/9999): loss=5081.394348745433, w0=13.712377371426566, w1=-56.81228826417263\n",
      "Gradient Descent(5209/9999): loss=5081.394348745433, w0=13.712377371426566, w1=-56.81228826417263\n",
      "Gradient Descent(5210/9999): loss=5081.394348745433, w0=13.712377371426566, w1=-56.81228826417263\n",
      "Gradient Descent(5211/9999): loss=5081.394348745433, w0=13.712377371426566, w1=-56.81228826417263\n",
      "Gradient Descent(5212/9999): loss=5081.394348745433, w0=4.285977371426567, w1=-59.47058826417263\n",
      "Gradient Descent(5213/9999): loss=5779.473613489904, w0=4.285977371426567, w1=-59.47058826417263\n",
      "Gradient Descent(5214/9999): loss=5779.473613489904, w0=4.285977371426567, w1=-59.47058826417263\n",
      "Gradient Descent(5215/9999): loss=5779.473613489904, w0=4.285977371426567, w1=-59.47058826417263\n",
      "Gradient Descent(5216/9999): loss=5779.473613489904, w0=13.167977371426566, w1=-56.925288264172636\n",
      "Gradient Descent(5217/9999): loss=4503.600544798947, w0=13.167977371426566, w1=-56.925288264172636\n",
      "Gradient Descent(5218/9999): loss=4503.600544798947, w0=13.167977371426566, w1=-56.925288264172636\n",
      "Gradient Descent(5219/9999): loss=4503.600544798947, w0=13.167977371426566, w1=-56.925288264172636\n",
      "Gradient Descent(5220/9999): loss=4503.600544798947, w0=-3.266222628573434, w1=-63.797288264172636\n",
      "Gradient Descent(5221/9999): loss=5802.4994844197445, w0=-3.266222628573434, w1=-63.797288264172636\n",
      "Gradient Descent(5222/9999): loss=5802.4994844197445, w0=-3.266222628573434, w1=-63.797288264172636\n",
      "Gradient Descent(5223/9999): loss=5802.4994844197445, w0=-3.266222628573434, w1=-63.797288264172636\n",
      "Gradient Descent(5224/9999): loss=5802.4994844197445, w0=6.021977371426567, w1=-63.701788264172635\n",
      "Gradient Descent(5225/9999): loss=5790.977782710892, w0=6.021977371426567, w1=-63.701788264172635\n",
      "Gradient Descent(5226/9999): loss=5790.977782710892, w0=6.021977371426567, w1=-63.701788264172635\n",
      "Gradient Descent(5227/9999): loss=5790.977782710892, w0=6.021977371426567, w1=-63.701788264172635\n",
      "Gradient Descent(5228/9999): loss=5790.977782710892, w0=6.021977371426567, w1=-63.701788264172635\n",
      "Gradient Descent(5229/9999): loss=5790.977782710892, w0=6.021977371426567, w1=-63.701788264172635\n",
      "Gradient Descent(5230/9999): loss=5790.977782710892, w0=6.021977371426567, w1=-63.701788264172635\n",
      "Gradient Descent(5231/9999): loss=5790.977782710892, w0=17.776477371426566, w1=-63.192188264172636\n",
      "Gradient Descent(5232/9999): loss=4286.4143509473215, w0=17.776477371426566, w1=-63.192188264172636\n",
      "Gradient Descent(5233/9999): loss=4286.4143509473215, w0=8.210877371426564, w1=-64.86518826417263\n",
      "Gradient Descent(5234/9999): loss=5802.4994844197445, w0=18.935577371426568, w1=-60.84548826417263\n",
      "Gradient Descent(5235/9999): loss=4227.562459072288, w0=18.935577371426568, w1=-60.84548826417263\n",
      "Gradient Descent(5236/9999): loss=4227.562459072288, w0=18.935577371426568, w1=-60.84548826417263\n",
      "Gradient Descent(5237/9999): loss=4227.562459072288, w0=18.935577371426568, w1=-60.84548826417263\n",
      "Gradient Descent(5238/9999): loss=4227.562459072288, w0=18.935577371426568, w1=-60.84548826417263\n",
      "Gradient Descent(5239/9999): loss=4227.562459072288, w0=18.935577371426568, w1=-60.84548826417263\n",
      "Gradient Descent(5240/9999): loss=4227.562459072288, w0=18.935577371426568, w1=-60.84548826417263\n",
      "Gradient Descent(5241/9999): loss=4227.562459072288, w0=18.935577371426568, w1=-60.84548826417263\n",
      "Gradient Descent(5242/9999): loss=4227.562459072288, w0=27.360377371426566, w1=-55.41958826417263\n",
      "Gradient Descent(5243/9999): loss=14360.219143002905, w0=18.210377371426567, w1=-59.04538826417263\n",
      "Gradient Descent(5244/9999): loss=4719.8278239273, w0=18.210377371426567, w1=-59.04538826417263\n",
      "Gradient Descent(5245/9999): loss=4719.8278239273, w0=18.210377371426567, w1=-59.04538826417263\n",
      "Gradient Descent(5246/9999): loss=4719.8278239273, w0=18.210377371426567, w1=-59.04538826417263\n",
      "Gradient Descent(5247/9999): loss=4719.8278239273, w0=18.210377371426567, w1=-59.04538826417263\n",
      "Gradient Descent(5248/9999): loss=4719.8278239273, w0=9.578777371426566, w1=-61.73308826417263\n",
      "Gradient Descent(5249/9999): loss=5414.089267001211, w0=9.578777371426566, w1=-61.73308826417263\n",
      "Gradient Descent(5250/9999): loss=5414.089267001211, w0=9.578777371426566, w1=-61.73308826417263\n",
      "Gradient Descent(5251/9999): loss=5414.089267001211, w0=9.578777371426566, w1=-61.73308826417263\n",
      "Gradient Descent(5252/9999): loss=5414.089267001211, w0=9.578777371426566, w1=-61.73308826417263\n",
      "Gradient Descent(5253/9999): loss=5414.089267001211, w0=9.578777371426566, w1=-61.73308826417263\n",
      "Gradient Descent(5254/9999): loss=5414.089267001211, w0=9.578777371426566, w1=-61.73308826417263\n",
      "Gradient Descent(5255/9999): loss=5414.089267001211, w0=9.578777371426566, w1=-61.73308826417263\n",
      "Gradient Descent(5256/9999): loss=5414.089267001211, w0=9.578777371426566, w1=-61.73308826417263\n",
      "Gradient Descent(5257/9999): loss=5414.089267001211, w0=9.578777371426566, w1=-61.73308826417263\n",
      "Gradient Descent(5258/9999): loss=5414.089267001211, w0=18.261077371426566, w1=-55.41358826417263\n",
      "Gradient Descent(5259/9999): loss=4409.439182072616, w0=18.261077371426566, w1=-55.41358826417263\n",
      "Gradient Descent(5260/9999): loss=4409.439182072616, w0=18.261077371426566, w1=-55.41358826417263\n",
      "Gradient Descent(5261/9999): loss=4409.439182072616, w0=18.261077371426566, w1=-55.41358826417263\n",
      "Gradient Descent(5262/9999): loss=4409.439182072616, w0=27.099177371426567, w1=-49.377288264172634\n",
      "Gradient Descent(5263/9999): loss=15944.568576918122, w0=19.826877371426566, w1=-57.056888264172635\n",
      "Gradient Descent(5264/9999): loss=4853.63641496667, w0=8.051977371426565, w1=-59.812488264172636\n",
      "Gradient Descent(5265/9999): loss=5744.934809470458, w0=8.051977371426565, w1=-59.812488264172636\n",
      "Gradient Descent(5266/9999): loss=5744.934809470458, w0=8.051977371426565, w1=-59.812488264172636\n",
      "Gradient Descent(5267/9999): loss=5744.934809470458, w0=8.051977371426565, w1=-59.812488264172636\n",
      "Gradient Descent(5268/9999): loss=5744.934809470458, w0=8.051977371426565, w1=-59.812488264172636\n",
      "Gradient Descent(5269/9999): loss=5744.934809470458, w0=8.051977371426565, w1=-59.812488264172636\n",
      "Gradient Descent(5270/9999): loss=5744.934809470458, w0=8.051977371426565, w1=-59.812488264172636\n",
      "Gradient Descent(5271/9999): loss=5744.934809470458, w0=8.051977371426565, w1=-59.812488264172636\n",
      "Gradient Descent(5272/9999): loss=5744.934809470458, w0=8.051977371426565, w1=-59.812488264172636\n",
      "Gradient Descent(5273/9999): loss=5744.934809470458, w0=8.051977371426565, w1=-59.812488264172636\n",
      "Gradient Descent(5274/9999): loss=5744.934809470458, w0=8.051977371426565, w1=-59.812488264172636\n",
      "Gradient Descent(5275/9999): loss=5744.934809470458, w0=16.931677371426566, w1=-58.53608826417263\n",
      "Gradient Descent(5276/9999): loss=4215.166793809038, w0=16.931677371426566, w1=-58.53608826417263\n",
      "Gradient Descent(5277/9999): loss=4215.166793809038, w0=16.931677371426566, w1=-58.53608826417263\n",
      "Gradient Descent(5278/9999): loss=4215.166793809038, w0=16.931677371426566, w1=-58.53608826417263\n",
      "Gradient Descent(5279/9999): loss=4215.166793809038, w0=16.931677371426566, w1=-58.53608826417263\n",
      "Gradient Descent(5280/9999): loss=4215.166793809038, w0=16.931677371426566, w1=-58.53608826417263\n",
      "Gradient Descent(5281/9999): loss=4215.166793809038, w0=16.931677371426566, w1=-58.53608826417263\n",
      "Gradient Descent(5282/9999): loss=4215.166793809038, w0=6.555677371426565, w1=-63.52188826417263\n",
      "Gradient Descent(5283/9999): loss=5802.4994844197445, w0=6.555677371426565, w1=-63.52188826417263\n",
      "Gradient Descent(5284/9999): loss=5802.4994844197445, w0=17.954377371426567, w1=-56.19548826417263\n",
      "Gradient Descent(5285/9999): loss=4276.259617404257, w0=17.954377371426567, w1=-56.19548826417263\n",
      "Gradient Descent(5286/9999): loss=4276.259617404257, w0=17.954377371426567, w1=-56.19548826417263\n",
      "Gradient Descent(5287/9999): loss=4276.259617404257, w0=17.954377371426567, w1=-56.19548826417263\n",
      "Gradient Descent(5288/9999): loss=4276.259617404257, w0=17.954377371426567, w1=-56.19548826417263\n",
      "Gradient Descent(5289/9999): loss=4276.259617404257, w0=28.851777371426564, w1=-51.20208826417263\n",
      "Gradient Descent(5290/9999): loss=15166.405781140682, w0=28.851777371426564, w1=-51.20208826417263\n",
      "Gradient Descent(5291/9999): loss=15166.405781140682, w0=16.78501198587303, w1=-58.60178826417263\n",
      "Gradient Descent(5292/9999): loss=6197.1990441324, w0=16.78501198587303, w1=-58.60178826417263\n",
      "Gradient Descent(5293/9999): loss=6197.1990441324, w0=16.78501198587303, w1=-58.60178826417263\n",
      "Gradient Descent(5294/9999): loss=6197.1990441324, w0=16.78501198587303, w1=-58.60178826417263\n",
      "Gradient Descent(5295/9999): loss=6197.1990441324, w0=16.78501198587303, w1=-58.60178826417263\n",
      "Gradient Descent(5296/9999): loss=6197.1990441324, w0=16.78501198587303, w1=-58.60178826417263\n",
      "Gradient Descent(5297/9999): loss=6197.1990441324, w0=16.78501198587303, w1=-58.60178826417263\n",
      "Gradient Descent(5298/9999): loss=6197.1990441324, w0=16.78501198587303, w1=-58.60178826417263\n",
      "Gradient Descent(5299/9999): loss=6197.1990441324, w0=16.78501198587303, w1=-58.60178826417263\n",
      "Gradient Descent(5300/9999): loss=6197.1990441324, w0=16.78501198587303, w1=-58.60178826417263\n",
      "Gradient Descent(5301/9999): loss=6197.1990441324, w0=16.78501198587303, w1=-58.60178826417263\n",
      "Gradient Descent(5302/9999): loss=6197.1990441324, w0=16.78501198587303, w1=-58.60178826417263\n",
      "Gradient Descent(5303/9999): loss=6197.1990441324, w0=10.047811985873029, w1=-63.336688264172636\n",
      "Gradient Descent(5304/9999): loss=4687.294578432749, w0=10.047811985873029, w1=-63.336688264172636\n",
      "Gradient Descent(5305/9999): loss=4687.294578432749, w0=10.047811985873029, w1=-63.336688264172636\n",
      "Gradient Descent(5306/9999): loss=4687.294578432749, w0=10.047811985873029, w1=-63.336688264172636\n",
      "Gradient Descent(5307/9999): loss=4687.294578432749, w0=10.047811985873029, w1=-63.336688264172636\n",
      "Gradient Descent(5308/9999): loss=4687.294578432749, w0=10.047811985873029, w1=-63.336688264172636\n",
      "Gradient Descent(5309/9999): loss=4687.294578432749, w0=22.52731198587303, w1=-60.650188264172634\n",
      "Gradient Descent(5310/9999): loss=7376.314652201544, w0=22.52731198587303, w1=-60.650188264172634\n",
      "Gradient Descent(5311/9999): loss=7376.314652201544, w0=22.52731198587303, w1=-60.650188264172634\n",
      "Gradient Descent(5312/9999): loss=7376.314652201544, w0=22.52731198587303, w1=-60.650188264172634\n",
      "Gradient Descent(5313/9999): loss=7376.314652201544, w0=22.52731198587303, w1=-60.650188264172634\n",
      "Gradient Descent(5314/9999): loss=7376.314652201544, w0=15.74331198587303, w1=-61.520288264172635\n",
      "Gradient Descent(5315/9999): loss=4328.9760050509385, w0=15.74331198587303, w1=-61.520288264172635\n",
      "Gradient Descent(5316/9999): loss=4328.9760050509385, w0=15.74331198587303, w1=-61.520288264172635\n",
      "Gradient Descent(5317/9999): loss=4328.9760050509385, w0=15.74331198587303, w1=-61.520288264172635\n",
      "Gradient Descent(5318/9999): loss=4328.9760050509385, w0=26.04131198587303, w1=-57.23698826417264\n",
      "Gradient Descent(5319/9999): loss=10551.018598441098, w0=26.04131198587303, w1=-57.23698826417264\n",
      "Gradient Descent(5320/9999): loss=10551.018598441098, w0=17.687611985873026, w1=-57.96128826417264\n",
      "Gradient Descent(5321/9999): loss=4239.850303068237, w0=9.333911985873025, w1=-58.68558826417264\n",
      "Gradient Descent(5322/9999): loss=5790.986500522251, w0=9.333911985873025, w1=-58.68558826417264\n",
      "Gradient Descent(5323/9999): loss=5790.986500522251, w0=9.333911985873025, w1=-58.68558826417264\n",
      "Gradient Descent(5324/9999): loss=5790.986500522251, w0=9.333911985873025, w1=-58.68558826417264\n",
      "Gradient Descent(5325/9999): loss=5790.986500522251, w0=9.333911985873025, w1=-58.68558826417264\n",
      "Gradient Descent(5326/9999): loss=5790.986500522251, w0=22.720311985873025, w1=-54.03478826417263\n",
      "Gradient Descent(5327/9999): loss=4631.463081033314, w0=22.720311985873025, w1=-54.03478826417263\n",
      "Gradient Descent(5328/9999): loss=4631.463081033314, w0=22.720311985873025, w1=-54.03478826417263\n",
      "Gradient Descent(5329/9999): loss=4631.463081033314, w0=22.720311985873025, w1=-54.03478826417263\n",
      "Gradient Descent(5330/9999): loss=4631.463081033314, w0=22.720311985873025, w1=-54.03478826417263\n",
      "Gradient Descent(5331/9999): loss=4631.463081033314, w0=0.7591119858730231, w1=-56.63388826417263\n",
      "Gradient Descent(5332/9999): loss=5802.4994844197445, w0=0.7591119858730231, w1=-56.63388826417263\n",
      "Gradient Descent(5333/9999): loss=5802.4994844197445, w0=15.053011985873024, w1=-55.87868826417263\n",
      "Gradient Descent(5334/9999): loss=4283.744322403654, w0=15.053011985873024, w1=-55.87868826417263\n",
      "Gradient Descent(5335/9999): loss=4283.744322403654, w0=15.053011985873024, w1=-55.87868826417263\n",
      "Gradient Descent(5336/9999): loss=4283.744322403654, w0=15.053011985873024, w1=-55.87868826417263\n",
      "Gradient Descent(5337/9999): loss=4283.744322403654, w0=15.053011985873024, w1=-55.87868826417263\n",
      "Gradient Descent(5338/9999): loss=4283.744322403654, w0=15.053011985873024, w1=-55.87868826417263\n",
      "Gradient Descent(5339/9999): loss=4283.744322403654, w0=25.611011985873024, w1=-52.567988264172634\n",
      "Gradient Descent(5340/9999): loss=14665.48341792657, w0=25.611011985873024, w1=-52.567988264172634\n",
      "Gradient Descent(5341/9999): loss=14665.48341792657, w0=25.611011985873024, w1=-52.567988264172634\n",
      "Gradient Descent(5342/9999): loss=14665.48341792657, w0=13.54424660031949, w1=-60.07138826417263\n",
      "Gradient Descent(5343/9999): loss=5032.963048771359, w0=13.54424660031949, w1=-60.07138826417263\n",
      "Gradient Descent(5344/9999): loss=5032.963048771359, w0=13.54424660031949, w1=-60.07138826417263\n",
      "Gradient Descent(5345/9999): loss=5032.963048771359, w0=13.54424660031949, w1=-60.07138826417263\n",
      "Gradient Descent(5346/9999): loss=5032.963048771359, w0=13.54424660031949, w1=-60.07138826417263\n",
      "Gradient Descent(5347/9999): loss=5032.963048771359, w0=13.54424660031949, w1=-60.07138826417263\n",
      "Gradient Descent(5348/9999): loss=5032.963048771359, w0=5.414646600319488, w1=-63.670088264172634\n",
      "Gradient Descent(5349/9999): loss=4632.890080338828, w0=17.196946600319485, w1=-60.55658826417263\n",
      "Gradient Descent(5350/9999): loss=8806.953365720346, w0=17.196946600319485, w1=-60.55658826417263\n",
      "Gradient Descent(5351/9999): loss=8806.953365720346, w0=17.196946600319485, w1=-60.55658826417263\n",
      "Gradient Descent(5352/9999): loss=8806.953365720346, w0=17.196946600319485, w1=-60.55658826417263\n",
      "Gradient Descent(5353/9999): loss=8806.953365720346, w0=17.196946600319485, w1=-60.55658826417263\n",
      "Gradient Descent(5354/9999): loss=8806.953365720346, w0=17.196946600319485, w1=-60.55658826417263\n",
      "Gradient Descent(5355/9999): loss=8806.953365720346, w0=7.318946600319485, w1=-61.02858826417263\n",
      "Gradient Descent(5356/9999): loss=4498.863775658219, w0=21.070546600319485, w1=-56.79328826417263\n",
      "Gradient Descent(5357/9999): loss=10171.174097963703, w0=9.059746600319485, w1=-63.826988264172634\n",
      "Gradient Descent(5358/9999): loss=4589.607768502621, w0=9.059746600319485, w1=-63.826988264172634\n",
      "Gradient Descent(5359/9999): loss=4589.607768502621, w0=18.698846600319484, w1=-61.59868826417264\n",
      "Gradient Descent(5360/9999): loss=9333.220416842172, w0=18.698846600319484, w1=-61.59868826417264\n",
      "Gradient Descent(5361/9999): loss=9333.220416842172, w0=10.728746600319482, w1=-61.783788264172635\n",
      "Gradient Descent(5362/9999): loss=4430.562789999591, w0=10.728746600319482, w1=-61.783788264172635\n",
      "Gradient Descent(5363/9999): loss=4430.562789999591, w0=10.728746600319482, w1=-61.783788264172635\n",
      "Gradient Descent(5364/9999): loss=4430.562789999591, w0=10.728746600319482, w1=-61.783788264172635\n",
      "Gradient Descent(5365/9999): loss=4430.562789999591, w0=10.728746600319482, w1=-61.783788264172635\n",
      "Gradient Descent(5366/9999): loss=4430.562789999591, w0=3.1828466003194817, w1=-63.850788264172635\n",
      "Gradient Descent(5367/9999): loss=5790.986548954825, w0=3.1828466003194817, w1=-63.850788264172635\n",
      "Gradient Descent(5368/9999): loss=5790.986548954825, w0=15.662346600319484, w1=-61.16428826417263\n",
      "Gradient Descent(5369/9999): loss=4600.690025327569, w0=15.662346600319484, w1=-61.16428826417263\n",
      "Gradient Descent(5370/9999): loss=4600.690025327569, w0=15.662346600319484, w1=-61.16428826417263\n",
      "Gradient Descent(5371/9999): loss=4600.690025327569, w0=15.662346600319484, w1=-61.16428826417263\n",
      "Gradient Descent(5372/9999): loss=4600.690025327569, w0=15.662346600319484, w1=-61.16428826417263\n",
      "Gradient Descent(5373/9999): loss=4600.690025327569, w0=15.662346600319484, w1=-61.16428826417263\n",
      "Gradient Descent(5374/9999): loss=4600.690025327569, w0=15.662346600319484, w1=-61.16428826417263\n",
      "Gradient Descent(5375/9999): loss=4600.690025327569, w0=6.098446600319484, w1=-64.40748826417263\n",
      "Gradient Descent(5376/9999): loss=5112.706291319966, w0=6.098446600319484, w1=-64.40748826417263\n",
      "Gradient Descent(5377/9999): loss=5112.706291319966, w0=6.098446600319484, w1=-64.40748826417263\n",
      "Gradient Descent(5378/9999): loss=5112.706291319966, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5379/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5380/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5381/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5382/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5383/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5384/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5385/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5386/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5387/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5388/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5389/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5390/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5391/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5392/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5393/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5394/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5395/9999): loss=4808.980536687848, w0=15.402346600319484, w1=-61.737488264172626\n",
      "Gradient Descent(5396/9999): loss=4808.980536687848, w0=7.7597466038407505, w1=-65.3549882625059\n",
      "Gradient Descent(5397/9999): loss=4851.161813861821, w0=7.7597466038407505, w1=-65.3549882625059\n",
      "Gradient Descent(5398/9999): loss=4851.161813861821, w0=7.7597466038407505, w1=-65.3549882625059\n",
      "Gradient Descent(5399/9999): loss=4851.161813861821, w0=7.7597466038407505, w1=-65.3549882625059\n",
      "Gradient Descent(5400/9999): loss=4851.161813861821, w0=7.7597466038407505, w1=-65.3549882625059\n",
      "Gradient Descent(5401/9999): loss=4851.161813861821, w0=7.7597466038407505, w1=-65.3549882625059\n",
      "Gradient Descent(5402/9999): loss=4851.161813861821, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5403/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5404/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5405/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5406/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5407/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5408/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5409/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5410/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5411/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5412/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5413/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5414/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5415/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5416/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5417/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5418/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5419/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5420/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5421/9999): loss=6216.961383825041, w0=21.405046603840752, w1=-61.6484882625059\n",
      "Gradient Descent(5422/9999): loss=6216.961383825041, w0=12.524446603840753, w1=-65.2925882625059\n",
      "Gradient Descent(5423/9999): loss=4670.005393819914, w0=12.524446603840753, w1=-65.2925882625059\n",
      "Gradient Descent(5424/9999): loss=4670.005393819914, w0=12.524446603840753, w1=-65.2925882625059\n",
      "Gradient Descent(5425/9999): loss=4670.005393819914, w0=12.524446603840753, w1=-65.2925882625059\n",
      "Gradient Descent(5426/9999): loss=4670.005393819914, w0=23.502046603840753, w1=-61.8289882625059\n",
      "Gradient Descent(5427/9999): loss=6058.045062301906, w0=23.502046603840753, w1=-61.8289882625059\n",
      "Gradient Descent(5428/9999): loss=6058.045062301906, w0=23.502046603840753, w1=-61.8289882625059\n",
      "Gradient Descent(5429/9999): loss=6058.045062301906, w0=23.502046603840753, w1=-61.8289882625059\n",
      "Gradient Descent(5430/9999): loss=6058.045062301906, w0=23.502046603840753, w1=-61.8289882625059\n",
      "Gradient Descent(5431/9999): loss=6058.045062301906, w0=23.502046603840753, w1=-61.8289882625059\n",
      "Gradient Descent(5432/9999): loss=6058.045062301906, w0=16.572146603840753, w1=-65.9282882625059\n",
      "Gradient Descent(5433/9999): loss=4594.156945983876, w0=16.572146603840753, w1=-65.9282882625059\n",
      "Gradient Descent(5434/9999): loss=4594.156945983876, w0=16.572146603840753, w1=-65.9282882625059\n",
      "Gradient Descent(5435/9999): loss=4594.156945983876, w0=16.572146603840753, w1=-65.9282882625059\n",
      "Gradient Descent(5436/9999): loss=4594.156945983876, w0=16.572146603840753, w1=-65.9282882625059\n",
      "Gradient Descent(5437/9999): loss=4594.156945983876, w0=16.572146603840753, w1=-65.9282882625059\n",
      "Gradient Descent(5438/9999): loss=4594.156945983876, w0=16.572146603840753, w1=-65.9282882625059\n",
      "Gradient Descent(5439/9999): loss=4594.156945983876, w0=30.839646603840755, w1=-63.2550882625059\n",
      "Gradient Descent(5440/9999): loss=11815.04022212001, w0=30.839646603840755, w1=-63.2550882625059\n",
      "Gradient Descent(5441/9999): loss=11815.04022212001, w0=18.512846603840757, w1=-66.2556882625059\n",
      "Gradient Descent(5442/9999): loss=4743.085006220959, w0=18.512846603840757, w1=-66.2556882625059\n",
      "Gradient Descent(5443/9999): loss=4743.085006220959, w0=18.512846603840757, w1=-66.2556882625059\n",
      "Gradient Descent(5444/9999): loss=4743.085006220959, w0=38.182346603840756, w1=-64.4118882625059\n",
      "Gradient Descent(5445/9999): loss=15887.8342217801, w0=26.115581218287222, w1=-74.3670882625059\n",
      "Gradient Descent(5446/9999): loss=6954.484696848414, w0=26.115581218287222, w1=-74.3670882625059\n",
      "Gradient Descent(5447/9999): loss=6954.484696848414, w0=26.115581218287222, w1=-74.3670882625059\n",
      "Gradient Descent(5448/9999): loss=6954.484696848414, w0=26.115581218287222, w1=-74.3670882625059\n",
      "Gradient Descent(5449/9999): loss=6954.484696848414, w0=13.133681218287222, w1=-81.4184882625059\n",
      "Gradient Descent(5450/9999): loss=4446.6234175959635, w0=13.133681218287222, w1=-81.4184882625059\n",
      "Gradient Descent(5451/9999): loss=4446.6234175959635, w0=13.133681218287222, w1=-81.4184882625059\n",
      "Gradient Descent(5452/9999): loss=4446.6234175959635, w0=13.133681218287222, w1=-81.4184882625059\n",
      "Gradient Descent(5453/9999): loss=4446.6234175959635, w0=13.133681218287222, w1=-81.4184882625059\n",
      "Gradient Descent(5454/9999): loss=4446.6234175959635, w0=13.133681218287222, w1=-81.4184882625059\n",
      "Gradient Descent(5455/9999): loss=4446.6234175959635, w0=13.133681218287222, w1=-81.4184882625059\n",
      "Gradient Descent(5456/9999): loss=4446.6234175959635, w0=13.133681218287222, w1=-81.4184882625059\n",
      "Gradient Descent(5457/9999): loss=4446.6234175959635, w0=13.133681218287222, w1=-81.4184882625059\n",
      "Gradient Descent(5458/9999): loss=4446.6234175959635, w0=23.081881218287222, w1=-76.6001882625059\n",
      "Gradient Descent(5459/9999): loss=5553.687218151967, w0=23.081881218287222, w1=-76.6001882625059\n",
      "Gradient Descent(5460/9999): loss=5553.687218151967, w0=29.842081218287223, w1=-71.19158826250589\n",
      "Gradient Descent(5461/9999): loss=11683.11698591042, w0=22.912181218287223, w1=-75.29088826250589\n",
      "Gradient Descent(5462/9999): loss=4572.605265633403, w0=22.912181218287223, w1=-75.29088826250589\n",
      "Gradient Descent(5463/9999): loss=4572.605265633403, w0=22.912181218287223, w1=-75.29088826250589\n",
      "Gradient Descent(5464/9999): loss=4572.605265633403, w0=22.912181218287223, w1=-75.29088826250589\n",
      "Gradient Descent(5465/9999): loss=4572.605265633403, w0=22.912181218287223, w1=-75.29088826250589\n",
      "Gradient Descent(5466/9999): loss=4572.605265633403, w0=22.912181218287223, w1=-75.29088826250589\n",
      "Gradient Descent(5467/9999): loss=4572.605265633403, w0=22.912181218287223, w1=-75.29088826250589\n",
      "Gradient Descent(5468/9999): loss=4572.605265633403, w0=22.912181218287223, w1=-75.29088826250589\n",
      "Gradient Descent(5469/9999): loss=4572.605265633403, w0=22.912181218287223, w1=-75.29088826250589\n",
      "Gradient Descent(5470/9999): loss=4572.605265633403, w0=22.912181218287223, w1=-75.29088826250589\n",
      "Gradient Descent(5471/9999): loss=4572.605265633403, w0=15.032081218287223, w1=-77.44928826250589\n",
      "Gradient Descent(5472/9999): loss=4535.95450538602, w0=15.032081218287223, w1=-77.44928826250589\n",
      "Gradient Descent(5473/9999): loss=4535.95450538602, w0=15.032081218287223, w1=-77.44928826250589\n",
      "Gradient Descent(5474/9999): loss=4535.95450538602, w0=15.032081218287223, w1=-77.44928826250589\n",
      "Gradient Descent(5475/9999): loss=4535.95450538602, w0=15.032081218287223, w1=-77.44928826250589\n",
      "Gradient Descent(5476/9999): loss=4535.95450538602, w0=15.032081218287223, w1=-77.44928826250589\n",
      "Gradient Descent(5477/9999): loss=4535.95450538602, w0=15.032081218287223, w1=-77.44928826250589\n",
      "Gradient Descent(5478/9999): loss=4535.95450538602, w0=15.032081218287223, w1=-77.44928826250589\n",
      "Gradient Descent(5479/9999): loss=4535.95450538602, w0=15.032081218287223, w1=-77.44928826250589\n",
      "Gradient Descent(5480/9999): loss=4535.95450538602, w0=15.032081218287223, w1=-77.44928826250589\n",
      "Gradient Descent(5481/9999): loss=4535.95450538602, w0=24.898681218287216, w1=-74.81188826250589\n",
      "Gradient Descent(5482/9999): loss=4836.897761078421, w0=24.898681218287216, w1=-74.81188826250589\n",
      "Gradient Descent(5483/9999): loss=4836.897761078421, w0=24.898681218287216, w1=-74.81188826250589\n",
      "Gradient Descent(5484/9999): loss=4836.897761078421, w0=24.898681218287216, w1=-74.81188826250589\n",
      "Gradient Descent(5485/9999): loss=4836.897761078421, w0=24.898681218287216, w1=-74.81188826250589\n",
      "Gradient Descent(5486/9999): loss=4836.897761078421, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5487/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5488/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5489/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5490/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5491/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5492/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5493/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5494/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5495/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5496/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5497/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5498/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5499/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5500/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5501/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5502/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5503/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5504/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5505/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5506/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5507/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5508/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5509/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5510/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5511/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5512/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5513/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5514/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5515/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5516/9999): loss=4899.0424513174175, w0=14.566381218287216, w1=-77.36948826250588\n",
      "Gradient Descent(5517/9999): loss=4899.0424513174175, w0=26.697381218287216, w1=-76.38638826250589\n",
      "Gradient Descent(5518/9999): loss=5111.782618763296, w0=26.697381218287216, w1=-76.38638826250589\n",
      "Gradient Descent(5519/9999): loss=5111.782618763296, w0=26.697381218287216, w1=-76.38638826250589\n",
      "Gradient Descent(5520/9999): loss=5111.782618763296, w0=13.930381218287215, w1=-81.32978826250589\n",
      "Gradient Descent(5521/9999): loss=5042.64574373504, w0=23.176481218287215, w1=-75.60838826250588\n",
      "Gradient Descent(5522/9999): loss=4351.820085178225, w0=23.176481218287215, w1=-75.60838826250588\n",
      "Gradient Descent(5523/9999): loss=4351.820085178225, w0=38.21638121828722, w1=-67.83748826250589\n",
      "Gradient Descent(5524/9999): loss=16093.71112685327, w0=38.21638121828722, w1=-67.83748826250589\n",
      "Gradient Descent(5525/9999): loss=16093.71112685327, w0=26.149615832733684, w1=-75.97218826250588\n",
      "Gradient Descent(5526/9999): loss=5373.732705884566, w0=26.149615832733684, w1=-75.97218826250588\n",
      "Gradient Descent(5527/9999): loss=5373.732705884566, w0=26.149615832733684, w1=-75.97218826250588\n",
      "Gradient Descent(5528/9999): loss=5373.732705884566, w0=36.09781583273369, w1=-71.15388826250589\n",
      "Gradient Descent(5529/9999): loss=13561.933745773575, w0=15.807515832733685, w1=-80.87748826250589\n",
      "Gradient Descent(5530/9999): loss=4291.3442248735255, w0=6.579515832733685, w1=-81.0848882625059\n",
      "Gradient Descent(5531/9999): loss=5572.341950875421, w0=6.579515832733685, w1=-81.0848882625059\n",
      "Gradient Descent(5532/9999): loss=5572.341950875421, w0=6.579515832733685, w1=-81.0848882625059\n",
      "Gradient Descent(5533/9999): loss=5572.341950875421, w0=6.579515832733685, w1=-81.0848882625059\n",
      "Gradient Descent(5534/9999): loss=5572.341950875421, w0=6.579515832733685, w1=-81.0848882625059\n",
      "Gradient Descent(5535/9999): loss=5572.341950875421, w0=6.579515832733685, w1=-81.0848882625059\n",
      "Gradient Descent(5536/9999): loss=5572.341950875421, w0=6.579515832733685, w1=-81.0848882625059\n",
      "Gradient Descent(5537/9999): loss=5572.341950875421, w0=6.579515832733685, w1=-81.0848882625059\n",
      "Gradient Descent(5538/9999): loss=5572.341950875421, w0=6.579515832733685, w1=-81.0848882625059\n",
      "Gradient Descent(5539/9999): loss=5572.341950875421, w0=6.579515832733685, w1=-81.0848882625059\n",
      "Gradient Descent(5540/9999): loss=5572.341950875421, w0=6.579515832733685, w1=-81.0848882625059\n",
      "Gradient Descent(5541/9999): loss=5572.341950875421, w0=6.579515832733685, w1=-81.0848882625059\n",
      "Gradient Descent(5542/9999): loss=5572.341950875421, w0=16.916115832733688, w1=-78.6595882625059\n",
      "Gradient Descent(5543/9999): loss=4420.893089618966, w0=16.916115832733688, w1=-78.6595882625059\n",
      "Gradient Descent(5544/9999): loss=4420.893089618966, w0=4.607415832733686, w1=-81.2677882625059\n",
      "Gradient Descent(5545/9999): loss=5496.7303266495655, w0=4.607415832733686, w1=-81.2677882625059\n",
      "Gradient Descent(5546/9999): loss=5496.7303266495655, w0=4.607415832733686, w1=-81.2677882625059\n",
      "Gradient Descent(5547/9999): loss=5496.7303266495655, w0=4.607415832733686, w1=-81.2677882625059\n",
      "Gradient Descent(5548/9999): loss=5496.7303266495655, w0=4.607415832733686, w1=-81.2677882625059\n",
      "Gradient Descent(5549/9999): loss=5496.7303266495655, w0=14.096815832733686, w1=-77.7639882625059\n",
      "Gradient Descent(5550/9999): loss=4281.574383133711, w0=14.096815832733686, w1=-77.7639882625059\n",
      "Gradient Descent(5551/9999): loss=4281.574383133711, w0=14.096815832733686, w1=-77.7639882625059\n",
      "Gradient Descent(5552/9999): loss=4281.574383133711, w0=14.096815832733686, w1=-77.7639882625059\n",
      "Gradient Descent(5553/9999): loss=4281.574383133711, w0=14.096815832733686, w1=-77.7639882625059\n",
      "Gradient Descent(5554/9999): loss=4281.574383133711, w0=14.096815832733686, w1=-77.7639882625059\n",
      "Gradient Descent(5555/9999): loss=4281.574383133711, w0=14.096815832733686, w1=-77.7639882625059\n",
      "Gradient Descent(5556/9999): loss=4281.574383133711, w0=6.078015832733685, w1=-79.6582882625059\n",
      "Gradient Descent(5557/9999): loss=5019.619877509453, w0=6.078015832733685, w1=-79.6582882625059\n",
      "Gradient Descent(5558/9999): loss=5019.619877509453, w0=6.078015832733685, w1=-79.6582882625059\n",
      "Gradient Descent(5559/9999): loss=5019.619877509453, w0=20.421115832733687, w1=-77.7618882625059\n",
      "Gradient Descent(5560/9999): loss=7404.501933443797, w0=20.421115832733687, w1=-77.7618882625059\n",
      "Gradient Descent(5561/9999): loss=7404.501933443797, w0=20.421115832733687, w1=-77.7618882625059\n",
      "Gradient Descent(5562/9999): loss=7404.501933443797, w0=20.421115832733687, w1=-77.7618882625059\n",
      "Gradient Descent(5563/9999): loss=7404.501933443797, w0=20.421115832733687, w1=-77.7618882625059\n",
      "Gradient Descent(5564/9999): loss=7404.501933443797, w0=20.421115832733687, w1=-77.7618882625059\n",
      "Gradient Descent(5565/9999): loss=7404.501933443797, w0=20.421115832733687, w1=-77.7618882625059\n",
      "Gradient Descent(5566/9999): loss=7404.501933443797, w0=20.421115832733687, w1=-77.7618882625059\n",
      "Gradient Descent(5567/9999): loss=7404.501933443797, w0=20.421115832733687, w1=-77.7618882625059\n",
      "Gradient Descent(5568/9999): loss=7404.501933443797, w0=11.762515832733687, w1=-79.73628826250591\n",
      "Gradient Descent(5569/9999): loss=4424.53611022054, w0=11.762515832733687, w1=-79.73628826250591\n",
      "Gradient Descent(5570/9999): loss=4424.53611022054, w0=11.762515832733687, w1=-79.73628826250591\n",
      "Gradient Descent(5571/9999): loss=4424.53611022054, w0=11.762515832733687, w1=-79.73628826250591\n",
      "Gradient Descent(5572/9999): loss=4424.53611022054, w0=11.762515832733687, w1=-79.73628826250591\n",
      "Gradient Descent(5573/9999): loss=4424.53611022054, w0=11.762515832733687, w1=-79.73628826250591\n",
      "Gradient Descent(5574/9999): loss=4424.53611022054, w0=18.933615832733686, w1=-76.38878826250591\n",
      "Gradient Descent(5575/9999): loss=5899.390847108816, w0=18.933615832733686, w1=-76.38878826250591\n",
      "Gradient Descent(5576/9999): loss=5899.390847108816, w0=18.933615832733686, w1=-76.38878826250591\n",
      "Gradient Descent(5577/9999): loss=5899.390847108816, w0=18.933615832733686, w1=-76.38878826250591\n",
      "Gradient Descent(5578/9999): loss=5899.390847108816, w0=18.933615832733686, w1=-76.38878826250591\n",
      "Gradient Descent(5579/9999): loss=5899.390847108816, w0=18.933615832733686, w1=-76.38878826250591\n",
      "Gradient Descent(5580/9999): loss=5899.390847108816, w0=18.933615832733686, w1=-76.38878826250591\n",
      "Gradient Descent(5581/9999): loss=5899.390847108816, w0=-0.7219841672663136, w1=-83.02348826250591\n",
      "Gradient Descent(5582/9999): loss=5494.088775913027, w0=-0.7219841672663136, w1=-83.02348826250591\n",
      "Gradient Descent(5583/9999): loss=5494.088775913027, w0=-0.7219841672663136, w1=-83.02348826250591\n",
      "Gradient Descent(5584/9999): loss=5494.088775913027, w0=-0.7219841672663136, w1=-83.02348826250591\n",
      "Gradient Descent(5585/9999): loss=5494.088775913027, w0=-0.7219841672663136, w1=-83.02348826250591\n",
      "Gradient Descent(5586/9999): loss=5494.088775913027, w0=12.028815832733686, w1=-77.42248826250591\n",
      "Gradient Descent(5587/9999): loss=4563.628794703939, w0=12.028815832733686, w1=-77.42248826250591\n",
      "Gradient Descent(5588/9999): loss=4563.628794703939, w0=12.028815832733686, w1=-77.42248826250591\n",
      "Gradient Descent(5589/9999): loss=4563.628794703939, w0=12.028815832733686, w1=-77.42248826250591\n",
      "Gradient Descent(5590/9999): loss=4563.628794703939, w0=12.028815832733686, w1=-77.42248826250591\n",
      "Gradient Descent(5591/9999): loss=4563.628794703939, w0=12.028815832733686, w1=-77.42248826250591\n",
      "Gradient Descent(5592/9999): loss=4563.628794703939, w0=12.028815832733686, w1=-77.42248826250591\n",
      "Gradient Descent(5593/9999): loss=4563.628794703939, w0=12.028815832733686, w1=-77.42248826250591\n",
      "Gradient Descent(5594/9999): loss=4563.628794703939, w0=12.028815832733686, w1=-77.42248826250591\n",
      "Gradient Descent(5595/9999): loss=4563.628794703939, w0=12.028815832733686, w1=-77.42248826250591\n",
      "Gradient Descent(5596/9999): loss=4563.628794703939, w0=12.028815832733686, w1=-77.42248826250591\n",
      "Gradient Descent(5597/9999): loss=4563.628794703939, w0=12.028815832733686, w1=-77.42248826250591\n",
      "Gradient Descent(5598/9999): loss=4563.628794703939, w0=12.028815832733686, w1=-77.42248826250591\n",
      "Gradient Descent(5599/9999): loss=4563.628794703939, w0=3.3972158327336857, w1=-80.11018826250591\n",
      "Gradient Descent(5600/9999): loss=4730.276463453717, w0=3.3972158327336857, w1=-80.11018826250591\n",
      "Gradient Descent(5601/9999): loss=4730.276463453717, w0=3.3972158327336857, w1=-80.11018826250591\n",
      "Gradient Descent(5602/9999): loss=4730.276463453717, w0=3.3972158327336857, w1=-80.11018826250591\n",
      "Gradient Descent(5603/9999): loss=4730.276463453717, w0=3.3972158327336857, w1=-80.11018826250591\n",
      "Gradient Descent(5604/9999): loss=4730.276463453717, w0=3.3972158327336857, w1=-80.11018826250591\n",
      "Gradient Descent(5605/9999): loss=4730.276463453717, w0=3.3972158327336857, w1=-80.11018826250591\n",
      "Gradient Descent(5606/9999): loss=4730.276463453717, w0=3.3972158327336857, w1=-80.11018826250591\n",
      "Gradient Descent(5607/9999): loss=4730.276463453717, w0=3.3972158327336857, w1=-80.11018826250591\n",
      "Gradient Descent(5608/9999): loss=4730.276463453717, w0=3.3972158327336857, w1=-80.11018826250591\n",
      "Gradient Descent(5609/9999): loss=4730.276463453717, w0=3.3972158327336857, w1=-80.11018826250591\n",
      "Gradient Descent(5610/9999): loss=4730.276463453717, w0=16.120515832733687, w1=-76.05288826250592\n",
      "Gradient Descent(5611/9999): loss=4800.87443044571, w0=28.18728121828722, w1=-66.95748826250592\n",
      "Gradient Descent(5612/9999): loss=10624.920688257302, w0=28.18728121828722, w1=-66.95748826250592\n",
      "Gradient Descent(5613/9999): loss=10624.920688257302, w0=16.120515832733687, w1=-73.76738826250592\n",
      "Gradient Descent(5614/9999): loss=4522.396255218273, w0=16.120515832733687, w1=-73.76738826250592\n",
      "Gradient Descent(5615/9999): loss=4522.396255218273, w0=16.120515832733687, w1=-73.76738826250592\n",
      "Gradient Descent(5616/9999): loss=4522.396255218273, w0=16.120515832733687, w1=-73.76738826250592\n",
      "Gradient Descent(5617/9999): loss=4522.396255218273, w0=7.766815832733686, w1=-74.49168826250592\n",
      "Gradient Descent(5618/9999): loss=5733.423996849251, w0=18.991615832733686, w1=-66.88658826250591\n",
      "Gradient Descent(5619/9999): loss=4594.163673862197, w0=31.221115832733688, w1=-64.7078882625059\n",
      "Gradient Descent(5620/9999): loss=7950.855222259503, w0=31.221115832733688, w1=-64.7078882625059\n",
      "Gradient Descent(5621/9999): loss=7950.855222259503, w0=22.94461583273369, w1=-69.4790882625059\n",
      "Gradient Descent(5622/9999): loss=4252.484422123062, w0=22.94461583273369, w1=-69.4790882625059\n",
      "Gradient Descent(5623/9999): loss=4252.484422123062, w0=22.94461583273369, w1=-69.4790882625059\n",
      "Gradient Descent(5624/9999): loss=4252.484422123062, w0=22.94461583273369, w1=-69.4790882625059\n",
      "Gradient Descent(5625/9999): loss=4252.484422123062, w0=22.94461583273369, w1=-69.4790882625059\n",
      "Gradient Descent(5626/9999): loss=4252.484422123062, w0=22.94461583273369, w1=-69.4790882625059\n",
      "Gradient Descent(5627/9999): loss=4252.484422123062, w0=22.94461583273369, w1=-69.4790882625059\n",
      "Gradient Descent(5628/9999): loss=4252.484422123062, w0=33.37641583273369, w1=-65.10608826250589\n",
      "Gradient Descent(5629/9999): loss=11775.4289337391, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5630/9999): loss=4462.064332217931, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5631/9999): loss=4462.064332217931, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5632/9999): loss=4462.064332217931, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5633/9999): loss=4462.064332217931, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5634/9999): loss=4462.064332217931, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5635/9999): loss=4462.064332217931, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5636/9999): loss=4462.064332217931, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5637/9999): loss=4462.064332217931, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5638/9999): loss=4462.064332217931, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5639/9999): loss=4462.064332217931, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5640/9999): loss=4462.064332217931, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5641/9999): loss=4462.064332217931, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5642/9999): loss=4462.064332217931, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5643/9999): loss=4462.064332217931, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5644/9999): loss=4462.064332217931, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5645/9999): loss=4462.064332217931, w0=23.53651583273369, w1=-69.63388826250589\n",
      "Gradient Descent(5646/9999): loss=4462.064332217931, w0=35.60328121828722, w1=-56.015588262505894\n",
      "Gradient Descent(5647/9999): loss=14071.026395485602, w0=21.814181218287224, w1=-60.840988262505896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(5648/9999): loss=4620.466349117595, w0=21.814181218287224, w1=-60.840988262505896\n",
      "Gradient Descent(5649/9999): loss=4620.466349117595, w0=21.814181218287224, w1=-60.840988262505896\n",
      "Gradient Descent(5650/9999): loss=4620.466349117595, w0=21.814181218287224, w1=-60.840988262505896\n",
      "Gradient Descent(5651/9999): loss=4620.466349117595, w0=29.998081218287226, w1=-59.2885882625059\n",
      "Gradient Descent(5652/9999): loss=14413.630493845872, w0=29.998081218287226, w1=-59.2885882625059\n",
      "Gradient Descent(5653/9999): loss=14413.630493845872, w0=17.314781218287223, w1=-61.340988262505896\n",
      "Gradient Descent(5654/9999): loss=4489.867150349641, w0=27.498181218287222, w1=-57.8829882625059\n",
      "Gradient Descent(5655/9999): loss=14232.714170804347, w0=15.431415832733688, w1=-63.713388262505894\n",
      "Gradient Descent(5656/9999): loss=5303.783536840587, w0=3.656515832733687, w1=-66.46898826250589\n",
      "Gradient Descent(5657/9999): loss=4922.8374618672815, w0=3.656515832733687, w1=-66.46898826250589\n",
      "Gradient Descent(5658/9999): loss=4922.8374618672815, w0=3.656515832733687, w1=-66.46898826250589\n",
      "Gradient Descent(5659/9999): loss=4922.8374618672815, w0=3.656515832733687, w1=-66.46898826250589\n",
      "Gradient Descent(5660/9999): loss=4922.8374618672815, w0=3.656515832733687, w1=-66.46898826250589\n",
      "Gradient Descent(5661/9999): loss=4922.8374618672815, w0=16.93161583273369, w1=-63.464188262505886\n",
      "Gradient Descent(5662/9999): loss=7475.33438802132, w0=16.93161583273369, w1=-63.464188262505886\n",
      "Gradient Descent(5663/9999): loss=7475.33438802132, w0=16.93161583273369, w1=-63.464188262505886\n",
      "Gradient Descent(5664/9999): loss=7475.33438802132, w0=16.93161583273369, w1=-63.464188262505886\n",
      "Gradient Descent(5665/9999): loss=7475.33438802132, w0=16.93161583273369, w1=-63.464188262505886\n",
      "Gradient Descent(5666/9999): loss=7475.33438802132, w0=16.93161583273369, w1=-63.464188262505886\n",
      "Gradient Descent(5667/9999): loss=7475.33438802132, w0=-4.1799841672663085, w1=-72.43758826250588\n",
      "Gradient Descent(5668/9999): loss=4916.010559708619, w0=5.053615832733692, w1=-68.77858826250588\n",
      "Gradient Descent(5669/9999): loss=4766.326298047079, w0=5.053615832733692, w1=-68.77858826250588\n",
      "Gradient Descent(5670/9999): loss=4766.326298047079, w0=5.053615832733692, w1=-68.77858826250588\n",
      "Gradient Descent(5671/9999): loss=4766.326298047079, w0=5.053615832733692, w1=-68.77858826250588\n",
      "Gradient Descent(5672/9999): loss=4766.326298047079, w0=5.053615832733692, w1=-68.77858826250588\n",
      "Gradient Descent(5673/9999): loss=4766.326298047079, w0=5.053615832733692, w1=-68.77858826250588\n",
      "Gradient Descent(5674/9999): loss=4766.326298047079, w0=5.053615832733692, w1=-68.77858826250588\n",
      "Gradient Descent(5675/9999): loss=4766.326298047079, w0=5.053615832733692, w1=-68.77858826250588\n",
      "Gradient Descent(5676/9999): loss=4766.326298047079, w0=5.053615832733692, w1=-68.77858826250588\n",
      "Gradient Descent(5677/9999): loss=4766.326298047079, w0=5.053615832733692, w1=-68.77858826250588\n",
      "Gradient Descent(5678/9999): loss=4766.326298047079, w0=5.053615832733692, w1=-68.77858826250588\n",
      "Gradient Descent(5679/9999): loss=4766.326298047079, w0=-0.9291841672663086, w1=-71.82768826250587\n",
      "Gradient Descent(5680/9999): loss=4552.567860690068, w0=-0.9291841672663086, w1=-71.82768826250587\n",
      "Gradient Descent(5681/9999): loss=4552.567860690068, w0=10.390515832733692, w1=-67.56768826250587\n",
      "Gradient Descent(5682/9999): loss=6719.700266873262, w0=10.390515832733692, w1=-67.56768826250587\n",
      "Gradient Descent(5683/9999): loss=6719.700266873262, w0=10.390515832733692, w1=-67.56768826250587\n",
      "Gradient Descent(5684/9999): loss=6719.700266873262, w0=10.390515832733692, w1=-67.56768826250587\n",
      "Gradient Descent(5685/9999): loss=6719.700266873262, w0=1.042815832733691, w1=-74.80158826250587\n",
      "Gradient Descent(5686/9999): loss=4890.484958259889, w0=12.278915832733691, w1=-68.34538826250588\n",
      "Gradient Descent(5687/9999): loss=5470.4354951899895, w0=23.110815832733692, w1=-61.38818826250588\n",
      "Gradient Descent(5688/9999): loss=15811.545289088273, w0=23.110815832733692, w1=-61.38818826250588\n",
      "Gradient Descent(5689/9999): loss=15811.545289088273, w0=23.110815832733692, w1=-61.38818826250588\n",
      "Gradient Descent(5690/9999): loss=15811.545289088273, w0=11.044050447180158, w1=-68.49618826250588\n",
      "Gradient Descent(5691/9999): loss=6773.783392778854, w0=11.044050447180158, w1=-68.49618826250588\n",
      "Gradient Descent(5692/9999): loss=6773.783392778854, w0=2.308950447180157, w1=-69.02238826250588\n",
      "Gradient Descent(5693/9999): loss=4386.597466565508, w0=-4.556649552819843, w1=-71.55178826250588\n",
      "Gradient Descent(5694/9999): loss=5710.3960007003825, w0=6.449350447180157, w1=-70.80638826250588\n",
      "Gradient Descent(5695/9999): loss=4377.727242750774, w0=6.449350447180157, w1=-70.80638826250588\n",
      "Gradient Descent(5696/9999): loss=4377.727242750774, w0=6.449350447180157, w1=-70.80638826250588\n",
      "Gradient Descent(5697/9999): loss=4377.727242750774, w0=6.449350447180157, w1=-70.80638826250588\n",
      "Gradient Descent(5698/9999): loss=4377.727242750774, w0=6.449350447180157, w1=-70.80638826250588\n",
      "Gradient Descent(5699/9999): loss=4377.727242750774, w0=6.449350447180157, w1=-70.80638826250588\n",
      "Gradient Descent(5700/9999): loss=4377.727242750774, w0=6.449350447180157, w1=-70.80638826250588\n",
      "Gradient Descent(5701/9999): loss=4377.727242750774, w0=6.449350447180157, w1=-70.80638826250588\n",
      "Gradient Descent(5702/9999): loss=4377.727242750774, w0=6.449350447180157, w1=-70.80638826250588\n",
      "Gradient Descent(5703/9999): loss=4377.727242750774, w0=6.449350447180157, w1=-70.80638826250588\n",
      "Gradient Descent(5704/9999): loss=4377.727242750774, w0=6.449350447180157, w1=-70.80638826250588\n",
      "Gradient Descent(5705/9999): loss=4377.727242750774, w0=-1.8771495528198443, w1=-72.65258826250587\n",
      "Gradient Descent(5706/9999): loss=5442.594690876947, w0=-1.8771495528198443, w1=-72.65258826250587\n",
      "Gradient Descent(5707/9999): loss=5442.594690876947, w0=-1.8771495528198443, w1=-72.65258826250587\n",
      "Gradient Descent(5708/9999): loss=5442.594690876947, w0=-1.8771495528198443, w1=-72.65258826250587\n",
      "Gradient Descent(5709/9999): loss=5442.594690876947, w0=-1.8771495528198443, w1=-72.65258826250587\n",
      "Gradient Descent(5710/9999): loss=5442.594690876947, w0=-1.8771495528198443, w1=-72.65258826250587\n",
      "Gradient Descent(5711/9999): loss=5442.594690876947, w0=-1.8771495528198443, w1=-72.65258826250587\n",
      "Gradient Descent(5712/9999): loss=5442.594690876947, w0=-1.8771495528198443, w1=-72.65258826250587\n",
      "Gradient Descent(5713/9999): loss=5442.594690876947, w0=11.000250447180157, w1=-71.81618826250588\n",
      "Gradient Descent(5714/9999): loss=4239.270886112071, w0=11.000250447180157, w1=-71.81618826250588\n",
      "Gradient Descent(5715/9999): loss=4239.270886112071, w0=11.000250447180157, w1=-71.81618826250588\n",
      "Gradient Descent(5716/9999): loss=4239.270886112071, w0=11.000250447180157, w1=-71.81618826250588\n",
      "Gradient Descent(5717/9999): loss=4239.270886112071, w0=11.000250447180157, w1=-71.81618826250588\n",
      "Gradient Descent(5718/9999): loss=4239.270886112071, w0=11.000250447180157, w1=-71.81618826250588\n",
      "Gradient Descent(5719/9999): loss=4239.270886112071, w0=11.000250447180157, w1=-71.81618826250588\n",
      "Gradient Descent(5720/9999): loss=4239.270886112071, w0=20.161650447180158, w1=-64.24158826250587\n",
      "Gradient Descent(5721/9999): loss=12501.227830671298, w0=20.161650447180158, w1=-64.24158826250587\n",
      "Gradient Descent(5722/9999): loss=12501.227830671298, w0=20.161650447180158, w1=-64.24158826250587\n",
      "Gradient Descent(5723/9999): loss=12501.227830671298, w0=2.665250447180153, w1=-74.46708826250587\n",
      "Gradient Descent(5724/9999): loss=4822.115955347326, w0=2.665250447180153, w1=-74.46708826250587\n",
      "Gradient Descent(5725/9999): loss=4822.115955347326, w0=2.665250447180153, w1=-74.46708826250587\n",
      "Gradient Descent(5726/9999): loss=4822.115955347326, w0=14.732015832733687, w1=-61.81518826250587\n",
      "Gradient Descent(5727/9999): loss=5559.531585218266, w0=14.732015832733687, w1=-61.81518826250587\n",
      "Gradient Descent(5728/9999): loss=5559.531585218266, w0=2.665250447180153, w1=-68.71218826250588\n",
      "Gradient Descent(5729/9999): loss=5802.4994844197445, w0=2.665250447180153, w1=-68.71218826250588\n",
      "Gradient Descent(5730/9999): loss=5802.4994844197445, w0=2.665250447180153, w1=-68.71218826250588\n",
      "Gradient Descent(5731/9999): loss=5802.4994844197445, w0=2.665250447180153, w1=-68.71218826250588\n",
      "Gradient Descent(5732/9999): loss=5802.4994844197445, w0=2.665250447180153, w1=-68.71218826250588\n",
      "Gradient Descent(5733/9999): loss=5802.4994844197445, w0=2.665250447180153, w1=-68.71218826250588\n",
      "Gradient Descent(5734/9999): loss=5802.4994844197445, w0=12.304350447180154, w1=-66.48388826250587\n",
      "Gradient Descent(5735/9999): loss=4406.333333564204, w0=12.304350447180154, w1=-66.48388826250587\n",
      "Gradient Descent(5736/9999): loss=4406.333333564204, w0=12.304350447180154, w1=-66.48388826250587\n",
      "Gradient Descent(5737/9999): loss=4406.333333564204, w0=12.304350447180154, w1=-66.48388826250587\n",
      "Gradient Descent(5738/9999): loss=4406.333333564204, w0=12.304350447180154, w1=-66.48388826250587\n",
      "Gradient Descent(5739/9999): loss=4406.333333564204, w0=12.304350447180154, w1=-66.48388826250587\n",
      "Gradient Descent(5740/9999): loss=4406.333333564204, w0=12.304350447180154, w1=-66.48388826250587\n",
      "Gradient Descent(5741/9999): loss=4406.333333564204, w0=12.304350447180154, w1=-66.48388826250587\n",
      "Gradient Descent(5742/9999): loss=4406.333333564204, w0=12.304350447180154, w1=-66.48388826250587\n",
      "Gradient Descent(5743/9999): loss=4406.333333564204, w0=12.304350447180154, w1=-66.48388826250587\n",
      "Gradient Descent(5744/9999): loss=4406.333333564204, w0=22.212950447180155, w1=-62.35478826250587\n",
      "Gradient Descent(5745/9999): loss=11662.324308497564, w0=22.212950447180155, w1=-62.35478826250587\n",
      "Gradient Descent(5746/9999): loss=11662.324308497564, w0=22.212950447180155, w1=-62.35478826250587\n",
      "Gradient Descent(5747/9999): loss=11662.324308497564, w0=22.212950447180155, w1=-62.35478826250587\n",
      "Gradient Descent(5748/9999): loss=11662.324308497564, w0=22.212950447180155, w1=-62.35478826250587\n",
      "Gradient Descent(5749/9999): loss=11662.324308497564, w0=0.4281537783575047, w1=-72.96078664071146\n",
      "Gradient Descent(5750/9999): loss=4541.369301610591, w0=0.4281537783575047, w1=-72.96078664071146\n",
      "Gradient Descent(5751/9999): loss=4541.369301610591, w0=15.468053778357506, w1=-65.18988664071146\n",
      "Gradient Descent(5752/9999): loss=11350.356156851856, w0=6.8866537783575055, w1=-70.40898664071146\n",
      "Gradient Descent(5753/9999): loss=4411.870857564178, w0=6.8866537783575055, w1=-70.40898664071146\n",
      "Gradient Descent(5754/9999): loss=4411.870857564178, w0=18.05755377835751, w1=-63.44598664071146\n",
      "Gradient Descent(5755/9999): loss=13827.612584969844, w0=-4.028446221642493, w1=-71.66738664071146\n",
      "Gradient Descent(5756/9999): loss=4466.84803337865, w0=8.03831916391104, w1=-61.71108664071146\n",
      "Gradient Descent(5757/9999): loss=8867.857119938313, w0=8.03831916391104, w1=-61.71108664071146\n",
      "Gradient Descent(5758/9999): loss=8867.857119938313, w0=8.03831916391104, w1=-61.71108664071146\n",
      "Gradient Descent(5759/9999): loss=8867.857119938313, w0=-8.639580836088964, w1=-61.76768664071146\n",
      "Gradient Descent(5760/9999): loss=4830.746303248281, w0=-8.639580836088964, w1=-61.76768664071146\n",
      "Gradient Descent(5761/9999): loss=4830.746303248281, w0=-8.639580836088964, w1=-61.76768664071146\n",
      "Gradient Descent(5762/9999): loss=4830.746303248281, w0=-8.639580836088964, w1=-61.76768664071146\n",
      "Gradient Descent(5763/9999): loss=4830.746303248281, w0=-8.639580836088964, w1=-61.76768664071146\n",
      "Gradient Descent(5764/9999): loss=4830.746303248281, w0=3.4271845494645703, w1=-52.67228664071146\n",
      "Gradient Descent(5765/9999): loss=4642.251812018747, w0=3.4271845494645703, w1=-52.67228664071146\n",
      "Gradient Descent(5766/9999): loss=4642.251812018747, w0=15.493949935018104, w1=-42.34868664071146\n",
      "Gradient Descent(5767/9999): loss=14528.55734515437, w0=5.298749935018103, w1=-48.780886640711465\n",
      "Gradient Descent(5768/9999): loss=4868.748703669759, w0=5.298749935018103, w1=-48.780886640711465\n",
      "Gradient Descent(5769/9999): loss=4868.748703669759, w0=-4.987650064981898, w1=-53.32138664071147\n",
      "Gradient Descent(5770/9999): loss=5192.316046651574, w0=5.019849935018103, w1=-52.48888664071146\n",
      "Gradient Descent(5771/9999): loss=6021.772770151934, w0=5.019849935018103, w1=-52.48888664071146\n",
      "Gradient Descent(5772/9999): loss=6021.772770151934, w0=17.08661532057164, w1=-33.66148664071146\n",
      "Gradient Descent(5773/9999): loss=16923.99514353268, w0=5.278815320571638, w1=-38.61148664071146\n",
      "Gradient Descent(5774/9999): loss=8070.8002383720395, w0=-5.370784679428363, w1=-40.66318664071146\n",
      "Gradient Descent(5775/9999): loss=4784.778639388933, w0=6.666515320571637, w1=-39.15018664071146\n",
      "Gradient Descent(5776/9999): loss=8060.073565693261, w0=6.666515320571637, w1=-39.15018664071146\n",
      "Gradient Descent(5777/9999): loss=8060.073565693261, w0=-6.267984678493338, w1=-48.01078664007093\n",
      "Gradient Descent(5778/9999): loss=5391.489238100737, w0=-6.267984678493338, w1=-48.01078664007093\n",
      "Gradient Descent(5779/9999): loss=5391.489238100737, w0=-6.267984678493338, w1=-48.01078664007093\n",
      "Gradient Descent(5780/9999): loss=5391.489238100737, w0=-6.267984678493338, w1=-48.01078664007093\n",
      "Gradient Descent(5781/9999): loss=5391.489238100737, w0=-6.267984678493338, w1=-48.01078664007093\n",
      "Gradient Descent(5782/9999): loss=5391.489238100737, w0=-6.267984678493338, w1=-48.01078664007093\n",
      "Gradient Descent(5783/9999): loss=5391.489238100737, w0=6.469015321506664, w1=-46.98918664007093\n",
      "Gradient Descent(5784/9999): loss=8408.505193139707, w0=1.025715321506663, w1=-51.671386640070935\n",
      "Gradient Descent(5785/9999): loss=4475.09681968333, w0=1.025715321506663, w1=-51.671386640070935\n",
      "Gradient Descent(5786/9999): loss=4475.09681968333, w0=1.025715321506663, w1=-51.671386640070935\n",
      "Gradient Descent(5787/9999): loss=4475.09681968333, w0=1.025715321506663, w1=-51.671386640070935\n",
      "Gradient Descent(5788/9999): loss=4475.09681968333, w0=1.025715321506663, w1=-51.671386640070935\n",
      "Gradient Descent(5789/9999): loss=4475.09681968333, w0=1.025715321506663, w1=-51.671386640070935\n",
      "Gradient Descent(5790/9999): loss=4475.09681968333, w0=1.025715321506663, w1=-51.671386640070935\n",
      "Gradient Descent(5791/9999): loss=4475.09681968333, w0=1.025715321506663, w1=-51.671386640070935\n",
      "Gradient Descent(5792/9999): loss=4475.09681968333, w0=8.863715321506664, w1=-49.38638664007094\n",
      "Gradient Descent(5793/9999): loss=8171.916865978919, w0=8.863715321506664, w1=-49.38638664007094\n",
      "Gradient Descent(5794/9999): loss=8171.916865978919, w0=8.863715321506664, w1=-49.38638664007094\n",
      "Gradient Descent(5795/9999): loss=8171.916865978919, w0=8.863715321506664, w1=-49.38638664007094\n",
      "Gradient Descent(5796/9999): loss=8171.916865978919, w0=8.863715321506664, w1=-49.38638664007094\n",
      "Gradient Descent(5797/9999): loss=8171.916865978919, w0=8.863715321506664, w1=-49.38638664007094\n",
      "Gradient Descent(5798/9999): loss=8171.916865978919, w0=8.863715321506664, w1=-49.38638664007094\n",
      "Gradient Descent(5799/9999): loss=8171.916865978919, w0=1.6493153215066663, w1=-54.288286640070936\n",
      "Gradient Descent(5800/9999): loss=4400.955390376361, w0=1.6493153215066663, w1=-54.288286640070936\n",
      "Gradient Descent(5801/9999): loss=4400.955390376361, w0=1.6493153215066663, w1=-54.288286640070936\n",
      "Gradient Descent(5802/9999): loss=4400.955390376361, w0=1.6493153215066663, w1=-54.288286640070936\n",
      "Gradient Descent(5803/9999): loss=4400.955390376361, w0=1.6493153215066663, w1=-54.288286640070936\n",
      "Gradient Descent(5804/9999): loss=4400.955390376361, w0=1.6493153215066663, w1=-54.288286640070936\n",
      "Gradient Descent(5805/9999): loss=4400.955390376361, w0=1.6493153215066663, w1=-54.288286640070936\n",
      "Gradient Descent(5806/9999): loss=4400.955390376361, w0=1.6493153215066663, w1=-54.288286640070936\n",
      "Gradient Descent(5807/9999): loss=4400.955390376361, w0=1.6493153215066663, w1=-54.288286640070936\n",
      "Gradient Descent(5808/9999): loss=4400.955390376361, w0=1.6493153215066663, w1=-54.288286640070936\n",
      "Gradient Descent(5809/9999): loss=4400.955390376361, w0=13.7160807070602, w1=-39.20808664007093\n",
      "Gradient Descent(5810/9999): loss=16290.787321906106, w0=-0.3116192929398025, w1=-40.14378664007093\n",
      "Gradient Descent(5811/9999): loss=6433.60846300407, w0=-0.3116192929398025, w1=-40.14378664007093\n",
      "Gradient Descent(5812/9999): loss=6433.60846300407, w0=-0.3116192929398025, w1=-40.14378664007093\n",
      "Gradient Descent(5813/9999): loss=6433.60846300407, w0=-0.3116192929398025, w1=-40.14378664007093\n",
      "Gradient Descent(5814/9999): loss=6433.60846300407, w0=-0.3116192929398025, w1=-40.14378664007093\n",
      "Gradient Descent(5815/9999): loss=6433.60846300407, w0=-8.347219292939803, w1=-41.132986640070925\n",
      "Gradient Descent(5816/9999): loss=4996.944078983286, w0=-8.347219292939803, w1=-41.132986640070925\n",
      "Gradient Descent(5817/9999): loss=4996.944078983286, w0=-8.347219292939803, w1=-41.132986640070925\n",
      "Gradient Descent(5818/9999): loss=4996.944078983286, w0=-8.347219292939803, w1=-41.132986640070925\n",
      "Gradient Descent(5819/9999): loss=4996.944078983286, w0=-8.347219292939803, w1=-41.132986640070925\n",
      "Gradient Descent(5820/9999): loss=4996.944078983286, w0=-8.347219292939803, w1=-41.132986640070925\n",
      "Gradient Descent(5821/9999): loss=4996.944078983286, w0=-0.0024192929398036966, w1=-38.38868664007092\n",
      "Gradient Descent(5822/9999): loss=7117.355466850706, w0=-0.0024192929398036966, w1=-38.38868664007092\n",
      "Gradient Descent(5823/9999): loss=7117.355466850706, w0=-0.0024192929398036966, w1=-38.38868664007092\n",
      "Gradient Descent(5824/9999): loss=7117.355466850706, w0=-4.4232192929398035, w1=-45.460486640070926\n",
      "Gradient Descent(5825/9999): loss=4916.003153592007, w0=-4.4232192929398035, w1=-45.460486640070926\n",
      "Gradient Descent(5826/9999): loss=4916.003153592007, w0=-4.4232192929398035, w1=-45.460486640070926\n",
      "Gradient Descent(5827/9999): loss=4916.003153592007, w0=-4.4232192929398035, w1=-45.460486640070926\n",
      "Gradient Descent(5828/9999): loss=4916.003153592007, w0=-4.4232192929398035, w1=-45.460486640070926\n",
      "Gradient Descent(5829/9999): loss=4916.003153592007, w0=5.803280707060198, w1=-41.935186640070924\n",
      "Gradient Descent(5830/9999): loss=13898.319510049081, w0=-6.263484678493336, w1=-50.43098664007093\n",
      "Gradient Descent(5831/9999): loss=5514.648903168905, w0=-6.263484678493336, w1=-50.43098664007093\n",
      "Gradient Descent(5832/9999): loss=5514.648903168905, w0=-6.263484678493336, w1=-50.43098664007093\n",
      "Gradient Descent(5833/9999): loss=5514.648903168905, w0=-6.263484678493336, w1=-50.43098664007093\n",
      "Gradient Descent(5834/9999): loss=5514.648903168905, w0=-6.263484678493336, w1=-50.43098664007093\n",
      "Gradient Descent(5835/9999): loss=5514.648903168905, w0=-6.263484678493336, w1=-50.43098664007093\n",
      "Gradient Descent(5836/9999): loss=5514.648903168905, w0=-6.263484678493336, w1=-50.43098664007093\n",
      "Gradient Descent(5837/9999): loss=5514.648903168905, w0=-6.263484678493336, w1=-50.43098664007093\n",
      "Gradient Descent(5838/9999): loss=5514.648903168905, w0=-6.263484678493336, w1=-50.43098664007093\n",
      "Gradient Descent(5839/9999): loss=5514.648903168905, w0=4.422215321506666, w1=-45.08508664007093\n",
      "Gradient Descent(5840/9999): loss=14384.042460417873, w0=-9.931884678493335, w1=-52.75098664007093\n",
      "Gradient Descent(5841/9999): loss=4883.307999400633, w0=-9.931884678493335, w1=-52.75098664007093\n",
      "Gradient Descent(5842/9999): loss=4883.307999400633, w0=-9.931884678493335, w1=-52.75098664007093\n",
      "Gradient Descent(5843/9999): loss=4883.307999400633, w0=-9.931884678493335, w1=-52.75098664007093\n",
      "Gradient Descent(5844/9999): loss=4883.307999400633, w0=-9.931884678493335, w1=-52.75098664007093\n",
      "Gradient Descent(5845/9999): loss=4883.307999400633, w0=-9.931884678493335, w1=-52.75098664007093\n",
      "Gradient Descent(5846/9999): loss=4883.307999400633, w0=-9.931884678493335, w1=-52.75098664007093\n",
      "Gradient Descent(5847/9999): loss=4883.307999400633, w0=2.3367153215066665, w1=-46.14698664007093\n",
      "Gradient Descent(5848/9999): loss=13797.826516411464, w0=-9.730050064046868, w1=-55.46158664007093\n",
      "Gradient Descent(5849/9999): loss=4617.741038175933, w0=-12.930150064046867, w1=-62.580786640070926\n",
      "Gradient Descent(5850/9999): loss=5802.363894222351, w0=-12.930150064046867, w1=-62.580786640070926\n",
      "Gradient Descent(5851/9999): loss=5802.363894222351, w0=-12.930150064046867, w1=-62.580786640070926\n",
      "Gradient Descent(5852/9999): loss=5802.363894222351, w0=-12.930150064046867, w1=-62.580786640070926\n",
      "Gradient Descent(5853/9999): loss=5802.363894222351, w0=0.8214499359531331, w1=-58.345486640070924\n",
      "Gradient Descent(5854/9999): loss=4332.965569280816, w0=-9.554550064046868, w1=-63.33128664007093\n",
      "Gradient Descent(5855/9999): loss=5802.4994844197445, w0=-9.554550064046868, w1=-63.33128664007093\n",
      "Gradient Descent(5856/9999): loss=5802.4994844197445, w0=-9.554550064046868, w1=-63.33128664007093\n",
      "Gradient Descent(5857/9999): loss=5802.4994844197445, w0=-9.554550064046868, w1=-63.33128664007093\n",
      "Gradient Descent(5858/9999): loss=5802.4994844197445, w0=-9.554550064046868, w1=-63.33128664007093\n",
      "Gradient Descent(5859/9999): loss=5802.4994844197445, w0=-9.554550064046868, w1=-63.33128664007093\n",
      "Gradient Descent(5860/9999): loss=5802.4994844197445, w0=-0.6089500640468675, w1=-54.74268664007093\n",
      "Gradient Descent(5861/9999): loss=4327.32081013161, w0=-0.6089500640468675, w1=-54.74268664007093\n",
      "Gradient Descent(5862/9999): loss=4327.32081013161, w0=-0.6089500640468675, w1=-54.74268664007093\n",
      "Gradient Descent(5863/9999): loss=4327.32081013161, w0=-0.6089500640468675, w1=-54.74268664007093\n",
      "Gradient Descent(5864/9999): loss=4327.32081013161, w0=-0.6089500640468675, w1=-54.74268664007093\n",
      "Gradient Descent(5865/9999): loss=4327.32081013161, w0=-0.6089500640468675, w1=-54.74268664007093\n",
      "Gradient Descent(5866/9999): loss=4327.32081013161, w0=6.151249935953134, w1=-49.33408664007093\n",
      "Gradient Descent(5867/9999): loss=8079.995657937638, w0=6.151249935953134, w1=-49.33408664007093\n",
      "Gradient Descent(5868/9999): loss=8079.995657937638, w0=6.151249935953134, w1=-49.33408664007093\n",
      "Gradient Descent(5869/9999): loss=8079.995657937638, w0=-2.6071500640468663, w1=-53.152286640070926\n",
      "Gradient Descent(5870/9999): loss=4565.207078291873, w0=-2.6071500640468663, w1=-53.152286640070926\n",
      "Gradient Descent(5871/9999): loss=4565.207078291873, w0=-2.6071500640468663, w1=-53.152286640070926\n",
      "Gradient Descent(5872/9999): loss=4565.207078291873, w0=-2.6071500640468663, w1=-53.152286640070926\n",
      "Gradient Descent(5873/9999): loss=4565.207078291873, w0=6.075149935953133, w1=-46.83278664007093\n",
      "Gradient Descent(5874/9999): loss=6475.879192599447, w0=6.075149935953133, w1=-46.83278664007093\n",
      "Gradient Descent(5875/9999): loss=6475.879192599447, w0=6.075149935953133, w1=-46.83278664007093\n",
      "Gradient Descent(5876/9999): loss=6475.879192599447, w0=-7.713950064046866, w1=-51.65818664007093\n",
      "Gradient Descent(5877/9999): loss=5030.384262274118, w0=-7.713950064046866, w1=-51.65818664007093\n",
      "Gradient Descent(5878/9999): loss=5030.384262274118, w0=-7.713950064046866, w1=-51.65818664007093\n",
      "Gradient Descent(5879/9999): loss=5030.384262274118, w0=-7.713950064046866, w1=-51.65818664007093\n",
      "Gradient Descent(5880/9999): loss=5030.384262274118, w0=-7.713950064046866, w1=-51.65818664007093\n",
      "Gradient Descent(5881/9999): loss=5030.384262274118, w0=-7.713950064046866, w1=-51.65818664007093\n",
      "Gradient Descent(5882/9999): loss=5030.384262274118, w0=-7.713950064046866, w1=-51.65818664007093\n",
      "Gradient Descent(5883/9999): loss=5030.384262274118, w0=-7.713950064046866, w1=-51.65818664007093\n",
      "Gradient Descent(5884/9999): loss=5030.384262274118, w0=3.941149935953135, w1=-50.93598664007093\n",
      "Gradient Descent(5885/9999): loss=8638.440013459443, w0=3.941149935953135, w1=-50.93598664007093\n",
      "Gradient Descent(5886/9999): loss=8638.440013459443, w0=-8.1256154496004, w1=-59.63758664007093\n",
      "Gradient Descent(5887/9999): loss=5624.173268802651, w0=-8.1256154496004, w1=-59.63758664007093\n",
      "Gradient Descent(5888/9999): loss=5624.173268802651, w0=2.265584550399602, w1=-59.007586640070926\n",
      "Gradient Descent(5889/9999): loss=5224.162682149254, w0=2.265584550399602, w1=-59.007586640070926\n",
      "Gradient Descent(5890/9999): loss=5224.162682149254, w0=2.265584550399602, w1=-59.007586640070926\n",
      "Gradient Descent(5891/9999): loss=5224.162682149254, w0=2.265584550399602, w1=-59.007586640070926\n",
      "Gradient Descent(5892/9999): loss=5224.162682149254, w0=2.265584550399602, w1=-59.007586640070926\n",
      "Gradient Descent(5893/9999): loss=5224.162682149254, w0=2.265584550399602, w1=-59.007586640070926\n",
      "Gradient Descent(5894/9999): loss=5224.162682149254, w0=13.501684550399602, w1=-52.55138664007092\n",
      "Gradient Descent(5895/9999): loss=15473.130791848806, w0=13.501684550399602, w1=-52.55138664007092\n",
      "Gradient Descent(5896/9999): loss=15473.130791848806, w0=13.501684550399602, w1=-52.55138664007092\n",
      "Gradient Descent(5897/9999): loss=15473.130791848806, w0=6.041384550399601, w1=-59.708786640070926\n",
      "Gradient Descent(5898/9999): loss=7250.330980809353, w0=6.041384550399601, w1=-59.708786640070926\n",
      "Gradient Descent(5899/9999): loss=7250.330980809353, w0=6.041384550399601, w1=-59.708786640070926\n",
      "Gradient Descent(5900/9999): loss=7250.330980809353, w0=6.041384550399601, w1=-59.708786640070926\n",
      "Gradient Descent(5901/9999): loss=7250.330980809353, w0=-1.0491154496003992, w1=-62.848486640070924\n",
      "Gradient Descent(5902/9999): loss=4927.138371586501, w0=-1.0491154496003992, w1=-62.848486640070924\n",
      "Gradient Descent(5903/9999): loss=4927.138371586501, w0=-1.0491154496003992, w1=-62.848486640070924\n",
      "Gradient Descent(5904/9999): loss=4927.138371586501, w0=-24.275415449600402, w1=-65.42608664007092\n",
      "Gradient Descent(5905/9999): loss=5802.4994844197445, w0=-24.275415449600402, w1=-65.42608664007092\n",
      "Gradient Descent(5906/9999): loss=5802.4994844197445, w0=-24.275415449600402, w1=-65.42608664007092\n",
      "Gradient Descent(5907/9999): loss=5802.4994844197445, w0=-24.275415449600402, w1=-65.42608664007092\n",
      "Gradient Descent(5908/9999): loss=5802.4994844197445, w0=-12.323615449600403, w1=-62.12648664007092\n",
      "Gradient Descent(5909/9999): loss=5802.4994844197445, w0=-12.323615449600403, w1=-62.12648664007092\n",
      "Gradient Descent(5910/9999): loss=5802.4994844197445, w0=-3.978815449600404, w1=-59.38218664007092\n",
      "Gradient Descent(5911/9999): loss=4601.842178347886, w0=-3.978815449600404, w1=-59.38218664007092\n",
      "Gradient Descent(5912/9999): loss=4601.842178347886, w0=-3.978815449600404, w1=-59.38218664007092\n",
      "Gradient Descent(5913/9999): loss=4601.842178347886, w0=-3.978815449600404, w1=-59.38218664007092\n",
      "Gradient Descent(5914/9999): loss=4601.842178347886, w0=-3.978815449600404, w1=-59.38218664007092\n",
      "Gradient Descent(5915/9999): loss=4601.842178347886, w0=-3.978815449600404, w1=-59.38218664007092\n",
      "Gradient Descent(5916/9999): loss=4601.842178347886, w0=-3.978815449600404, w1=-59.38218664007092\n",
      "Gradient Descent(5917/9999): loss=4601.842178347886, w0=9.286184550399597, w1=-57.53958664007092\n",
      "Gradient Descent(5918/9999): loss=8020.701231796951, w0=9.286184550399597, w1=-57.53958664007092\n",
      "Gradient Descent(5919/9999): loss=8020.701231796951, w0=9.286184550399597, w1=-57.53958664007092\n",
      "Gradient Descent(5920/9999): loss=8020.701231796951, w0=9.286184550399597, w1=-57.53958664007092\n",
      "Gradient Descent(5921/9999): loss=8020.701231796951, w0=9.286184550399597, w1=-57.53958664007092\n",
      "Gradient Descent(5922/9999): loss=8020.701231796951, w0=9.286184550399597, w1=-57.53958664007092\n",
      "Gradient Descent(5923/9999): loss=8020.701231796951, w0=9.286184550399597, w1=-57.53958664007092\n",
      "Gradient Descent(5924/9999): loss=8020.701231796951, w0=-3.117515449600404, w1=-61.56648664007092\n",
      "Gradient Descent(5925/9999): loss=5035.124434992393, w0=-3.117515449600404, w1=-61.56648664007092\n",
      "Gradient Descent(5926/9999): loss=5035.124434992393, w0=-3.117515449600404, w1=-61.56648664007092\n",
      "Gradient Descent(5927/9999): loss=5035.124434992393, w0=-3.117515449600404, w1=-61.56648664007092\n",
      "Gradient Descent(5928/9999): loss=5035.124434992393, w0=8.834284550399595, w1=-58.26688664007092\n",
      "Gradient Descent(5929/9999): loss=5872.908554305435, w0=8.834284550399595, w1=-58.26688664007092\n",
      "Gradient Descent(5930/9999): loss=5872.908554305435, w0=8.834284550399595, w1=-58.26688664007092\n",
      "Gradient Descent(5931/9999): loss=5872.908554305435, w0=8.834284550399595, w1=-58.26688664007092\n",
      "Gradient Descent(5932/9999): loss=5872.908554305435, w0=3.842984550399594, w1=-60.72338664007092\n",
      "Gradient Descent(5933/9999): loss=4425.443718391794, w0=3.842984550399594, w1=-60.72338664007092\n",
      "Gradient Descent(5934/9999): loss=4425.443718391794, w0=-6.5288154496004065, w1=-61.13078664007092\n",
      "Gradient Descent(5935/9999): loss=5802.4994844197445, w0=7.8129845503995945, w1=-54.20768664007092\n",
      "Gradient Descent(5936/9999): loss=4455.211243216819, w0=7.8129845503995945, w1=-54.20768664007092\n",
      "Gradient Descent(5937/9999): loss=4455.211243216819, w0=7.8129845503995945, w1=-54.20768664007092\n",
      "Gradient Descent(5938/9999): loss=4455.211243216819, w0=21.088084550399596, w1=-51.202886640070915\n",
      "Gradient Descent(5939/9999): loss=13930.384853999269, w0=21.088084550399596, w1=-51.202886640070915\n",
      "Gradient Descent(5940/9999): loss=13930.384853999269, w0=21.088084550399596, w1=-51.202886640070915\n",
      "Gradient Descent(5941/9999): loss=13930.384853999269, w0=21.088084550399596, w1=-51.202886640070915\n",
      "Gradient Descent(5942/9999): loss=13930.384853999269, w0=21.088084550399596, w1=-51.202886640070915\n",
      "Gradient Descent(5943/9999): loss=13930.384853999269, w0=9.021319164846062, w1=-58.36588664007091\n",
      "Gradient Descent(5944/9999): loss=5056.846790603843, w0=3.5219191648460617, w1=-61.822086640070914\n",
      "Gradient Descent(5945/9999): loss=4939.02930252692, w0=3.5219191648460617, w1=-61.822086640070914\n",
      "Gradient Descent(5946/9999): loss=4939.02930252692, w0=3.5219191648460617, w1=-61.822086640070914\n",
      "Gradient Descent(5947/9999): loss=4939.02930252692, w0=16.196219164846063, w1=-56.375586640070914\n",
      "Gradient Descent(5948/9999): loss=5802.903634558224, w0=16.196219164846063, w1=-56.375586640070914\n",
      "Gradient Descent(5949/9999): loss=5802.903634558224, w0=16.196219164846063, w1=-56.375586640070914\n",
      "Gradient Descent(5950/9999): loss=5802.903634558224, w0=16.196219164846063, w1=-56.375586640070914\n",
      "Gradient Descent(5951/9999): loss=5802.903634558224, w0=16.196219164846063, w1=-56.375586640070914\n",
      "Gradient Descent(5952/9999): loss=5802.903634558224, w0=16.196219164846063, w1=-56.375586640070914\n",
      "Gradient Descent(5953/9999): loss=5802.903634558224, w0=6.326619164846063, w1=-56.714686640070916\n",
      "Gradient Descent(5954/9999): loss=4823.9016946857755, w0=19.811719164846064, w1=-53.333686640070916\n",
      "Gradient Descent(5955/9999): loss=7644.288817030629, w0=6.1857191648460645, w1=-58.181486640070915\n",
      "Gradient Descent(5956/9999): loss=5583.7537112470245, w0=6.1857191648460645, w1=-58.181486640070915\n",
      "Gradient Descent(5957/9999): loss=5583.7537112470245, w0=6.1857191648460645, w1=-58.181486640070915\n",
      "Gradient Descent(5958/9999): loss=5583.7537112470245, w0=6.1857191648460645, w1=-58.181486640070915\n",
      "Gradient Descent(5959/9999): loss=5583.7537112470245, w0=6.1857191648460645, w1=-58.181486640070915\n",
      "Gradient Descent(5960/9999): loss=5583.7537112470245, w0=22.565219164846063, w1=-57.994886640070916\n",
      "Gradient Descent(5961/9999): loss=4779.6861747262465, w0=22.565219164846063, w1=-57.994886640070916\n",
      "Gradient Descent(5962/9999): loss=4779.6861747262465, w0=15.149219164846063, w1=-63.06748664007092\n",
      "Gradient Descent(5963/9999): loss=4892.97636806047, w0=15.149219164846063, w1=-63.06748664007092\n",
      "Gradient Descent(5964/9999): loss=4892.97636806047, w0=15.149219164846063, w1=-63.06748664007092\n",
      "Gradient Descent(5965/9999): loss=4892.97636806047, w0=15.149219164846063, w1=-63.06748664007092\n",
      "Gradient Descent(5966/9999): loss=4892.97636806047, w0=27.891219164846063, w1=-58.924886640070916\n",
      "Gradient Descent(5967/9999): loss=6549.331153781501, w0=27.891219164846063, w1=-58.924886640070916\n",
      "Gradient Descent(5968/9999): loss=6549.331153781501, w0=27.891219164846063, w1=-58.924886640070916\n",
      "Gradient Descent(5969/9999): loss=6549.331153781501, w0=27.891219164846063, w1=-58.924886640070916\n",
      "Gradient Descent(5970/9999): loss=6549.331153781501, w0=27.891219164846063, w1=-58.924886640070916\n",
      "Gradient Descent(5971/9999): loss=6549.331153781501, w0=27.891219164846063, w1=-58.924886640070916\n",
      "Gradient Descent(5972/9999): loss=6549.331153781501, w0=27.891219164846063, w1=-58.924886640070916\n",
      "Gradient Descent(5973/9999): loss=6549.331153781501, w0=27.891219164846063, w1=-58.924886640070916\n",
      "Gradient Descent(5974/9999): loss=6549.331153781501, w0=27.891219164846063, w1=-58.924886640070916\n",
      "Gradient Descent(5975/9999): loss=6549.331153781501, w0=27.891219164846063, w1=-58.924886640070916\n",
      "Gradient Descent(5976/9999): loss=6549.331153781501, w0=16.755819164846063, w1=-62.71908664007091\n",
      "Gradient Descent(5977/9999): loss=4766.335294043076, w0=16.755819164846063, w1=-62.71908664007091\n",
      "Gradient Descent(5978/9999): loss=4766.335294043076, w0=16.755819164846063, w1=-62.71908664007091\n",
      "Gradient Descent(5979/9999): loss=4766.335294043076, w0=5.571719164846062, w1=-66.23368664007091\n",
      "Gradient Descent(5980/9999): loss=5753.797036852027, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5981/9999): loss=4624.392222797127, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5982/9999): loss=4624.392222797127, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5983/9999): loss=4624.392222797127, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5984/9999): loss=4624.392222797127, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5985/9999): loss=4624.392222797127, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5986/9999): loss=4624.392222797127, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5987/9999): loss=4624.392222797127, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5988/9999): loss=4624.392222797127, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5989/9999): loss=4624.392222797127, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5990/9999): loss=4624.392222797127, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5991/9999): loss=4624.392222797127, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5992/9999): loss=4624.392222797127, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5993/9999): loss=4624.392222797127, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5994/9999): loss=4624.392222797127, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5995/9999): loss=4624.392222797127, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5996/9999): loss=4624.392222797127, w0=18.836719164846063, w1=-64.39108664007091\n",
      "Gradient Descent(5997/9999): loss=4624.392222797127, w0=32.529319164846065, w1=-54.43928664007091\n",
      "Gradient Descent(5998/9999): loss=13812.894095772126, w0=32.529319164846065, w1=-54.43928664007091\n",
      "Gradient Descent(5999/9999): loss=13812.894095772126, w0=11.417719164846066, w1=-63.41268664007091\n",
      "Gradient Descent(6000/9999): loss=4373.972422890047, w0=-2.031280835153936, w1=-64.0814866400709\n",
      "Gradient Descent(6001/9999): loss=5802.4994844197445, w0=-2.031280835153936, w1=-64.0814866400709\n",
      "Gradient Descent(6002/9999): loss=5802.4994844197445, w0=-2.031280835153936, w1=-64.0814866400709\n",
      "Gradient Descent(6003/9999): loss=5802.4994844197445, w0=-2.031280835153936, w1=-64.0814866400709\n",
      "Gradient Descent(6004/9999): loss=5802.4994844197445, w0=9.204819164846064, w1=-57.625286640070904\n",
      "Gradient Descent(6005/9999): loss=4547.243547039407, w0=9.204819164846064, w1=-57.625286640070904\n",
      "Gradient Descent(6006/9999): loss=4547.243547039407, w0=9.204819164846064, w1=-57.625286640070904\n",
      "Gradient Descent(6007/9999): loss=4547.243547039407, w0=19.806219164846063, w1=-52.991786640070906\n",
      "Gradient Descent(6008/9999): loss=8658.82967237425, w0=19.806219164846063, w1=-52.991786640070906\n",
      "Gradient Descent(6009/9999): loss=8658.82967237425, w0=13.388119164846064, w1=-58.511886640070905\n",
      "Gradient Descent(6010/9999): loss=4294.195969817529, w0=13.388119164846064, w1=-58.511886640070905\n",
      "Gradient Descent(6011/9999): loss=4294.195969817529, w0=13.388119164846064, w1=-58.511886640070905\n",
      "Gradient Descent(6012/9999): loss=4294.195969817529, w0=13.388119164846064, w1=-58.511886640070905\n",
      "Gradient Descent(6013/9999): loss=4294.195969817529, w0=13.388119164846064, w1=-58.511886640070905\n",
      "Gradient Descent(6014/9999): loss=4294.195969817529, w0=13.388119164846064, w1=-58.511886640070905\n",
      "Gradient Descent(6015/9999): loss=4294.195969817529, w0=13.388119164846064, w1=-58.511886640070905\n",
      "Gradient Descent(6016/9999): loss=4294.195969817529, w0=24.707819164846065, w1=-54.25188664007091\n",
      "Gradient Descent(6017/9999): loss=12398.801055373779, w0=24.707819164846065, w1=-54.25188664007091\n",
      "Gradient Descent(6018/9999): loss=12398.801055373779, w0=24.707819164846065, w1=-54.25188664007091\n",
      "Gradient Descent(6019/9999): loss=12398.801055373779, w0=13.484219164846063, w1=-58.646086640070905\n",
      "Gradient Descent(6020/9999): loss=4293.908077602491, w0=13.484219164846063, w1=-58.646086640070905\n",
      "Gradient Descent(6021/9999): loss=4293.908077602491, w0=24.387119164846062, w1=-58.3210866400709\n",
      "Gradient Descent(6022/9999): loss=11987.364334739996, w0=16.26871916484606, w1=-59.6281866400709\n",
      "Gradient Descent(6023/9999): loss=4408.7188492610185, w0=16.26871916484606, w1=-59.6281866400709\n",
      "Gradient Descent(6024/9999): loss=4408.7188492610185, w0=27.73341916484606, w1=-56.0676866400709\n",
      "Gradient Descent(6025/9999): loss=13655.28874975565, w0=15.666653779292528, w1=-61.9108866400709\n",
      "Gradient Descent(6026/9999): loss=4226.8321762519845, w0=15.666653779292528, w1=-61.9108866400709\n",
      "Gradient Descent(6027/9999): loss=4226.8321762519845, w0=15.666653779292528, w1=-61.9108866400709\n",
      "Gradient Descent(6028/9999): loss=4226.8321762519845, w0=15.666653779292528, w1=-61.9108866400709\n",
      "Gradient Descent(6029/9999): loss=4226.8321762519845, w0=15.666653779292528, w1=-61.9108866400709\n",
      "Gradient Descent(6030/9999): loss=4226.8321762519845, w0=5.7886537792925274, w1=-62.3828866400709\n",
      "Gradient Descent(6031/9999): loss=5514.677091969115, w0=5.7886537792925274, w1=-62.3828866400709\n",
      "Gradient Descent(6032/9999): loss=5514.677091969115, w0=5.7886537792925274, w1=-62.3828866400709\n",
      "Gradient Descent(6033/9999): loss=5514.677091969115, w0=5.7886537792925274, w1=-62.3828866400709\n",
      "Gradient Descent(6034/9999): loss=5514.677091969115, w0=5.7886537792925274, w1=-62.3828866400709\n",
      "Gradient Descent(6035/9999): loss=5514.677091969115, w0=15.945753779292527, w1=-59.659086640070896\n",
      "Gradient Descent(6036/9999): loss=4410.424876675323, w0=15.945753779292527, w1=-59.659086640070896\n",
      "Gradient Descent(6037/9999): loss=4410.424876675323, w0=8.061953779292526, w1=-62.3613866400709\n",
      "Gradient Descent(6038/9999): loss=5517.797359374863, w0=20.029653779292527, w1=-56.46208664007089\n",
      "Gradient Descent(6039/9999): loss=4440.322525658867, w0=20.029653779292527, w1=-56.46208664007089\n",
      "Gradient Descent(6040/9999): loss=4440.322525658867, w0=-7.866046220707474, w1=-66.3109866400709\n",
      "Gradient Descent(6041/9999): loss=5802.4994844197445, w0=-7.866046220707474, w1=-66.3109866400709\n",
      "Gradient Descent(6042/9999): loss=5802.4994844197445, w0=1.1948537792925258, w1=-65.99068664007089\n",
      "Gradient Descent(6043/9999): loss=5802.4994844197445, w0=1.1948537792925258, w1=-65.99068664007089\n",
      "Gradient Descent(6044/9999): loss=5802.4994844197445, w0=1.1948537792925258, w1=-65.99068664007089\n",
      "Gradient Descent(6045/9999): loss=5802.4994844197445, w0=1.1948537792925258, w1=-65.99068664007089\n",
      "Gradient Descent(6046/9999): loss=5802.4994844197445, w0=1.1948537792925258, w1=-65.99068664007089\n",
      "Gradient Descent(6047/9999): loss=5802.4994844197445, w0=15.224953779292528, w1=-64.50698664007089\n",
      "Gradient Descent(6048/9999): loss=4574.960138843424, w0=15.224953779292528, w1=-64.50698664007089\n",
      "Gradient Descent(6049/9999): loss=4574.960138843424, w0=15.224953779292528, w1=-64.50698664007089\n",
      "Gradient Descent(6050/9999): loss=4574.960138843424, w0=15.224953779292528, w1=-64.50698664007089\n",
      "Gradient Descent(6051/9999): loss=4574.960138843424, w0=15.224953779292528, w1=-64.50698664007089\n",
      "Gradient Descent(6052/9999): loss=4574.960138843424, w0=15.224953779292528, w1=-64.50698664007089\n",
      "Gradient Descent(6053/9999): loss=4574.960138843424, w0=15.224953779292528, w1=-64.50698664007089\n",
      "Gradient Descent(6054/9999): loss=4574.960138843424, w0=27.59305377929253, w1=-57.412486640070895\n",
      "Gradient Descent(6055/9999): loss=15991.255921469441, w0=27.59305377929253, w1=-57.412486640070895\n",
      "Gradient Descent(6056/9999): loss=15991.255921469441, w0=13.978453779292526, w1=-59.009686640070896\n",
      "Gradient Descent(6057/9999): loss=4413.5490795136975, w0=13.978453779292526, w1=-59.009686640070896\n",
      "Gradient Descent(6058/9999): loss=4413.5490795136975, w0=22.100353779292526, w1=-54.635686640070894\n",
      "Gradient Descent(6059/9999): loss=10497.783739991171, w0=22.100353779292526, w1=-54.635686640070894\n",
      "Gradient Descent(6060/9999): loss=10497.783739991171, w0=12.575353779292525, w1=-57.033186640070895\n",
      "Gradient Descent(6061/9999): loss=4283.264670824392, w0=24.881553779292528, w1=-53.285986640070895\n",
      "Gradient Descent(6062/9999): loss=12340.040239371738, w0=15.615153779292527, w1=-58.415086640070896\n",
      "Gradient Descent(6063/9999): loss=4353.786360230442, w0=15.615153779292527, w1=-58.415086640070896\n",
      "Gradient Descent(6064/9999): loss=4353.786360230442, w0=15.615153779292527, w1=-58.415086640070896\n",
      "Gradient Descent(6065/9999): loss=4353.786360230442, w0=15.615153779292527, w1=-58.415086640070896\n",
      "Gradient Descent(6066/9999): loss=4353.786360230442, w0=25.333053779292527, w1=-54.5743866400709\n",
      "Gradient Descent(6067/9999): loss=8935.060315762854, w0=13.571153779292526, w1=-58.8802866400709\n",
      "Gradient Descent(6068/9999): loss=5307.268260909668, w0=13.571153779292526, w1=-58.8802866400709\n",
      "Gradient Descent(6069/9999): loss=5307.268260909668, w0=13.571153779292526, w1=-58.8802866400709\n",
      "Gradient Descent(6070/9999): loss=5307.268260909668, w0=13.571153779292526, w1=-58.8802866400709\n",
      "Gradient Descent(6071/9999): loss=5307.268260909668, w0=13.571153779292526, w1=-58.8802866400709\n",
      "Gradient Descent(6072/9999): loss=5307.268260909668, w0=23.92515377929253, w1=-54.3790866400709\n",
      "Gradient Descent(6073/9999): loss=6226.435648726615, w0=23.92515377929253, w1=-54.3790866400709\n",
      "Gradient Descent(6074/9999): loss=6226.435648726615, w0=23.92515377929253, w1=-54.3790866400709\n",
      "Gradient Descent(6075/9999): loss=6226.435648726615, w0=9.571053779292528, w1=-62.0449866400709\n",
      "Gradient Descent(6076/9999): loss=5295.456170416912, w0=22.103153779292526, w1=-60.227186640070904\n",
      "Gradient Descent(6077/9999): loss=6772.757574498048, w0=14.188953779292525, w1=-62.381486640070904\n",
      "Gradient Descent(6078/9999): loss=4282.5533130836375, w0=14.188953779292525, w1=-62.381486640070904\n",
      "Gradient Descent(6079/9999): loss=4282.5533130836375, w0=14.188953779292525, w1=-62.381486640070904\n",
      "Gradient Descent(6080/9999): loss=4282.5533130836375, w0=14.188953779292525, w1=-62.381486640070904\n",
      "Gradient Descent(6081/9999): loss=4282.5533130836375, w0=14.188953779292525, w1=-62.381486640070904\n",
      "Gradient Descent(6082/9999): loss=4282.5533130836375, w0=26.828553779292527, w1=-58.47278664007091\n",
      "Gradient Descent(6083/9999): loss=11931.288243027999, w0=26.828553779292527, w1=-58.47278664007091\n",
      "Gradient Descent(6084/9999): loss=11931.288243027999, w0=12.775853779292525, w1=-66.8882866400709\n",
      "Gradient Descent(6085/9999): loss=4223.564558373241, w0=12.775853779292525, w1=-66.8882866400709\n",
      "Gradient Descent(6086/9999): loss=4223.564558373241, w0=12.775853779292525, w1=-66.8882866400709\n",
      "Gradient Descent(6087/9999): loss=4223.564558373241, w0=-0.6776462207074747, w1=-68.38378664007091\n",
      "Gradient Descent(6088/9999): loss=5802.4994844197445, w0=-0.6776462207074747, w1=-68.38378664007091\n",
      "Gradient Descent(6089/9999): loss=5802.4994844197445, w0=-0.6776462207074747, w1=-68.38378664007091\n",
      "Gradient Descent(6090/9999): loss=5802.4994844197445, w0=11.913153779292525, w1=-67.4122866400709\n",
      "Gradient Descent(6091/9999): loss=4536.469564794632, w0=11.913153779292525, w1=-67.4122866400709\n",
      "Gradient Descent(6092/9999): loss=4536.469564794632, w0=11.913153779292525, w1=-67.4122866400709\n",
      "Gradient Descent(6093/9999): loss=4536.469564794632, w0=11.913153779292525, w1=-67.4122866400709\n",
      "Gradient Descent(6094/9999): loss=4536.469564794632, w0=3.513753779292525, w1=-68.9366866400709\n",
      "Gradient Descent(6095/9999): loss=5802.4994844197445, w0=17.143853779292527, w1=-67.9700866400709\n",
      "Gradient Descent(6096/9999): loss=5632.6451750999095, w0=17.143853779292527, w1=-67.9700866400709\n",
      "Gradient Descent(6097/9999): loss=5632.6451750999095, w0=1.7260537792925277, w1=-71.35898664007091\n",
      "Gradient Descent(6098/9999): loss=5761.457325427997, w0=1.7260537792925277, w1=-71.35898664007091\n",
      "Gradient Descent(6099/9999): loss=5761.457325427997, w0=1.7260537792925277, w1=-71.35898664007091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(6100/9999): loss=5761.457325427997, w0=1.7260537792925277, w1=-71.35898664007091\n",
      "Gradient Descent(6101/9999): loss=5761.457325427997, w0=1.7260537792925277, w1=-71.35898664007091\n",
      "Gradient Descent(6102/9999): loss=5761.457325427997, w0=1.7260537792925277, w1=-71.35898664007091\n",
      "Gradient Descent(6103/9999): loss=5761.457325427997, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6104/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6105/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6106/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6107/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6108/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6109/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6110/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6111/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6112/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6113/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6114/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6115/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6116/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6117/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6118/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6119/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6120/9999): loss=4516.723973915309, w0=15.371353779292528, w1=-67.6524866400709\n",
      "Gradient Descent(6121/9999): loss=4516.723973915309, w0=27.73945377929253, w1=-60.55798664007091\n",
      "Gradient Descent(6122/9999): loss=15562.37328638352, w0=15.672688393738994, w1=-66.1635866400709\n",
      "Gradient Descent(6123/9999): loss=4674.252379501318, w0=15.672688393738994, w1=-66.1635866400709\n",
      "Gradient Descent(6124/9999): loss=4674.252379501318, w0=15.672688393738994, w1=-66.1635866400709\n",
      "Gradient Descent(6125/9999): loss=4674.252379501318, w0=1.833288393738993, w1=-67.3745866400709\n",
      "Gradient Descent(6126/9999): loss=5802.4994844197445, w0=1.833288393738993, w1=-67.3745866400709\n",
      "Gradient Descent(6127/9999): loss=5802.4994844197445, w0=1.833288393738993, w1=-67.3745866400709\n",
      "Gradient Descent(6128/9999): loss=5802.4994844197445, w0=1.833288393738993, w1=-67.3745866400709\n",
      "Gradient Descent(6129/9999): loss=5802.4994844197445, w0=1.833288393738993, w1=-67.3745866400709\n",
      "Gradient Descent(6130/9999): loss=5802.4994844197445, w0=1.833288393738993, w1=-67.3745866400709\n",
      "Gradient Descent(6131/9999): loss=5802.4994844197445, w0=1.833288393738993, w1=-67.3745866400709\n",
      "Gradient Descent(6132/9999): loss=5802.4994844197445, w0=1.833288393738993, w1=-67.3745866400709\n",
      "Gradient Descent(6133/9999): loss=5802.4994844197445, w0=15.137788393738992, w1=-63.7118866400709\n",
      "Gradient Descent(6134/9999): loss=4317.630798400933, w0=7.952588393738991, w1=-66.0249866400709\n",
      "Gradient Descent(6135/9999): loss=5802.4994844197445, w0=7.952588393738991, w1=-66.0249866400709\n",
      "Gradient Descent(6136/9999): loss=5802.4994844197445, w0=7.952588393738991, w1=-66.0249866400709\n",
      "Gradient Descent(6137/9999): loss=5802.4994844197445, w0=7.952588393738991, w1=-66.0249866400709\n",
      "Gradient Descent(6138/9999): loss=5802.4994844197445, w0=17.21668839373899, w1=-59.57148664007091\n",
      "Gradient Descent(6139/9999): loss=4410.3328098926195, w0=17.21668839373899, w1=-59.57148664007091\n",
      "Gradient Descent(6140/9999): loss=4410.3328098926195, w0=17.21668839373899, w1=-59.57148664007091\n",
      "Gradient Descent(6141/9999): loss=4410.3328098926195, w0=17.21668839373899, w1=-59.57148664007091\n",
      "Gradient Descent(6142/9999): loss=4410.3328098926195, w0=17.21668839373899, w1=-59.57148664007091\n",
      "Gradient Descent(6143/9999): loss=4410.3328098926195, w0=5.962988393738989, w1=-60.49508664007091\n",
      "Gradient Descent(6144/9999): loss=5802.4994844197445, w0=5.962988393738989, w1=-60.49508664007091\n",
      "Gradient Descent(6145/9999): loss=5802.4994844197445, w0=5.962988393738989, w1=-60.49508664007091\n",
      "Gradient Descent(6146/9999): loss=5802.4994844197445, w0=16.777088393738993, w1=-60.05828664007091\n",
      "Gradient Descent(6147/9999): loss=4270.026934089328, w0=16.777088393738993, w1=-60.05828664007091\n",
      "Gradient Descent(6148/9999): loss=4270.026934089328, w0=16.777088393738993, w1=-60.05828664007091\n",
      "Gradient Descent(6149/9999): loss=4270.026934089328, w0=16.777088393738993, w1=-60.05828664007091\n",
      "Gradient Descent(6150/9999): loss=4270.026934089328, w0=16.777088393738993, w1=-60.05828664007091\n",
      "Gradient Descent(6151/9999): loss=4270.026934089328, w0=16.777088393738993, w1=-60.05828664007091\n",
      "Gradient Descent(6152/9999): loss=4270.026934089328, w0=24.028088393738994, w1=-55.15568664007091\n",
      "Gradient Descent(6153/9999): loss=6862.568408958836, w0=24.028088393738994, w1=-55.15568664007091\n",
      "Gradient Descent(6154/9999): loss=6862.568408958836, w0=24.028088393738994, w1=-55.15568664007091\n",
      "Gradient Descent(6155/9999): loss=6862.568408958836, w0=-8.67281160626101, w1=-60.65798664007091\n",
      "Gradient Descent(6156/9999): loss=5802.4994844197445, w0=3.3939537792925236, w1=-47.62608664007091\n",
      "Gradient Descent(6157/9999): loss=4905.060144880549, w0=3.3939537792925236, w1=-47.62608664007091\n",
      "Gradient Descent(6158/9999): loss=4905.060144880549, w0=-4.904846220707476, w1=-52.281186640070906\n",
      "Gradient Descent(6159/9999): loss=5790.986548954825, w0=-4.904846220707476, w1=-52.281186640070906\n",
      "Gradient Descent(6160/9999): loss=5790.986548954825, w0=6.911953779292524, w1=-48.77138664007091\n",
      "Gradient Descent(6161/9999): loss=4796.198292009671, w0=22.131953779292523, w1=-40.881986640070906\n",
      "Gradient Descent(6162/9999): loss=16624.724818828734, w0=22.131953779292523, w1=-40.881986640070906\n",
      "Gradient Descent(6163/9999): loss=16624.724818828734, w0=22.131953779292523, w1=-40.881986640070906\n",
      "Gradient Descent(6164/9999): loss=16624.724818828734, w0=2.784953779292522, w1=-55.63718664007091\n",
      "Gradient Descent(6165/9999): loss=4542.4430165257, w0=2.784953779292522, w1=-55.63718664007091\n",
      "Gradient Descent(6166/9999): loss=4542.4430165257, w0=2.784953779292522, w1=-55.63718664007091\n",
      "Gradient Descent(6167/9999): loss=4542.4430165257, w0=-8.989946220707479, w1=-58.39278664007091\n",
      "Gradient Descent(6168/9999): loss=5802.4994844197445, w0=5.305153779292521, w1=-58.18468664007091\n",
      "Gradient Descent(6169/9999): loss=4476.792170424851, w0=17.12195377929252, w1=-54.67488664007091\n",
      "Gradient Descent(6170/9999): loss=9943.359857608833, w0=17.12195377929252, w1=-54.67488664007091\n",
      "Gradient Descent(6171/9999): loss=9943.359857608833, w0=9.622153779292521, w1=-61.846886640070906\n",
      "Gradient Descent(6172/9999): loss=4381.110044751072, w0=9.622153779292521, w1=-61.846886640070906\n",
      "Gradient Descent(6173/9999): loss=4381.110044751072, w0=9.622153779292521, w1=-61.846886640070906\n",
      "Gradient Descent(6174/9999): loss=4381.110044751072, w0=9.622153779292521, w1=-61.846886640070906\n",
      "Gradient Descent(6175/9999): loss=4381.110044751072, w0=9.622153779292521, w1=-61.846886640070906\n",
      "Gradient Descent(6176/9999): loss=4381.110044751072, w0=9.622153779292521, w1=-61.846886640070906\n",
      "Gradient Descent(6177/9999): loss=4381.110044751072, w0=9.622153779292521, w1=-61.846886640070906\n",
      "Gradient Descent(6178/9999): loss=4381.110044751072, w0=20.086153779292523, w1=-54.702786640070904\n",
      "Gradient Descent(6179/9999): loss=8808.372012503129, w0=20.086153779292523, w1=-54.702786640070904\n",
      "Gradient Descent(6180/9999): loss=8808.372012503129, w0=20.086153779292523, w1=-54.702786640070904\n",
      "Gradient Descent(6181/9999): loss=8808.372012503129, w0=20.086153779292523, w1=-54.702786640070904\n",
      "Gradient Descent(6182/9999): loss=8808.372012503129, w0=20.086153779292523, w1=-54.702786640070904\n",
      "Gradient Descent(6183/9999): loss=8808.372012503129, w0=32.152919164846054, w1=-44.746486640070906\n",
      "Gradient Descent(6184/9999): loss=17085.190108704104, w0=32.152919164846054, w1=-44.746486640070906\n",
      "Gradient Descent(6185/9999): loss=17085.190108704104, w0=20.08615377929252, w1=-52.150586640070905\n",
      "Gradient Descent(6186/9999): loss=10464.09522384508, w0=20.08615377929252, w1=-52.150586640070905\n",
      "Gradient Descent(6187/9999): loss=10464.09522384508, w0=20.08615377929252, w1=-52.150586640070905\n",
      "Gradient Descent(6188/9999): loss=10464.09522384508, w0=20.08615377929252, w1=-52.150586640070905\n",
      "Gradient Descent(6189/9999): loss=10464.09522384508, w0=20.08615377929252, w1=-52.150586640070905\n",
      "Gradient Descent(6190/9999): loss=10464.09522384508, w0=20.08615377929252, w1=-52.150586640070905\n",
      "Gradient Descent(6191/9999): loss=10464.09522384508, w0=20.08615377929252, w1=-52.150586640070905\n",
      "Gradient Descent(6192/9999): loss=10464.09522384508, w0=11.57795377929252, w1=-56.7435866400709\n",
      "Gradient Descent(6193/9999): loss=4253.38786407729, w0=11.57795377929252, w1=-56.7435866400709\n",
      "Gradient Descent(6194/9999): loss=4253.38786407729, w0=11.57795377929252, w1=-56.7435866400709\n",
      "Gradient Descent(6195/9999): loss=4253.38786407729, w0=11.57795377929252, w1=-56.7435866400709\n",
      "Gradient Descent(6196/9999): loss=4253.38786407729, w0=11.57795377929252, w1=-56.7435866400709\n",
      "Gradient Descent(6197/9999): loss=4253.38786407729, w0=11.57795377929252, w1=-56.7435866400709\n",
      "Gradient Descent(6198/9999): loss=4253.38786407729, w0=21.29585377929252, w1=-52.9028866400709\n",
      "Gradient Descent(6199/9999): loss=8750.343588357327, w0=21.29585377929252, w1=-52.9028866400709\n",
      "Gradient Descent(6200/9999): loss=8750.343588357327, w0=21.29585377929252, w1=-52.9028866400709\n",
      "Gradient Descent(6201/9999): loss=8750.343588357327, w0=21.29585377929252, w1=-52.9028866400709\n",
      "Gradient Descent(6202/9999): loss=8750.343588357327, w0=12.020853779292521, w1=-57.4252866400709\n",
      "Gradient Descent(6203/9999): loss=4439.553466572878, w0=12.020853779292521, w1=-57.4252866400709\n",
      "Gradient Descent(6204/9999): loss=4439.553466572878, w0=12.020853779292521, w1=-57.4252866400709\n",
      "Gradient Descent(6205/9999): loss=4439.553466572878, w0=12.020853779292521, w1=-57.4252866400709\n",
      "Gradient Descent(6206/9999): loss=4439.553466572878, w0=12.020853779292521, w1=-57.4252866400709\n",
      "Gradient Descent(6207/9999): loss=4439.553466572878, w0=12.020853779292521, w1=-57.4252866400709\n",
      "Gradient Descent(6208/9999): loss=4439.553466572878, w0=12.020853779292521, w1=-57.4252866400709\n",
      "Gradient Descent(6209/9999): loss=4439.553466572878, w0=22.283953779292524, w1=-50.7766866400709\n",
      "Gradient Descent(6210/9999): loss=8485.741821219252, w0=12.879353779292524, w1=-53.4919866400709\n",
      "Gradient Descent(6211/9999): loss=4593.768316913737, w0=12.879353779292524, w1=-53.4919866400709\n",
      "Gradient Descent(6212/9999): loss=4593.768316913737, w0=12.879353779292524, w1=-53.4919866400709\n",
      "Gradient Descent(6213/9999): loss=4593.768316913737, w0=12.879353779292524, w1=-53.4919866400709\n",
      "Gradient Descent(6214/9999): loss=4593.768316913737, w0=12.879353779292524, w1=-53.4919866400709\n",
      "Gradient Descent(6215/9999): loss=4593.768316913737, w0=12.879353779292524, w1=-53.4919866400709\n",
      "Gradient Descent(6216/9999): loss=4593.768316913737, w0=12.879353779292524, w1=-53.4919866400709\n",
      "Gradient Descent(6217/9999): loss=4593.768316913737, w0=12.879353779292524, w1=-53.4919866400709\n",
      "Gradient Descent(6218/9999): loss=4593.768316913737, w0=12.879353779292524, w1=-53.4919866400709\n",
      "Gradient Descent(6219/9999): loss=4593.768316913737, w0=12.879353779292524, w1=-53.4919866400709\n",
      "Gradient Descent(6220/9999): loss=4593.768316913737, w0=27.12075377929252, w1=-51.3785866400709\n",
      "Gradient Descent(6221/9999): loss=11130.433602521935, w0=27.12075377929252, w1=-51.3785866400709\n",
      "Gradient Descent(6222/9999): loss=11130.433602521935, w0=15.053988393738987, w1=-58.1884866400709\n",
      "Gradient Descent(6223/9999): loss=4916.005461870562, w0=15.053988393738987, w1=-58.1884866400709\n",
      "Gradient Descent(6224/9999): loss=4916.005461870562, w0=15.053988393738987, w1=-58.1884866400709\n",
      "Gradient Descent(6225/9999): loss=4916.005461870562, w0=15.053988393738987, w1=-58.1884866400709\n",
      "Gradient Descent(6226/9999): loss=4916.005461870562, w0=15.053988393738987, w1=-58.1884866400709\n",
      "Gradient Descent(6227/9999): loss=4916.005461870562, w0=15.053988393738987, w1=-58.1884866400709\n",
      "Gradient Descent(6228/9999): loss=4916.005461870562, w0=27.12075377929252, w1=-38.8282866400709\n",
      "Gradient Descent(6229/9999): loss=7682.465683651446, w0=27.12075377929252, w1=-38.8282866400709\n",
      "Gradient Descent(6230/9999): loss=7682.465683651446, w0=34.37175377929252, w1=-33.9256866400709\n",
      "Gradient Descent(6231/9999): loss=15777.474323103188, w0=34.37175377929252, w1=-33.9256866400709\n",
      "Gradient Descent(6232/9999): loss=15777.474323103188, w0=22.304988393738984, w1=-43.7765866400709\n",
      "Gradient Descent(6233/9999): loss=4634.471936734666, w0=34.52828839373898, w1=-41.4423866400709\n",
      "Gradient Descent(6234/9999): loss=15101.077408810404, w0=34.52828839373898, w1=-41.4423866400709\n",
      "Gradient Descent(6235/9999): loss=15101.077408810404, w0=22.46152300818545, w1=-50.2005866400709\n",
      "Gradient Descent(6236/9999): loss=4406.295519917663, w0=22.46152300818545, w1=-50.2005866400709\n",
      "Gradient Descent(6237/9999): loss=4406.295519917663, w0=22.46152300818545, w1=-50.2005866400709\n",
      "Gradient Descent(6238/9999): loss=4406.295519917663, w0=22.46152300818545, w1=-50.2005866400709\n",
      "Gradient Descent(6239/9999): loss=4406.295519917663, w0=22.46152300818545, w1=-50.2005866400709\n",
      "Gradient Descent(6240/9999): loss=4406.295519917663, w0=22.46152300818545, w1=-50.2005866400709\n",
      "Gradient Descent(6241/9999): loss=4406.295519917663, w0=31.64382300818545, w1=-45.733586640070904\n",
      "Gradient Descent(6242/9999): loss=14901.300199822079, w0=19.577057622631916, w1=-54.33968664007091\n",
      "Gradient Descent(6243/9999): loss=4357.086638551838, w0=19.577057622631916, w1=-54.33968664007091\n",
      "Gradient Descent(6244/9999): loss=4357.086638551838, w0=19.577057622631916, w1=-54.33968664007091\n",
      "Gradient Descent(6245/9999): loss=4357.086638551838, w0=28.217257622631916, w1=-51.47898664007091\n",
      "Gradient Descent(6246/9999): loss=11371.441767884206, w0=28.217257622631916, w1=-51.47898664007091\n",
      "Gradient Descent(6247/9999): loss=11371.441767884206, w0=17.732457622631916, w1=-57.74088664007091\n",
      "Gradient Descent(6248/9999): loss=4495.286058864763, w0=17.732457622631916, w1=-57.74088664007091\n",
      "Gradient Descent(6249/9999): loss=4495.286058864763, w0=17.732457622631916, w1=-57.74088664007091\n",
      "Gradient Descent(6250/9999): loss=4495.286058864763, w0=17.732457622631916, w1=-57.74088664007091\n",
      "Gradient Descent(6251/9999): loss=4495.286058864763, w0=17.731023525380373, w1=-57.74119112612455\n",
      "Gradient Descent(6252/9999): loss=4496.136557001048, w0=17.731023525380373, w1=-57.74119112612455\n",
      "Gradient Descent(6253/9999): loss=4496.136557001048, w0=17.731023525380373, w1=-57.74119112612455\n",
      "Gradient Descent(6254/9999): loss=4496.136557001048, w0=17.731023525380373, w1=-57.74119112612455\n",
      "Gradient Descent(6255/9999): loss=4496.136557001048, w0=17.731023525380373, w1=-57.74119112612455\n",
      "Gradient Descent(6256/9999): loss=4496.136557001048, w0=17.731023525380373, w1=-57.74119112612455\n",
      "Gradient Descent(6257/9999): loss=4496.136557001048, w0=17.731023525380373, w1=-57.74119112612455\n",
      "Gradient Descent(6258/9999): loss=4496.136557001048, w0=30.673723525380375, w1=-49.85449112612454\n",
      "Gradient Descent(6259/9999): loss=14604.278507952948, w0=30.673723525380375, w1=-49.85449112612454\n",
      "Gradient Descent(6260/9999): loss=14604.278507952948, w0=30.673723525380375, w1=-49.85449112612454\n",
      "Gradient Descent(6261/9999): loss=14604.278507952948, w0=17.760223525380376, w1=-53.600891126124544\n",
      "Gradient Descent(6262/9999): loss=4348.6153563501475, w0=17.760223525380376, w1=-53.600891126124544\n",
      "Gradient Descent(6263/9999): loss=4348.6153563501475, w0=17.760223525380376, w1=-53.600891126124544\n",
      "Gradient Descent(6264/9999): loss=4348.6153563501475, w0=17.760223525380376, w1=-53.600891126124544\n",
      "Gradient Descent(6265/9999): loss=4348.6153563501475, w0=17.760223525380376, w1=-53.600891126124544\n",
      "Gradient Descent(6266/9999): loss=4348.6153563501475, w0=17.760223525380376, w1=-53.600891126124544\n",
      "Gradient Descent(6267/9999): loss=4348.6153563501475, w0=17.760223525380376, w1=-53.600891126124544\n",
      "Gradient Descent(6268/9999): loss=4348.6153563501475, w0=17.760223525380376, w1=-53.600891126124544\n",
      "Gradient Descent(6269/9999): loss=4348.6153563501475, w0=31.225923525380377, w1=-46.497991126124546\n",
      "Gradient Descent(6270/9999): loss=16256.287457262551, w0=19.159158139826843, w1=-54.11709112612455\n",
      "Gradient Descent(6271/9999): loss=6037.3012878335985, w0=19.159158139826843, w1=-54.11709112612455\n",
      "Gradient Descent(6272/9999): loss=6037.3012878335985, w0=19.159158139826843, w1=-54.11709112612455\n",
      "Gradient Descent(6273/9999): loss=6037.3012878335985, w0=19.159158139826843, w1=-54.11709112612455\n",
      "Gradient Descent(6274/9999): loss=6037.3012878335985, w0=19.159158139826843, w1=-54.11709112612455\n",
      "Gradient Descent(6275/9999): loss=6037.3012878335985, w0=19.159158139826843, w1=-54.11709112612455\n",
      "Gradient Descent(6276/9999): loss=6037.3012878335985, w0=19.159158139826843, w1=-54.11709112612455\n",
      "Gradient Descent(6277/9999): loss=6037.3012878335985, w0=19.159158139826843, w1=-54.11709112612455\n",
      "Gradient Descent(6278/9999): loss=6037.3012878335985, w0=-7.946541860173159, w1=-64.65979112612455\n",
      "Gradient Descent(6279/9999): loss=5802.4994844197445, w0=-7.946541860173159, w1=-64.65979112612455\n",
      "Gradient Descent(6280/9999): loss=5802.4994844197445, w0=-7.946541860173159, w1=-64.65979112612455\n",
      "Gradient Descent(6281/9999): loss=5802.4994844197445, w0=3.4146581398268427, w1=-62.734891126124545\n",
      "Gradient Descent(6282/9999): loss=5802.4994844197445, w0=3.4146581398268427, w1=-62.734891126124545\n",
      "Gradient Descent(6283/9999): loss=5802.4994844197445, w0=3.4146581398268427, w1=-62.734891126124545\n",
      "Gradient Descent(6284/9999): loss=5802.4994844197445, w0=3.4146581398268427, w1=-62.734891126124545\n",
      "Gradient Descent(6285/9999): loss=5802.4994844197445, w0=3.4146581398268427, w1=-62.734891126124545\n",
      "Gradient Descent(6286/9999): loss=5802.4994844197445, w0=3.4146581398268427, w1=-62.734891126124545\n",
      "Gradient Descent(6287/9999): loss=5802.4994844197445, w0=3.4146581398268427, w1=-62.734891126124545\n",
      "Gradient Descent(6288/9999): loss=5802.4994844197445, w0=3.4146581398268427, w1=-62.734891126124545\n",
      "Gradient Descent(6289/9999): loss=5802.4994844197445, w0=3.4146581398268427, w1=-62.734891126124545\n",
      "Gradient Descent(6290/9999): loss=5802.4994844197445, w0=3.4146581398268427, w1=-62.734891126124545\n",
      "Gradient Descent(6291/9999): loss=5802.4994844197445, w0=3.4146581398268427, w1=-62.734891126124545\n",
      "Gradient Descent(6292/9999): loss=5802.4994844197445, w0=3.4146581398268427, w1=-62.734891126124545\n",
      "Gradient Descent(6293/9999): loss=5802.4994844197445, w0=16.153358139826842, w1=-58.99919112612454\n",
      "Gradient Descent(6294/9999): loss=4226.0570024794, w0=16.153358139826842, w1=-58.99919112612454\n",
      "Gradient Descent(6295/9999): loss=4226.0570024794, w0=16.153358139826842, w1=-58.99919112612454\n",
      "Gradient Descent(6296/9999): loss=4226.0570024794, w0=16.153358139826842, w1=-58.99919112612454\n",
      "Gradient Descent(6297/9999): loss=4226.0570024794, w0=16.153358139826842, w1=-58.99919112612454\n",
      "Gradient Descent(6298/9999): loss=4226.0570024794, w0=16.153358139826842, w1=-58.99919112612454\n",
      "Gradient Descent(6299/9999): loss=4226.0570024794, w0=16.153358139826842, w1=-58.99919112612454\n",
      "Gradient Descent(6300/9999): loss=4226.0570024794, w0=16.153358139826842, w1=-58.99919112612454\n",
      "Gradient Descent(6301/9999): loss=4226.0570024794, w0=16.153358139826842, w1=-58.99919112612454\n",
      "Gradient Descent(6302/9999): loss=4226.0570024794, w0=6.227858139826843, w1=-61.515891126124544\n",
      "Gradient Descent(6303/9999): loss=5802.4668036962485, w0=6.227858139826843, w1=-61.515891126124544\n",
      "Gradient Descent(6304/9999): loss=5802.4668036962485, w0=18.966558139826844, w1=-57.78019112612454\n",
      "Gradient Descent(6305/9999): loss=4925.223680025903, w0=18.966558139826844, w1=-57.78019112612454\n",
      "Gradient Descent(6306/9999): loss=4925.223680025903, w0=18.966558139826844, w1=-57.78019112612454\n",
      "Gradient Descent(6307/9999): loss=4925.223680025903, w0=18.966558139826844, w1=-57.78019112612454\n",
      "Gradient Descent(6308/9999): loss=4925.223680025903, w0=30.732258139826847, w1=-54.580791126124545\n",
      "Gradient Descent(6309/9999): loss=15457.975049246978, w0=19.053792300032292, w1=-62.24835096171574\n",
      "Gradient Descent(6310/9999): loss=4804.544370577538, w0=31.328892300032294, w1=-57.066750961715734\n",
      "Gradient Descent(6311/9999): loss=14787.823273900256, w0=31.328892300032294, w1=-57.066750961715734\n",
      "Gradient Descent(6312/9999): loss=14787.823273900256, w0=19.26212691447876, w1=-64.12775096171573\n",
      "Gradient Descent(6313/9999): loss=6186.093787465061, w0=19.26212691447876, w1=-64.12775096171573\n",
      "Gradient Descent(6314/9999): loss=6186.093787465061, w0=19.26212691447876, w1=-64.12775096171573\n",
      "Gradient Descent(6315/9999): loss=6186.093787465061, w0=5.47302691447876, w1=-68.95315096171574\n",
      "Gradient Descent(6316/9999): loss=4705.881265641798, w0=5.47302691447876, w1=-68.95315096171574\n",
      "Gradient Descent(6317/9999): loss=4705.881265641798, w0=5.47302691447876, w1=-68.95315096171574\n",
      "Gradient Descent(6318/9999): loss=4705.881265641798, w0=5.47302691447876, w1=-68.95315096171574\n",
      "Gradient Descent(6319/9999): loss=4705.881265641798, w0=5.47302691447876, w1=-68.95315096171574\n",
      "Gradient Descent(6320/9999): loss=4705.881265641798, w0=5.47302691447876, w1=-68.95315096171574\n",
      "Gradient Descent(6321/9999): loss=4705.881265641798, w0=5.47302691447876, w1=-68.95315096171574\n",
      "Gradient Descent(6322/9999): loss=4705.881265641798, w0=5.47302691447876, w1=-68.95315096171574\n",
      "Gradient Descent(6323/9999): loss=4705.881265641798, w0=5.47302691447876, w1=-68.95315096171574\n",
      "Gradient Descent(6324/9999): loss=4705.881265641798, w0=5.47302691447876, w1=-68.95315096171574\n",
      "Gradient Descent(6325/9999): loss=4705.881265641798, w0=18.79052691447876, w1=-59.55595096171574\n",
      "Gradient Descent(6326/9999): loss=8101.168388749212, w0=4.032226914478761, w1=-60.943950961715736\n",
      "Gradient Descent(6327/9999): loss=4984.120387168511, w0=13.219926914478762, w1=-57.069550961715734\n",
      "Gradient Descent(6328/9999): loss=4788.893299061041, w0=13.219926914478762, w1=-57.069550961715734\n",
      "Gradient Descent(6329/9999): loss=4788.893299061041, w0=25.286692300032296, w1=-44.98235096171573\n",
      "Gradient Descent(6330/9999): loss=16636.171757134784, w0=16.615792300032297, w1=-52.24215096171573\n",
      "Gradient Descent(6331/9999): loss=10122.610470546362, w0=2.4977923000322946, w1=-58.50185096171573\n",
      "Gradient Descent(6332/9999): loss=4990.553556309084, w0=2.4977923000322946, w1=-58.50185096171573\n",
      "Gradient Descent(6333/9999): loss=4990.553556309084, w0=15.440492300032297, w1=-50.61515096171573\n",
      "Gradient Descent(6334/9999): loss=9922.816057824548, w0=3.3737269144787625, w1=-56.37375096171573\n",
      "Gradient Descent(6335/9999): loss=4702.301806342271, w0=3.3737269144787625, w1=-56.37375096171573\n",
      "Gradient Descent(6336/9999): loss=4702.301806342271, w0=3.3737269144787625, w1=-56.37375096171573\n",
      "Gradient Descent(6337/9999): loss=4702.301806342271, w0=15.440492300032297, w1=-52.17785096171573\n",
      "Gradient Descent(6338/9999): loss=12303.397251004695, w0=3.3737269144787625, w1=-59.34085096171573\n",
      "Gradient Descent(6339/9999): loss=4992.817582724733, w0=3.3737269144787625, w1=-59.34085096171573\n",
      "Gradient Descent(6340/9999): loss=4992.817582724733, w0=3.3737269144787625, w1=-59.34085096171573\n",
      "Gradient Descent(6341/9999): loss=4992.817582724733, w0=0.07362691447876246, w1=-67.00395096171573\n",
      "Gradient Descent(6342/9999): loss=5723.356135273201, w0=0.07362691447876246, w1=-67.00395096171573\n",
      "Gradient Descent(6343/9999): loss=5723.356135273201, w0=0.07362691447876246, w1=-67.00395096171573\n",
      "Gradient Descent(6344/9999): loss=5723.356135273201, w0=0.07362691447876246, w1=-67.00395096171573\n",
      "Gradient Descent(6345/9999): loss=5723.356135273201, w0=0.07362691447876246, w1=-67.00395096171573\n",
      "Gradient Descent(6346/9999): loss=5723.356135273201, w0=13.391126914478765, w1=-57.60675096171573\n",
      "Gradient Descent(6347/9999): loss=5403.73887158005, w0=13.391126914478765, w1=-57.60675096171573\n",
      "Gradient Descent(6348/9999): loss=5403.73887158005, w0=13.391126914478765, w1=-57.60675096171573\n",
      "Gradient Descent(6349/9999): loss=5403.73887158005, w0=13.391126914478765, w1=-57.60675096171573\n",
      "Gradient Descent(6350/9999): loss=5403.73887158005, w0=13.391126914478765, w1=-57.60675096171573\n",
      "Gradient Descent(6351/9999): loss=5403.73887158005, w0=13.391126914478765, w1=-57.60675096171573\n",
      "Gradient Descent(6352/9999): loss=5403.73887158005, w0=13.391126914478765, w1=-57.60675096171573\n",
      "Gradient Descent(6353/9999): loss=5403.73887158005, w0=13.391126914478765, w1=-57.60675096171573\n",
      "Gradient Descent(6354/9999): loss=5403.73887158005, w0=24.223026914478766, w1=-50.64955096171573\n",
      "Gradient Descent(6355/9999): loss=16169.275631492561, w0=24.223026914478766, w1=-50.64955096171573\n",
      "Gradient Descent(6356/9999): loss=16169.275631492561, w0=14.561426914478766, w1=-56.66445096171573\n",
      "Gradient Descent(6357/9999): loss=5559.872633942368, w0=14.561426914478766, w1=-56.66445096171573\n",
      "Gradient Descent(6358/9999): loss=5559.872633942368, w0=14.561426914478766, w1=-56.66445096171573\n",
      "Gradient Descent(6359/9999): loss=5559.872633942368, w0=14.561426914478766, w1=-56.66445096171573\n",
      "Gradient Descent(6360/9999): loss=5559.872633942368, w0=14.561426914478766, w1=-56.66445096171573\n",
      "Gradient Descent(6361/9999): loss=5559.872633942368, w0=14.561426914478766, w1=-56.66445096171573\n",
      "Gradient Descent(6362/9999): loss=5559.872633942368, w0=6.957926914478765, w1=-60.413050961715726\n",
      "Gradient Descent(6363/9999): loss=4531.233048011692, w0=6.957926914478765, w1=-60.413050961715726\n",
      "Gradient Descent(6364/9999): loss=4531.233048011692, w0=6.957926914478765, w1=-60.413050961715726\n",
      "Gradient Descent(6365/9999): loss=4531.233048011692, w0=-8.849573085521234, w1=-61.596250961715725\n",
      "Gradient Descent(6366/9999): loss=5802.4994844197445, w0=-8.849573085521234, w1=-61.596250961715725\n",
      "Gradient Descent(6367/9999): loss=5802.4994844197445, w0=-8.849573085521234, w1=-61.596250961715725\n",
      "Gradient Descent(6368/9999): loss=5802.4994844197445, w0=-8.849573085521234, w1=-61.596250961715725\n",
      "Gradient Descent(6369/9999): loss=5802.4994844197445, w0=3.2171923000323, w1=-54.60275096171573\n",
      "Gradient Descent(6370/9999): loss=4930.642629636803, w0=12.322692300032301, w1=-52.619350961715725\n",
      "Gradient Descent(6371/9999): loss=5326.2110785196455, w0=12.322692300032301, w1=-52.619350961715725\n",
      "Gradient Descent(6372/9999): loss=5326.2110785196455, w0=24.389457685585835, w1=-45.505050961715725\n",
      "Gradient Descent(6373/9999): loss=16034.45123239631, w0=12.509857685585834, w1=-52.51485096171572\n",
      "Gradient Descent(6374/9999): loss=4225.634134371383, w0=12.509857685585834, w1=-52.51485096171572\n",
      "Gradient Descent(6375/9999): loss=4225.634134371383, w0=12.509857685585834, w1=-52.51485096171572\n",
      "Gradient Descent(6376/9999): loss=4225.634134371383, w0=12.509857685585834, w1=-52.51485096171572\n",
      "Gradient Descent(6377/9999): loss=4225.634134371383, w0=12.509857685585834, w1=-52.51485096171572\n",
      "Gradient Descent(6378/9999): loss=4225.634134371383, w0=12.509857685585834, w1=-52.51485096171572\n",
      "Gradient Descent(6379/9999): loss=4225.634134371383, w0=12.509857685585834, w1=-52.51485096171572\n",
      "Gradient Descent(6380/9999): loss=4225.634134371383, w0=12.509857685585834, w1=-52.51485096171572\n",
      "Gradient Descent(6381/9999): loss=4225.634134371383, w0=12.509857685585834, w1=-52.51485096171572\n",
      "Gradient Descent(6382/9999): loss=4225.634134371383, w0=25.251780201063447, w1=-48.372276153003\n",
      "Gradient Descent(6383/9999): loss=15122.237301960306, w0=16.74328020106345, w1=-54.535376153003\n",
      "Gradient Descent(6384/9999): loss=4939.675075455618, w0=16.74328020106345, w1=-54.535376153003\n",
      "Gradient Descent(6385/9999): loss=4939.675075455618, w0=16.74328020106345, w1=-54.535376153003\n",
      "Gradient Descent(6386/9999): loss=4939.675075455618, w0=16.74328020106345, w1=-54.535376153003\n",
      "Gradient Descent(6387/9999): loss=4939.675075455618, w0=16.74328020106345, w1=-54.535376153003\n",
      "Gradient Descent(6388/9999): loss=4939.675075455618, w0=16.74328020106345, w1=-54.535376153003\n",
      "Gradient Descent(6389/9999): loss=4939.675075455618, w0=16.74328020106345, w1=-54.535376153003\n",
      "Gradient Descent(6390/9999): loss=4939.675075455618, w0=-0.3052197989365517, w1=-55.665776153003\n",
      "Gradient Descent(6391/9999): loss=5802.4994844197445, w0=-0.3052197989365517, w1=-55.665776153003\n",
      "Gradient Descent(6392/9999): loss=5802.4994844197445, w0=-0.3052197989365517, w1=-55.665776153003\n",
      "Gradient Descent(6393/9999): loss=5802.4994844197445, w0=-0.3052197989365517, w1=-55.665776153003\n",
      "Gradient Descent(6394/9999): loss=5802.4994844197445, w0=-0.3052197989365517, w1=-55.665776153003\n",
      "Gradient Descent(6395/9999): loss=5802.4994844197445, w0=-0.3052197989365517, w1=-55.665776153003\n",
      "Gradient Descent(6396/9999): loss=5802.4994844197445, w0=-0.3052197989365517, w1=-55.665776153003\n",
      "Gradient Descent(6397/9999): loss=5802.4994844197445, w0=-0.3052197989365517, w1=-55.665776153003\n",
      "Gradient Descent(6398/9999): loss=5802.4994844197445, w0=-0.3052197989365517, w1=-55.665776153003\n",
      "Gradient Descent(6399/9999): loss=5802.4994844197445, w0=-0.3052197989365517, w1=-55.665776153003\n",
      "Gradient Descent(6400/9999): loss=5802.4994844197445, w0=-0.3052197989365517, w1=-55.665776153003\n",
      "Gradient Descent(6401/9999): loss=5802.4994844197445, w0=-0.3052197989365517, w1=-55.665776153003\n",
      "Gradient Descent(6402/9999): loss=5802.4994844197445, w0=-0.3052197989365517, w1=-55.665776153003\n",
      "Gradient Descent(6403/9999): loss=5802.4994844197445, w0=-0.3052197989365517, w1=-55.665776153003\n",
      "Gradient Descent(6404/9999): loss=5802.4994844197445, w0=-0.3052197989365517, w1=-55.665776153003\n",
      "Gradient Descent(6405/9999): loss=5802.4994844197445, w0=8.377080201063448, w1=-49.346276153003004\n",
      "Gradient Descent(6406/9999): loss=5365.6377839738025, w0=8.377080201063448, w1=-49.346276153003004\n",
      "Gradient Descent(6407/9999): loss=5365.6377839738025, w0=8.377080201063448, w1=-49.346276153003004\n",
      "Gradient Descent(6408/9999): loss=5365.6377839738025, w0=8.377080201063448, w1=-49.346276153003004\n",
      "Gradient Descent(6409/9999): loss=5365.6377839738025, w0=8.377080201063448, w1=-49.346276153003004\n",
      "Gradient Descent(6410/9999): loss=5365.6377839738025, w0=8.377080201063448, w1=-49.346276153003004\n",
      "Gradient Descent(6411/9999): loss=5365.6377839738025, w0=8.377080201063448, w1=-49.346276153003004\n",
      "Gradient Descent(6412/9999): loss=5365.6377839738025, w0=8.377080201063448, w1=-49.346276153003004\n",
      "Gradient Descent(6413/9999): loss=5365.6377839738025, w0=8.377080201063448, w1=-49.346276153003004\n",
      "Gradient Descent(6414/9999): loss=5365.6377839738025, w0=8.377080201063448, w1=-49.346276153003004\n",
      "Gradient Descent(6415/9999): loss=5365.6377839738025, w0=8.377080201063448, w1=-49.346276153003004\n",
      "Gradient Descent(6416/9999): loss=5365.6377839738025, w0=8.377080201063448, w1=-49.346276153003004\n",
      "Gradient Descent(6417/9999): loss=5365.6377839738025, w0=8.377080201063448, w1=-49.346276153003004\n",
      "Gradient Descent(6418/9999): loss=5365.6377839738025, w0=8.377080201063448, w1=-49.346276153003004\n",
      "Gradient Descent(6419/9999): loss=5365.6377839738025, w0=17.984880201063447, w1=-46.720676153003005\n",
      "Gradient Descent(6420/9999): loss=5999.531301277559, w0=4.837480201063448, w1=-52.99747615300301\n",
      "Gradient Descent(6421/9999): loss=5744.934527108362, w0=16.66108020106345, w1=-49.96667615300301\n",
      "Gradient Descent(6422/9999): loss=4330.733825246063, w0=16.66108020106345, w1=-49.96667615300301\n",
      "Gradient Descent(6423/9999): loss=4330.733825246063, w0=16.66108020106345, w1=-49.96667615300301\n",
      "Gradient Descent(6424/9999): loss=4330.733825246063, w0=16.66108020106345, w1=-49.96667615300301\n",
      "Gradient Descent(6425/9999): loss=4330.733825246063, w0=16.66108020106345, w1=-49.96667615300301\n",
      "Gradient Descent(6426/9999): loss=4330.733825246063, w0=16.66108020106345, w1=-49.96667615300301\n",
      "Gradient Descent(6427/9999): loss=4330.733825246063, w0=16.66108020106345, w1=-49.96667615300301\n",
      "Gradient Descent(6428/9999): loss=4330.733825246063, w0=16.66108020106345, w1=-49.96667615300301\n",
      "Gradient Descent(6429/9999): loss=4330.733825246063, w0=28.81418020106345, w1=-45.87847615300301\n",
      "Gradient Descent(6430/9999): loss=16244.731951102402, w0=21.052980201063452, w1=-51.746176153003006\n",
      "Gradient Descent(6431/9999): loss=6736.871351830896, w0=34.98048020106346, w1=-43.652976153003\n",
      "Gradient Descent(6432/9999): loss=17041.6540067276, w0=22.913714815509923, w1=-52.258876153003\n",
      "Gradient Descent(6433/9999): loss=7338.81593753177, w0=22.913714815509923, w1=-52.258876153003\n",
      "Gradient Descent(6434/9999): loss=7338.81593753177, w0=5.449514815509922, w1=-53.811076153003\n",
      "Gradient Descent(6435/9999): loss=5744.934770214191, w0=5.449514815509922, w1=-53.811076153003\n",
      "Gradient Descent(6436/9999): loss=5744.934770214191, w0=5.449514815509922, w1=-53.811076153003\n",
      "Gradient Descent(6437/9999): loss=5744.934770214191, w0=5.449514815509922, w1=-53.811076153003\n",
      "Gradient Descent(6438/9999): loss=5744.934770214191, w0=5.449514815509922, w1=-53.811076153003\n",
      "Gradient Descent(6439/9999): loss=5744.934770214191, w0=21.194214815509923, w1=-50.044276153003\n",
      "Gradient Descent(6440/9999): loss=9269.394574778491, w0=13.154414815509924, w1=-57.739076153003\n",
      "Gradient Descent(6441/9999): loss=4493.3658923617595, w0=13.15441481694324, w1=-57.73907615269438\n",
      "Gradient Descent(6442/9999): loss=4493.365892089067, w0=13.15441481694324, w1=-57.73907615269438\n",
      "Gradient Descent(6443/9999): loss=4493.365892089067, w0=13.15441481694324, w1=-57.73907615269438\n",
      "Gradient Descent(6444/9999): loss=4493.365892089067, w0=23.38091481694324, w1=-54.21377615269438\n",
      "Gradient Descent(6445/9999): loss=13707.707206697563, w0=11.314149431389705, w1=-61.516776152694376\n",
      "Gradient Descent(6446/9999): loss=4848.685085741397, w0=-4.9657505686102965, w1=-63.101276152694375\n",
      "Gradient Descent(6447/9999): loss=5676.250103391105, w0=5.425449431389705, w1=-62.47127615269437\n",
      "Gradient Descent(6448/9999): loss=5261.43064907193, w0=5.425449431389705, w1=-62.47127615269437\n",
      "Gradient Descent(6449/9999): loss=5261.43064907193, w0=5.425449431389705, w1=-62.47127615269437\n",
      "Gradient Descent(6450/9999): loss=5261.43064907193, w0=5.425449431389705, w1=-62.47127615269437\n",
      "Gradient Descent(6451/9999): loss=5261.43064907193, w0=-2.748350568610295, w1=-64.76677615269438\n",
      "Gradient Descent(6452/9999): loss=5414.717465610396, w0=-2.748350568610295, w1=-64.76677615269438\n",
      "Gradient Descent(6453/9999): loss=5414.717465610396, w0=9.571249431389706, w1=-63.083476152694374\n",
      "Gradient Descent(6454/9999): loss=5595.282026913648, w0=9.571249431389706, w1=-63.083476152694374\n",
      "Gradient Descent(6455/9999): loss=5595.282026913648, w0=9.571249431389706, w1=-63.083476152694374\n",
      "Gradient Descent(6456/9999): loss=5595.282026913648, w0=9.571249431389706, w1=-63.083476152694374\n",
      "Gradient Descent(6457/9999): loss=5595.282026913648, w0=9.571249431389706, w1=-63.083476152694374\n",
      "Gradient Descent(6458/9999): loss=5595.282026913648, w0=9.571249431389706, w1=-63.083476152694374\n",
      "Gradient Descent(6459/9999): loss=5595.282026913648, w0=9.571249431389706, w1=-63.083476152694374\n",
      "Gradient Descent(6460/9999): loss=5595.282026913648, w0=9.571249431389706, w1=-63.083476152694374\n",
      "Gradient Descent(6461/9999): loss=5595.282026913648, w0=9.571249431389706, w1=-63.083476152694374\n",
      "Gradient Descent(6462/9999): loss=5595.282026913648, w0=9.571249431389706, w1=-63.083476152694374\n",
      "Gradient Descent(6463/9999): loss=5595.282026913648, w0=1.5862494313897066, w1=-64.91807615269437\n",
      "Gradient Descent(6464/9999): loss=4705.731907750238, w0=1.5862494313897066, w1=-64.91807615269437\n",
      "Gradient Descent(6465/9999): loss=4705.731907750238, w0=1.5862494313897066, w1=-64.91807615269437\n",
      "Gradient Descent(6466/9999): loss=4705.731907750238, w0=12.980649431389708, w1=-60.544476152694365\n",
      "Gradient Descent(6467/9999): loss=8959.01371242983, w0=12.980649431389708, w1=-60.544476152694365\n",
      "Gradient Descent(6468/9999): loss=8959.01371242983, w0=12.980649431389708, w1=-60.544476152694365\n",
      "Gradient Descent(6469/9999): loss=8959.01371242983, w0=4.907049431389707, w1=-62.55187615269436\n",
      "Gradient Descent(6470/9999): loss=4714.022100062966, w0=4.907049431389707, w1=-62.55187615269436\n",
      "Gradient Descent(6471/9999): loss=4714.022100062966, w0=4.907049431389707, w1=-62.55187615269436\n",
      "Gradient Descent(6472/9999): loss=4714.022100062966, w0=4.907049431389707, w1=-62.55187615269436\n",
      "Gradient Descent(6473/9999): loss=4714.022100062966, w0=4.907049431389707, w1=-62.55187615269436\n",
      "Gradient Descent(6474/9999): loss=4714.022100062966, w0=4.907049431389707, w1=-62.55187615269436\n",
      "Gradient Descent(6475/9999): loss=4714.022100062966, w0=4.907049431389707, w1=-62.55187615269436\n",
      "Gradient Descent(6476/9999): loss=4714.022100062966, w0=4.907049431389707, w1=-62.55187615269436\n",
      "Gradient Descent(6477/9999): loss=4714.022100062966, w0=4.907049431389707, w1=-62.55187615269436\n",
      "Gradient Descent(6478/9999): loss=4714.022100062966, w0=4.907049431389707, w1=-62.55187615269436\n",
      "Gradient Descent(6479/9999): loss=4714.022100062966, w0=4.907049431389707, w1=-62.55187615269436\n",
      "Gradient Descent(6480/9999): loss=4714.022100062966, w0=4.907049431389707, w1=-62.55187615269436\n",
      "Gradient Descent(6481/9999): loss=4714.022100062966, w0=4.907049431389707, w1=-62.55187615269436\n",
      "Gradient Descent(6482/9999): loss=4714.022100062966, w0=4.907049431389707, w1=-62.55187615269436\n",
      "Gradient Descent(6483/9999): loss=4714.022100062966, w0=4.907049431389707, w1=-62.55187615269436\n",
      "Gradient Descent(6484/9999): loss=4714.022100062966, w0=-3.209650568610293, w1=-66.34527615269437\n",
      "Gradient Descent(6485/9999): loss=5618.298394679643, w0=-3.209650568610293, w1=-66.34527615269437\n",
      "Gradient Descent(6486/9999): loss=5618.298394679643, w0=-3.209650568610293, w1=-66.34527615269437\n",
      "Gradient Descent(6487/9999): loss=5618.298394679643, w0=-3.209650568610293, w1=-66.34527615269437\n",
      "Gradient Descent(6488/9999): loss=5618.298394679643, w0=-3.209650568610293, w1=-66.34527615269437\n",
      "Gradient Descent(6489/9999): loss=5618.298394679643, w0=-3.209650568610293, w1=-66.34527615269437\n",
      "Gradient Descent(6490/9999): loss=5618.298394679643, w0=-3.209650568610293, w1=-66.34527615269437\n",
      "Gradient Descent(6491/9999): loss=5618.298394679643, w0=-3.209650568610293, w1=-66.34527615269437\n",
      "Gradient Descent(6492/9999): loss=5618.298394679643, w0=-3.209650568610293, w1=-66.34527615269437\n",
      "Gradient Descent(6493/9999): loss=5618.298394679643, w0=-3.209650568610293, w1=-66.34527615269437\n",
      "Gradient Descent(6494/9999): loss=5618.298394679643, w0=10.397649431389706, w1=-61.16847615269437\n",
      "Gradient Descent(6495/9999): loss=5082.787642642378, w0=10.397649431389706, w1=-61.16847615269437\n",
      "Gradient Descent(6496/9999): loss=5082.787642642378, w0=10.397649431389706, w1=-61.16847615269437\n",
      "Gradient Descent(6497/9999): loss=5082.787642642378, w0=10.397649431389706, w1=-61.16847615269437\n",
      "Gradient Descent(6498/9999): loss=5082.787642642378, w0=10.397649431389706, w1=-61.16847615269437\n",
      "Gradient Descent(6499/9999): loss=5082.787642642378, w0=10.397649431389706, w1=-61.16847615269437\n",
      "Gradient Descent(6500/9999): loss=5082.787642642378, w0=10.397649431389706, w1=-61.16847615269437\n",
      "Gradient Descent(6501/9999): loss=5082.787642642378, w0=10.397649431389706, w1=-61.16847615269437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(6502/9999): loss=5082.787642642378, w0=10.397649431389706, w1=-61.16847615269437\n",
      "Gradient Descent(6503/9999): loss=5082.787642642378, w0=1.1312494313897048, w1=-66.29757615269438\n",
      "Gradient Descent(6504/9999): loss=5645.555055416908, w0=1.1312494313897048, w1=-66.29757615269438\n",
      "Gradient Descent(6505/9999): loss=5645.555055416908, w0=1.1312494313897048, w1=-66.29757615269438\n",
      "Gradient Descent(6506/9999): loss=5645.555055416908, w0=12.254649431389705, w1=-63.94487615269438\n",
      "Gradient Descent(6507/9999): loss=5026.047890890431, w0=12.254649431389705, w1=-63.94487615269438\n",
      "Gradient Descent(6508/9999): loss=5026.047890890431, w0=12.254649431389705, w1=-63.94487615269438\n",
      "Gradient Descent(6509/9999): loss=5026.047890890431, w0=12.254649431389705, w1=-63.94487615269438\n",
      "Gradient Descent(6510/9999): loss=5026.047890890431, w0=12.254649431389705, w1=-63.94487615269438\n",
      "Gradient Descent(6511/9999): loss=5026.047890890431, w0=12.254649431389705, w1=-63.94487615269438\n",
      "Gradient Descent(6512/9999): loss=5026.047890890431, w0=4.181049431389704, w1=-65.95227615269438\n",
      "Gradient Descent(6513/9999): loss=4628.198525440306, w0=4.181049431389704, w1=-65.95227615269438\n",
      "Gradient Descent(6514/9999): loss=4628.198525440306, w0=13.368749431389706, w1=-62.07787615269438\n",
      "Gradient Descent(6515/9999): loss=5332.393482042693, w0=13.368749431389706, w1=-62.07787615269438\n",
      "Gradient Descent(6516/9999): loss=5332.393482042693, w0=13.368749431389706, w1=-62.07787615269438\n",
      "Gradient Descent(6517/9999): loss=5332.393482042693, w0=13.368749431389706, w1=-62.07787615269438\n",
      "Gradient Descent(6518/9999): loss=5332.393482042693, w0=13.368749431389706, w1=-62.07787615269438\n",
      "Gradient Descent(6519/9999): loss=5332.393482042693, w0=13.368749431389706, w1=-62.07787615269438\n",
      "Gradient Descent(6520/9999): loss=5332.393482042693, w0=13.368749431389706, w1=-62.07787615269438\n",
      "Gradient Descent(6521/9999): loss=5332.393482042693, w0=13.368749431389706, w1=-62.07787615269438\n",
      "Gradient Descent(6522/9999): loss=5332.393482042693, w0=13.368749431389706, w1=-62.07787615269438\n",
      "Gradient Descent(6523/9999): loss=5332.393482042693, w0=23.335702695297677, w1=-57.47504637961942\n",
      "Gradient Descent(6524/9999): loss=13738.69132930617, w0=11.268937309744143, w1=-65.97174637961942\n",
      "Gradient Descent(6525/9999): loss=4677.120091761288, w0=11.268937309744143, w1=-65.97174637961942\n",
      "Gradient Descent(6526/9999): loss=4677.120091761288, w0=11.268937309744143, w1=-65.97174637961942\n",
      "Gradient Descent(6527/9999): loss=4677.120091761288, w0=19.651337309744143, w1=-63.36344637961942\n",
      "Gradient Descent(6528/9999): loss=13294.747643100283, w0=6.884337309744142, w1=-68.30684637961942\n",
      "Gradient Descent(6529/9999): loss=4556.231750521727, w0=6.884337309744142, w1=-68.30684637961942\n",
      "Gradient Descent(6530/9999): loss=4556.231750521727, w0=-1.5820626902558583, w1=-72.04224637961941\n",
      "Gradient Descent(6531/9999): loss=5675.915633494566, w0=10.015937309744142, w1=-71.49594637961941\n",
      "Gradient Descent(6532/9999): loss=4614.163472569636, w0=10.015937309744142, w1=-71.49594637961941\n",
      "Gradient Descent(6533/9999): loss=4614.163472569636, w0=0.7879373097441427, w1=-71.70334637961942\n",
      "Gradient Descent(6534/9999): loss=4725.594197204971, w0=10.696537309744143, w1=-67.57424637961942\n",
      "Gradient Descent(6535/9999): loss=7743.118819947325, w0=0.6360373097441414, w1=-72.32914637961943\n",
      "Gradient Descent(6536/9999): loss=4570.6141980646025, w0=-6.630262690255859, w1=-74.09394637961942\n",
      "Gradient Descent(6537/9999): loss=5802.4994844197445, w0=-6.630262690255859, w1=-74.09394637961942\n",
      "Gradient Descent(6538/9999): loss=5802.4994844197445, w0=-6.630262690255859, w1=-74.09394637961942\n",
      "Gradient Descent(6539/9999): loss=5802.4994844197445, w0=2.7035373097441413, w1=-68.72744637961942\n",
      "Gradient Descent(6540/9999): loss=4614.34189295313, w0=2.7035373097441413, w1=-68.72744637961942\n",
      "Gradient Descent(6541/9999): loss=4614.34189295313, w0=2.7035373097441413, w1=-68.72744637961942\n",
      "Gradient Descent(6542/9999): loss=4614.34189295313, w0=14.720237309744142, w1=-66.20834637961943\n",
      "Gradient Descent(6543/9999): loss=7002.2961706337865, w0=14.720237309744142, w1=-66.20834637961943\n",
      "Gradient Descent(6544/9999): loss=7002.2961706337865, w0=14.720237309744142, w1=-66.20834637961943\n",
      "Gradient Descent(6545/9999): loss=7002.2961706337865, w0=14.720237309744142, w1=-66.20834637961943\n",
      "Gradient Descent(6546/9999): loss=7002.2961706337865, w0=4.858437309744142, w1=-71.55224637961943\n",
      "Gradient Descent(6547/9999): loss=4454.744084552626, w0=18.074537309744144, w1=-65.89414637961943\n",
      "Gradient Descent(6548/9999): loss=7682.584664052216, w0=18.074537309744144, w1=-65.89414637961943\n",
      "Gradient Descent(6549/9999): loss=7682.584664052216, w0=18.074537309744144, w1=-65.89414637961943\n",
      "Gradient Descent(6550/9999): loss=7682.584664052216, w0=18.074537309744144, w1=-65.89414637961943\n",
      "Gradient Descent(6551/9999): loss=7682.584664052216, w0=18.074537309744144, w1=-65.89414637961943\n",
      "Gradient Descent(6552/9999): loss=7682.584664052216, w0=18.074537309744144, w1=-65.89414637961943\n",
      "Gradient Descent(6553/9999): loss=7682.584664052216, w0=18.074537309744144, w1=-65.89414637961943\n",
      "Gradient Descent(6554/9999): loss=7682.584664052216, w0=8.252437309744144, w1=-73.69914637961944\n",
      "Gradient Descent(6555/9999): loss=4628.177910633791, w0=8.252437309744144, w1=-73.69914637961944\n",
      "Gradient Descent(6556/9999): loss=4628.177910633791, w0=8.252437309744144, w1=-73.69914637961944\n",
      "Gradient Descent(6557/9999): loss=4628.177910633791, w0=8.252437309744144, w1=-73.69914637961944\n",
      "Gradient Descent(6558/9999): loss=4628.177910633791, w0=8.252437309744144, w1=-73.69914637961944\n",
      "Gradient Descent(6559/9999): loss=4628.177910633791, w0=19.572137309744143, w1=-69.43914637961943\n",
      "Gradient Descent(6560/9999): loss=5629.052128261152, w0=19.572137309744143, w1=-69.43914637961943\n",
      "Gradient Descent(6561/9999): loss=5629.052128261152, w0=19.572137309744143, w1=-69.43914637961943\n",
      "Gradient Descent(6562/9999): loss=5629.052128261152, w0=19.572137309744143, w1=-69.43914637961943\n",
      "Gradient Descent(6563/9999): loss=5629.052128261152, w0=19.572137309744143, w1=-69.43914637961943\n",
      "Gradient Descent(6564/9999): loss=5629.052128261152, w0=19.572137309744143, w1=-69.43914637961943\n",
      "Gradient Descent(6565/9999): loss=5629.052128261152, w0=7.078037309744142, w1=-75.31294637961943\n",
      "Gradient Descent(6566/9999): loss=5765.289900104934, w0=7.078037309744142, w1=-75.31294637961943\n",
      "Gradient Descent(6567/9999): loss=5765.289900104934, w0=7.078037309744142, w1=-75.31294637961943\n",
      "Gradient Descent(6568/9999): loss=5765.289900104934, w0=7.078037309744142, w1=-75.31294637961943\n",
      "Gradient Descent(6569/9999): loss=5765.289900104934, w0=7.078037309744142, w1=-75.31294637961943\n",
      "Gradient Descent(6570/9999): loss=5765.289900104934, w0=7.078037309744142, w1=-75.31294637961943\n",
      "Gradient Descent(6571/9999): loss=5765.289900104934, w0=7.078037309744142, w1=-75.31294637961943\n",
      "Gradient Descent(6572/9999): loss=5765.289900104934, w0=7.078037309744142, w1=-75.31294637961943\n",
      "Gradient Descent(6573/9999): loss=5765.289900104934, w0=7.078037309744142, w1=-75.31294637961943\n",
      "Gradient Descent(6574/9999): loss=5765.289900104934, w0=7.078037309744142, w1=-75.31294637961943\n",
      "Gradient Descent(6575/9999): loss=5765.289900104934, w0=18.248937309744143, w1=-68.34994637961944\n",
      "Gradient Descent(6576/9999): loss=4215.4160004349105, w0=18.248937309744143, w1=-68.34994637961944\n",
      "Gradient Descent(6577/9999): loss=4215.4160004349105, w0=29.14633730974414, w1=-63.35654637961944\n",
      "Gradient Descent(6578/9999): loss=13375.46805765601, w0=29.146337078626452, w1=-63.356546532791754\n",
      "Gradient Descent(6579/9999): loss=13375.468014162972, w0=19.15353707862645, w1=-66.37814653279176\n",
      "Gradient Descent(6580/9999): loss=4646.443201305739, w0=19.15353707862645, w1=-66.37814653279176\n",
      "Gradient Descent(6581/9999): loss=4646.443201305739, w0=19.15353707862645, w1=-66.37814653279176\n",
      "Gradient Descent(6582/9999): loss=4646.443201305739, w0=19.15353707862645, w1=-66.37814653279176\n",
      "Gradient Descent(6583/9999): loss=4646.443201305739, w0=19.15353707862645, w1=-66.37814653279176\n",
      "Gradient Descent(6584/9999): loss=4646.443201305739, w0=19.15353707862645, w1=-66.37814653279176\n",
      "Gradient Descent(6585/9999): loss=4646.443201305739, w0=19.15353707862645, w1=-66.37814653279176\n",
      "Gradient Descent(6586/9999): loss=4646.443201305739, w0=30.64853707862645, w1=-60.339046532791755\n",
      "Gradient Descent(6587/9999): loss=13849.766394985276, w0=16.64333707862645, w1=-67.63554653279175\n",
      "Gradient Descent(6588/9999): loss=4457.10655439622, w0=26.08973707862645, w1=-64.16244653279175\n",
      "Gradient Descent(6589/9999): loss=12251.900692161453, w0=15.803337078626448, w1=-68.70294653279174\n",
      "Gradient Descent(6590/9999): loss=4816.646335544318, w0=4.806437078626448, w1=-70.63184653279174\n",
      "Gradient Descent(6591/9999): loss=5196.419999187571, w0=4.806437078626448, w1=-70.63184653279174\n",
      "Gradient Descent(6592/9999): loss=5196.419999187571, w0=4.806437078626448, w1=-70.63184653279174\n",
      "Gradient Descent(6593/9999): loss=5196.419999187571, w0=4.806437078626448, w1=-70.63184653279174\n",
      "Gradient Descent(6594/9999): loss=5196.419999187571, w0=4.806437078626448, w1=-70.63184653279174\n",
      "Gradient Descent(6595/9999): loss=5196.419999187571, w0=4.806437078626448, w1=-70.63184653279174\n",
      "Gradient Descent(6596/9999): loss=5196.419999187571, w0=4.806437078626448, w1=-70.63184653279174\n",
      "Gradient Descent(6597/9999): loss=5196.419999187571, w0=4.806437078626448, w1=-70.63184653279174\n",
      "Gradient Descent(6598/9999): loss=5196.419999187571, w0=4.806437078626448, w1=-70.63184653279174\n",
      "Gradient Descent(6599/9999): loss=5196.419999187571, w0=17.99663707862645, w1=-61.46244653279174\n",
      "Gradient Descent(6600/9999): loss=4760.259622723056, w0=17.99663707862645, w1=-61.46244653279174\n",
      "Gradient Descent(6601/9999): loss=4760.259622723056, w0=17.99663707862645, w1=-61.46244653279174\n",
      "Gradient Descent(6602/9999): loss=4760.259622723056, w0=17.99663707862645, w1=-61.46244653279174\n",
      "Gradient Descent(6603/9999): loss=4760.259622723056, w0=17.99663707862645, w1=-61.46244653279174\n",
      "Gradient Descent(6604/9999): loss=4760.259622723056, w0=17.99663707862645, w1=-61.46244653279174\n",
      "Gradient Descent(6605/9999): loss=4760.259622723056, w0=17.99663707862645, w1=-61.46244653279174\n",
      "Gradient Descent(6606/9999): loss=4760.259622723056, w0=17.99663707862645, w1=-61.46244653279174\n",
      "Gradient Descent(6607/9999): loss=4760.259622723056, w0=17.99663707862645, w1=-61.46244653279174\n",
      "Gradient Descent(6608/9999): loss=4760.259622723056, w0=17.99663707862645, w1=-61.46244653279174\n",
      "Gradient Descent(6609/9999): loss=4760.259622723056, w0=17.99663707862645, w1=-61.46244653279174\n",
      "Gradient Descent(6610/9999): loss=4760.259622723056, w0=17.99663707862645, w1=-61.46244653279174\n",
      "Gradient Descent(6611/9999): loss=4760.259622723056, w0=17.99663707862645, w1=-61.46244653279174\n",
      "Gradient Descent(6612/9999): loss=4760.259622723056, w0=30.063402464179983, w1=-51.13884653279174\n",
      "Gradient Descent(6613/9999): loss=14304.615784542064, w0=30.063402464179983, w1=-51.13884653279174\n",
      "Gradient Descent(6614/9999): loss=14304.615784542064, w0=30.063402464179983, w1=-51.13884653279174\n",
      "Gradient Descent(6615/9999): loss=14304.615784542064, w0=23.962702464179984, w1=-56.48544653279174\n",
      "Gradient Descent(6616/9999): loss=5495.013554206949, w0=23.962702464179984, w1=-56.48544653279174\n",
      "Gradient Descent(6617/9999): loss=5495.013554206949, w0=7.279402464179984, w1=-59.65674653279174\n",
      "Gradient Descent(6618/9999): loss=5767.960685330578, w0=7.279402464179984, w1=-59.65674653279174\n",
      "Gradient Descent(6619/9999): loss=5767.960685330578, w0=7.279402464179984, w1=-59.65674653279174\n",
      "Gradient Descent(6620/9999): loss=5767.960685330578, w0=7.279402464179984, w1=-59.65674653279174\n",
      "Gradient Descent(6621/9999): loss=5767.960685330578, w0=7.279402464179984, w1=-59.65674653279174\n",
      "Gradient Descent(6622/9999): loss=5767.960685330578, w0=7.279402464179984, w1=-59.65674653279174\n",
      "Gradient Descent(6623/9999): loss=5767.960685330578, w0=7.279402464179984, w1=-59.65674653279174\n",
      "Gradient Descent(6624/9999): loss=5767.960685330578, w0=7.279402464179984, w1=-59.65674653279174\n",
      "Gradient Descent(6625/9999): loss=5767.960685330578, w0=16.760602464179986, w1=-59.39124653279174\n",
      "Gradient Descent(6626/9999): loss=4582.134316532021, w0=16.760602464179986, w1=-59.39124653279174\n",
      "Gradient Descent(6627/9999): loss=4582.134316532021, w0=16.760602464179986, w1=-59.39124653279174\n",
      "Gradient Descent(6628/9999): loss=4582.134316532021, w0=7.040502464179983, w1=-60.65464653279174\n",
      "Gradient Descent(6629/9999): loss=5802.4994844197445, w0=7.040502464179983, w1=-60.65464653279174\n",
      "Gradient Descent(6630/9999): loss=5802.4994844197445, w0=7.040502464179983, w1=-60.65464653279174\n",
      "Gradient Descent(6631/9999): loss=5802.4994844197445, w0=7.040502464179983, w1=-60.65464653279174\n",
      "Gradient Descent(6632/9999): loss=5802.4994844197445, w0=7.040502464179983, w1=-60.65464653279174\n",
      "Gradient Descent(6633/9999): loss=5802.4994844197445, w0=7.040502464179983, w1=-60.65464653279174\n",
      "Gradient Descent(6634/9999): loss=5802.4994844197445, w0=7.040502464179983, w1=-60.65464653279174\n",
      "Gradient Descent(6635/9999): loss=5802.4994844197445, w0=7.040502464179983, w1=-60.65464653279174\n",
      "Gradient Descent(6636/9999): loss=5802.4994844197445, w0=7.040502464179983, w1=-60.65464653279174\n",
      "Gradient Descent(6637/9999): loss=5802.4994844197445, w0=7.040502464179983, w1=-60.65464653279174\n",
      "Gradient Descent(6638/9999): loss=5802.4994844197445, w0=7.040502464179983, w1=-60.65464653279174\n",
      "Gradient Descent(6639/9999): loss=5802.4994844197445, w0=7.040502464179983, w1=-60.65464653279174\n",
      "Gradient Descent(6640/9999): loss=5802.4994844197445, w0=7.040502464179983, w1=-60.65464653279174\n",
      "Gradient Descent(6641/9999): loss=5802.4994844197445, w0=7.040502464179983, w1=-60.65464653279174\n",
      "Gradient Descent(6642/9999): loss=5802.4994844197445, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6643/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6644/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6645/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6646/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6647/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6648/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6649/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6650/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6651/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6652/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6653/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6654/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6655/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6656/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6657/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6658/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6659/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6660/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6661/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6662/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6663/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6664/9999): loss=4267.356463195074, w0=15.224402464179983, w1=-59.10224653279174\n",
      "Gradient Descent(6665/9999): loss=4267.356463195074, w0=26.349002464179982, w1=-58.37854653279174\n",
      "Gradient Descent(6666/9999): loss=10554.825803486214, w0=26.349002464179982, w1=-58.37854653279174\n",
      "Gradient Descent(6667/9999): loss=10554.825803486214, w0=26.349002464179982, w1=-58.37854653279174\n",
      "Gradient Descent(6668/9999): loss=10554.825803486214, w0=18.137602464179984, w1=-63.202546532791736\n",
      "Gradient Descent(6669/9999): loss=4454.2384946, w0=18.137602464179984, w1=-63.202546532791736\n",
      "Gradient Descent(6670/9999): loss=4454.2384946, w0=18.137602464179984, w1=-63.202546532791736\n",
      "Gradient Descent(6671/9999): loss=4454.2384946, w0=18.137602464179984, w1=-63.202546532791736\n",
      "Gradient Descent(6672/9999): loss=4454.2384946, w0=18.137602464179984, w1=-63.202546532791736\n",
      "Gradient Descent(6673/9999): loss=4454.2384946, w0=18.137602464179984, w1=-63.202546532791736\n",
      "Gradient Descent(6674/9999): loss=4454.2384946, w0=10.257502464179984, w1=-65.36094653279173\n",
      "Gradient Descent(6675/9999): loss=4777.510000337052, w0=10.257502464179984, w1=-65.36094653279173\n",
      "Gradient Descent(6676/9999): loss=4777.510000337052, w0=10.257502464179984, w1=-65.36094653279173\n",
      "Gradient Descent(6677/9999): loss=4777.510000337052, w0=10.257502464179984, w1=-65.36094653279173\n",
      "Gradient Descent(6678/9999): loss=4777.510000337052, w0=20.492702464179985, w1=-59.73534653279173\n",
      "Gradient Descent(6679/9999): loss=6103.504463525263, w0=20.492702464179985, w1=-59.73534653279173\n",
      "Gradient Descent(6680/9999): loss=6103.504463525263, w0=20.492702464179985, w1=-59.73534653279173\n",
      "Gradient Descent(6681/9999): loss=6103.504463525263, w0=20.492702464179985, w1=-59.73534653279173\n",
      "Gradient Descent(6682/9999): loss=6103.504463525263, w0=20.492702464179985, w1=-59.73534653279173\n",
      "Gradient Descent(6683/9999): loss=6103.504463525263, w0=20.492702464179985, w1=-59.73534653279173\n",
      "Gradient Descent(6684/9999): loss=6103.504463525263, w0=20.492702464179985, w1=-59.73534653279173\n",
      "Gradient Descent(6685/9999): loss=6103.504463525263, w0=20.492702464179985, w1=-59.73534653279173\n",
      "Gradient Descent(6686/9999): loss=6103.504463525263, w0=13.307502464179983, w1=-62.04844653279173\n",
      "Gradient Descent(6687/9999): loss=4910.451702658029, w0=13.307502464179983, w1=-62.04844653279173\n",
      "Gradient Descent(6688/9999): loss=4910.451702658029, w0=13.307502464179983, w1=-62.04844653279173\n",
      "Gradient Descent(6689/9999): loss=4910.451702658029, w0=13.307502464179983, w1=-62.04844653279173\n",
      "Gradient Descent(6690/9999): loss=4910.451702658029, w0=25.374267849733517, w1=-56.77254653279173\n",
      "Gradient Descent(6691/9999): loss=4419.851267989189, w0=25.374267849733517, w1=-56.77254653279173\n",
      "Gradient Descent(6692/9999): loss=4419.851267989189, w0=25.374267849733517, w1=-56.77254653279173\n",
      "Gradient Descent(6693/9999): loss=4419.851267989189, w0=35.162867849733516, w1=-55.00574653279173\n",
      "Gradient Descent(6694/9999): loss=14649.241930900615, w0=25.809867849733514, w1=-59.502846532791736\n",
      "Gradient Descent(6695/9999): loss=5049.210547341174, w0=14.163367849733513, w1=-61.81074653279174\n",
      "Gradient Descent(6696/9999): loss=4754.87609574246, w0=27.95826784973351, w1=-56.07074653279174\n",
      "Gradient Descent(6697/9999): loss=6027.540807883692, w0=27.95826784973351, w1=-56.07074653279174\n",
      "Gradient Descent(6698/9999): loss=6027.540807883692, w0=27.95826784973351, w1=-56.07074653279174\n",
      "Gradient Descent(6699/9999): loss=6027.540807883692, w0=27.95826784973351, w1=-56.07074653279174\n",
      "Gradient Descent(6700/9999): loss=6027.540807883692, w0=27.95826784973351, w1=-56.07074653279174\n",
      "Gradient Descent(6701/9999): loss=6027.540807883692, w0=27.95826784973351, w1=-56.07074653279174\n",
      "Gradient Descent(6702/9999): loss=6027.540807883692, w0=27.95826784973351, w1=-56.07074653279174\n",
      "Gradient Descent(6703/9999): loss=6027.540807883692, w0=27.95826784973351, w1=-56.07074653279174\n",
      "Gradient Descent(6704/9999): loss=6027.540807883692, w0=27.95826784973351, w1=-56.07074653279174\n",
      "Gradient Descent(6705/9999): loss=6027.540807883692, w0=27.95826784973351, w1=-56.07074653279174\n",
      "Gradient Descent(6706/9999): loss=6027.540807883692, w0=27.95826784973351, w1=-56.07074653279174\n",
      "Gradient Descent(6707/9999): loss=6027.540807883692, w0=38.42726784973351, w1=-50.762446532791735\n",
      "Gradient Descent(6708/9999): loss=15650.34955747443, w0=21.77646784973351, w1=-60.66404653279174\n",
      "Gradient Descent(6709/9999): loss=4330.7244069867775, w0=2.274067849733509, w1=-64.03304653279173\n",
      "Gradient Descent(6710/9999): loss=5802.4994844197445, w0=2.274067849733509, w1=-64.03304653279173\n",
      "Gradient Descent(6711/9999): loss=5802.4994844197445, w0=15.149967849733509, w1=-63.03174653279173\n",
      "Gradient Descent(6712/9999): loss=4501.554224599429, w0=15.149967849733509, w1=-63.03174653279173\n",
      "Gradient Descent(6713/9999): loss=4501.554224599429, w0=15.149967849733509, w1=-63.03174653279173\n",
      "Gradient Descent(6714/9999): loss=4501.554224599429, w0=15.149967849733509, w1=-63.03174653279173\n",
      "Gradient Descent(6715/9999): loss=4501.554224599429, w0=-0.6575321502664906, w1=-64.21494653279173\n",
      "Gradient Descent(6716/9999): loss=5802.4994844197445, w0=-0.6575321502664906, w1=-64.21494653279173\n",
      "Gradient Descent(6717/9999): loss=5802.4994844197445, w0=11.832667849733511, w1=-63.21044653279173\n",
      "Gradient Descent(6718/9999): loss=5549.214912812806, w0=11.832667849733511, w1=-63.21044653279173\n",
      "Gradient Descent(6719/9999): loss=5549.214912812806, w0=11.832667849733511, w1=-63.21044653279173\n",
      "Gradient Descent(6720/9999): loss=5549.214912812806, w0=22.47746784973351, w1=-59.10234653279173\n",
      "Gradient Descent(6721/9999): loss=4489.793049866206, w0=22.47746784973351, w1=-59.10234653279173\n",
      "Gradient Descent(6722/9999): loss=4489.793049866206, w0=22.47746784973351, w1=-59.10234653279173\n",
      "Gradient Descent(6723/9999): loss=4489.793049866206, w0=33.96656784973351, w1=-58.751446532791725\n",
      "Gradient Descent(6724/9999): loss=10474.147272978187, w0=21.899802464179974, w1=-65.80724653279172\n",
      "Gradient Descent(6725/9999): loss=4374.316491553446, w0=21.899802464179974, w1=-65.80724653279172\n",
      "Gradient Descent(6726/9999): loss=4374.316491553446, w0=21.899802464179974, w1=-65.80724653279172\n",
      "Gradient Descent(6727/9999): loss=4374.316491553446, w0=32.12630246417997, w1=-62.28194653279172\n",
      "Gradient Descent(6728/9999): loss=15292.75326364399, w0=32.12630246417997, w1=-62.28194653279172\n",
      "Gradient Descent(6729/9999): loss=15292.75326364399, w0=32.12630246417997, w1=-62.28194653279172\n",
      "Gradient Descent(6730/9999): loss=15292.75326364399, w0=20.059537078626438, w1=-70.60634653279172\n",
      "Gradient Descent(6731/9999): loss=6296.698495787704, w0=20.059537078626438, w1=-70.60634653279172\n",
      "Gradient Descent(6732/9999): loss=6296.698495787704, w0=20.059537078626438, w1=-70.60634653279172\n",
      "Gradient Descent(6733/9999): loss=6296.698495787704, w0=29.383037078626437, w1=-65.99744653279171\n",
      "Gradient Descent(6734/9999): loss=15046.542162707972, w0=16.72213707862644, w1=-71.47224653279171\n",
      "Gradient Descent(6735/9999): loss=5740.17939850762, w0=16.72213707862644, w1=-71.47224653279171\n",
      "Gradient Descent(6736/9999): loss=5740.17939850762, w0=16.72213707862644, w1=-71.47224653279171\n",
      "Gradient Descent(6737/9999): loss=5740.17939850762, w0=16.72213707862644, w1=-71.47224653279171\n",
      "Gradient Descent(6738/9999): loss=5740.17939850762, w0=16.72213707862644, w1=-71.47224653279171\n",
      "Gradient Descent(6739/9999): loss=5740.17939850762, w0=8.648537078626438, w1=-73.47964653279172\n",
      "Gradient Descent(6740/9999): loss=4340.947172618386, w0=8.648537078626438, w1=-73.47964653279172\n",
      "Gradient Descent(6741/9999): loss=4340.947172618386, w0=8.648537078626438, w1=-73.47964653279172\n",
      "Gradient Descent(6742/9999): loss=4340.947172618386, w0=8.648537078626438, w1=-73.47964653279172\n",
      "Gradient Descent(6743/9999): loss=4340.947172618386, w0=8.648537078626438, w1=-73.47964653279172\n",
      "Gradient Descent(6744/9999): loss=4340.947172618386, w0=8.648537078626438, w1=-73.47964653279172\n",
      "Gradient Descent(6745/9999): loss=4340.947172618386, w0=8.648537078626438, w1=-73.47964653279172\n",
      "Gradient Descent(6746/9999): loss=4340.947172618386, w0=8.648537078626438, w1=-73.47964653279172\n",
      "Gradient Descent(6747/9999): loss=4340.947172618386, w0=8.648537078626438, w1=-73.47964653279172\n",
      "Gradient Descent(6748/9999): loss=4340.947172618386, w0=8.648537078626438, w1=-73.47964653279172\n",
      "Gradient Descent(6749/9999): loss=4340.947172618386, w0=8.648537078626438, w1=-73.47964653279172\n",
      "Gradient Descent(6750/9999): loss=4340.947172618386, w0=8.648537078626438, w1=-73.47964653279172\n",
      "Gradient Descent(6751/9999): loss=4340.947172618386, w0=20.44113707862644, w1=-69.59574653279172\n",
      "Gradient Descent(6752/9999): loss=6448.879996409365, w0=20.44113707862644, w1=-69.59574653279172\n",
      "Gradient Descent(6753/9999): loss=6448.879996409365, w0=3.7632370786264353, w1=-69.65234653279173\n",
      "Gradient Descent(6754/9999): loss=5343.350551744068, w0=3.7632370786264353, w1=-69.65234653279173\n",
      "Gradient Descent(6755/9999): loss=5343.350551744068, w0=3.7632370786264353, w1=-69.65234653279173\n",
      "Gradient Descent(6756/9999): loss=5343.350551744068, w0=13.400437078626437, w1=-69.45014653279172\n",
      "Gradient Descent(6757/9999): loss=4452.872504881968, w0=13.400437078626437, w1=-69.45014653279172\n",
      "Gradient Descent(6758/9999): loss=4452.872504881968, w0=13.400437078626437, w1=-69.45014653279172\n",
      "Gradient Descent(6759/9999): loss=4452.872504881968, w0=13.400437078626437, w1=-69.45014653279172\n",
      "Gradient Descent(6760/9999): loss=4452.872504881968, w0=13.400437078626437, w1=-69.45014653279172\n",
      "Gradient Descent(6761/9999): loss=4452.872504881968, w0=13.400437078626437, w1=-69.45014653279172\n",
      "Gradient Descent(6762/9999): loss=4452.872504881968, w0=13.400437078626437, w1=-69.45014653279172\n",
      "Gradient Descent(6763/9999): loss=4452.872504881968, w0=13.400437078626437, w1=-69.45014653279172\n",
      "Gradient Descent(6764/9999): loss=4452.872504881968, w0=13.400437078626437, w1=-69.45014653279172\n",
      "Gradient Descent(6765/9999): loss=4452.872504881968, w0=21.782837078626436, w1=-66.84184653279172\n",
      "Gradient Descent(6766/9999): loss=10732.043380424344, w0=21.782837078626436, w1=-66.84184653279172\n",
      "Gradient Descent(6767/9999): loss=10732.043380424344, w0=21.782837078626436, w1=-66.84184653279172\n",
      "Gradient Descent(6768/9999): loss=10732.043380424344, w0=21.782837078626436, w1=-66.84184653279172\n",
      "Gradient Descent(6769/9999): loss=10732.043380424344, w0=-0.5641629213735655, w1=-78.04594653279172\n",
      "Gradient Descent(6770/9999): loss=5710.393947132863, w0=11.502602464179969, w1=-54.61874653279172\n",
      "Gradient Descent(6771/9999): loss=4840.737435706773, w0=11.502602464179969, w1=-54.61874653279172\n",
      "Gradient Descent(6772/9999): loss=4840.737435706773, w0=0.329102464179968, w1=-57.207946532791716\n",
      "Gradient Descent(6773/9999): loss=5675.857195201197, w0=0.329102464179968, w1=-57.207946532791716\n",
      "Gradient Descent(6774/9999): loss=5675.857195201197, w0=0.329102464179968, w1=-57.207946532791716\n",
      "Gradient Descent(6775/9999): loss=5675.857195201197, w0=0.329102464179968, w1=-57.207946532791716\n",
      "Gradient Descent(6776/9999): loss=5675.857195201197, w0=10.619302464179968, w1=-53.31914653279171\n",
      "Gradient Descent(6777/9999): loss=5171.036400046117, w0=10.619302464179968, w1=-53.31914653279171\n",
      "Gradient Descent(6778/9999): loss=5171.036400046117, w0=22.686067849733504, w1=-48.04304653279171\n",
      "Gradient Descent(6779/9999): loss=16271.689363025353, w0=22.686067849733504, w1=-48.04304653279171\n",
      "Gradient Descent(6780/9999): loss=16271.689363025353, w0=22.686067849733504, w1=-48.04304653279171\n",
      "Gradient Descent(6781/9999): loss=16271.689363025353, w0=10.61930246417997, w1=-57.95014653279171\n",
      "Gradient Descent(6782/9999): loss=4268.929551575455, w0=10.61930246417997, w1=-57.95014653279171\n",
      "Gradient Descent(6783/9999): loss=4268.929551575455, w0=10.61930246417997, w1=-57.95014653279171\n",
      "Gradient Descent(6784/9999): loss=4268.929551575455, w0=10.61930246417997, w1=-57.95014653279171\n",
      "Gradient Descent(6785/9999): loss=4268.929551575455, w0=10.61930246417997, w1=-57.95014653279171\n",
      "Gradient Descent(6786/9999): loss=4268.929551575455, w0=10.61930246417997, w1=-57.95014653279171\n",
      "Gradient Descent(6787/9999): loss=4268.929551575455, w0=10.61930246417997, w1=-57.95014653279171\n",
      "Gradient Descent(6788/9999): loss=4268.929551575455, w0=10.61930246417997, w1=-57.95014653279171\n",
      "Gradient Descent(6789/9999): loss=4268.929551575455, w0=10.61930246417997, w1=-57.95014653279171\n",
      "Gradient Descent(6790/9999): loss=4268.929551575455, w0=20.77640246417997, w1=-55.22634653279171\n",
      "Gradient Descent(6791/9999): loss=11872.798346112051, w0=8.709637078626436, w1=-62.65204653279171\n",
      "Gradient Descent(6792/9999): loss=4361.360551999554, w0=8.709637078626436, w1=-62.65204653279171\n",
      "Gradient Descent(6793/9999): loss=4361.360551999554, w0=20.533237078626435, w1=-59.62124653279171\n",
      "Gradient Descent(6794/9999): loss=10334.910845096008, w0=20.533237078626435, w1=-59.62124653279171\n",
      "Gradient Descent(6795/9999): loss=10334.910845096008, w0=20.533237078626435, w1=-59.62124653279171\n",
      "Gradient Descent(6796/9999): loss=10334.910845096008, w0=20.533237078626435, w1=-59.62124653279171\n",
      "Gradient Descent(6797/9999): loss=10334.910845096008, w0=20.533237078626435, w1=-59.62124653279171\n",
      "Gradient Descent(6798/9999): loss=10334.910845096008, w0=20.533237078626435, w1=-59.62124653279171\n",
      "Gradient Descent(6799/9999): loss=10334.910845096008, w0=20.533237078626435, w1=-59.62124653279171\n",
      "Gradient Descent(6800/9999): loss=10334.910845096008, w0=9.471937078626434, w1=-60.02994653279171\n",
      "Gradient Descent(6801/9999): loss=4298.131095841807, w0=-6.335562921373565, w1=-61.21314653279171\n",
      "Gradient Descent(6802/9999): loss=5802.4994844197445, w0=-6.335562921373565, w1=-61.21314653279171\n",
      "Gradient Descent(6803/9999): loss=5802.4994844197445, w0=4.193337078626435, w1=-57.529146532791714\n",
      "Gradient Descent(6804/9999): loss=5057.342244250505, w0=4.193337078626435, w1=-57.529146532791714\n",
      "Gradient Descent(6805/9999): loss=5057.342244250505, w0=4.193337078626435, w1=-57.529146532791714\n",
      "Gradient Descent(6806/9999): loss=5057.342244250505, w0=11.703437078626436, w1=-56.50334653279172\n",
      "Gradient Descent(6807/9999): loss=4428.949825058353, w0=-3.054862921373564, w1=-57.891346532791715\n",
      "Gradient Descent(6808/9999): loss=5802.4994844197445, w0=-3.054862921373564, w1=-57.891346532791715\n",
      "Gradient Descent(6809/9999): loss=5802.4994844197445, w0=-3.054862921373564, w1=-57.891346532791715\n",
      "Gradient Descent(6810/9999): loss=5802.4994844197445, w0=7.411837078626437, w1=-52.38454653279172\n",
      "Gradient Descent(6811/9999): loss=4207.593902907592, w0=7.411837078626437, w1=-52.38454653279172\n",
      "Gradient Descent(6812/9999): loss=4207.593902907592, w0=7.411837078626437, w1=-52.38454653279172\n",
      "Gradient Descent(6813/9999): loss=4207.593902907592, w0=7.411837078626437, w1=-52.38454653279172\n",
      "Gradient Descent(6814/9999): loss=4207.593902907592, w0=7.411837078626437, w1=-52.38454653279172\n",
      "Gradient Descent(6815/9999): loss=4207.593902907592, w0=7.411837078626437, w1=-52.38454653279172\n",
      "Gradient Descent(6816/9999): loss=4207.593902907592, w0=7.411837078626437, w1=-52.38454653279172\n",
      "Gradient Descent(6817/9999): loss=4207.593902907592, w0=7.411837078626437, w1=-52.38454653279172\n",
      "Gradient Descent(6818/9999): loss=4207.593902907592, w0=20.153837078626438, w1=-48.241946532791715\n",
      "Gradient Descent(6819/9999): loss=13197.115123655361, w0=20.153837078626438, w1=-48.241946532791715\n",
      "Gradient Descent(6820/9999): loss=13197.115123655361, w0=11.990037078626438, w1=-53.301846532791714\n",
      "Gradient Descent(6821/9999): loss=4984.628318993617, w0=11.990037078626438, w1=-53.301846532791714\n",
      "Gradient Descent(6822/9999): loss=4984.628318993617, w0=11.990037078626438, w1=-53.301846532791714\n",
      "Gradient Descent(6823/9999): loss=4984.628318993617, w0=20.672337078626438, w1=-46.982346532791716\n",
      "Gradient Descent(6824/9999): loss=13031.92177787454, w0=8.605571693072903, w1=-54.485746532791715\n",
      "Gradient Descent(6825/9999): loss=4562.753026605169, w0=8.605571693072903, w1=-54.485746532791715\n",
      "Gradient Descent(6826/9999): loss=4562.753026605169, w0=8.605571693072903, w1=-54.485746532791715\n",
      "Gradient Descent(6827/9999): loss=4562.753026605169, w0=18.973571693072905, w1=-48.108346532791714\n",
      "Gradient Descent(6828/9999): loss=13196.093370876533, w0=4.887371693072906, w1=-55.72304653279171\n",
      "Gradient Descent(6829/9999): loss=4321.36821528279, w0=4.887371693072906, w1=-55.72304653279171\n",
      "Gradient Descent(6830/9999): loss=4321.36821528279, w0=4.887371693072906, w1=-55.72304653279171\n",
      "Gradient Descent(6831/9999): loss=4321.36821528279, w0=4.887371693072906, w1=-55.72304653279171\n",
      "Gradient Descent(6832/9999): loss=4321.36821528279, w0=4.887371693072906, w1=-55.72304653279171\n",
      "Gradient Descent(6833/9999): loss=4321.36821528279, w0=4.887371693072906, w1=-55.72304653279171\n",
      "Gradient Descent(6834/9999): loss=4321.36821528279, w0=4.887371693072906, w1=-55.72304653279171\n",
      "Gradient Descent(6835/9999): loss=4321.36821528279, w0=4.887371693072906, w1=-55.72304653279171\n",
      "Gradient Descent(6836/9999): loss=4321.36821528279, w0=4.887371693072906, w1=-55.72304653279171\n",
      "Gradient Descent(6837/9999): loss=4321.36821528279, w0=4.887371693072906, w1=-55.72304653279171\n",
      "Gradient Descent(6838/9999): loss=4321.36821528279, w0=4.887371693072906, w1=-55.72304653279171\n",
      "Gradient Descent(6839/9999): loss=4321.36821528279, w0=-4.637628306927095, w1=-58.120546532791714\n",
      "Gradient Descent(6840/9999): loss=5709.28394630843, w0=-4.637628306927095, w1=-58.120546532791714\n",
      "Gradient Descent(6841/9999): loss=5709.28394630843, w0=-4.637628306927095, w1=-58.120546532791714\n",
      "Gradient Descent(6842/9999): loss=5709.28394630843, w0=-4.637628306927095, w1=-58.120546532791714\n",
      "Gradient Descent(6843/9999): loss=5709.28394630843, w0=-4.637628306927095, w1=-58.120546532791714\n",
      "Gradient Descent(6844/9999): loss=5709.28394630843, w0=-4.637628306927095, w1=-58.120546532791714\n",
      "Gradient Descent(6845/9999): loss=5709.28394630843, w0=-4.637628306927095, w1=-58.120546532791714\n",
      "Gradient Descent(6846/9999): loss=5709.28394630843, w0=-4.637628306927095, w1=-58.120546532791714\n",
      "Gradient Descent(6847/9999): loss=5709.28394630843, w0=-4.637628306927095, w1=-58.120546532791714\n",
      "Gradient Descent(6848/9999): loss=5709.28394630843, w0=-4.637628306927095, w1=-58.120546532791714\n",
      "Gradient Descent(6849/9999): loss=5709.28394630843, w0=-4.637628306927095, w1=-58.120546532791714\n",
      "Gradient Descent(6850/9999): loss=5709.28394630843, w0=-4.637628306927095, w1=-58.120546532791714\n",
      "Gradient Descent(6851/9999): loss=5709.28394630843, w0=-4.637628306927095, w1=-58.120546532791714\n",
      "Gradient Descent(6852/9999): loss=5709.28394630843, w0=-4.637628306927095, w1=-58.120546532791714\n",
      "Gradient Descent(6853/9999): loss=5709.28394630843, w0=-4.637628306927095, w1=-58.120546532791714\n",
      "Gradient Descent(6854/9999): loss=5709.28394630843, w0=-4.637628306927095, w1=-58.120546532791714\n",
      "Gradient Descent(6855/9999): loss=5709.28394630843, w0=9.113971693072905, w1=-53.88524653279171\n",
      "Gradient Descent(6856/9999): loss=4430.763211815378, w0=9.113971693072905, w1=-53.88524653279171\n",
      "Gradient Descent(6857/9999): loss=4430.763211815378, w0=9.113971693072905, w1=-53.88524653279171\n",
      "Gradient Descent(6858/9999): loss=4430.763211815378, w0=21.18073707862644, w1=-26.61764653279171\n",
      "Gradient Descent(6859/9999): loss=17119.71504643633, w0=21.18073707862644, w1=-26.61764653279171\n",
      "Gradient Descent(6860/9999): loss=17119.71504643633, w0=21.18073707862644, w1=-26.61764653279171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(6861/9999): loss=17119.71504643633, w0=9.113971693072905, w1=-33.44534653279171\n",
      "Gradient Descent(6862/9999): loss=10108.046850979972, w0=9.113971693072905, w1=-33.44534653279171\n",
      "Gradient Descent(6863/9999): loss=10108.046850979972, w0=9.113971693072905, w1=-33.44534653279171\n",
      "Gradient Descent(6864/9999): loss=10108.046850979972, w0=0.8553716930729056, w1=-36.91324653279171\n",
      "Gradient Descent(6865/9999): loss=4583.273814802175, w0=0.8553716930729056, w1=-36.91324653279171\n",
      "Gradient Descent(6866/9999): loss=4583.273814802175, w0=0.8553716930729056, w1=-36.91324653279171\n",
      "Gradient Descent(6867/9999): loss=4583.273814802175, w0=0.8553716930729056, w1=-36.91324653279171\n",
      "Gradient Descent(6868/9999): loss=4583.273814802175, w0=0.8553716930729056, w1=-36.91324653279171\n",
      "Gradient Descent(6869/9999): loss=4583.273814802175, w0=0.8553716930729056, w1=-36.91324653279171\n",
      "Gradient Descent(6870/9999): loss=4583.273814802175, w0=0.8553716930729056, w1=-36.91324653279171\n",
      "Gradient Descent(6871/9999): loss=4583.273814802175, w0=0.8553716930729056, w1=-36.91324653279171\n",
      "Gradient Descent(6872/9999): loss=4583.273814802175, w0=0.8553716930729056, w1=-36.91324653279171\n",
      "Gradient Descent(6873/9999): loss=4583.273814802175, w0=-10.421428306927094, w1=-38.27594653279171\n",
      "Gradient Descent(6874/9999): loss=5802.4994844197445, w0=-1.0957283069270929, w1=-35.286146532791705\n",
      "Gradient Descent(6875/9999): loss=4486.736040662037, w0=-1.0957283069270929, w1=-35.286146532791705\n",
      "Gradient Descent(6876/9999): loss=4486.736040662037, w0=-1.0957283069270929, w1=-35.286146532791705\n",
      "Gradient Descent(6877/9999): loss=4486.736040662037, w0=-1.0957283069270929, w1=-35.286146532791705\n",
      "Gradient Descent(6878/9999): loss=4486.736040662037, w0=-1.0956582138493502, w1=-35.28614477111114\n",
      "Gradient Descent(6879/9999): loss=4486.816568933615, w0=-1.0956582138493502, w1=-35.28614477111114\n",
      "Gradient Descent(6880/9999): loss=4486.816568933615, w0=-1.0956582138493502, w1=-35.28614477111114\n",
      "Gradient Descent(6881/9999): loss=4486.816568933615, w0=-1.0956582138493502, w1=-35.28614477111114\n",
      "Gradient Descent(6882/9999): loss=4486.816568933615, w0=-1.0956582138493502, w1=-35.28614477111114\n",
      "Gradient Descent(6883/9999): loss=4486.816568933615, w0=8.10314178615065, w1=-29.353944771111138\n",
      "Gradient Descent(6884/9999): loss=15728.131265125325, w0=8.10314178615065, w1=-29.353944771111138\n",
      "Gradient Descent(6885/9999): loss=15728.131265125325, w0=-2.2927582138493516, w1=-38.56354477111114\n",
      "Gradient Descent(6886/9999): loss=4457.485800372602, w0=-2.2927582138493516, w1=-38.56354477111114\n",
      "Gradient Descent(6887/9999): loss=4457.485800372602, w0=-2.2927582138493516, w1=-38.56354477111114\n",
      "Gradient Descent(6888/9999): loss=4457.485800372602, w0=-2.2927582138493516, w1=-38.56354477111114\n",
      "Gradient Descent(6889/9999): loss=4457.485800372602, w0=-10.773858213849111, w1=-42.121644771111036\n",
      "Gradient Descent(6890/9999): loss=5549.792356713482, w0=-10.773858213849111, w1=-42.121644771111036\n",
      "Gradient Descent(6891/9999): loss=5549.792356713482, w0=-10.773858213849111, w1=-42.121644771111036\n",
      "Gradient Descent(6892/9999): loss=5549.792356713482, w0=-10.773858213849111, w1=-42.121644771111036\n",
      "Gradient Descent(6893/9999): loss=5549.792356713482, w0=-10.773858213849111, w1=-42.121644771111036\n",
      "Gradient Descent(6894/9999): loss=5549.792356713482, w0=-10.773858213849111, w1=-42.121644771111036\n",
      "Gradient Descent(6895/9999): loss=5549.792356713482, w0=-10.773858213849111, w1=-42.121644771111036\n",
      "Gradient Descent(6896/9999): loss=5549.792356713482, w0=-10.773858213849111, w1=-42.121644771111036\n",
      "Gradient Descent(6897/9999): loss=5549.792356713482, w0=-10.773858213849111, w1=-42.121644771111036\n",
      "Gradient Descent(6898/9999): loss=5549.792356713482, w0=-10.773858213849111, w1=-42.121644771111036\n",
      "Gradient Descent(6899/9999): loss=5549.792356713482, w0=0.9666417861508894, w1=-41.540244771111034\n",
      "Gradient Descent(6900/9999): loss=6511.79453194228, w0=0.9666417861508894, w1=-41.540244771111034\n",
      "Gradient Descent(6901/9999): loss=6511.79453194228, w0=-7.7323582138491105, w1=-48.00544477111104\n",
      "Gradient Descent(6902/9999): loss=5078.5198463034985, w0=-7.7323582138491105, w1=-48.00544477111104\n",
      "Gradient Descent(6903/9999): loss=5078.5198463034985, w0=-7.7323582138491105, w1=-48.00544477111104\n",
      "Gradient Descent(6904/9999): loss=5078.5198463034985, w0=-7.7323582138491105, w1=-48.00544477111104\n",
      "Gradient Descent(6905/9999): loss=5078.5198463034985, w0=-7.7323582138491105, w1=-48.00544477111104\n",
      "Gradient Descent(6906/9999): loss=5078.5198463034985, w0=-7.7323582138491105, w1=-48.00544477111104\n",
      "Gradient Descent(6907/9999): loss=5078.5198463034985, w0=-7.7323582138491105, w1=-48.00544477111104\n",
      "Gradient Descent(6908/9999): loss=5078.5198463034985, w0=0.6207417861508908, w1=-42.639844771111036\n",
      "Gradient Descent(6909/9999): loss=6642.291505596505, w0=0.6207417861508908, w1=-42.639844771111036\n",
      "Gradient Descent(6910/9999): loss=6642.291505596505, w0=0.620741786187724, w1=-42.63984477106501\n",
      "Gradient Descent(6911/9999): loss=6642.291505661964, w0=0.620741786187724, w1=-42.63984477106501\n",
      "Gradient Descent(6912/9999): loss=6642.291505661964, w0=0.620741786187724, w1=-42.63984477106501\n",
      "Gradient Descent(6913/9999): loss=6642.291505661964, w0=0.620741786187724, w1=-42.63984477106501\n",
      "Gradient Descent(6914/9999): loss=6642.291505661964, w0=-11.44602359936581, w1=-48.92014477106501\n",
      "Gradient Descent(6915/9999): loss=5031.139353892215, w0=-11.44602359936581, w1=-48.92014477106501\n",
      "Gradient Descent(6916/9999): loss=5031.139353892215, w0=-11.44602359936581, w1=-48.92014477106501\n",
      "Gradient Descent(6917/9999): loss=5031.139353892215, w0=-11.44602359936581, w1=-48.92014477106501\n",
      "Gradient Descent(6918/9999): loss=5031.139353892215, w0=-11.44602359936581, w1=-48.92014477106501\n",
      "Gradient Descent(6919/9999): loss=5031.139353892215, w0=-11.44602359936581, w1=-48.92014477106501\n",
      "Gradient Descent(6920/9999): loss=5031.139353892215, w0=-11.44602359936581, w1=-48.92014477106501\n",
      "Gradient Descent(6921/9999): loss=5031.139353892215, w0=-11.44602359936581, w1=-48.92014477106501\n",
      "Gradient Descent(6922/9999): loss=5031.139353892215, w0=-11.44602359936581, w1=-48.92014477106501\n",
      "Gradient Descent(6923/9999): loss=5031.139353892215, w0=-11.44602359936581, w1=-48.92014477106501\n",
      "Gradient Descent(6924/9999): loss=5031.139353892215, w0=-3.1012235993658113, w1=-46.17584477106501\n",
      "Gradient Descent(6925/9999): loss=5654.010361542557, w0=-3.1012235993658113, w1=-46.17584477106501\n",
      "Gradient Descent(6926/9999): loss=5654.010361542557, w0=-3.1012235993658113, w1=-46.17584477106501\n",
      "Gradient Descent(6927/9999): loss=5654.010361542557, w0=-3.1012235993658113, w1=-46.17584477106501\n",
      "Gradient Descent(6928/9999): loss=5654.010361542557, w0=-20.565423599365815, w1=-47.72804477106501\n",
      "Gradient Descent(6929/9999): loss=5802.4994844197445, w0=-20.565423599365815, w1=-47.72804477106501\n",
      "Gradient Descent(6930/9999): loss=5802.4994844197445, w0=-20.565423599365815, w1=-47.72804477106501\n",
      "Gradient Descent(6931/9999): loss=5802.4994844197445, w0=-20.565423599365815, w1=-47.72804477106501\n",
      "Gradient Descent(6932/9999): loss=5802.4994844197445, w0=-20.565423599365815, w1=-47.72804477106501\n",
      "Gradient Descent(6933/9999): loss=5802.4994844197445, w0=-9.127723599365813, w1=-42.10734477106501\n",
      "Gradient Descent(6934/9999): loss=4390.3349239338695, w0=-9.127723599365813, w1=-42.10734477106501\n",
      "Gradient Descent(6935/9999): loss=4390.3349239338695, w0=-9.127723599365813, w1=-42.10734477106501\n",
      "Gradient Descent(6936/9999): loss=4390.3349239338695, w0=2.0970764006341867, w1=-34.50224477106501\n",
      "Gradient Descent(6937/9999): loss=11696.99728028466, w0=-13.525323599365812, w1=-43.78864477106501\n",
      "Gradient Descent(6938/9999): loss=4927.709205697859, w0=-13.525323599365812, w1=-43.78864477106501\n",
      "Gradient Descent(6939/9999): loss=4927.709205697859, w0=-13.525323599365812, w1=-43.78864477106501\n",
      "Gradient Descent(6940/9999): loss=4927.709205697859, w0=-13.525323599365812, w1=-43.78864477106501\n",
      "Gradient Descent(6941/9999): loss=4927.709205697859, w0=-13.525323599365812, w1=-43.78864477106501\n",
      "Gradient Descent(6942/9999): loss=4927.709205697859, w0=-1.4764235993658126, w1=-43.54404477106501\n",
      "Gradient Descent(6943/9999): loss=10150.627554521265, w0=-13.355923599365813, w1=-44.47954477106501\n",
      "Gradient Descent(6944/9999): loss=4634.69535908367, w0=-1.2891582138122786, w1=-29.399344771065003\n",
      "Gradient Descent(6945/9999): loss=15620.651065400216, w0=-13.355923599365813, w1=-38.259544771065\n",
      "Gradient Descent(6946/9999): loss=5154.087534871229, w0=-13.355923599365813, w1=-38.259544771065\n",
      "Gradient Descent(6947/9999): loss=5154.087534871229, w0=-13.355923599365813, w1=-38.259544771065\n",
      "Gradient Descent(6948/9999): loss=5154.087534871229, w0=-13.355923599365813, w1=-38.259544771065\n",
      "Gradient Descent(6949/9999): loss=5154.087534871229, w0=-13.355923599365813, w1=-38.259544771065\n",
      "Gradient Descent(6950/9999): loss=5154.087534871229, w0=-13.355923599365813, w1=-38.259544771065\n",
      "Gradient Descent(6951/9999): loss=5154.087534871229, w0=-13.355923599365813, w1=-38.259544771065\n",
      "Gradient Descent(6952/9999): loss=5154.087534871229, w0=-13.355923599365813, w1=-38.259544771065\n",
      "Gradient Descent(6953/9999): loss=5154.087534871229, w0=-13.355923599365813, w1=-38.259544771065\n",
      "Gradient Descent(6954/9999): loss=5154.087534871229, w0=-20.959423599365813, w1=-42.008144771065005\n",
      "Gradient Descent(6955/9999): loss=5347.404497496924, w0=-8.65322359936581, w1=-38.260944771065006\n",
      "Gradient Descent(6956/9999): loss=6416.373574117466, w0=-8.65322359936581, w1=-38.260944771065006\n",
      "Gradient Descent(6957/9999): loss=6416.373574117466, w0=-8.65322359936581, w1=-38.260944771065006\n",
      "Gradient Descent(6958/9999): loss=6416.373574117466, w0=-8.65322359936581, w1=-38.260944771065006\n",
      "Gradient Descent(6959/9999): loss=6416.373574117466, w0=-8.65322359936581, w1=-38.260944771065006\n",
      "Gradient Descent(6960/9999): loss=6416.373574117466, w0=-8.65322359936581, w1=-38.260944771065006\n",
      "Gradient Descent(6961/9999): loss=6416.373574117466, w0=-25.48332359936581, w1=-45.13024477106501\n",
      "Gradient Descent(6962/9999): loss=5802.4994844197445, w0=-25.48332359936581, w1=-45.13024477106501\n",
      "Gradient Descent(6963/9999): loss=5802.4994844197445, w0=-25.48332359936581, w1=-45.13024477106501\n",
      "Gradient Descent(6964/9999): loss=5802.4994844197445, w0=-25.48332359936581, w1=-45.13024477106501\n",
      "Gradient Descent(6965/9999): loss=5802.4994844197445, w0=-25.48332359936581, w1=-45.13024477106501\n",
      "Gradient Descent(6966/9999): loss=5802.4994844197445, w0=-25.48332359936581, w1=-45.13024477106501\n",
      "Gradient Descent(6967/9999): loss=5802.4994844197445, w0=-12.951223599365811, w1=-43.31244477106501\n",
      "Gradient Descent(6968/9999): loss=7141.887577116251, w0=-12.951223599365811, w1=-43.31244477106501\n",
      "Gradient Descent(6969/9999): loss=7141.887577116251, w0=-12.951223599365811, w1=-43.31244477106501\n",
      "Gradient Descent(6970/9999): loss=7141.887577116251, w0=-12.951223599365811, w1=-43.31244477106501\n",
      "Gradient Descent(6971/9999): loss=7141.887577116251, w0=-12.951223599365811, w1=-43.31244477106501\n",
      "Gradient Descent(6972/9999): loss=7141.887577116251, w0=-12.951223599365811, w1=-43.31244477106501\n",
      "Gradient Descent(6973/9999): loss=7141.887577116251, w0=-12.951223599365811, w1=-43.31244477106501\n",
      "Gradient Descent(6974/9999): loss=7141.887577116251, w0=-12.951223599365811, w1=-43.31244477106501\n",
      "Gradient Descent(6975/9999): loss=7141.887577116251, w0=-12.951223599365811, w1=-43.31244477106501\n",
      "Gradient Descent(6976/9999): loss=7141.887577116251, w0=-12.951223599365811, w1=-43.31244477106501\n",
      "Gradient Descent(6977/9999): loss=7141.887577116251, w0=-12.951223599365811, w1=-43.31244477106501\n",
      "Gradient Descent(6978/9999): loss=7141.887577116251, w0=-24.496023599365813, w1=-50.05994477106501\n",
      "Gradient Descent(6979/9999): loss=5046.749597186133, w0=-24.496023599365813, w1=-50.05994477106501\n",
      "Gradient Descent(6980/9999): loss=5046.749597186133, w0=-24.496023599365813, w1=-50.05994477106501\n",
      "Gradient Descent(6981/9999): loss=5046.749597186133, w0=-13.109223599365826, w1=-49.94854477106501\n",
      "Gradient Descent(6982/9999): loss=7549.966377915751, w0=-28.527023599365826, w1=-53.33744477106501\n",
      "Gradient Descent(6983/9999): loss=5790.966002339786, w0=-28.527023599365826, w1=-53.33744477106501\n",
      "Gradient Descent(6984/9999): loss=5790.966002339786, w0=-15.041923599365825, w1=-49.95644477106501\n",
      "Gradient Descent(6985/9999): loss=5939.855884631203, w0=-21.779123599365825, w1=-54.691344771065005\n",
      "Gradient Descent(6986/9999): loss=5171.388681454905, w0=-21.779123599365825, w1=-54.691344771065005\n",
      "Gradient Descent(6987/9999): loss=5171.388681454905, w0=-21.779123599365825, w1=-54.691344771065005\n",
      "Gradient Descent(6988/9999): loss=5171.388681454905, w0=-21.779123599365825, w1=-54.691344771065005\n",
      "Gradient Descent(6989/9999): loss=5171.388681454905, w0=-21.779123599365825, w1=-54.691344771065005\n",
      "Gradient Descent(6990/9999): loss=5171.388681454905, w0=-21.779123599365825, w1=-54.691344771065005\n",
      "Gradient Descent(6991/9999): loss=5171.388681454905, w0=-21.779123599365825, w1=-54.691344771065005\n",
      "Gradient Descent(6992/9999): loss=5171.388681454905, w0=-21.779123599365825, w1=-54.691344771065005\n",
      "Gradient Descent(6993/9999): loss=5171.388681454905, w0=-21.779123599365825, w1=-54.691344771065005\n",
      "Gradient Descent(6994/9999): loss=5171.388681454905, w0=-10.554323599365825, w1=-47.086244771065004\n",
      "Gradient Descent(6995/9999): loss=5609.425668609089, w0=0.13137640063417777, w1=-41.740344771065004\n",
      "Gradient Descent(6996/9999): loss=14788.04847419274, w0=-11.935388984919356, w1=-51.184544771065006\n",
      "Gradient Descent(6997/9999): loss=4843.078400439611, w0=-11.935388984919356, w1=-51.184544771065006\n",
      "Gradient Descent(6998/9999): loss=4843.078400439611, w0=-11.935388984919356, w1=-51.184544771065006\n",
      "Gradient Descent(6999/9999): loss=4843.078400439611, w0=-21.119188984919354, w1=-51.703344771065005\n",
      "Gradient Descent(7000/9999): loss=5456.925511243784, w0=-21.119188984919354, w1=-51.703344771065005\n",
      "Gradient Descent(7001/9999): loss=5456.925511243784, w0=-11.873088984919354, w1=-45.981944771065\n",
      "Gradient Descent(7002/9999): loss=5477.141344887557, w0=-11.873088984919354, w1=-45.981944771065\n",
      "Gradient Descent(7003/9999): loss=5477.141344887557, w0=0.19367640063418, w1=-31.985044771065002\n",
      "Gradient Descent(7004/9999): loss=16947.046669606127, w0=-8.52962359936582, w1=-37.173844771065006\n",
      "Gradient Descent(7005/9999): loss=10998.424452838051, w0=-20.596388984919354, w1=-43.549444771065005\n",
      "Gradient Descent(7006/9999): loss=4750.866724952337, w0=-20.596388984919354, w1=-43.549444771065005\n",
      "Gradient Descent(7007/9999): loss=4750.866724952337, w0=-20.596388984919354, w1=-43.549444771065005\n",
      "Gradient Descent(7008/9999): loss=4750.866724952337, w0=-8.779588984919354, w1=-40.03964477106501\n",
      "Gradient Descent(7009/9999): loss=12236.721097106594, w0=-8.779588984919354, w1=-40.03964477106501\n",
      "Gradient Descent(7010/9999): loss=12236.721097106594, w0=-20.846354370472888, w1=-44.81364477106501\n",
      "Gradient Descent(7011/9999): loss=5046.836691114479, w0=-20.846354370472888, w1=-44.81364477106501\n",
      "Gradient Descent(7012/9999): loss=5046.836691114479, w0=-20.846354370472888, w1=-44.81364477106501\n",
      "Gradient Descent(7013/9999): loss=5046.836691114479, w0=-20.846354370472888, w1=-44.81364477106501\n",
      "Gradient Descent(7014/9999): loss=5046.836691114479, w0=-20.846354370472888, w1=-44.81364477106501\n",
      "Gradient Descent(7015/9999): loss=5046.836691114479, w0=-20.846354370472888, w1=-44.81364477106501\n",
      "Gradient Descent(7016/9999): loss=5046.836691114479, w0=-20.846354370472888, w1=-44.81364477106501\n",
      "Gradient Descent(7017/9999): loss=5046.836691114479, w0=-20.846354370472888, w1=-44.81364477106501\n",
      "Gradient Descent(7018/9999): loss=5046.836691114479, w0=-31.043654370472886, w1=-45.87804477106501\n",
      "Gradient Descent(7019/9999): loss=5802.4994844197445, w0=-31.043654370472886, w1=-45.87804477106501\n",
      "Gradient Descent(7020/9999): loss=5802.4994844197445, w0=-22.667354370472886, w1=-43.813344771065005\n",
      "Gradient Descent(7021/9999): loss=4604.991286169291, w0=-22.667354370472886, w1=-43.813344771065005\n",
      "Gradient Descent(7022/9999): loss=4604.991286169291, w0=-22.667354370472886, w1=-43.813344771065005\n",
      "Gradient Descent(7023/9999): loss=4604.991286169291, w0=-22.667354370472886, w1=-43.813344771065005\n",
      "Gradient Descent(7024/9999): loss=4604.991286169291, w0=-22.667354370472886, w1=-43.813344771065005\n",
      "Gradient Descent(7025/9999): loss=4604.991286169291, w0=-22.667354370472886, w1=-43.813344771065005\n",
      "Gradient Descent(7026/9999): loss=4604.991286169291, w0=-22.667354370472886, w1=-43.813344771065005\n",
      "Gradient Descent(7027/9999): loss=4604.991286169291, w0=-22.667354370472886, w1=-43.813344771065005\n",
      "Gradient Descent(7028/9999): loss=4604.991286169291, w0=-22.667354370472886, w1=-43.813344771065005\n",
      "Gradient Descent(7029/9999): loss=4604.991286169291, w0=-22.667354370472886, w1=-43.813344771065005\n",
      "Gradient Descent(7030/9999): loss=4604.991286169291, w0=-9.022054370472885, w1=-40.106844771065006\n",
      "Gradient Descent(7031/9999): loss=11509.469417476586, w0=-21.088819756026417, w1=-45.71244477106501\n",
      "Gradient Descent(7032/9999): loss=5802.4994844197445, w0=-21.088819756026417, w1=-45.71244477106501\n",
      "Gradient Descent(7033/9999): loss=5802.4994844197445, w0=-21.088819756026417, w1=-45.71244477106501\n",
      "Gradient Descent(7034/9999): loss=5802.4994844197445, w0=-9.593819756026416, w1=-39.673344771065004\n",
      "Gradient Descent(7035/9999): loss=4608.529783624841, w0=-9.593819756026416, w1=-39.673344771065004\n",
      "Gradient Descent(7036/9999): loss=4608.529783624841, w0=-9.593819756026416, w1=-39.673344771065004\n",
      "Gradient Descent(7037/9999): loss=4608.529783624841, w0=-9.593819756026416, w1=-39.673344771065004\n",
      "Gradient Descent(7038/9999): loss=4608.529783624841, w0=-9.593819756026416, w1=-39.673344771065004\n",
      "Gradient Descent(7039/9999): loss=4608.529783624841, w0=-9.593819756026416, w1=-39.673344771065004\n",
      "Gradient Descent(7040/9999): loss=4608.529783624841, w0=-26.630019756026417, w1=-47.61284477106501\n",
      "Gradient Descent(7041/9999): loss=5802.4994844197445, w0=-26.630019756026417, w1=-47.61284477106501\n",
      "Gradient Descent(7042/9999): loss=5802.4994844197445, w0=-14.321019756026416, w1=-47.07204477106501\n",
      "Gradient Descent(7043/9999): loss=4582.2480634176945, w0=-4.616819756026416, w1=-41.24844477106501\n",
      "Gradient Descent(7044/9999): loss=12206.067466112632, w0=-4.616819756026416, w1=-41.24844477106501\n",
      "Gradient Descent(7045/9999): loss=12206.067466112632, w0=-4.616819756026416, w1=-41.24844477106501\n",
      "Gradient Descent(7046/9999): loss=12206.067466112632, w0=-22.29871975602642, w1=-49.23904477106501\n",
      "Gradient Descent(7047/9999): loss=5237.125812376867, w0=-22.29871975602642, w1=-49.23904477106501\n",
      "Gradient Descent(7048/9999): loss=5237.125812376867, w0=-22.29871975602642, w1=-49.23904477106501\n",
      "Gradient Descent(7049/9999): loss=5237.125812376867, w0=-22.29871975602642, w1=-49.23904477106501\n",
      "Gradient Descent(7050/9999): loss=5237.125812376867, w0=-8.833019756026417, w1=-42.13614477106501\n",
      "Gradient Descent(7051/9999): loss=11256.32120784152, w0=-8.833019756026417, w1=-42.13614477106501\n",
      "Gradient Descent(7052/9999): loss=11256.32120784152, w0=-8.833019756026417, w1=-42.13614477106501\n",
      "Gradient Descent(7053/9999): loss=11256.32120784152, w0=-14.757619756026418, w1=-50.500744771065015\n",
      "Gradient Descent(7054/9999): loss=4718.780163711019, w0=-3.7644197560264168, w1=-46.66884477106502\n",
      "Gradient Descent(7055/9999): loss=12854.903446328683, w0=-3.7644197560264168, w1=-46.66884477106502\n",
      "Gradient Descent(7056/9999): loss=12854.903446328683, w0=-3.7644197560264168, w1=-46.66884477106502\n",
      "Gradient Descent(7057/9999): loss=12854.903446328683, w0=-12.989519756026418, w1=-47.21644477106502\n",
      "Gradient Descent(7058/9999): loss=5744.3863403110345, w0=-12.989519756026418, w1=-47.21644477106502\n",
      "Gradient Descent(7059/9999): loss=5744.3863403110345, w0=-12.989519756026418, w1=-47.21644477106502\n",
      "Gradient Descent(7060/9999): loss=5744.3863403110345, w0=-25.27671975602642, w1=-49.72414477106502\n",
      "Gradient Descent(7061/9999): loss=5779.473613489904, w0=-13.892619756026418, w1=-48.67594477106502\n",
      "Gradient Descent(7062/9999): loss=4771.435187905438, w0=-13.892619756026418, w1=-48.67594477106502\n",
      "Gradient Descent(7063/9999): loss=4771.435187905438, w0=-22.509519756026418, w1=-49.67204477106502\n",
      "Gradient Descent(7064/9999): loss=5790.986549066892, w0=-22.509519756026418, w1=-49.67204477106502\n",
      "Gradient Descent(7065/9999): loss=5790.986549066892, w0=-8.627319756026417, w1=-49.38464477106502\n",
      "Gradient Descent(7066/9999): loss=4799.373330328451, w0=-8.627319756026417, w1=-49.38464477106502\n",
      "Gradient Descent(7067/9999): loss=4799.373330328451, w0=-8.627319756026417, w1=-49.38464477106502\n",
      "Gradient Descent(7068/9999): loss=4799.373330328451, w0=-19.901219756026414, w1=-52.50954477106502\n",
      "Gradient Descent(7069/9999): loss=5744.237416417848, w0=-19.901219756026414, w1=-52.50954477106502\n",
      "Gradient Descent(7070/9999): loss=5744.237416417848, w0=-19.901219756026414, w1=-52.50954477106502\n",
      "Gradient Descent(7071/9999): loss=5744.237416417848, w0=-19.901219756026414, w1=-52.50954477106502\n",
      "Gradient Descent(7072/9999): loss=5744.237416417848, w0=-19.901219756026414, w1=-52.50954477106502\n",
      "Gradient Descent(7073/9999): loss=5744.237416417848, w0=-19.901219756026414, w1=-52.50954477106502\n",
      "Gradient Descent(7074/9999): loss=5744.237416417848, w0=-19.901219756026414, w1=-52.50954477106502\n",
      "Gradient Descent(7075/9999): loss=5744.237416417848, w0=-19.901219756026414, w1=-52.50954477106502\n",
      "Gradient Descent(7076/9999): loss=5744.237416417848, w0=-10.458619756026414, w1=-49.80674477106502\n",
      "Gradient Descent(7077/9999): loss=4627.012527703828, w0=-17.6712197560263, w1=-53.90054477106496\n",
      "Gradient Descent(7078/9999): loss=5698.8852987210075, w0=-17.6712197560263, w1=-53.90054477106496\n",
      "Gradient Descent(7079/9999): loss=5698.8852987210075, w0=-17.6712197560263, w1=-53.90054477106496\n",
      "Gradient Descent(7080/9999): loss=5698.8852987210075, w0=-17.6712197560263, w1=-53.90054477106496\n",
      "Gradient Descent(7081/9999): loss=5698.8852987210075, w0=-8.9523197560263, w1=-53.85454477106496\n",
      "Gradient Descent(7082/9999): loss=4742.678982104522, w0=-8.9523197560263, w1=-53.85454477106496\n",
      "Gradient Descent(7083/9999): loss=4742.678982104522, w0=-8.9523197560263, w1=-53.85454477106496\n",
      "Gradient Descent(7084/9999): loss=4742.678982104522, w0=-8.9523197560263, w1=-53.85454477106496\n",
      "Gradient Descent(7085/9999): loss=4742.678982104522, w0=-8.9523197560263, w1=-53.85454477106496\n",
      "Gradient Descent(7086/9999): loss=4742.678982104522, w0=-8.9523197560263, w1=-53.85454477106496\n",
      "Gradient Descent(7087/9999): loss=4742.678982104522, w0=-8.9523197560263, w1=-53.85454477106496\n",
      "Gradient Descent(7088/9999): loss=4742.678982104522, w0=-8.9523197560263, w1=-53.85454477106496\n",
      "Gradient Descent(7089/9999): loss=4742.678982104522, w0=-8.9523197560263, w1=-53.85454477106496\n",
      "Gradient Descent(7090/9999): loss=4742.678982104522, w0=3.114445629527234, w1=-48.57864477106496\n",
      "Gradient Descent(7091/9999): loss=10131.428285721893, w0=-4.267154370472767, w1=-52.85154477106496\n",
      "Gradient Descent(7092/9999): loss=5117.813266268773, w0=-4.267154370472767, w1=-52.85154477106496\n",
      "Gradient Descent(7093/9999): loss=5117.813266268773, w0=-4.267154370472767, w1=-52.85154477106496\n",
      "Gradient Descent(7094/9999): loss=5117.813266268773, w0=-4.267154370472767, w1=-52.85154477106496\n",
      "Gradient Descent(7095/9999): loss=5117.813266268773, w0=-20.547054370472768, w1=-54.43604477106496\n",
      "Gradient Descent(7096/9999): loss=5767.960678024983, w0=-20.547054370472768, w1=-54.43604477106496\n",
      "Gradient Descent(7097/9999): loss=5767.960678024983, w0=-20.547054370472768, w1=-54.43604477106496\n",
      "Gradient Descent(7098/9999): loss=5767.960678024983, w0=-8.480288984919234, w1=-46.10514477106496\n",
      "Gradient Descent(7099/9999): loss=7100.80053172593, w0=-19.318288984919235, w1=-50.34324477106496\n",
      "Gradient Descent(7100/9999): loss=5159.198925733293, w0=-19.318288984919235, w1=-50.34324477106496\n",
      "Gradient Descent(7101/9999): loss=5159.198925733293, w0=-19.318288984919235, w1=-50.34324477106496\n",
      "Gradient Descent(7102/9999): loss=5159.198925733293, w0=-19.318288984919235, w1=-50.34324477106496\n",
      "Gradient Descent(7103/9999): loss=5159.198925733293, w0=-5.566688984919235, w1=-46.10794477106496\n",
      "Gradient Descent(7104/9999): loss=6816.034210621486, w0=-5.566688984919235, w1=-46.10794477106496\n",
      "Gradient Descent(7105/9999): loss=6816.034210621486, w0=-5.566688984919235, w1=-46.10794477106496\n",
      "Gradient Descent(7106/9999): loss=6816.034210621486, w0=-5.566688984919235, w1=-46.10794477106496\n",
      "Gradient Descent(7107/9999): loss=6816.034210621486, w0=-5.566688984919235, w1=-46.10794477106496\n",
      "Gradient Descent(7108/9999): loss=6816.034210621486, w0=-5.566688984919235, w1=-46.10794477106496\n",
      "Gradient Descent(7109/9999): loss=6816.034210621486, w0=-5.566688984919235, w1=-46.10794477106496\n",
      "Gradient Descent(7110/9999): loss=6816.034210621486, w0=-5.566688984919235, w1=-46.10794477106496\n",
      "Gradient Descent(7111/9999): loss=6816.034210621486, w0=-5.566688984919235, w1=-46.10794477106496\n",
      "Gradient Descent(7112/9999): loss=6816.034210621486, w0=-5.566688984919235, w1=-46.10794477106496\n",
      "Gradient Descent(7113/9999): loss=6816.034210621486, w0=-5.566688984919235, w1=-46.10794477106496\n",
      "Gradient Descent(7114/9999): loss=6816.034210621486, w0=-5.566688984919235, w1=-46.10794477106496\n",
      "Gradient Descent(7115/9999): loss=6816.034210621486, w0=-5.566688984919235, w1=-46.10794477106496\n",
      "Gradient Descent(7116/9999): loss=6816.034210621486, w0=-5.566688984919235, w1=-46.10794477106496\n",
      "Gradient Descent(7117/9999): loss=6816.034210621486, w0=-5.566688984919235, w1=-46.10794477106496\n",
      "Gradient Descent(7118/9999): loss=6816.034210621486, w0=-5.566688984919235, w1=-46.10794477106496\n",
      "Gradient Descent(7119/9999): loss=6816.034210621486, w0=-17.63345437047277, w1=-51.921044771064956\n",
      "Gradient Descent(7120/9999): loss=5790.986548954825, w0=-17.63345437047277, w1=-51.921044771064956\n",
      "Gradient Descent(7121/9999): loss=5790.986548954825, w0=-5.566688984919235, w1=-41.880144771064955\n",
      "Gradient Descent(7122/9999): loss=4669.4850097743565, w0=-32.236988984919236, w1=-48.39864477106496\n",
      "Gradient Descent(7123/9999): loss=5802.4994844197445, w0=-32.236988984919236, w1=-48.39864477106496\n",
      "Gradient Descent(7124/9999): loss=5802.4994844197445, w0=-20.170223599365702, w1=-41.28434477106496\n",
      "Gradient Descent(7125/9999): loss=5802.4994844197445, w0=-20.170223599365702, w1=-41.28434477106496\n",
      "Gradient Descent(7126/9999): loss=5802.4994844197445, w0=-10.2220235993657, w1=-36.46604477106496\n",
      "Gradient Descent(7127/9999): loss=4822.386330564592, w0=-10.2220235993657, w1=-36.46604477106496\n",
      "Gradient Descent(7128/9999): loss=4822.386330564592, w0=-10.2220235993657, w1=-36.46604477106496\n",
      "Gradient Descent(7129/9999): loss=4822.386330564592, w0=-26.210823599365703, w1=-41.77624477106496\n",
      "Gradient Descent(7130/9999): loss=5802.4994844197445, w0=-26.210823599365703, w1=-41.77624477106496\n",
      "Gradient Descent(7131/9999): loss=5802.4994844197445, w0=-14.578323599365703, w1=-37.942244771064956\n",
      "Gradient Descent(7132/9999): loss=5795.165830641593, w0=-3.6242235993657026, w1=-37.010044771064955\n",
      "Gradient Descent(7133/9999): loss=7152.190665997937, w0=-3.6242235993657026, w1=-37.010044771064955\n",
      "Gradient Descent(7134/9999): loss=7152.190665997937, w0=-3.6242235993657026, w1=-37.010044771064955\n",
      "Gradient Descent(7135/9999): loss=7152.190665997937, w0=-17.742223599365705, w1=-43.26974477106496\n",
      "Gradient Descent(7136/9999): loss=5802.4994844197445, w0=-7.833623599365705, w1=-39.140644771064956\n",
      "Gradient Descent(7137/9999): loss=7406.3546479531615, w0=-7.833623599365705, w1=-39.140644771064956\n",
      "Gradient Descent(7138/9999): loss=7406.3546479531615, w0=-7.833623599365705, w1=-39.140644771064956\n",
      "Gradient Descent(7139/9999): loss=7406.3546479531615, w0=-7.833623599365705, w1=-39.140644771064956\n",
      "Gradient Descent(7140/9999): loss=7406.3546479531615, w0=-7.833623599365705, w1=-39.140644771064956\n",
      "Gradient Descent(7141/9999): loss=7406.3546479531615, w0=-7.833623599365705, w1=-39.140644771064956\n",
      "Gradient Descent(7142/9999): loss=7406.3546479531615, w0=-17.138523599365705, w1=-41.239944771064955\n",
      "Gradient Descent(7143/9999): loss=5802.4994844197445, w0=-5.071758213812171, w1=-30.916344771064956\n",
      "Gradient Descent(7144/9999): loss=5457.860527053217, w0=-13.398258213812172, w1=-32.76254477106496\n",
      "Gradient Descent(7145/9999): loss=5802.4994844197445, w0=-13.398258213812172, w1=-32.76254477106496\n",
      "Gradient Descent(7146/9999): loss=5802.4994844197445, w0=-13.398258213812172, w1=-32.76254477106496\n",
      "Gradient Descent(7147/9999): loss=5802.4994844197445, w0=0.5639417861878311, w1=-32.41894477106496\n",
      "Gradient Descent(7148/9999): loss=5042.498059028949, w0=0.5639417861878311, w1=-32.41894477106496\n",
      "Gradient Descent(7149/9999): loss=5042.498059028949, w0=0.5639417861878311, w1=-32.41894477106496\n",
      "Gradient Descent(7150/9999): loss=5042.498059028949, w0=0.5639417861878311, w1=-32.41894477106496\n",
      "Gradient Descent(7151/9999): loss=5042.498059028949, w0=0.5639417861878311, w1=-32.41894477106496\n",
      "Gradient Descent(7152/9999): loss=5042.498059028949, w0=-16.900258213812172, w1=-33.97114477106496\n",
      "Gradient Descent(7153/9999): loss=5802.4994844197445, w0=-16.900258213812172, w1=-33.97114477106496\n",
      "Gradient Descent(7154/9999): loss=5802.4994844197445, w0=-16.900258213812172, w1=-33.97114477106496\n",
      "Gradient Descent(7155/9999): loss=5802.4994844197445, w0=-16.900258213812172, w1=-33.97114477106496\n",
      "Gradient Descent(7156/9999): loss=5802.4994844197445, w0=-16.900258213812172, w1=-33.97114477106496\n",
      "Gradient Descent(7157/9999): loss=5802.4994844197445, w0=-16.900258213812172, w1=-33.97114477106496\n",
      "Gradient Descent(7158/9999): loss=5802.4994844197445, w0=-16.900258213812172, w1=-33.97114477106496\n",
      "Gradient Descent(7159/9999): loss=5802.4994844197445, w0=-16.900258213812172, w1=-33.97114477106496\n",
      "Gradient Descent(7160/9999): loss=5802.4994844197445, w0=-6.892758213812172, w1=-33.13864477106495\n",
      "Gradient Descent(7161/9999): loss=4780.905061402855, w0=-6.892758213812172, w1=-33.13864477106495\n",
      "Gradient Descent(7162/9999): loss=4780.905061402855, w0=-6.892758213812172, w1=-33.13864477106495\n",
      "Gradient Descent(7163/9999): loss=4780.905061402855, w0=-6.892758213812172, w1=-33.13864477106495\n",
      "Gradient Descent(7164/9999): loss=4780.905061402855, w0=-26.395158213812174, w1=-36.50764477106495\n",
      "Gradient Descent(7165/9999): loss=5802.4994844197445, w0=-26.395158213812174, w1=-36.50764477106495\n",
      "Gradient Descent(7166/9999): loss=5802.4994844197445, w0=-26.395158213812174, w1=-36.50764477106495\n",
      "Gradient Descent(7167/9999): loss=5802.4994844197445, w0=-26.395158213812174, w1=-36.50764477106495\n",
      "Gradient Descent(7168/9999): loss=5802.4994844197445, w0=-26.395158213812174, w1=-36.50764477106495\n",
      "Gradient Descent(7169/9999): loss=5802.4994844197445, w0=-26.395158213812174, w1=-36.50764477106495\n",
      "Gradient Descent(7170/9999): loss=5802.4994844197445, w0=-26.395158213812174, w1=-36.50764477106495\n",
      "Gradient Descent(7171/9999): loss=5802.4994844197445, w0=-18.018858213812173, w1=-34.44294477106495\n",
      "Gradient Descent(7172/9999): loss=5802.4994844197445, w0=-18.018858213812173, w1=-34.44294477106495\n",
      "Gradient Descent(7173/9999): loss=5802.4994844197445, w0=-18.018858213812173, w1=-34.44294477106495\n",
      "Gradient Descent(7174/9999): loss=5802.4994844197445, w0=-18.018858213812173, w1=-34.44294477106495\n",
      "Gradient Descent(7175/9999): loss=5802.4994844197445, w0=-18.018858213812173, w1=-34.44294477106495\n",
      "Gradient Descent(7176/9999): loss=5802.4994844197445, w0=-7.434558213812174, w1=-33.55074477106495\n",
      "Gradient Descent(7177/9999): loss=4945.100657589218, w0=-7.434558213812174, w1=-33.55074477106495\n",
      "Gradient Descent(7178/9999): loss=4945.100657589218, w0=-7.434558213812174, w1=-33.55074477106495\n",
      "Gradient Descent(7179/9999): loss=4945.100657589218, w0=0.9185417861878271, w1=-28.185144771064948\n",
      "Gradient Descent(7180/9999): loss=14430.683528776997, w0=-8.400158213812174, w1=-32.74344477106495\n",
      "Gradient Descent(7181/9999): loss=5840.920512477397, w0=0.8459417861878258, w1=-27.02204477106495\n",
      "Gradient Descent(7182/9999): loss=14956.835703888526, w0=-8.177658213812174, w1=-31.650844771064953\n",
      "Gradient Descent(7183/9999): loss=5055.650148900072, w0=1.010041786187827, w1=-27.776444771064952\n",
      "Gradient Descent(7184/9999): loss=12397.414861820862, w0=-12.171758213812172, w1=-28.98434477106495\n",
      "Gradient Descent(7185/9999): loss=5037.841162997621, w0=-0.3549582138121714, w1=-25.47454477106495\n",
      "Gradient Descent(7186/9999): loss=12673.80914829502, w0=-0.3549582138121714, w1=-25.47454477106495\n",
      "Gradient Descent(7187/9999): loss=12673.80914829502, w0=-0.3549582138121714, w1=-25.47454477106495\n",
      "Gradient Descent(7188/9999): loss=12673.80914829502, w0=-12.421723599365706, w1=-32.62324477106495\n",
      "Gradient Descent(7189/9999): loss=4701.931039977735, w0=-12.421723599365706, w1=-32.62324477106495\n",
      "Gradient Descent(7190/9999): loss=4701.931039977735, w0=-12.421723599365706, w1=-32.62324477106495\n",
      "Gradient Descent(7191/9999): loss=4701.931039977735, w0=-12.421723599365706, w1=-32.62324477106495\n",
      "Gradient Descent(7192/9999): loss=4701.931039977735, w0=-12.421723599365706, w1=-32.62324477106495\n",
      "Gradient Descent(7193/9999): loss=4701.931039977735, w0=-12.421723599365706, w1=-32.62324477106495\n",
      "Gradient Descent(7194/9999): loss=4701.931039977735, w0=-12.421723599365706, w1=-32.62324477106495\n",
      "Gradient Descent(7195/9999): loss=4701.931039977735, w0=-12.421723599365706, w1=-32.62324477106495\n",
      "Gradient Descent(7196/9999): loss=4701.931039977735, w0=-12.421723599365706, w1=-32.62324477106495\n",
      "Gradient Descent(7197/9999): loss=4701.931039977735, w0=-12.421723599365706, w1=-32.62324477106495\n",
      "Gradient Descent(7198/9999): loss=4701.931039977735, w0=-0.8677235993657035, w1=-28.681544771064946\n",
      "Gradient Descent(7199/9999): loss=15725.925166506768, w0=-6.822423599365703, w1=-35.562644771064946\n",
      "Gradient Descent(7200/9999): loss=5287.7318067130545, w0=-6.822423599365703, w1=-35.562644771064946\n",
      "Gradient Descent(7201/9999): loss=5287.7318067130545, w0=-16.127323599365702, w1=-37.661944771064945\n",
      "Gradient Descent(7202/9999): loss=5802.4994844197445, w0=-16.127323599365702, w1=-37.661944771064945\n",
      "Gradient Descent(7203/9999): loss=5802.4994844197445, w0=-16.127323599365702, w1=-37.661944771064945\n",
      "Gradient Descent(7204/9999): loss=5802.4994844197445, w0=2.7636764006342993, w1=-29.478744771064946\n",
      "Gradient Descent(7205/9999): loss=5585.296219562559, w0=-4.421523599365702, w1=-31.791844771064945\n",
      "Gradient Descent(7206/9999): loss=5802.4994844197445, w0=-4.421523599365702, w1=-31.791844771064945\n",
      "Gradient Descent(7207/9999): loss=5802.4994844197445, w0=-4.421523599365702, w1=-31.791844771064945\n",
      "Gradient Descent(7208/9999): loss=5802.4994844197445, w0=-4.421523599365702, w1=-31.791844771064945\n",
      "Gradient Descent(7209/9999): loss=5802.4994844197445, w0=-4.421523599365702, w1=-31.791844771064945\n",
      "Gradient Descent(7210/9999): loss=5802.4994844197445, w0=-4.421523599365702, w1=-31.791844771064945\n",
      "Gradient Descent(7211/9999): loss=5802.4994844197445, w0=-4.421523599365702, w1=-31.791844771064945\n",
      "Gradient Descent(7212/9999): loss=5802.4994844197445, w0=-4.421523599365702, w1=-31.791844771064945\n",
      "Gradient Descent(7213/9999): loss=5802.4994844197445, w0=-4.421523599365702, w1=-31.791844771064945\n",
      "Gradient Descent(7214/9999): loss=5802.4994844197445, w0=-4.421523599365702, w1=-31.791844771064945\n",
      "Gradient Descent(7215/9999): loss=5802.4994844197445, w0=4.4581764006343, w1=-30.515444771064946\n",
      "Gradient Descent(7216/9999): loss=4567.4825532803625, w0=-7.608588984919234, w1=-39.21704477106495\n",
      "Gradient Descent(7217/9999): loss=5802.4994844197445, w0=-0.43748898491923427, w1=-35.86954477106495\n",
      "Gradient Descent(7218/9999): loss=5636.940370385362, w0=-0.43748898491923427, w1=-35.86954477106495\n",
      "Gradient Descent(7219/9999): loss=5636.940370385362, w0=-0.43748898491923427, w1=-35.86954477106495\n",
      "Gradient Descent(7220/9999): loss=5636.940370385362, w0=-0.43748898491923427, w1=-35.86954477106495\n",
      "Gradient Descent(7221/9999): loss=5636.940370385362, w0=-0.43748898491923427, w1=-35.86954477106495\n",
      "Gradient Descent(7222/9999): loss=5636.940370385362, w0=-0.43748898491923427, w1=-35.86954477106495\n",
      "Gradient Descent(7223/9999): loss=5636.940370385362, w0=14.111111015080766, w1=-34.325744771064954\n",
      "Gradient Descent(7224/9999): loss=8434.347139591013, w0=14.111111015080766, w1=-34.325744771064954\n",
      "Gradient Descent(7225/9999): loss=8434.347139591013, w0=14.111111015080766, w1=-34.325744771064954\n",
      "Gradient Descent(7226/9999): loss=8434.347139591013, w0=14.111111015080766, w1=-34.325744771064954\n",
      "Gradient Descent(7227/9999): loss=8434.347139591013, w0=2.044345629527232, w1=-41.351044771064956\n",
      "Gradient Descent(7228/9999): loss=4728.754810763568, w0=14.552445629527233, w1=-37.17344477106496\n",
      "Gradient Descent(7229/9999): loss=12998.723535026338, w0=7.553945629527233, w1=-40.902144771064954\n",
      "Gradient Descent(7230/9999): loss=4334.079093415299, w0=7.553945629527233, w1=-40.902144771064954\n",
      "Gradient Descent(7231/9999): loss=4334.079093415299, w0=7.553945629527233, w1=-40.902144771064954\n",
      "Gradient Descent(7232/9999): loss=4334.079093415299, w0=7.553945629527233, w1=-40.902144771064954\n",
      "Gradient Descent(7233/9999): loss=4334.079093415299, w0=14.812245629527233, w1=-36.64784477106495\n",
      "Gradient Descent(7234/9999): loss=12575.962280849268, w0=2.7454802439736987, w1=-44.456944771064954\n",
      "Gradient Descent(7235/9999): loss=4511.024756535856, w0=2.7454802439736987, w1=-44.456944771064954\n",
      "Gradient Descent(7236/9999): loss=4511.024756535856, w0=2.7454802439736987, w1=-44.456944771064954\n",
      "Gradient Descent(7237/9999): loss=4511.024756535856, w0=2.7454802439736987, w1=-44.456944771064954\n",
      "Gradient Descent(7238/9999): loss=4511.024756535856, w0=2.7454802439736987, w1=-44.456944771064954\n",
      "Gradient Descent(7239/9999): loss=4511.024756535856, w0=2.7454802439736987, w1=-44.456944771064954\n",
      "Gradient Descent(7240/9999): loss=4511.024756535856, w0=2.7454802439736987, w1=-44.456944771064954\n",
      "Gradient Descent(7241/9999): loss=4511.024756535856, w0=13.303480243973699, w1=-41.14624477106496\n",
      "Gradient Descent(7242/9999): loss=10151.86947325475, w0=13.303480243973699, w1=-41.14624477106496\n",
      "Gradient Descent(7243/9999): loss=10151.86947325475, w0=13.303480243973699, w1=-41.14624477106496\n",
      "Gradient Descent(7244/9999): loss=10151.86947325475, w0=13.303480243973699, w1=-41.14624477106496\n",
      "Gradient Descent(7245/9999): loss=10151.86947325475, w0=13.303480243973699, w1=-41.14624477106496\n",
      "Gradient Descent(7246/9999): loss=10151.86947325475, w0=1.2367148584201644, w1=-49.97564477106496\n",
      "Gradient Descent(7247/9999): loss=4541.52631231855, w0=1.2367148584201644, w1=-49.97564477106496\n",
      "Gradient Descent(7248/9999): loss=4541.52631231855, w0=14.781714858420164, w1=-47.12634477106496\n",
      "Gradient Descent(7249/9999): loss=9379.975399470513, w0=14.781714858420164, w1=-47.12634477106496\n",
      "Gradient Descent(7250/9999): loss=9379.975399470513, w0=14.781714858420164, w1=-47.12634477106496\n",
      "Gradient Descent(7251/9999): loss=9379.975399470513, w0=5.063914858420164, w1=-51.50564477106496\n",
      "Gradient Descent(7252/9999): loss=5284.417400144532, w0=-9.137785141579837, w1=-52.29164477106496\n",
      "Gradient Descent(7253/9999): loss=5802.4994844197445, w0=1.5917148584201648, w1=-50.23894477106496\n",
      "Gradient Descent(7254/9999): loss=5652.831323375582, w0=1.5917148584201648, w1=-50.23894477106496\n",
      "Gradient Descent(7255/9999): loss=5652.831323375582, w0=12.978514858420166, w1=-50.127544771064954\n",
      "Gradient Descent(7256/9999): loss=4630.654350346878, w0=12.978514858420166, w1=-50.127544771064954\n",
      "Gradient Descent(7257/9999): loss=4630.654350346878, w0=-3.0102851415798355, w1=-55.437744771064956\n",
      "Gradient Descent(7258/9999): loss=5802.4994844197445, w0=7.256214858420165, w1=-54.55234477106496\n",
      "Gradient Descent(7259/9999): loss=4745.560126956273, w0=7.256214858420165, w1=-54.55234477106496\n",
      "Gradient Descent(7260/9999): loss=4745.560126956273, w0=7.256214858420165, w1=-54.55234477106496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(7261/9999): loss=4745.560126956273, w0=14.931014858420166, w1=-51.74884477106496\n",
      "Gradient Descent(7262/9999): loss=5627.968544722251, w0=14.931014858420166, w1=-51.74884477106496\n",
      "Gradient Descent(7263/9999): loss=5627.968544722251, w0=14.931014858420166, w1=-51.74884477106496\n",
      "Gradient Descent(7264/9999): loss=5627.968544722251, w0=14.931014858420166, w1=-51.74884477106496\n",
      "Gradient Descent(7265/9999): loss=5627.968544722251, w0=14.931014858420166, w1=-51.74884477106496\n",
      "Gradient Descent(7266/9999): loss=5627.968544722251, w0=14.931014858420166, w1=-51.74884477106496\n",
      "Gradient Descent(7267/9999): loss=5627.968544722251, w0=14.931014858420166, w1=-51.74884477106496\n",
      "Gradient Descent(7268/9999): loss=5627.968544722251, w0=14.931014858420166, w1=-51.74884477106496\n",
      "Gradient Descent(7269/9999): loss=5627.968544722251, w0=14.931014858420166, w1=-51.74884477106496\n",
      "Gradient Descent(7270/9999): loss=5627.968544722251, w0=-11.869485141579833, w1=-62.74434477106496\n",
      "Gradient Descent(7271/9999): loss=5802.4994844197445, w0=0.19728024397370092, w1=-51.70714477106496\n",
      "Gradient Descent(7272/9999): loss=4547.673857336244, w0=0.19728024397370092, w1=-51.70714477106496\n",
      "Gradient Descent(7273/9999): loss=4547.673857336244, w0=0.19728024397370092, w1=-51.70714477106496\n",
      "Gradient Descent(7274/9999): loss=4547.673857336244, w0=15.043080243973701, w1=-49.36424477106496\n",
      "Gradient Descent(7275/9999): loss=12129.163086169992, w0=3.498280243973701, w1=-56.11174477106496\n",
      "Gradient Descent(7276/9999): loss=4344.931800097464, w0=3.498280243973701, w1=-56.11174477106496\n",
      "Gradient Descent(7277/9999): loss=4344.931800097464, w0=-7.5630197560263, w1=-56.520444771064966\n",
      "Gradient Descent(7278/9999): loss=5802.4994844197445, w0=-7.5630197560263, w1=-56.520444771064966\n",
      "Gradient Descent(7279/9999): loss=5802.4994844197445, w0=-7.5630197560263, w1=-56.520444771064966\n",
      "Gradient Descent(7280/9999): loss=5802.4994844197445, w0=6.2136802439737, w1=-56.04904477106496\n",
      "Gradient Descent(7281/9999): loss=4484.18301190101, w0=-9.125319756026299, w1=-63.89084477106496\n",
      "Gradient Descent(7282/9999): loss=5802.4994844197445, w0=-9.125319756026299, w1=-63.89084477106496\n",
      "Gradient Descent(7283/9999): loss=5802.4994844197445, w0=3.470480243973702, w1=-62.391344771064965\n",
      "Gradient Descent(7284/9999): loss=4385.438223739745, w0=3.470480243973702, w1=-62.391344771064965\n",
      "Gradient Descent(7285/9999): loss=4385.438223739745, w0=15.537245629527236, w1=-47.31114477106496\n",
      "Gradient Descent(7286/9999): loss=15627.152916264084, w0=15.537245629527236, w1=-47.31114477106496\n",
      "Gradient Descent(7287/9999): loss=15627.152916264084, w0=15.537245629527236, w1=-47.31114477106496\n",
      "Gradient Descent(7288/9999): loss=15627.152916264084, w0=9.436545629527236, w1=-52.65774477106496\n",
      "Gradient Descent(7289/9999): loss=6139.201488747225, w0=19.332645629527235, w1=-46.63244477106496\n",
      "Gradient Descent(7290/9999): loss=16140.268591407923, w0=7.265880243973701, w1=-54.49164477106496\n",
      "Gradient Descent(7291/9999): loss=7241.909400158107, w0=7.265880243973701, w1=-54.49164477106496\n",
      "Gradient Descent(7292/9999): loss=7241.909400158107, w0=-5.647619756026298, w1=-58.23804477106496\n",
      "Gradient Descent(7293/9999): loss=5032.440691378582, w0=-5.647619756026298, w1=-58.23804477106496\n",
      "Gradient Descent(7294/9999): loss=5032.440691378582, w0=6.419145629527236, w1=-47.200844771064965\n",
      "Gradient Descent(7295/9999): loss=9834.458273630666, w0=-1.2234543704727647, w1=-50.818344771064965\n",
      "Gradient Descent(7296/9999): loss=4353.424187068578, w0=-9.137654370472765, w1=-52.972644771064964\n",
      "Gradient Descent(7297/9999): loss=5549.2149032111, w0=-9.137654370472765, w1=-52.972644771064964\n",
      "Gradient Descent(7298/9999): loss=5549.2149032111, w0=-9.137654370472765, w1=-52.972644771064964\n",
      "Gradient Descent(7299/9999): loss=5549.2149032111, w0=5.204145629527236, w1=-46.04954477106496\n",
      "Gradient Descent(7300/9999): loss=5165.6149533014195, w0=5.204145629527236, w1=-46.04954477106496\n",
      "Gradient Descent(7301/9999): loss=5165.6149533014195, w0=-3.8363543704727636, w1=-49.247244771064956\n",
      "Gradient Descent(7302/9999): loss=4939.029324590392, w0=-3.8363543704727636, w1=-49.247244771064956\n",
      "Gradient Descent(7303/9999): loss=4939.029324590392, w0=-3.8363543704727636, w1=-49.247244771064956\n",
      "Gradient Descent(7304/9999): loss=4939.029324590392, w0=-3.8363543704727636, w1=-49.247244771064956\n",
      "Gradient Descent(7305/9999): loss=4939.029324590392, w0=-3.8363543704727636, w1=-49.247244771064956\n",
      "Gradient Descent(7306/9999): loss=4939.029324590392, w0=-3.8363543704727636, w1=-49.247244771064956\n",
      "Gradient Descent(7307/9999): loss=4939.029324590392, w0=-3.8363543704727636, w1=-49.247244771064956\n",
      "Gradient Descent(7308/9999): loss=4939.029324590392, w0=-3.8363543704727636, w1=-49.247244771064956\n",
      "Gradient Descent(7309/9999): loss=4939.029324590392, w0=-3.8363543704727636, w1=-49.247244771064956\n",
      "Gradient Descent(7310/9999): loss=4939.029324590392, w0=-3.8363543704727636, w1=-49.247244771064956\n",
      "Gradient Descent(7311/9999): loss=4939.029324590392, w0=-3.8363543704727636, w1=-49.247244771064956\n",
      "Gradient Descent(7312/9999): loss=4939.029324590392, w0=9.428645629527237, w1=-47.40464477106496\n",
      "Gradient Descent(7313/9999): loss=6948.147076456987, w0=9.428645629527237, w1=-47.40464477106496\n",
      "Gradient Descent(7314/9999): loss=6948.147076456987, w0=9.428645629527237, w1=-47.40464477106496\n",
      "Gradient Descent(7315/9999): loss=6948.147076456987, w0=9.428645629527237, w1=-47.40464477106496\n",
      "Gradient Descent(7316/9999): loss=6948.147076456987, w0=9.428645629527237, w1=-47.40464477106496\n",
      "Gradient Descent(7317/9999): loss=6948.147076456987, w0=9.428645629527237, w1=-47.40464477106496\n",
      "Gradient Descent(7318/9999): loss=6948.147076456987, w0=0.8945456295272365, w1=-50.15824477106496\n",
      "Gradient Descent(7319/9999): loss=4789.356323535913, w0=0.8945456295272365, w1=-50.15824477106496\n",
      "Gradient Descent(7320/9999): loss=4789.356323535913, w0=0.8945456295272365, w1=-50.15824477106496\n",
      "Gradient Descent(7321/9999): loss=4789.356323535913, w0=0.8945456295272365, w1=-50.15824477106496\n",
      "Gradient Descent(7322/9999): loss=4789.356323535913, w0=0.8945456295272365, w1=-50.15824477106496\n",
      "Gradient Descent(7323/9999): loss=4789.356323535913, w0=13.426645629527236, w1=-48.34044477106496\n",
      "Gradient Descent(7324/9999): loss=9739.905205653198, w0=13.426645629527236, w1=-48.34044477106496\n",
      "Gradient Descent(7325/9999): loss=9739.905205653198, w0=13.426645629527236, w1=-48.34044477106496\n",
      "Gradient Descent(7326/9999): loss=9739.905205653198, w0=13.426645629527236, w1=-48.34044477106496\n",
      "Gradient Descent(7327/9999): loss=9739.905205653198, w0=13.426645629527236, w1=-48.34044477106496\n",
      "Gradient Descent(7328/9999): loss=9739.905205653198, w0=13.426645629527236, w1=-48.34044477106496\n",
      "Gradient Descent(7329/9999): loss=9739.905205653198, w0=13.426645629527236, w1=-48.34044477106496\n",
      "Gradient Descent(7330/9999): loss=9739.905205653198, w0=4.546045629527237, w1=-51.98454477106496\n",
      "Gradient Descent(7331/9999): loss=4576.608039599451, w0=4.546045629527237, w1=-51.98454477106496\n",
      "Gradient Descent(7332/9999): loss=4576.608039599451, w0=4.546045629527237, w1=-51.98454477106496\n",
      "Gradient Descent(7333/9999): loss=4576.608039599451, w0=4.546045629527237, w1=-51.98454477106496\n",
      "Gradient Descent(7334/9999): loss=4576.608039599451, w0=4.546045629527237, w1=-51.98454477106496\n",
      "Gradient Descent(7335/9999): loss=4576.608039599451, w0=-9.235854370472763, w1=-54.640044771064964\n",
      "Gradient Descent(7336/9999): loss=5802.4994844197445, w0=-9.235854370472763, w1=-54.640044771064964\n",
      "Gradient Descent(7337/9999): loss=5802.4994844197445, w0=-9.235854370472763, w1=-54.640044771064964\n",
      "Gradient Descent(7338/9999): loss=5802.4994844197445, w0=4.309145629527237, w1=-51.790744771064965\n",
      "Gradient Descent(7339/9999): loss=4697.3053370515145, w0=4.309145629527237, w1=-51.790744771064965\n",
      "Gradient Descent(7340/9999): loss=4697.3053370515145, w0=4.309145629527237, w1=-51.790744771064965\n",
      "Gradient Descent(7341/9999): loss=4697.3053370515145, w0=4.309145629527237, w1=-51.790744771064965\n",
      "Gradient Descent(7342/9999): loss=4697.3053370515145, w0=4.309145629527237, w1=-51.790744771064965\n",
      "Gradient Descent(7343/9999): loss=4697.3053370515145, w0=16.677245629527235, w1=-44.69624477106497\n",
      "Gradient Descent(7344/9999): loss=11391.685727443848, w0=27.913345629527235, w1=-38.240044771064966\n",
      "Gradient Descent(7345/9999): loss=17223.33146562061, w0=27.913345629527235, w1=-38.240044771064966\n",
      "Gradient Descent(7346/9999): loss=17223.33146562061, w0=11.23544562952723, w1=-38.29664477106497\n",
      "Gradient Descent(7347/9999): loss=8129.8666205769705, w0=5.34164562952723, w1=-42.40284477106497\n",
      "Gradient Descent(7348/9999): loss=4580.392274564556, w0=5.34164562952723, w1=-42.40284477106497\n",
      "Gradient Descent(7349/9999): loss=4580.392274564556, w0=16.77344562952723, w1=-33.80124477106497\n",
      "Gradient Descent(7350/9999): loss=16716.762291468523, w0=16.77344562952723, w1=-33.80124477106497\n",
      "Gradient Descent(7351/9999): loss=16716.762291468523, w0=6.01234562952723, w1=-36.60764477106497\n",
      "Gradient Descent(7352/9999): loss=5247.824308695556, w0=6.01234562952723, w1=-36.60764477106497\n",
      "Gradient Descent(7353/9999): loss=5247.824308695556, w0=18.165445629527234, w1=-32.51944477106497\n",
      "Gradient Descent(7354/9999): loss=16904.019747901693, w0=10.539945629527235, w1=-37.38764477106497\n",
      "Gradient Descent(7355/9999): loss=12148.958436592573, w0=1.6528456295272331, w1=-44.51374477106497\n",
      "Gradient Descent(7356/9999): loss=4401.142806254198, w0=1.6528456295272331, w1=-44.51374477106497\n",
      "Gradient Descent(7357/9999): loss=4401.142806254198, w0=1.6528456295272331, w1=-44.51374477106497\n",
      "Gradient Descent(7358/9999): loss=4401.142806254198, w0=1.6528456295272331, w1=-44.51374477106497\n",
      "Gradient Descent(7359/9999): loss=4401.142806254198, w0=1.6528456295272331, w1=-44.51374477106497\n",
      "Gradient Descent(7360/9999): loss=4401.142806254198, w0=1.6528456295272331, w1=-44.51374477106497\n",
      "Gradient Descent(7361/9999): loss=4401.142806254198, w0=1.6528456295272331, w1=-44.51374477106497\n",
      "Gradient Descent(7362/9999): loss=4401.142806254198, w0=12.006845629527234, w1=-40.012544771064974\n",
      "Gradient Descent(7363/9999): loss=15738.16279055555, w0=0.7531456295272321, w1=-40.936144771064974\n",
      "Gradient Descent(7364/9999): loss=5497.329090953975, w0=0.7531456295272321, w1=-40.936144771064974\n",
      "Gradient Descent(7365/9999): loss=5497.329090953975, w0=-12.872854370472767, w1=-45.783944771064974\n",
      "Gradient Descent(7366/9999): loss=5802.4994844197445, w0=-12.872854370472767, w1=-45.783944771064974\n",
      "Gradient Descent(7367/9999): loss=5802.4994844197445, w0=1.675745629527233, w1=-44.240144771064976\n",
      "Gradient Descent(7368/9999): loss=4585.939386753102, w0=1.675745629527233, w1=-44.240144771064976\n",
      "Gradient Descent(7369/9999): loss=4585.939386753102, w0=1.675745629527233, w1=-44.240144771064976\n",
      "Gradient Descent(7370/9999): loss=4585.939386753102, w0=1.675745629527233, w1=-44.240144771064976\n",
      "Gradient Descent(7371/9999): loss=4585.939386753102, w0=1.675745629527233, w1=-44.240144771064976\n",
      "Gradient Descent(7372/9999): loss=4585.939386753102, w0=1.675745629527233, w1=-44.240144771064976\n",
      "Gradient Descent(7373/9999): loss=4585.939386753102, w0=1.675745629527233, w1=-44.240144771064976\n",
      "Gradient Descent(7374/9999): loss=4585.939386753102, w0=1.675745629527233, w1=-44.240144771064976\n",
      "Gradient Descent(7375/9999): loss=4585.939386753102, w0=1.675745629527233, w1=-44.240144771064976\n",
      "Gradient Descent(7376/9999): loss=4585.939386753102, w0=11.001945629527233, w1=-39.60664477106498\n",
      "Gradient Descent(7377/9999): loss=9532.518997917023, w0=11.001945629527233, w1=-39.60664477106498\n",
      "Gradient Descent(7378/9999): loss=9532.518997917023, w0=2.6447456295272325, w1=-40.318444771064975\n",
      "Gradient Descent(7379/9999): loss=4417.462157482597, w0=2.6447456295272325, w1=-40.318444771064975\n",
      "Gradient Descent(7380/9999): loss=4417.462157482597, w0=2.6447456295272325, w1=-40.318444771064975\n",
      "Gradient Descent(7381/9999): loss=4417.462157482597, w0=2.6447456295272325, w1=-40.318444771064975\n",
      "Gradient Descent(7382/9999): loss=4417.462157482597, w0=2.6447456295272325, w1=-40.318444771064975\n",
      "Gradient Descent(7383/9999): loss=4417.462157482597, w0=-6.505654370472767, w1=-43.63294477106498\n",
      "Gradient Descent(7384/9999): loss=5744.935417713768, w0=-6.505654370472767, w1=-43.63294477106498\n",
      "Gradient Descent(7385/9999): loss=5744.935417713768, w0=-6.505654370472767, w1=-43.63294477106498\n",
      "Gradient Descent(7386/9999): loss=5744.935417713768, w0=-6.505654370472767, w1=-43.63294477106498\n",
      "Gradient Descent(7387/9999): loss=5744.935417713768, w0=-6.505654370472767, w1=-43.63294477106498\n",
      "Gradient Descent(7388/9999): loss=5744.935417713768, w0=-6.505654370472767, w1=-43.63294477106498\n",
      "Gradient Descent(7389/9999): loss=5744.935417713768, w0=3.4971456295272336, w1=-37.68514477106498\n",
      "Gradient Descent(7390/9999): loss=4481.930764930934, w0=3.4971456295272336, w1=-37.68514477106498\n",
      "Gradient Descent(7391/9999): loss=4481.930764930934, w0=3.4971456295272336, w1=-37.68514477106498\n",
      "Gradient Descent(7392/9999): loss=4481.930764930934, w0=3.4971456295272336, w1=-37.68514477106498\n",
      "Gradient Descent(7393/9999): loss=4481.930764930934, w0=3.4971456295272336, w1=-37.68514477106498\n",
      "Gradient Descent(7394/9999): loss=4481.930764930934, w0=3.4971456295272336, w1=-37.68514477106498\n",
      "Gradient Descent(7395/9999): loss=4481.930764930934, w0=3.4971456295272336, w1=-37.68514477106498\n",
      "Gradient Descent(7396/9999): loss=4481.930764930934, w0=3.4971456295272336, w1=-37.68514477106498\n",
      "Gradient Descent(7397/9999): loss=4481.930764930934, w0=3.4971456295272336, w1=-37.68514477106498\n",
      "Gradient Descent(7398/9999): loss=4481.930764930934, w0=3.4971456295272336, w1=-37.68514477106498\n",
      "Gradient Descent(7399/9999): loss=4481.930764930934, w0=-4.681754370472767, w1=-39.81104477106498\n",
      "Gradient Descent(7400/9999): loss=5630.685587986108, w0=-4.681754370472767, w1=-39.81104477106498\n",
      "Gradient Descent(7401/9999): loss=5630.685587986108, w0=-4.681754370472767, w1=-39.81104477106498\n",
      "Gradient Descent(7402/9999): loss=5630.685587986108, w0=-4.681754370472767, w1=-39.81104477106498\n",
      "Gradient Descent(7403/9999): loss=5630.685587986108, w0=-4.681754370472767, w1=-39.81104477106498\n",
      "Gradient Descent(7404/9999): loss=5630.685587986108, w0=-4.681754370472767, w1=-39.81104477106498\n",
      "Gradient Descent(7405/9999): loss=5630.685587986108, w0=-4.681754370472767, w1=-39.81104477106498\n",
      "Gradient Descent(7406/9999): loss=5630.685587986108, w0=-4.681754370472767, w1=-39.81104477106498\n",
      "Gradient Descent(7407/9999): loss=5630.685587986108, w0=-4.681754370472767, w1=-39.81104477106498\n",
      "Gradient Descent(7408/9999): loss=5630.685587986108, w0=-4.681754370472767, w1=-39.81104477106498\n",
      "Gradient Descent(7409/9999): loss=5630.685587986108, w0=-4.681754370472767, w1=-39.81104477106498\n",
      "Gradient Descent(7410/9999): loss=5630.685587986108, w0=-4.681754370472767, w1=-39.81104477106498\n",
      "Gradient Descent(7411/9999): loss=5630.685587986108, w0=-4.681754370472767, w1=-39.81104477106498\n",
      "Gradient Descent(7412/9999): loss=5630.685587986108, w0=-4.681754370472767, w1=-39.81104477106498\n",
      "Gradient Descent(7413/9999): loss=5630.685587986108, w0=-4.681754370472767, w1=-39.81104477106498\n",
      "Gradient Descent(7414/9999): loss=5630.685587986108, w0=3.2105456295272337, w1=-36.58764477106498\n",
      "Gradient Descent(7415/9999): loss=4502.086891944408, w0=3.2105456295272337, w1=-36.58764477106498\n",
      "Gradient Descent(7416/9999): loss=4502.086891944408, w0=3.2105456295272337, w1=-36.58764477106498\n",
      "Gradient Descent(7417/9999): loss=4502.086891944408, w0=3.2105456295272337, w1=-36.58764477106498\n",
      "Gradient Descent(7418/9999): loss=4502.086891944408, w0=-8.066254370472766, w1=-37.95034477106498\n",
      "Gradient Descent(7419/9999): loss=5802.4994844197445, w0=-8.066254370472766, w1=-37.95034477106498\n",
      "Gradient Descent(7420/9999): loss=5802.4994844197445, w0=-8.066254370472766, w1=-37.95034477106498\n",
      "Gradient Descent(7421/9999): loss=5802.4994844197445, w0=-8.066254370472766, w1=-37.95034477106498\n",
      "Gradient Descent(7422/9999): loss=5802.4994844197445, w0=-8.066254370472766, w1=-37.95034477106498\n",
      "Gradient Descent(7423/9999): loss=5802.4994844197445, w0=-8.066254370472766, w1=-37.95034477106498\n",
      "Gradient Descent(7424/9999): loss=5802.4994844197445, w0=-8.066254370472766, w1=-37.95034477106498\n",
      "Gradient Descent(7425/9999): loss=5802.4994844197445, w0=-8.066254370472766, w1=-37.95034477106498\n",
      "Gradient Descent(7426/9999): loss=5802.4994844197445, w0=2.823445629527235, w1=-30.214244771064976\n",
      "Gradient Descent(7427/9999): loss=4692.038944644556, w0=2.823445629527235, w1=-30.214244771064976\n",
      "Gradient Descent(7428/9999): loss=4692.038944644556, w0=15.427845629527235, w1=-29.324644771064975\n",
      "Gradient Descent(7429/9999): loss=16673.559501002914, w0=15.427845629527235, w1=-29.324644771064975\n",
      "Gradient Descent(7430/9999): loss=16673.559501002914, w0=15.427845629527235, w1=-29.324644771064975\n",
      "Gradient Descent(7431/9999): loss=16673.559501002914, w0=15.427845629527235, w1=-29.324644771064975\n",
      "Gradient Descent(7432/9999): loss=16673.559501002914, w0=5.099545629527237, w1=-34.80554477106497\n",
      "Gradient Descent(7433/9999): loss=5315.32014547229, w0=26.54324562952724, w1=-28.205644771064975\n",
      "Gradient Descent(7434/9999): loss=17188.79265922585, w0=16.68144562952724, w1=-33.54954477106497\n",
      "Gradient Descent(7435/9999): loss=14953.92516638196, w0=4.614680243973705, w1=-40.649144771064975\n",
      "Gradient Descent(7436/9999): loss=4352.953227048563, w0=4.614680243973705, w1=-40.649144771064975\n",
      "Gradient Descent(7437/9999): loss=4352.953227048563, w0=4.614680243973705, w1=-40.649144771064975\n",
      "Gradient Descent(7438/9999): loss=4352.953227048563, w0=4.614680243973705, w1=-40.649144771064975\n",
      "Gradient Descent(7439/9999): loss=4352.953227048563, w0=4.614680243973705, w1=-40.649144771064975\n",
      "Gradient Descent(7440/9999): loss=4352.953227048563, w0=4.614680243973705, w1=-40.649144771064975\n",
      "Gradient Descent(7441/9999): loss=4352.953227048563, w0=14.590880243973706, w1=-36.04204477106497\n",
      "Gradient Descent(7442/9999): loss=12491.244944682425, w0=14.590880243973706, w1=-36.04204477106497\n",
      "Gradient Descent(7443/9999): loss=12491.244944682425, w0=0.3891802439737049, w1=-36.828044771064974\n",
      "Gradient Descent(7444/9999): loss=4680.096528688879, w0=0.3891802439737049, w1=-36.828044771064974\n",
      "Gradient Descent(7445/9999): loss=4680.096528688879, w0=12.757280243973705, w1=-29.733544771064974\n",
      "Gradient Descent(7446/9999): loss=15221.541350399686, w0=0.6905148584201708, w1=-37.831944771064975\n",
      "Gradient Descent(7447/9999): loss=4359.705704863064, w0=0.6905148584201708, w1=-37.831944771064975\n",
      "Gradient Descent(7448/9999): loss=4359.705704863064, w0=-10.30638514157983, w1=-39.760844771064974\n",
      "Gradient Descent(7449/9999): loss=5802.4994844197445, w0=-10.30638514157983, w1=-39.760844771064974\n",
      "Gradient Descent(7450/9999): loss=5802.4994844197445, w0=0.7386148584201724, w1=-38.715044771064974\n",
      "Gradient Descent(7451/9999): loss=4358.649041322595, w0=0.7386148584201724, w1=-38.715044771064974\n",
      "Gradient Descent(7452/9999): loss=4358.649041322595, w0=0.7386148584201724, w1=-38.715044771064974\n",
      "Gradient Descent(7453/9999): loss=4358.649041322595, w0=0.7386148584201724, w1=-38.715044771064974\n",
      "Gradient Descent(7454/9999): loss=4358.649041322595, w0=11.327314858420173, w1=-33.587244771064974\n",
      "Gradient Descent(7455/9999): loss=15159.394289624404, w0=11.327314858420173, w1=-33.587244771064974\n",
      "Gradient Descent(7456/9999): loss=15159.394289624404, w0=-13.078285141579826, w1=-44.36034477106497\n",
      "Gradient Descent(7457/9999): loss=5093.25696875818, w0=-13.078285141579826, w1=-44.36034477106497\n",
      "Gradient Descent(7458/9999): loss=5093.25696875818, w0=-13.078285141579826, w1=-44.36034477106497\n",
      "Gradient Descent(7459/9999): loss=5093.25696875818, w0=-13.078285141579826, w1=-44.36034477106497\n",
      "Gradient Descent(7460/9999): loss=5093.25696875818, w0=-13.078285141579826, w1=-44.36034477106497\n",
      "Gradient Descent(7461/9999): loss=5093.25696875818, w0=-13.078285141579826, w1=-44.36034477106497\n",
      "Gradient Descent(7462/9999): loss=5093.25696875818, w0=1.1892148584201756, w1=-41.68714477106497\n",
      "Gradient Descent(7463/9999): loss=12746.622267516253, w0=-6.974585141579825, w1=-46.74704477106497\n",
      "Gradient Descent(7464/9999): loss=5019.346062827057, w0=-6.974585141579825, w1=-46.74704477106497\n",
      "Gradient Descent(7465/9999): loss=5019.346062827057, w0=-6.974585141579825, w1=-46.74704477106497\n",
      "Gradient Descent(7466/9999): loss=5019.346062827057, w0=-18.749485141579825, w1=-49.50264477106497\n",
      "Gradient Descent(7467/9999): loss=5802.4994844197445, w0=-18.749485141579825, w1=-49.50264477106497\n",
      "Gradient Descent(7468/9999): loss=5802.4994844197445, w0=-6.760185141579825, w1=-49.21434477106497\n",
      "Gradient Descent(7469/9999): loss=4597.61959169789, w0=-6.760185141579825, w1=-49.21434477106497\n",
      "Gradient Descent(7470/9999): loss=4597.61959169789, w0=-6.760185141579825, w1=-49.21434477106497\n",
      "Gradient Descent(7471/9999): loss=4597.61959169789, w0=-6.760185141579825, w1=-49.21434477106497\n",
      "Gradient Descent(7472/9999): loss=4597.61959169789, w0=14.683514858420178, w1=-42.614444771064974\n",
      "Gradient Descent(7473/9999): loss=16978.07820999441, w0=2.616749472866644, w1=-53.426744771064975\n",
      "Gradient Descent(7474/9999): loss=7980.894010531547, w0=2.616749472866644, w1=-53.426744771064975\n",
      "Gradient Descent(7475/9999): loss=7980.894010531547, w0=2.616749472866644, w1=-53.426744771064975\n",
      "Gradient Descent(7476/9999): loss=7980.894010531547, w0=-9.45001591268689, w1=-60.11634477106497\n",
      "Gradient Descent(7477/9999): loss=4732.564288648648, w0=0.9411840873131112, w1=-59.48634477106497\n",
      "Gradient Descent(7478/9999): loss=8170.6288443430585, w0=0.9411840873131112, w1=-59.48634477106497\n",
      "Gradient Descent(7479/9999): loss=8170.6288443430585, w0=0.9411840873131112, w1=-59.48634477106497\n",
      "Gradient Descent(7480/9999): loss=8170.6288443430585, w0=0.9411840873131112, w1=-59.48634477106497\n",
      "Gradient Descent(7481/9999): loss=8170.6288443430585, w0=0.9411840873131112, w1=-59.48634477106497\n",
      "Gradient Descent(7482/9999): loss=8170.6288443430585, w0=0.9411840873131112, w1=-59.48634477106497\n",
      "Gradient Descent(7483/9999): loss=8170.6288443430585, w0=0.9411840873131112, w1=-59.48634477106497\n",
      "Gradient Descent(7484/9999): loss=8170.6288443430585, w0=0.9411840873131112, w1=-59.48634477106497\n",
      "Gradient Descent(7485/9999): loss=8170.6288443430585, w0=-7.7251159126868885, w1=-64.88734477106497\n",
      "Gradient Descent(7486/9999): loss=4766.308901644359, w0=1.9630840873131135, w1=-60.358044771064975\n",
      "Gradient Descent(7487/9999): loss=7225.923683761501, w0=1.9630840873131135, w1=-60.358044771064975\n",
      "Gradient Descent(7488/9999): loss=7225.923683761501, w0=1.9630840873131135, w1=-60.358044771064975\n",
      "Gradient Descent(7489/9999): loss=7225.923683761501, w0=-14.025715912686888, w1=-65.66824477106498\n",
      "Gradient Descent(7490/9999): loss=5767.960678024983, w0=-14.025715912686888, w1=-65.66824477106498\n",
      "Gradient Descent(7491/9999): loss=5767.960678024983, w0=-14.025715912686888, w1=-65.66824477106498\n",
      "Gradient Descent(7492/9999): loss=5767.960678024983, w0=-14.025715912686888, w1=-65.66824477106498\n",
      "Gradient Descent(7493/9999): loss=5767.960678024983, w0=-5.713715912686887, w1=-61.86974477106498\n",
      "Gradient Descent(7494/9999): loss=4594.05040188608, w0=-16.00551591268689, w1=-62.35834477106498\n",
      "Gradient Descent(7495/9999): loss=5802.4994844197445, w0=-16.00551591268689, w1=-62.35834477106498\n",
      "Gradient Descent(7496/9999): loss=5802.4994844197445, w0=-16.00551591268689, w1=-62.35834477106498\n",
      "Gradient Descent(7497/9999): loss=5802.4994844197445, w0=-6.761115912686888, w1=-61.13084477106498\n",
      "Gradient Descent(7498/9999): loss=4565.377527290011, w0=-6.761115912686888, w1=-61.13084477106498\n",
      "Gradient Descent(7499/9999): loss=4565.377527290011, w0=-6.761115912686888, w1=-61.13084477106498\n",
      "Gradient Descent(7500/9999): loss=4565.377527290011, w0=-6.761115912686888, w1=-61.13084477106498\n",
      "Gradient Descent(7501/9999): loss=4565.377527290011, w0=-6.761115912686888, w1=-61.13084477106498\n",
      "Gradient Descent(7502/9999): loss=4565.377527290011, w0=-6.761115912686888, w1=-61.13084477106498\n",
      "Gradient Descent(7503/9999): loss=4565.377527290011, w0=3.147484087313112, w1=-57.00174477106498\n",
      "Gradient Descent(7504/9999): loss=10946.717269493187, w0=-5.742515912686889, w1=-62.42354477106498\n",
      "Gradient Descent(7505/9999): loss=4605.257521871772, w0=7.53998408731311, w1=-56.83064477106498\n",
      "Gradient Descent(7506/9999): loss=12975.058180810594, w0=-4.526781298240424, w1=-65.73764477106498\n",
      "Gradient Descent(7507/9999): loss=4842.479711595137, w0=6.061918701759577, w1=-60.60984477106498\n",
      "Gradient Descent(7508/9999): loss=12853.098538644597, w0=6.061918701759577, w1=-60.60984477106498\n",
      "Gradient Descent(7509/9999): loss=12853.098538644597, w0=-6.004846683793957, w1=-68.09834477106497\n",
      "Gradient Descent(7510/9999): loss=5555.666085725509, w0=-16.26734668379396, w1=-74.84434477106497\n",
      "Gradient Descent(7511/9999): loss=5756.4477425600635, w0=-0.08304668379395963, w1=-73.59634477106496\n",
      "Gradient Descent(7512/9999): loss=4869.950223482424, w0=-0.08304668379395963, w1=-73.59634477106496\n",
      "Gradient Descent(7513/9999): loss=4869.950223482424, w0=-16.671946683793962, w1=-78.03244477106496\n",
      "Gradient Descent(7514/9999): loss=5790.986548954825, w0=-16.671946683793962, w1=-78.03244477106496\n",
      "Gradient Descent(7515/9999): loss=5790.986548954825, w0=-4.398946683793961, w1=-76.55514477106496\n",
      "Gradient Descent(7516/9999): loss=4366.612800889869, w0=-4.398946683793961, w1=-76.55514477106496\n",
      "Gradient Descent(7517/9999): loss=4366.612800889869, w0=-4.398946683793961, w1=-76.55514477106496\n",
      "Gradient Descent(7518/9999): loss=4366.612800889869, w0=-14.038546683793962, w1=-78.21214477106496\n",
      "Gradient Descent(7519/9999): loss=5779.711732094454, w0=-14.038546683793962, w1=-78.21214477106496\n",
      "Gradient Descent(7520/9999): loss=5779.711732094454, w0=-14.038546683793962, w1=-78.21214477106496\n",
      "Gradient Descent(7521/9999): loss=5779.711732094454, w0=-14.038546683793962, w1=-78.21214477106496\n",
      "Gradient Descent(7522/9999): loss=5779.711732094454, w0=-1.7013466837939593, w1=-75.97754477106496\n",
      "Gradient Descent(7523/9999): loss=5395.51772875186, w0=-1.7013466837939593, w1=-75.97754477106496\n",
      "Gradient Descent(7524/9999): loss=5395.51772875186, w0=-1.7013466837939593, w1=-75.97754477106496\n",
      "Gradient Descent(7525/9999): loss=5395.51772875186, w0=-1.7013466837939593, w1=-75.97754477106496\n",
      "Gradient Descent(7526/9999): loss=5395.51772875186, w0=-1.7013466837939593, w1=-75.97754477106496\n",
      "Gradient Descent(7527/9999): loss=5395.51772875186, w0=-1.7013466837939593, w1=-75.97754477106496\n",
      "Gradient Descent(7528/9999): loss=5395.51772875186, w0=-9.88024668379396, w1=-78.10344477106496\n",
      "Gradient Descent(7529/9999): loss=4534.481422675923, w0=-9.88024668379396, w1=-78.10344477106496\n",
      "Gradient Descent(7530/9999): loss=4534.481422675923, w0=-9.88024668379396, w1=-78.10344477106496\n",
      "Gradient Descent(7531/9999): loss=4534.481422675923, w0=-9.88024668379396, w1=-78.10344477106496\n",
      "Gradient Descent(7532/9999): loss=4534.481422675923, w0=-9.88024668379396, w1=-78.10344477106496\n",
      "Gradient Descent(7533/9999): loss=4534.481422675923, w0=-9.88024668379396, w1=-78.10344477106496\n",
      "Gradient Descent(7534/9999): loss=4534.481422675923, w0=-9.88024668379396, w1=-78.10344477106496\n",
      "Gradient Descent(7535/9999): loss=4534.481422675923, w0=-9.88024668379396, w1=-78.10344477106496\n",
      "Gradient Descent(7536/9999): loss=4534.481422675923, w0=-9.88024668379396, w1=-78.10344477106496\n",
      "Gradient Descent(7537/9999): loss=4534.481422675923, w0=-9.88024668379396, w1=-78.10344477106496\n",
      "Gradient Descent(7538/9999): loss=4534.481422675923, w0=-9.88024668379396, w1=-78.10344477106496\n",
      "Gradient Descent(7539/9999): loss=4534.481422675923, w0=4.154653316206041, w1=-76.76614477106496\n",
      "Gradient Descent(7540/9999): loss=8396.65752595403, w0=4.154653316206041, w1=-76.76614477106496\n",
      "Gradient Descent(7541/9999): loss=8396.65752595403, w0=-3.3739466837939602, w1=-83.51244477106496\n",
      "Gradient Descent(7542/9999): loss=4478.511900933488, w0=-3.3739466837939602, w1=-83.51244477106496\n",
      "Gradient Descent(7543/9999): loss=4478.511900933488, w0=-3.3739466837939602, w1=-83.51244477106496\n",
      "Gradient Descent(7544/9999): loss=4478.511900933488, w0=-3.3739466837939602, w1=-83.51244477106496\n",
      "Gradient Descent(7545/9999): loss=4478.511900933488, w0=-3.3739466837939602, w1=-83.51244477106496\n",
      "Gradient Descent(7546/9999): loss=4478.511900933488, w0=8.76845331620604, w1=-80.59734477106497\n",
      "Gradient Descent(7547/9999): loss=10096.23716797417, w0=8.76845331620604, w1=-80.59734477106497\n",
      "Gradient Descent(7548/9999): loss=10096.23716797417, w0=8.76845331620604, w1=-80.59734477106497\n",
      "Gradient Descent(7549/9999): loss=10096.23716797417, w0=-9.035746683793962, w1=-88.05344477106497\n",
      "Gradient Descent(7550/9999): loss=4546.667705589815, w0=-9.035746683793962, w1=-88.05344477106497\n",
      "Gradient Descent(7551/9999): loss=4546.667705589815, w0=-9.035746683793962, w1=-88.05344477106497\n",
      "Gradient Descent(7552/9999): loss=4546.667705589815, w0=-9.035746683793962, w1=-88.05344477106497\n",
      "Gradient Descent(7553/9999): loss=4546.667705589815, w0=-9.035746683793962, w1=-88.05344477106497\n",
      "Gradient Descent(7554/9999): loss=4546.667705589815, w0=-9.035746683793962, w1=-88.05344477106497\n",
      "Gradient Descent(7555/9999): loss=4546.667705589815, w0=-9.035746683793962, w1=-88.05344477106497\n",
      "Gradient Descent(7556/9999): loss=4546.667705589815, w0=4.4493533162060395, w1=-84.67244477106497\n",
      "Gradient Descent(7557/9999): loss=7566.349157941187, w0=2.2255533162060392, w1=-91.23594477106498\n",
      "Gradient Descent(7558/9999): loss=4487.239004398005, w0=2.2255533162060392, w1=-91.23594477106498\n",
      "Gradient Descent(7559/9999): loss=4487.239004398005, w0=2.2255533162060392, w1=-91.23594477106498\n",
      "Gradient Descent(7560/9999): loss=4487.239004398005, w0=2.2255533162060392, w1=-91.23594477106498\n",
      "Gradient Descent(7561/9999): loss=4487.239004398005, w0=2.2255533162060392, w1=-91.23594477106498\n",
      "Gradient Descent(7562/9999): loss=4487.239004398005, w0=11.551753316206039, w1=-86.60244477106498\n",
      "Gradient Descent(7563/9999): loss=8427.469894783691, w0=11.551753316206039, w1=-86.60244477106498\n",
      "Gradient Descent(7564/9999): loss=8427.469894783691, w0=11.551753316206039, w1=-86.60244477106498\n",
      "Gradient Descent(7565/9999): loss=8427.469894783691, w0=24.86925331620604, w1=-77.20524477106498\n",
      "Gradient Descent(7566/9999): loss=16756.640694869828, w0=17.768453316206042, w1=-80.67414477106499\n",
      "Gradient Descent(7567/9999): loss=10916.197122025282, w0=17.768453316206042, w1=-80.67414477106499\n",
      "Gradient Descent(7568/9999): loss=10916.197122025282, w0=11.64265331620604, w1=-87.87864477106498\n",
      "Gradient Descent(7569/9999): loss=4662.649832646144, w0=11.64265331620604, w1=-87.87864477106498\n",
      "Gradient Descent(7570/9999): loss=4662.649832646144, w0=11.64265331620604, w1=-87.87864477106498\n",
      "Gradient Descent(7571/9999): loss=4662.649832646144, w0=11.64265331620604, w1=-87.87864477106498\n",
      "Gradient Descent(7572/9999): loss=4662.649832646144, w0=11.64265331620604, w1=-87.87864477106498\n",
      "Gradient Descent(7573/9999): loss=4662.649832646144, w0=11.64265331620604, w1=-87.87864477106498\n",
      "Gradient Descent(7574/9999): loss=4662.649832646144, w0=11.64265331620604, w1=-87.87864477106498\n",
      "Gradient Descent(7575/9999): loss=4662.649832646144, w0=11.64265331620604, w1=-87.87864477106498\n",
      "Gradient Descent(7576/9999): loss=4662.649832646144, w0=11.64265331620604, w1=-87.87864477106498\n",
      "Gradient Descent(7577/9999): loss=4662.649832646144, w0=-0.424112069347494, w1=-94.77564477106499\n",
      "Gradient Descent(7578/9999): loss=5802.4994844197445, w0=12.986587930652506, w1=-94.31724477106499\n",
      "Gradient Descent(7579/9999): loss=4699.639911773311, w0=12.986587930652506, w1=-94.31724477106499\n",
      "Gradient Descent(7580/9999): loss=4699.639911773311, w0=24.418387930652507, w1=-85.71564477106499\n",
      "Gradient Descent(7581/9999): loss=6906.217038021978, w0=12.174187930652506, w1=-92.32544477106498\n",
      "Gradient Descent(7582/9999): loss=4432.460226152818, w0=12.174187930652506, w1=-92.32544477106498\n",
      "Gradient Descent(7583/9999): loss=4432.460226152818, w0=12.174187930652506, w1=-92.32544477106498\n",
      "Gradient Descent(7584/9999): loss=4432.460226152818, w0=12.174187930652506, w1=-92.32544477106498\n",
      "Gradient Descent(7585/9999): loss=4432.460226152818, w0=12.174187930652506, w1=-92.32544477106498\n",
      "Gradient Descent(7586/9999): loss=4432.460226152818, w0=12.174187930652506, w1=-92.32544477106498\n",
      "Gradient Descent(7587/9999): loss=4432.460226152818, w0=22.85988793065251, w1=-86.97954477106498\n",
      "Gradient Descent(7588/9999): loss=5668.095670027131, w0=22.85988793065251, w1=-86.97954477106498\n",
      "Gradient Descent(7589/9999): loss=5668.095670027131, w0=34.92665331620604, w1=-74.32764477106498\n",
      "Gradient Descent(7590/9999): loss=15600.48552517046, w0=23.059253316206043, w1=-80.25384477106498\n",
      "Gradient Descent(7591/9999): loss=5320.665953251487, w0=23.059253316206043, w1=-80.25384477106498\n",
      "Gradient Descent(7592/9999): loss=5320.665953251487, w0=10.207853316206041, w1=-81.02604477106497\n",
      "Gradient Descent(7593/9999): loss=5181.443885233678, w0=25.540953316206043, w1=-79.72384477106498\n",
      "Gradient Descent(7594/9999): loss=5253.928494469372, w0=39.88275331620604, w1=-72.80074477106497\n",
      "Gradient Descent(7595/9999): loss=13501.86968997304, w0=21.962953316206043, w1=-77.05024477106497\n",
      "Gradient Descent(7596/9999): loss=4628.546858391172, w0=21.962953316206043, w1=-77.05024477106497\n",
      "Gradient Descent(7597/9999): loss=4628.546858391172, w0=21.962953316206043, w1=-77.05024477106497\n",
      "Gradient Descent(7598/9999): loss=4628.546858391172, w0=21.962953316206043, w1=-77.05024477106497\n",
      "Gradient Descent(7599/9999): loss=4628.546858391172, w0=21.962953316206043, w1=-77.05024477106497\n",
      "Gradient Descent(7600/9999): loss=4628.546858391172, w0=21.962953316206043, w1=-77.05024477106497\n",
      "Gradient Descent(7601/9999): loss=4628.546858391172, w0=21.962953316206043, w1=-77.05024477106497\n",
      "Gradient Descent(7602/9999): loss=4628.546858391172, w0=21.962953316206043, w1=-77.05024477106497\n",
      "Gradient Descent(7603/9999): loss=4628.546858391172, w0=21.962953316206043, w1=-77.05024477106497\n",
      "Gradient Descent(7604/9999): loss=4628.546858391172, w0=21.962953316206043, w1=-77.05024477106497\n",
      "Gradient Descent(7605/9999): loss=4628.546858391172, w0=-1.6353466837939585, w1=-81.36374477106497\n",
      "Gradient Descent(7606/9999): loss=5802.4994844197445, w0=-1.6353466837939585, w1=-81.36374477106497\n",
      "Gradient Descent(7607/9999): loss=5802.4994844197445, w0=-1.6353466837939585, w1=-81.36374477106497\n",
      "Gradient Descent(7608/9999): loss=5802.4994844197445, w0=-1.6353466837939585, w1=-81.36374477106497\n",
      "Gradient Descent(7609/9999): loss=5802.4994844197445, w0=6.353553316206042, w1=-80.58804477106497\n",
      "Gradient Descent(7610/9999): loss=5211.001583166734, w0=6.353553316206042, w1=-80.58804477106497\n",
      "Gradient Descent(7611/9999): loss=5211.001583166734, w0=6.353553316206042, w1=-80.58804477106497\n",
      "Gradient Descent(7612/9999): loss=5211.001583166734, w0=6.353553316206042, w1=-80.58804477106497\n",
      "Gradient Descent(7613/9999): loss=5211.001583166734, w0=19.124453316206043, w1=-74.19094477106498\n",
      "Gradient Descent(7614/9999): loss=6170.542382777176, w0=19.124453316206043, w1=-74.19094477106498\n",
      "Gradient Descent(7615/9999): loss=6170.542382777176, w0=19.124453316206043, w1=-74.19094477106498\n",
      "Gradient Descent(7616/9999): loss=6170.542382777176, w0=19.124453316206043, w1=-74.19094477106498\n",
      "Gradient Descent(7617/9999): loss=6170.542382777176, w0=19.124453316206043, w1=-74.19094477106498\n",
      "Gradient Descent(7618/9999): loss=6170.542382777176, w0=19.124453316206043, w1=-74.19094477106498\n",
      "Gradient Descent(7619/9999): loss=6170.542382777176, w0=19.124453316206043, w1=-74.19094477106498\n",
      "Gradient Descent(7620/9999): loss=6170.542382777176, w0=19.124453316206043, w1=-74.19094477106498\n",
      "Gradient Descent(7621/9999): loss=6170.542382777176, w0=19.124453316206043, w1=-74.19094477106498\n",
      "Gradient Descent(7622/9999): loss=6170.542382777176, w0=19.124453316206043, w1=-74.19094477106498\n",
      "Gradient Descent(7623/9999): loss=6170.542382777176, w0=8.688653316206043, w1=-75.35294477106498\n",
      "Gradient Descent(7624/9999): loss=4892.977584922577, w0=8.688653316206043, w1=-75.35294477106498\n",
      "Gradient Descent(7625/9999): loss=4892.977584922577, w0=-0.5393466837939567, w1=-75.56034477106499\n",
      "Gradient Descent(7626/9999): loss=5802.4994844197445, w0=7.1354533162060445, w1=-72.75684477106499\n",
      "Gradient Descent(7627/9999): loss=4874.606121629664, w0=26.804953316206046, w1=-70.91304477106499\n",
      "Gradient Descent(7628/9999): loss=15133.529708345734, w0=13.064953316206044, w1=-80.58224477106499\n",
      "Gradient Descent(7629/9999): loss=4708.717588769699, w0=13.064953316206044, w1=-80.58224477106499\n",
      "Gradient Descent(7630/9999): loss=4708.717588769699, w0=13.064953316206044, w1=-80.58224477106499\n",
      "Gradient Descent(7631/9999): loss=4708.717588769699, w0=13.064953316206044, w1=-80.58224477106499\n",
      "Gradient Descent(7632/9999): loss=4708.717588769699, w0=13.064953316206044, w1=-80.58224477106499\n",
      "Gradient Descent(7633/9999): loss=4708.717588769699, w0=13.064953316206044, w1=-80.58224477106499\n",
      "Gradient Descent(7634/9999): loss=4708.717588769699, w0=13.064953316206044, w1=-80.58224477106499\n",
      "Gradient Descent(7635/9999): loss=4708.717588769699, w0=13.064953316206044, w1=-80.58224477106499\n",
      "Gradient Descent(7636/9999): loss=4708.717588769699, w0=13.064953316206044, w1=-80.58224477106499\n",
      "Gradient Descent(7637/9999): loss=4708.717588769699, w0=13.064953316206044, w1=-80.58224477106499\n",
      "Gradient Descent(7638/9999): loss=4708.717588769699, w0=13.064953316206044, w1=-80.58224477106499\n",
      "Gradient Descent(7639/9999): loss=4708.717588769699, w0=13.064953316206044, w1=-80.58224477106499\n",
      "Gradient Descent(7640/9999): loss=4708.717588769699, w0=13.064953316206044, w1=-80.58224477106499\n",
      "Gradient Descent(7641/9999): loss=4708.717588769699, w0=13.064953316206044, w1=-80.58224477106499\n",
      "Gradient Descent(7642/9999): loss=4708.717588769699, w0=4.978353316206043, w1=-83.586244771065\n",
      "Gradient Descent(7643/9999): loss=4606.180896522712, w0=4.978353316206043, w1=-83.586244771065\n",
      "Gradient Descent(7644/9999): loss=4606.180896522712, w0=4.978353316206043, w1=-83.586244771065\n",
      "Gradient Descent(7645/9999): loss=4606.180896522712, w0=19.320153316206046, w1=-76.66314477106499\n",
      "Gradient Descent(7646/9999): loss=5239.712951513777, w0=19.320153316206046, w1=-76.66314477106499\n",
      "Gradient Descent(7647/9999): loss=5239.712951513777, w0=19.320153316206046, w1=-76.66314477106499\n",
      "Gradient Descent(7648/9999): loss=5239.712951513777, w0=19.320153316206046, w1=-76.66314477106499\n",
      "Gradient Descent(7649/9999): loss=5239.712951513777, w0=19.320153316206046, w1=-76.66314477106499\n",
      "Gradient Descent(7650/9999): loss=5239.712951513777, w0=7.512353316206045, w1=-81.613144771065\n",
      "Gradient Descent(7651/9999): loss=5295.236630584544, w0=7.512353316206045, w1=-81.613144771065\n",
      "Gradient Descent(7652/9999): loss=5295.236630584544, w0=7.512353316206045, w1=-81.613144771065\n",
      "Gradient Descent(7653/9999): loss=5295.236630584544, w0=7.512353316206045, w1=-81.613144771065\n",
      "Gradient Descent(7654/9999): loss=5295.236630584544, w0=22.61305331620605, w1=-80.014344771065\n",
      "Gradient Descent(7655/9999): loss=7312.550907152196, w0=9.846053316206048, w1=-84.957744771065\n",
      "Gradient Descent(7656/9999): loss=4453.3613607521265, w0=22.565253316206046, w1=-79.48164477106499\n",
      "Gradient Descent(7657/9999): loss=8683.754335325106, w0=11.221253316206045, w1=-84.13564477106499\n",
      "Gradient Descent(7658/9999): loss=4348.147402469471, w0=11.221253316206045, w1=-84.13564477106499\n",
      "Gradient Descent(7659/9999): loss=4348.147402469471, w0=11.221253316206045, w1=-84.13564477106499\n",
      "Gradient Descent(7660/9999): loss=4348.147402469471, w0=11.221253316206045, w1=-84.13564477106499\n",
      "Gradient Descent(7661/9999): loss=4348.147402469471, w0=11.221253316206045, w1=-84.13564477106499\n",
      "Gradient Descent(7662/9999): loss=4348.147402469471, w0=11.221253316206045, w1=-84.13564477106499\n",
      "Gradient Descent(7663/9999): loss=4348.147402469471, w0=11.221253316206045, w1=-84.13564477106499\n",
      "Gradient Descent(7664/9999): loss=4348.147402469471, w0=11.221253316206045, w1=-84.13564477106499\n",
      "Gradient Descent(7665/9999): loss=4348.147402469471, w0=11.221253316206045, w1=-84.13564477106499\n",
      "Gradient Descent(7666/9999): loss=4348.147402469471, w0=-8.011846683793955, w1=-85.36294477106499\n",
      "Gradient Descent(7667/9999): loss=5802.4994844197445, w0=-8.011846683793955, w1=-85.36294477106499\n",
      "Gradient Descent(7668/9999): loss=5802.4994844197445, w0=-8.011846683793955, w1=-85.36294477106499\n",
      "Gradient Descent(7669/9999): loss=5802.4994844197445, w0=-8.011846683793955, w1=-85.36294477106499\n",
      "Gradient Descent(7670/9999): loss=5802.4994844197445, w0=-8.011846683793955, w1=-85.36294477106499\n",
      "Gradient Descent(7671/9999): loss=5802.4994844197445, w0=-8.011846683793955, w1=-85.36294477106499\n",
      "Gradient Descent(7672/9999): loss=5802.4994844197445, w0=-8.011846683793955, w1=-85.36294477106499\n",
      "Gradient Descent(7673/9999): loss=5802.4994844197445, w0=-8.011846683793955, w1=-85.36294477106499\n",
      "Gradient Descent(7674/9999): loss=5802.4994844197445, w0=-8.011846683793955, w1=-85.36294477106499\n",
      "Gradient Descent(7675/9999): loss=5802.4994844197445, w0=-8.011846683793955, w1=-85.36294477106499\n",
      "Gradient Descent(7676/9999): loss=5802.4994844197445, w0=-8.011846683793955, w1=-85.36294477106499\n",
      "Gradient Descent(7677/9999): loss=5802.4994844197445, w0=-8.011846683793955, w1=-85.36294477106499\n",
      "Gradient Descent(7678/9999): loss=5802.4994844197445, w0=-8.011846683793955, w1=-85.36294477106499\n",
      "Gradient Descent(7679/9999): loss=5802.4994844197445, w0=-8.011846683793955, w1=-85.36294477106499\n",
      "Gradient Descent(7680/9999): loss=5802.4994844197445, w0=4.004853316206045, w1=-82.843844771065\n",
      "Gradient Descent(7681/9999): loss=5368.251385365535, w0=4.004853316206045, w1=-82.843844771065\n",
      "Gradient Descent(7682/9999): loss=5368.251385365535, w0=4.004853316206045, w1=-82.843844771065\n",
      "Gradient Descent(7683/9999): loss=5368.251385365535, w0=4.004853316206045, w1=-82.843844771065\n",
      "Gradient Descent(7684/9999): loss=5368.251385365535, w0=4.004853316206045, w1=-82.843844771065\n",
      "Gradient Descent(7685/9999): loss=5368.251385365535, w0=19.81405331620605, w1=-78.950944771065\n",
      "Gradient Descent(7686/9999): loss=5832.09533212309, w0=19.81405331620605, w1=-78.950944771065\n",
      "Gradient Descent(7687/9999): loss=5832.09533212309, w0=19.81405331620605, w1=-78.950944771065\n",
      "Gradient Descent(7688/9999): loss=5832.09533212309, w0=1.9561533162060485, w1=-85.545544771065\n",
      "Gradient Descent(7689/9999): loss=5560.704612421603, w0=1.9561533162060485, w1=-85.545544771065\n",
      "Gradient Descent(7690/9999): loss=5560.704612421603, w0=1.9561533162060485, w1=-85.545544771065\n",
      "Gradient Descent(7691/9999): loss=5560.704612421603, w0=1.9561533162060485, w1=-85.545544771065\n",
      "Gradient Descent(7692/9999): loss=5560.704612421603, w0=1.9561533162060485, w1=-85.545544771065\n",
      "Gradient Descent(7693/9999): loss=5560.704612421603, w0=1.9561533162060485, w1=-85.545544771065\n",
      "Gradient Descent(7694/9999): loss=5560.704612421603, w0=1.9561533162060485, w1=-85.545544771065\n",
      "Gradient Descent(7695/9999): loss=5560.704612421603, w0=1.9561533162060485, w1=-85.545544771065\n",
      "Gradient Descent(7696/9999): loss=5560.704612421603, w0=1.9561533162060485, w1=-85.545544771065\n",
      "Gradient Descent(7697/9999): loss=5560.704612421603, w0=1.9561533162060485, w1=-85.545544771065\n",
      "Gradient Descent(7698/9999): loss=5560.704612421603, w0=1.9561533162060485, w1=-85.545544771065\n",
      "Gradient Descent(7699/9999): loss=5560.704612421603, w0=1.9561533162060485, w1=-85.545544771065\n",
      "Gradient Descent(7700/9999): loss=5560.704612421603, w0=1.9561533162060485, w1=-85.545544771065\n",
      "Gradient Descent(7701/9999): loss=5560.704612421603, w0=1.9561533162060485, w1=-85.545544771065\n",
      "Gradient Descent(7702/9999): loss=5560.704612421603, w0=12.68085331620605, w1=-81.525844771065\n",
      "Gradient Descent(7703/9999): loss=4258.409563751056, w0=12.68085331620605, w1=-81.525844771065\n",
      "Gradient Descent(7704/9999): loss=4258.409563751056, w0=12.68085331620605, w1=-81.525844771065\n",
      "Gradient Descent(7705/9999): loss=4258.409563751056, w0=24.30145331620605, w1=-77.591744771065\n",
      "Gradient Descent(7706/9999): loss=11597.483146491595, w0=8.969553316206051, w1=-86.52904477106499\n",
      "Gradient Descent(7707/9999): loss=4421.139841503678, w0=8.969553316206051, w1=-86.52904477106499\n",
      "Gradient Descent(7708/9999): loss=4421.139841503678, w0=8.969553316206051, w1=-86.52904477106499\n",
      "Gradient Descent(7709/9999): loss=4421.139841503678, w0=3.4701533162060505, w1=-89.98524477106498\n",
      "Gradient Descent(7710/9999): loss=5356.874668245176, w0=3.4701533162060505, w1=-89.98524477106498\n",
      "Gradient Descent(7711/9999): loss=5356.874668245176, w0=3.4701533162060505, w1=-89.98524477106498\n",
      "Gradient Descent(7712/9999): loss=5356.874668245176, w0=3.4701533162060505, w1=-89.98524477106498\n",
      "Gradient Descent(7713/9999): loss=5356.874668245176, w0=3.4701533162060505, w1=-89.98524477106498\n",
      "Gradient Descent(7714/9999): loss=5356.874668245176, w0=14.96755331620605, w1=-82.90784477106499\n",
      "Gradient Descent(7715/9999): loss=5816.052575228488, w0=14.96755331620605, w1=-82.90784477106499\n",
      "Gradient Descent(7716/9999): loss=5816.052575228488, w0=14.96755331620605, w1=-82.90784477106499\n",
      "Gradient Descent(7717/9999): loss=5816.052575228488, w0=14.96755331620605, w1=-82.90784477106499\n",
      "Gradient Descent(7718/9999): loss=5816.052575228488, w0=5.44255331620605, w1=-85.30534477106498\n",
      "Gradient Descent(7719/9999): loss=4314.879135865984, w0=5.44255331620605, w1=-85.30534477106498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(7720/9999): loss=4314.879135865984, w0=5.44255331620605, w1=-85.30534477106498\n",
      "Gradient Descent(7721/9999): loss=4314.879135865984, w0=5.44255331620605, w1=-85.30534477106498\n",
      "Gradient Descent(7722/9999): loss=4314.879135865984, w0=5.44255331620605, w1=-85.30534477106498\n",
      "Gradient Descent(7723/9999): loss=4314.879135865984, w0=5.44255331620605, w1=-85.30534477106498\n",
      "Gradient Descent(7724/9999): loss=4314.879135865984, w0=5.44255331620605, w1=-85.30534477106498\n",
      "Gradient Descent(7725/9999): loss=4314.879135865984, w0=5.44255331620605, w1=-85.30534477106498\n",
      "Gradient Descent(7726/9999): loss=4314.879135865984, w0=5.44255331620605, w1=-85.30534477106498\n",
      "Gradient Descent(7727/9999): loss=4314.879135865984, w0=5.44255331620605, w1=-85.30534477106498\n",
      "Gradient Descent(7728/9999): loss=4314.879135865984, w0=5.44255331620605, w1=-85.30534477106498\n",
      "Gradient Descent(7729/9999): loss=4314.879135865984, w0=5.44255331620605, w1=-85.30534477106498\n",
      "Gradient Descent(7730/9999): loss=4314.879135865984, w0=5.44255331620605, w1=-85.30534477106498\n",
      "Gradient Descent(7731/9999): loss=4314.879135865984, w0=5.442553316206052, w1=-85.30534477106498\n",
      "Gradient Descent(7732/9999): loss=4314.879135865984, w0=-4.435446683793948, w1=-85.77734477106497\n",
      "Gradient Descent(7733/9999): loss=5802.4994844197445, w0=6.584153316206052, w1=-82.37544477106498\n",
      "Gradient Descent(7734/9999): loss=4365.052958757293, w0=6.584153316206052, w1=-82.37544477106498\n",
      "Gradient Descent(7735/9999): loss=4365.052958757293, w0=6.584153316206052, w1=-82.37544477106498\n",
      "Gradient Descent(7736/9999): loss=4365.052958757293, w0=6.584153316206052, w1=-82.37544477106498\n",
      "Gradient Descent(7737/9999): loss=4365.052958757293, w0=6.584153316206052, w1=-82.37544477106498\n",
      "Gradient Descent(7738/9999): loss=4365.052958757293, w0=6.584153316206052, w1=-82.37544477106498\n",
      "Gradient Descent(7739/9999): loss=4365.052958757293, w0=6.584153316206052, w1=-82.37544477106498\n",
      "Gradient Descent(7740/9999): loss=4365.052958757293, w0=6.584153316206052, w1=-82.37544477106498\n",
      "Gradient Descent(7741/9999): loss=4365.052958757293, w0=1.0111721489939898, w1=-84.41777258127392\n",
      "Gradient Descent(7742/9999): loss=4766.014822426718, w0=1.0111721489939898, w1=-84.41777258127392\n",
      "Gradient Descent(7743/9999): loss=4766.014822426718, w0=1.0111721489939898, w1=-84.41777258127392\n",
      "Gradient Descent(7744/9999): loss=4766.014822426718, w0=1.0111721489939898, w1=-84.41777258127392\n",
      "Gradient Descent(7745/9999): loss=4766.014822426718, w0=1.0111721489939898, w1=-84.41777258127392\n",
      "Gradient Descent(7746/9999): loss=4766.014822426718, w0=1.0111721489939898, w1=-84.41777258127392\n",
      "Gradient Descent(7747/9999): loss=4766.014822426718, w0=1.0111721489939898, w1=-84.41777258127392\n",
      "Gradient Descent(7748/9999): loss=4766.014822426718, w0=1.0111721489939898, w1=-84.41777258127392\n",
      "Gradient Descent(7749/9999): loss=4766.014822426718, w0=10.14307214899399, w1=-81.35477258127392\n",
      "Gradient Descent(7750/9999): loss=4478.510682873529, w0=10.14307214899399, w1=-81.35477258127392\n",
      "Gradient Descent(7751/9999): loss=4478.510682873529, w0=10.14307214899399, w1=-81.35477258127392\n",
      "Gradient Descent(7752/9999): loss=4478.510682873529, w0=10.14307214899399, w1=-81.35477258127392\n",
      "Gradient Descent(7753/9999): loss=4478.510682873529, w0=10.14307214899399, w1=-81.35477258127392\n",
      "Gradient Descent(7754/9999): loss=4478.510682873529, w0=10.14307214899399, w1=-81.35477258127392\n",
      "Gradient Descent(7755/9999): loss=4478.510682873529, w0=10.14307214899399, w1=-81.35477258127392\n",
      "Gradient Descent(7756/9999): loss=4478.510682873529, w0=10.14307214899399, w1=-81.35477258127392\n",
      "Gradient Descent(7757/9999): loss=4478.510682873529, w0=10.14307214899399, w1=-81.35477258127392\n",
      "Gradient Descent(7758/9999): loss=4478.510682873529, w0=10.14307214899399, w1=-81.35477258127392\n",
      "Gradient Descent(7759/9999): loss=4478.510682873529, w0=10.14307214899399, w1=-81.35477258127392\n",
      "Gradient Descent(7760/9999): loss=4478.510682873529, w0=10.14307214899399, w1=-81.35477258127392\n",
      "Gradient Descent(7761/9999): loss=4478.510682873529, w0=10.14307214899399, w1=-81.35477258127392\n",
      "Gradient Descent(7762/9999): loss=4478.510682873529, w0=-0.14872785100600971, w1=-81.84337258127393\n",
      "Gradient Descent(7763/9999): loss=5549.994076045429, w0=-0.14872785100600971, w1=-81.84337258127393\n",
      "Gradient Descent(7764/9999): loss=5549.994076045429, w0=-0.14872785100600971, w1=-81.84337258127393\n",
      "Gradient Descent(7765/9999): loss=5549.994076045429, w0=-0.14872785100600971, w1=-81.84337258127393\n",
      "Gradient Descent(7766/9999): loss=5549.994076045429, w0=-0.14872785100600971, w1=-81.84337258127393\n",
      "Gradient Descent(7767/9999): loss=5549.994076045429, w0=-0.14872785100600971, w1=-81.84337258127393\n",
      "Gradient Descent(7768/9999): loss=5549.994076045429, w0=-0.14872785100600971, w1=-81.84337258127393\n",
      "Gradient Descent(7769/9999): loss=5549.994076045429, w0=11.34867214899399, w1=-74.76597258127393\n",
      "Gradient Descent(7770/9999): loss=6120.589715424282, w0=11.34867214899399, w1=-74.76597258127393\n",
      "Gradient Descent(7771/9999): loss=6120.589715424282, w0=11.34867214899399, w1=-74.76597258127393\n",
      "Gradient Descent(7772/9999): loss=6120.589715424282, w0=11.34867214899399, w1=-74.76597258127393\n",
      "Gradient Descent(7773/9999): loss=6120.589715424282, w0=11.34867214899399, w1=-74.76597258127393\n",
      "Gradient Descent(7774/9999): loss=6120.589715424282, w0=11.34867214899399, w1=-74.76597258127393\n",
      "Gradient Descent(7775/9999): loss=6120.589715424282, w0=11.34867214899399, w1=-74.76597258127393\n",
      "Gradient Descent(7776/9999): loss=6120.589715424282, w0=11.34867214899399, w1=-74.76597258127393\n",
      "Gradient Descent(7777/9999): loss=6120.589715424282, w0=11.34867214899399, w1=-74.76597258127393\n",
      "Gradient Descent(7778/9999): loss=6120.589715424282, w0=11.34867214899399, w1=-74.76597258127393\n",
      "Gradient Descent(7779/9999): loss=6120.589715424282, w0=11.34867214899399, w1=-74.76597258127393\n",
      "Gradient Descent(7780/9999): loss=6120.589715424282, w0=2.19827214899399, w1=-78.08047258127392\n",
      "Gradient Descent(7781/9999): loss=4340.4336433893295, w0=2.19827214899399, w1=-78.08047258127392\n",
      "Gradient Descent(7782/9999): loss=4340.4336433893295, w0=2.19827214899399, w1=-78.08047258127392\n",
      "Gradient Descent(7783/9999): loss=4340.4336433893295, w0=14.265037534547524, w1=-72.80437258127392\n",
      "Gradient Descent(7784/9999): loss=8688.049867388514, w0=14.265037534547524, w1=-72.80437258127392\n",
      "Gradient Descent(7785/9999): loss=8688.049867388514, w0=14.265037534547524, w1=-72.80437258127392\n",
      "Gradient Descent(7786/9999): loss=8688.049867388514, w0=0.804337534547523, w1=-76.35877258127393\n",
      "Gradient Descent(7787/9999): loss=4493.719835172932, w0=9.040937534547524, w1=-73.65937258127393\n",
      "Gradient Descent(7788/9999): loss=5702.045063143719, w0=-4.910462465452477, w1=-74.49517258127393\n",
      "Gradient Descent(7789/9999): loss=5434.102095378859, w0=7.156302920101057, w1=-63.457972581273935\n",
      "Gradient Descent(7790/9999): loss=6642.06590432872, w0=7.156302920101057, w1=-63.457972581273935\n",
      "Gradient Descent(7791/9999): loss=6642.06590432872, w0=-0.14159707989894343, w1=-65.17257258127394\n",
      "Gradient Descent(7792/9999): loss=4318.175135692792, w0=-0.14159707989894343, w1=-65.17257258127394\n",
      "Gradient Descent(7793/9999): loss=4318.175135692792, w0=-0.14159707989894343, w1=-65.17257258127394\n",
      "Gradient Descent(7794/9999): loss=4318.175135692792, w0=-0.14159707989894343, w1=-65.17257258127394\n",
      "Gradient Descent(7795/9999): loss=4318.175135692792, w0=-0.14159707989894343, w1=-65.17257258127394\n",
      "Gradient Descent(7796/9999): loss=4318.175135692792, w0=-0.14159707989894343, w1=-65.17257258127394\n",
      "Gradient Descent(7797/9999): loss=4318.175135692792, w0=-0.14159707989894343, w1=-65.17257258127394\n",
      "Gradient Descent(7798/9999): loss=4318.175135692792, w0=-0.14159707989894343, w1=-65.17257258127394\n",
      "Gradient Descent(7799/9999): loss=4318.175135692792, w0=-0.14159707989894343, w1=-65.17257258127394\n",
      "Gradient Descent(7800/9999): loss=4318.175135692792, w0=-0.14159707989894343, w1=-65.17257258127394\n",
      "Gradient Descent(7801/9999): loss=4318.175135692792, w0=-0.14159707989894343, w1=-65.17257258127394\n",
      "Gradient Descent(7802/9999): loss=4318.175135692792, w0=-0.14159707989894343, w1=-65.17257258127394\n",
      "Gradient Descent(7803/9999): loss=4318.175135692792, w0=10.195002920101057, w1=-62.74727258127394\n",
      "Gradient Descent(7804/9999): loss=9780.779816427841, w0=2.8180029201010575, w1=-67.86317258127394\n",
      "Gradient Descent(7805/9999): loss=4259.766108395311, w0=2.8180029201010575, w1=-67.86317258127394\n",
      "Gradient Descent(7806/9999): loss=4259.766108395311, w0=-4.662397079898943, w1=-69.95857258127394\n",
      "Gradient Descent(7807/9999): loss=5457.9606406504, w0=-4.662397079898943, w1=-69.95857258127394\n",
      "Gradient Descent(7808/9999): loss=5457.9606406504, w0=-4.662397079898943, w1=-69.95857258127394\n",
      "Gradient Descent(7809/9999): loss=5457.9606406504, w0=-4.662397079898943, w1=-69.95857258127394\n",
      "Gradient Descent(7810/9999): loss=5457.9606406504, w0=-4.662397079898943, w1=-69.95857258127394\n",
      "Gradient Descent(7811/9999): loss=5457.9606406504, w0=5.055502920101057, w1=-66.11787258127394\n",
      "Gradient Descent(7812/9999): loss=4200.889381206464, w0=5.055502920101057, w1=-66.11787258127394\n",
      "Gradient Descent(7813/9999): loss=4200.889381206464, w0=5.055502920101057, w1=-66.11787258127394\n",
      "Gradient Descent(7814/9999): loss=4200.889381206464, w0=-4.613097079898944, w1=-67.09137258127394\n",
      "Gradient Descent(7815/9999): loss=5643.608351770484, w0=-4.613097079898944, w1=-67.09137258127394\n",
      "Gradient Descent(7816/9999): loss=5643.608351770484, w0=13.283202920101056, w1=-59.67427258127394\n",
      "Gradient Descent(7817/9999): loss=6987.906415606246, w0=13.283202920101056, w1=-59.67427258127394\n",
      "Gradient Descent(7818/9999): loss=6987.906415606246, w0=13.283202920101056, w1=-59.67427258127394\n",
      "Gradient Descent(7819/9999): loss=6987.906415606246, w0=13.283202920101056, w1=-59.67427258127394\n",
      "Gradient Descent(7820/9999): loss=6987.906415606246, w0=13.283202920101056, w1=-59.67427258127394\n",
      "Gradient Descent(7821/9999): loss=6987.906415606246, w0=13.283202920101056, w1=-59.67427258127394\n",
      "Gradient Descent(7822/9999): loss=6987.906415606246, w0=13.283202920101056, w1=-59.67427258127394\n",
      "Gradient Descent(7823/9999): loss=6987.906415606246, w0=13.283202920101056, w1=-59.67427258127394\n",
      "Gradient Descent(7824/9999): loss=6987.906415606246, w0=13.283202920101056, w1=-59.67427258127394\n",
      "Gradient Descent(7825/9999): loss=6987.906415606246, w0=13.283202920101056, w1=-59.67427258127394\n",
      "Gradient Descent(7826/9999): loss=6987.906415606246, w0=4.318102920101055, w1=-63.64447258127394\n",
      "Gradient Descent(7827/9999): loss=4422.840659761281, w0=-3.650397079898946, w1=-64.39507258127394\n",
      "Gradient Descent(7828/9999): loss=5698.880712387148, w0=9.643802920101056, w1=-62.61887258127393\n",
      "Gradient Descent(7829/9999): loss=4300.487695986888, w0=9.643802920101056, w1=-62.61887258127393\n",
      "Gradient Descent(7830/9999): loss=4300.487695986888, w0=9.643802920101056, w1=-62.61887258127393\n",
      "Gradient Descent(7831/9999): loss=4300.487695986888, w0=9.643802920101056, w1=-62.61887258127393\n",
      "Gradient Descent(7832/9999): loss=4300.487695986888, w0=9.643802920101056, w1=-62.61887258127393\n",
      "Gradient Descent(7833/9999): loss=4300.487695986888, w0=9.643802920101056, w1=-62.61887258127393\n",
      "Gradient Descent(7834/9999): loss=4300.487695986888, w0=9.643802920101056, w1=-62.61887258127393\n",
      "Gradient Descent(7835/9999): loss=4300.487695986888, w0=9.643802920101056, w1=-62.61887258127393\n",
      "Gradient Descent(7836/9999): loss=4300.487695986888, w0=9.643802920101056, w1=-62.61887258127393\n",
      "Gradient Descent(7837/9999): loss=4300.487695986888, w0=9.643802920101056, w1=-62.61887258127393\n",
      "Gradient Descent(7838/9999): loss=4300.487695986888, w0=9.643802920101056, w1=-62.61887258127393\n",
      "Gradient Descent(7839/9999): loss=4300.487695986888, w0=9.643802920101056, w1=-62.61887258127393\n",
      "Gradient Descent(7840/9999): loss=4300.487695986888, w0=9.643802920101056, w1=-62.61887258127393\n",
      "Gradient Descent(7841/9999): loss=4300.487695986888, w0=9.643802920101056, w1=-62.61887258127393\n",
      "Gradient Descent(7842/9999): loss=4300.487695986888, w0=9.643802920101056, w1=-62.61887258127393\n",
      "Gradient Descent(7843/9999): loss=4300.487695986888, w0=0.8477029201010549, w1=-65.45717258127394\n",
      "Gradient Descent(7844/9999): loss=5295.928728826994, w0=0.8477029201010549, w1=-65.45717258127394\n",
      "Gradient Descent(7845/9999): loss=5295.928728826994, w0=14.531002920101056, w1=-64.75097258127394\n",
      "Gradient Descent(7846/9999): loss=4382.644231518339, w0=14.531002920101056, w1=-64.75097258127394\n",
      "Gradient Descent(7847/9999): loss=4382.644231518339, w0=14.531002920101056, w1=-64.75097258127394\n",
      "Gradient Descent(7848/9999): loss=4382.644231518339, w0=14.531002920101056, w1=-64.75097258127394\n",
      "Gradient Descent(7849/9999): loss=4382.644231518339, w0=14.531002920101056, w1=-64.75097258127394\n",
      "Gradient Descent(7850/9999): loss=4382.644231518339, w0=14.531002920101056, w1=-64.75097258127394\n",
      "Gradient Descent(7851/9999): loss=4382.644231518339, w0=14.531002920101056, w1=-64.75097258127394\n",
      "Gradient Descent(7852/9999): loss=4382.644231518339, w0=14.531002920101056, w1=-64.75097258127394\n",
      "Gradient Descent(7853/9999): loss=4382.644231518339, w0=14.531002920101056, w1=-64.75097258127394\n",
      "Gradient Descent(7854/9999): loss=4382.644231518339, w0=24.319602920101058, w1=-62.98417258127394\n",
      "Gradient Descent(7855/9999): loss=12724.98715720083, w0=4.146602920101056, w1=-70.00187258127394\n",
      "Gradient Descent(7856/9999): loss=4485.002556864611, w0=4.146602920101056, w1=-70.00187258127394\n",
      "Gradient Descent(7857/9999): loss=4485.002556864611, w0=4.146602920101056, w1=-70.00187258127394\n",
      "Gradient Descent(7858/9999): loss=4485.002556864611, w0=4.146602920101056, w1=-70.00187258127394\n",
      "Gradient Descent(7859/9999): loss=4485.002556864611, w0=4.146602920101056, w1=-70.00187258127394\n",
      "Gradient Descent(7860/9999): loss=4485.002556864611, w0=4.146602920101056, w1=-70.00187258127394\n",
      "Gradient Descent(7861/9999): loss=4485.002556864611, w0=12.134002920101057, w1=-66.37667258127394\n",
      "Gradient Descent(7862/9999): loss=5179.850506496231, w0=12.134002920101057, w1=-66.37667258127394\n",
      "Gradient Descent(7863/9999): loss=5179.850506496231, w0=12.134002920101057, w1=-66.37667258127394\n",
      "Gradient Descent(7864/9999): loss=5179.850506496231, w0=7.142702920101057, w1=-68.83317258127394\n",
      "Gradient Descent(7865/9999): loss=4628.874037628289, w0=7.142702920101057, w1=-68.83317258127394\n",
      "Gradient Descent(7866/9999): loss=4628.874037628289, w0=7.142702920101057, w1=-68.83317258127394\n",
      "Gradient Descent(7867/9999): loss=4628.874037628289, w0=7.142702920101057, w1=-68.83317258127394\n",
      "Gradient Descent(7868/9999): loss=4628.874037628289, w0=7.142702920101057, w1=-68.83317258127394\n",
      "Gradient Descent(7869/9999): loss=4628.874037628289, w0=15.326602920101056, w1=-67.28077258127394\n",
      "Gradient Descent(7870/9999): loss=6933.33276666017, w0=15.326602920101056, w1=-67.28077258127394\n",
      "Gradient Descent(7871/9999): loss=6933.33276666017, w0=25.79060292010106, w1=-60.136672581273935\n",
      "Gradient Descent(7872/9999): loss=16275.297341883217, w0=25.79060292010106, w1=-60.136672581273935\n",
      "Gradient Descent(7873/9999): loss=16275.297341883217, w0=7.089202920101055, w1=-68.89367258127393\n",
      "Gradient Descent(7874/9999): loss=4197.272358004271, w0=7.089202920101055, w1=-68.89367258127393\n",
      "Gradient Descent(7875/9999): loss=4197.272358004271, w0=7.089202920101055, w1=-68.89367258127393\n",
      "Gradient Descent(7876/9999): loss=4197.272358004271, w0=7.089202920101055, w1=-68.89367258127393\n",
      "Gradient Descent(7877/9999): loss=4197.272358004271, w0=17.457202920101057, w1=-62.51627258127393\n",
      "Gradient Descent(7878/9999): loss=9873.304700457687, w0=5.390437534547523, w1=-73.88127258127393\n",
      "Gradient Descent(7879/9999): loss=4884.899566563128, w0=5.390437534547523, w1=-73.88127258127393\n",
      "Gradient Descent(7880/9999): loss=4884.899566563128, w0=5.390437534547523, w1=-73.88127258127393\n",
      "Gradient Descent(7881/9999): loss=4884.899566563128, w0=5.390437534547523, w1=-73.88127258127393\n",
      "Gradient Descent(7882/9999): loss=4884.899566563128, w0=22.366137534547523, w1=-69.55627258127393\n",
      "Gradient Descent(7883/9999): loss=7586.1535780526665, w0=33.67693753454752, w1=-62.256072581273926\n",
      "Gradient Descent(7884/9999): loss=16958.53411618622, w0=27.811737534547518, w1=-69.13487258127392\n",
      "Gradient Descent(7885/9999): loss=11741.287901048818, w0=18.442637534547515, w1=-71.33347258127392\n",
      "Gradient Descent(7886/9999): loss=4525.085219962, w0=18.442637534547515, w1=-71.33347258127392\n",
      "Gradient Descent(7887/9999): loss=4525.085219962, w0=18.442637534547515, w1=-71.33347258127392\n",
      "Gradient Descent(7888/9999): loss=4525.085219962, w0=18.442637534547515, w1=-71.33347258127392\n",
      "Gradient Descent(7889/9999): loss=4525.085219962, w0=30.50940292010105, w1=-63.002572581273924\n",
      "Gradient Descent(7890/9999): loss=14736.512458282476, w0=17.124702920101047, w1=-67.20657258127392\n",
      "Gradient Descent(7891/9999): loss=5397.3016183480395, w0=17.124702920101047, w1=-67.20657258127392\n",
      "Gradient Descent(7892/9999): loss=5397.3016183480395, w0=17.124702920101047, w1=-67.20657258127392\n",
      "Gradient Descent(7893/9999): loss=5397.3016183480395, w0=17.124702920101047, w1=-67.20657258127392\n",
      "Gradient Descent(7894/9999): loss=5397.3016183480395, w0=17.124702920101047, w1=-67.20657258127392\n",
      "Gradient Descent(7895/9999): loss=5397.3016183480395, w0=3.380302920101048, w1=-73.52337258127392\n",
      "Gradient Descent(7896/9999): loss=4859.167809713459, w0=3.380302920101048, w1=-73.52337258127392\n",
      "Gradient Descent(7897/9999): loss=4859.167809713459, w0=3.380302920101048, w1=-73.52337258127392\n",
      "Gradient Descent(7898/9999): loss=4859.167809713459, w0=3.380302920101048, w1=-73.52337258127392\n",
      "Gradient Descent(7899/9999): loss=4859.167809713459, w0=3.380302920101048, w1=-73.52337258127392\n",
      "Gradient Descent(7900/9999): loss=4859.167809713459, w0=3.380302920101048, w1=-73.52337258127392\n",
      "Gradient Descent(7901/9999): loss=4859.167809713459, w0=3.380302920101048, w1=-73.52337258127392\n",
      "Gradient Descent(7902/9999): loss=4859.167809713459, w0=3.380302920101048, w1=-73.52337258127392\n",
      "Gradient Descent(7903/9999): loss=4859.167809713459, w0=3.380302920101048, w1=-73.52337258127392\n",
      "Gradient Descent(7904/9999): loss=4859.167809713459, w0=3.380302920101048, w1=-73.52337258127392\n",
      "Gradient Descent(7905/9999): loss=4859.167809713459, w0=3.380302920101048, w1=-73.52337258127392\n",
      "Gradient Descent(7906/9999): loss=4859.167809713459, w0=15.447068305654582, w1=-66.70707258127392\n",
      "Gradient Descent(7907/9999): loss=4722.206041469173, w0=25.88176830565458, w1=-62.26677258127392\n",
      "Gradient Descent(7908/9999): loss=11577.603151203266, w0=25.88176830565458, w1=-62.26677258127392\n",
      "Gradient Descent(7909/9999): loss=11577.603151203266, w0=25.88176830565458, w1=-62.26677258127392\n",
      "Gradient Descent(7910/9999): loss=11577.603151203266, w0=25.88176830565458, w1=-62.26677258127392\n",
      "Gradient Descent(7911/9999): loss=11577.603151203266, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7912/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7913/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7914/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7915/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7916/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7917/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7918/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7919/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7920/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7921/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7922/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7923/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7924/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7925/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7926/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7927/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7928/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7929/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7930/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7931/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7932/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7933/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7934/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7935/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7936/9999): loss=4520.642451458572, w0=13.815002920101048, w1=-69.15287258127393\n",
      "Gradient Descent(7937/9999): loss=4520.642451458572, w0=23.42280292010105, w1=-66.52727258127392\n",
      "Gradient Descent(7938/9999): loss=11812.248727082188, w0=11.356037534547514, w1=-72.76087258127392\n",
      "Gradient Descent(7939/9999): loss=5012.590843910868, w0=11.356037534547514, w1=-72.76087258127392\n",
      "Gradient Descent(7940/9999): loss=5012.590843910868, w0=2.188937534547513, w1=-75.98737258127392\n",
      "Gradient Descent(7941/9999): loss=4747.740714094983, w0=9.360037534547512, w1=-72.63987258127392\n",
      "Gradient Descent(7942/9999): loss=4833.493588476446, w0=9.360037534547512, w1=-72.63987258127392\n",
      "Gradient Descent(7943/9999): loss=4833.493588476446, w0=9.360037534547512, w1=-72.63987258127392\n",
      "Gradient Descent(7944/9999): loss=4833.493588476446, w0=9.360037534547512, w1=-72.63987258127392\n",
      "Gradient Descent(7945/9999): loss=4833.493588476446, w0=-1.0155624654524882, w1=-73.28697258127391\n",
      "Gradient Descent(7946/9999): loss=4835.488891775486, w0=8.310137534547513, w1=-70.29717258127391\n",
      "Gradient Descent(7947/9999): loss=4791.897785125057, w0=8.310137534547513, w1=-70.29717258127391\n",
      "Gradient Descent(7948/9999): loss=4791.897785125057, w0=8.310137534547513, w1=-70.29717258127391\n",
      "Gradient Descent(7949/9999): loss=4791.897785125057, w0=-0.9149624654524882, w1=-70.84477258127392\n",
      "Gradient Descent(7950/9999): loss=4736.978382281597, w0=-0.9149624654524882, w1=-70.84477258127392\n",
      "Gradient Descent(7951/9999): loss=4736.978382281597, w0=-0.9149624654524882, w1=-70.84477258127392\n",
      "Gradient Descent(7952/9999): loss=4736.978382281597, w0=9.439037534547513, w1=-66.34357258127392\n",
      "Gradient Descent(7953/9999): loss=6735.788937570197, w0=9.439037534547513, w1=-66.34357258127392\n",
      "Gradient Descent(7954/9999): loss=6735.788937570197, w0=-0.08596246545248754, w1=-68.74107258127391\n",
      "Gradient Descent(7955/9999): loss=4406.030406032069, w0=-0.08596246545248754, w1=-68.74107258127391\n",
      "Gradient Descent(7956/9999): loss=4406.030406032069, w0=-0.08596246545248754, w1=-68.74107258127391\n",
      "Gradient Descent(7957/9999): loss=4406.030406032069, w0=12.189137534547514, w1=-63.55947258127391\n",
      "Gradient Descent(7958/9999): loss=7613.408172195908, w0=12.189137534547514, w1=-63.55947258127391\n",
      "Gradient Descent(7959/9999): loss=7613.408172195908, w0=2.3111375345475142, w1=-64.0314725812739\n",
      "Gradient Descent(7960/9999): loss=4347.810252795155, w0=2.3111375345475142, w1=-64.0314725812739\n",
      "Gradient Descent(7961/9999): loss=4347.810252795155, w0=2.3111375345475142, w1=-64.0314725812739\n",
      "Gradient Descent(7962/9999): loss=4347.810252795155, w0=2.3111375345475142, w1=-64.0314725812739\n",
      "Gradient Descent(7963/9999): loss=4347.810252795155, w0=2.3111375345475142, w1=-64.0314725812739\n",
      "Gradient Descent(7964/9999): loss=4347.810252795155, w0=9.569437534547514, w1=-59.7771725812739\n",
      "Gradient Descent(7965/9999): loss=7849.525877706821, w0=2.864237534547515, w1=-62.1058725812739\n",
      "Gradient Descent(7966/9999): loss=4273.818976419054, w0=13.042237534547516, w1=-56.2851725812739\n",
      "Gradient Descent(7967/9999): loss=8639.569246882504, w0=13.042237534547516, w1=-56.2851725812739\n",
      "Gradient Descent(7968/9999): loss=8639.569246882504, w0=0.9754721489939815, w1=-68.3069725812739\n",
      "Gradient Descent(7969/9999): loss=5802.4994844197445, w0=0.9754721489939815, w1=-68.3069725812739\n",
      "Gradient Descent(7970/9999): loss=5802.4994844197445, w0=12.286272148993982, w1=-61.00677258127389\n",
      "Gradient Descent(7971/9999): loss=4202.834907599419, w0=19.86347214899398, w1=-57.79697258127389\n",
      "Gradient Descent(7972/9999): loss=8003.808380714103, w0=19.86347214899398, w1=-57.79697258127389\n",
      "Gradient Descent(7973/9999): loss=8003.808380714103, w0=7.796706763440447, w1=-63.67557258127389\n",
      "Gradient Descent(7974/9999): loss=5802.4994844197445, w0=7.796706763440447, w1=-63.67557258127389\n",
      "Gradient Descent(7975/9999): loss=5802.4994844197445, w0=7.796706763440447, w1=-63.67557258127389\n",
      "Gradient Descent(7976/9999): loss=5802.4994844197445, w0=7.796706763440447, w1=-63.67557258127389\n",
      "Gradient Descent(7977/9999): loss=5802.4994844197445, w0=7.796706763440447, w1=-63.67557258127389\n",
      "Gradient Descent(7978/9999): loss=5802.4994844197445, w0=19.86347214899398, w1=-59.77157258127389\n",
      "Gradient Descent(7979/9999): loss=4236.828230136982, w0=19.86347214899398, w1=-59.77157258127389\n",
      "Gradient Descent(7980/9999): loss=4236.828230136982, w0=11.98337214899398, w1=-61.92997258127389\n",
      "Gradient Descent(7981/9999): loss=5422.572611087423, w0=11.98337214899398, w1=-61.92997258127389\n",
      "Gradient Descent(7982/9999): loss=5422.572611087423, w0=22.873072148993984, w1=-54.19387258127389\n",
      "Gradient Descent(7983/9999): loss=5380.127142442064, w0=22.873072148993984, w1=-54.19387258127389\n",
      "Gradient Descent(7984/9999): loss=5380.127142442064, w0=22.873072148993984, w1=-54.19387258127389\n",
      "Gradient Descent(7985/9999): loss=5380.127142442064, w0=22.873072148993984, w1=-54.19387258127389\n",
      "Gradient Descent(7986/9999): loss=5380.127142442064, w0=22.873072148993984, w1=-54.19387258127389\n",
      "Gradient Descent(7987/9999): loss=5380.127142442064, w0=22.873072148993984, w1=-54.19387258127389\n",
      "Gradient Descent(7988/9999): loss=5380.127142442064, w0=15.785472148993982, w1=-58.07537258127389\n",
      "Gradient Descent(7989/9999): loss=4682.208116796945, w0=15.785472148993982, w1=-58.07537258127389\n",
      "Gradient Descent(7990/9999): loss=4682.208116796945, w0=15.785472148993982, w1=-58.07537258127389\n",
      "Gradient Descent(7991/9999): loss=4682.208116796945, w0=15.785472148993982, w1=-58.07537258127389\n",
      "Gradient Descent(7992/9999): loss=4682.208116796945, w0=15.785472148993982, w1=-58.07537258127389\n",
      "Gradient Descent(7993/9999): loss=4682.208116796945, w0=15.785472148993982, w1=-58.07537258127389\n",
      "Gradient Descent(7994/9999): loss=4682.208116796945, w0=15.785472148993982, w1=-58.07537258127389\n",
      "Gradient Descent(7995/9999): loss=4682.208116796945, w0=27.558472148993985, w1=-50.34717258127389\n",
      "Gradient Descent(7996/9999): loss=10019.585767484761, w0=20.468272148993986, w1=-53.18407258127389\n",
      "Gradient Descent(7997/9999): loss=4392.923629411185, w0=34.075572148993984, w1=-48.00727258127389\n",
      "Gradient Descent(7998/9999): loss=11577.181260269337, w0=34.075572148993984, w1=-48.00727258127389\n",
      "Gradient Descent(7999/9999): loss=11577.181260269337, w0=24.341672148993986, w1=-50.184872581273886\n",
      "Gradient Descent(8000/9999): loss=4648.788174803107, w0=24.341672148993986, w1=-50.184872581273886\n",
      "Gradient Descent(8001/9999): loss=4648.788174803107, w0=24.341672148993986, w1=-50.184872581273886\n",
      "Gradient Descent(8002/9999): loss=4648.788174803107, w0=33.223672148993984, w1=-47.63957258127389\n",
      "Gradient Descent(8003/9999): loss=9647.466336681493, w0=33.223672148993984, w1=-47.63957258127389\n",
      "Gradient Descent(8004/9999): loss=9647.466336681493, w0=0.5227721489939796, w1=-53.14187258127389\n",
      "Gradient Descent(8005/9999): loss=5802.4994844197445, w0=11.883972148993982, w1=-51.216972581273886\n",
      "Gradient Descent(8006/9999): loss=4313.201580054672, w0=11.883972148993982, w1=-51.216972581273886\n",
      "Gradient Descent(8007/9999): loss=4313.201580054672, w0=23.950737534547514, w1=-44.102672581273886\n",
      "Gradient Descent(8008/9999): loss=11413.925520066547, w0=23.950737534547514, w1=-44.102672581273886\n",
      "Gradient Descent(8009/9999): loss=11413.925520066547, w0=7.674737534547514, w1=-54.383672581273885\n",
      "Gradient Descent(8010/9999): loss=4847.643716755301, w0=7.674737534547514, w1=-54.383672581273885\n",
      "Gradient Descent(8011/9999): loss=4847.643716755301, w0=16.579337534547513, w1=-51.10487258127388\n",
      "Gradient Descent(8012/9999): loss=5268.991327404849, w0=16.579337534547513, w1=-51.10487258127388\n",
      "Gradient Descent(8013/9999): loss=5268.991327404849, w0=16.579337534547513, w1=-51.10487258127388\n",
      "Gradient Descent(8014/9999): loss=5268.991327404849, w0=16.579337534547513, w1=-51.10487258127388\n",
      "Gradient Descent(8015/9999): loss=5268.991327404849, w0=16.579337534547513, w1=-51.10487258127388\n",
      "Gradient Descent(8016/9999): loss=5268.991327404849, w0=16.579337534547513, w1=-51.10487258127388\n",
      "Gradient Descent(8017/9999): loss=5268.991327404849, w0=16.579337534547513, w1=-51.10487258127388\n",
      "Gradient Descent(8018/9999): loss=5268.991327404849, w0=16.579337534547513, w1=-51.10487258127388\n",
      "Gradient Descent(8019/9999): loss=5268.991327404849, w0=8.460237534547511, w1=-55.09207258127388\n",
      "Gradient Descent(8020/9999): loss=4836.294904344217, w0=8.460237534547511, w1=-55.09207258127388\n",
      "Gradient Descent(8021/9999): loss=4836.294904344217, w0=8.460237534547511, w1=-55.09207258127388\n",
      "Gradient Descent(8022/9999): loss=4836.294904344217, w0=8.460237534547511, w1=-55.09207258127388\n",
      "Gradient Descent(8023/9999): loss=4836.294904344217, w0=8.460237534547511, w1=-55.09207258127388\n",
      "Gradient Descent(8024/9999): loss=4836.294904344217, w0=20.509137534547513, w1=-54.847472581273884\n",
      "Gradient Descent(8025/9999): loss=8790.272162178131, w0=7.459637534547511, w1=-58.19587258127388\n",
      "Gradient Descent(8026/9999): loss=4397.921889206453, w0=7.459637534547511, w1=-58.19587258127388\n",
      "Gradient Descent(8027/9999): loss=4397.921889206453, w0=7.459637534547511, w1=-58.19587258127388\n",
      "Gradient Descent(8028/9999): loss=4397.921889206453, w0=7.459637534547511, w1=-58.19587258127388\n",
      "Gradient Descent(8029/9999): loss=4397.921889206453, w0=7.459637534547511, w1=-58.19587258127388\n",
      "Gradient Descent(8030/9999): loss=4397.921889206453, w0=18.89693753454751, w1=-54.232972581273884\n",
      "Gradient Descent(8031/9999): loss=10984.863542367451, w0=18.89693753454751, w1=-54.232972581273884\n",
      "Gradient Descent(8032/9999): loss=10984.863542367451, w0=18.89693753454751, w1=-54.232972581273884\n",
      "Gradient Descent(8033/9999): loss=10984.863542367451, w0=18.89693753454751, w1=-54.232972581273884\n",
      "Gradient Descent(8034/9999): loss=10984.863542367451, w0=8.528837534547511, w1=-59.95377258127388\n",
      "Gradient Descent(8035/9999): loss=4412.486727252965, w0=8.528837534547511, w1=-59.95377258127388\n",
      "Gradient Descent(8036/9999): loss=4412.486727252965, w0=8.528837534547511, w1=-59.95377258127388\n",
      "Gradient Descent(8037/9999): loss=4412.486727252965, w0=8.528837534547511, w1=-59.95377258127388\n",
      "Gradient Descent(8038/9999): loss=4412.486727252965, w0=8.528837534547511, w1=-59.95377258127388\n",
      "Gradient Descent(8039/9999): loss=4412.486727252965, w0=21.132637534547513, w1=-56.78547258127388\n",
      "Gradient Descent(8040/9999): loss=7619.1282319007605, w0=21.132637534547513, w1=-56.78547258127388\n",
      "Gradient Descent(8041/9999): loss=7619.1282319007605, w0=21.132637534547513, w1=-56.78547258127388\n",
      "Gradient Descent(8042/9999): loss=7619.1282319007605, w0=33.19940292010105, w1=-41.705272581273874\n",
      "Gradient Descent(8043/9999): loss=17108.202110971408, w0=21.132637534547516, w1=-49.15997258127388\n",
      "Gradient Descent(8044/9999): loss=15943.152475272156, w0=21.132637534547516, w1=-49.15997258127388\n",
      "Gradient Descent(8045/9999): loss=15943.152475272156, w0=7.683637534547515, w1=-49.828772581273874\n",
      "Gradient Descent(8046/9999): loss=4426.396488689689, w0=7.683637534547515, w1=-49.828772581273874\n",
      "Gradient Descent(8047/9999): loss=4426.396488689689, w0=7.683637534547515, w1=-49.828772581273874\n",
      "Gradient Descent(8048/9999): loss=4426.396488689689, w0=-10.066562465452488, w1=-53.687272581273874\n",
      "Gradient Descent(8049/9999): loss=5802.4994844197445, w0=-10.066562465452488, w1=-53.687272581273874\n",
      "Gradient Descent(8050/9999): loss=5802.4994844197445, w0=-10.066562465452488, w1=-53.687272581273874\n",
      "Gradient Descent(8051/9999): loss=5802.4994844197445, w0=-10.066562465452488, w1=-53.687272581273874\n",
      "Gradient Descent(8052/9999): loss=5802.4994844197445, w0=3.623837534547512, w1=-51.82787258127387\n",
      "Gradient Descent(8053/9999): loss=4383.756441596095, w0=3.623837534547512, w1=-51.82787258127387\n",
      "Gradient Descent(8054/9999): loss=4383.756441596095, w0=3.623837534547512, w1=-51.82787258127387\n",
      "Gradient Descent(8055/9999): loss=4383.756441596095, w0=3.623837534547512, w1=-51.82787258127387\n",
      "Gradient Descent(8056/9999): loss=4383.756441596095, w0=15.148637534547511, w1=-49.28117258127387\n",
      "Gradient Descent(8057/9999): loss=12731.337301394728, w0=15.148637534547511, w1=-49.28117258127387\n",
      "Gradient Descent(8058/9999): loss=12731.337301394728, w0=15.148637534547511, w1=-49.28117258127387\n",
      "Gradient Descent(8059/9999): loss=12731.337301394728, w0=3.9232375345475106, w1=-54.94187258127387\n",
      "Gradient Descent(8060/9999): loss=4317.335041011638, w0=13.560737534547512, w1=-51.92287258127387\n",
      "Gradient Descent(8061/9999): loss=10584.753971939575, w0=5.0943375345475115, w1=-55.65827258127387\n",
      "Gradient Descent(8062/9999): loss=4365.476399854563, w0=5.0943375345475115, w1=-55.65827258127387\n",
      "Gradient Descent(8063/9999): loss=4365.476399854563, w0=18.88923753454751, w1=-49.91827258127387\n",
      "Gradient Descent(8064/9999): loss=11422.198486643683, w0=18.88923753454751, w1=-49.91827258127387\n",
      "Gradient Descent(8065/9999): loss=11422.198486643683, w0=18.88923753454751, w1=-49.91827258127387\n",
      "Gradient Descent(8066/9999): loss=11422.198486643683, w0=18.88923753454751, w1=-49.91827258127387\n",
      "Gradient Descent(8067/9999): loss=11422.198486643683, w0=18.88923753454751, w1=-49.91827258127387\n",
      "Gradient Descent(8068/9999): loss=11422.198486643683, w0=18.88923753454751, w1=-49.91827258127387\n",
      "Gradient Descent(8069/9999): loss=11422.198486643683, w0=18.88923753454751, w1=-49.91827258127387\n",
      "Gradient Descent(8070/9999): loss=11422.198486643683, w0=10.612737534547511, w1=-54.68947258127387\n",
      "Gradient Descent(8071/9999): loss=4580.393233984755, w0=10.612737534547511, w1=-54.68947258127387\n",
      "Gradient Descent(8072/9999): loss=4580.393233984755, w0=10.612737534547511, w1=-54.68947258127387\n",
      "Gradient Descent(8073/9999): loss=4580.393233984755, w0=10.612737534547511, w1=-54.68947258127387\n",
      "Gradient Descent(8074/9999): loss=4580.393233984755, w0=10.612737534547511, w1=-54.68947258127387\n",
      "Gradient Descent(8075/9999): loss=4580.393233984755, w0=-1.195062465452489, w1=-59.63947258127387\n",
      "Gradient Descent(8076/9999): loss=5767.960679581416, w0=-1.195062465452489, w1=-59.63947258127387\n",
      "Gradient Descent(8077/9999): loss=5767.960679581416, w0=-1.195062465452489, w1=-59.63947258127387\n",
      "Gradient Descent(8078/9999): loss=5767.960679581416, w0=-1.195062465452489, w1=-59.63947258127387\n",
      "Gradient Descent(8079/9999): loss=5767.960679581416, w0=10.871702920101045, w1=-40.27927258127387\n",
      "Gradient Descent(8080/9999): loss=4556.679245728277, w0=10.871702920101045, w1=-40.27927258127387\n",
      "Gradient Descent(8081/9999): loss=4556.679245728277, w0=10.871702920101045, w1=-40.27927258127387\n",
      "Gradient Descent(8082/9999): loss=4556.679245728277, w0=10.871702920101045, w1=-40.27927258127387\n",
      "Gradient Descent(8083/9999): loss=4556.679245728277, w0=18.869402920101045, w1=-37.59667258127387\n",
      "Gradient Descent(8084/9999): loss=11219.458432676156, w0=18.869402920101045, w1=-37.59667258127387\n",
      "Gradient Descent(8085/9999): loss=11219.458432676156, w0=-11.439097079898954, w1=-46.41787258127387\n",
      "Gradient Descent(8086/9999): loss=5802.4994844197445, w0=-3.094297079898954, w1=-43.673572581273866\n",
      "Gradient Descent(8087/9999): loss=5767.960678036857, w0=-3.094297079898954, w1=-43.673572581273866\n",
      "Gradient Descent(8088/9999): loss=5767.960678036857, w0=-3.094297079898954, w1=-43.673572581273866\n",
      "Gradient Descent(8089/9999): loss=5767.960678036857, w0=8.581502920101046, w1=-43.047072581273866\n",
      "Gradient Descent(8090/9999): loss=6994.161642214887, w0=8.581502920101046, w1=-43.047072581273866\n",
      "Gradient Descent(8091/9999): loss=6994.161642214887, w0=8.581502920101046, w1=-43.047072581273866\n",
      "Gradient Descent(8092/9999): loss=6994.161642214887, w0=-9.276397079898954, w1=-49.641672581273866\n",
      "Gradient Descent(8093/9999): loss=5802.4994844197445, w0=-9.276397079898954, w1=-49.641672581273866\n",
      "Gradient Descent(8094/9999): loss=5802.4994844197445, w0=-9.276397079898954, w1=-49.641672581273866\n",
      "Gradient Descent(8095/9999): loss=5802.4994844197445, w0=-9.276397079898954, w1=-49.641672581273866\n",
      "Gradient Descent(8096/9999): loss=5802.4994844197445, w0=-9.276397079898954, w1=-49.641672581273866\n",
      "Gradient Descent(8097/9999): loss=5802.4994844197445, w0=-1.6991970798989549, w1=-46.431872581273865\n",
      "Gradient Descent(8098/9999): loss=4575.4536160271, w0=-1.6991970798989549, w1=-46.431872581273865\n",
      "Gradient Descent(8099/9999): loss=4575.4536160271, w0=-1.6991970798989549, w1=-46.431872581273865\n",
      "Gradient Descent(8100/9999): loss=4575.4536160271, w0=-1.6991970798989549, w1=-46.431872581273865\n",
      "Gradient Descent(8101/9999): loss=4575.4536160271, w0=-1.6991970798989549, w1=-46.431872581273865\n",
      "Gradient Descent(8102/9999): loss=4575.4536160271, w0=11.993402920101047, w1=-36.480072581273866\n",
      "Gradient Descent(8103/9999): loss=15589.731427665101, w0=-9.866697079898955, w1=-42.756372581273865\n",
      "Gradient Descent(8104/9999): loss=5163.622611819506, w0=0.6026029201010452, w1=-40.33677258127386\n",
      "Gradient Descent(8105/9999): loss=9850.667077131699, w0=0.6026029201010452, w1=-40.33677258127386\n",
      "Gradient Descent(8106/9999): loss=9850.667077131699, w0=0.6026029201010452, w1=-40.33677258127386\n",
      "Gradient Descent(8107/9999): loss=9850.667077131699, w0=0.6026029201010452, w1=-40.33677258127386\n",
      "Gradient Descent(8108/9999): loss=9850.667077131699, w0=0.6026029201010452, w1=-40.33677258127386\n",
      "Gradient Descent(8109/9999): loss=9850.667077131699, w0=0.6026029201010452, w1=-40.33677258127386\n",
      "Gradient Descent(8110/9999): loss=9850.667077131699, w0=0.6026029201010452, w1=-40.33677258127386\n",
      "Gradient Descent(8111/9999): loss=9850.667077131699, w0=-9.112897079898955, w1=-45.13427258127386\n",
      "Gradient Descent(8112/9999): loss=5278.313167495024, w0=-9.112897079898955, w1=-45.13427258127386\n",
      "Gradient Descent(8113/9999): loss=5278.313167495024, w0=-9.112897079898955, w1=-45.13427258127386\n",
      "Gradient Descent(8114/9999): loss=5278.313167495024, w0=-9.112897079898955, w1=-45.13427258127386\n",
      "Gradient Descent(8115/9999): loss=5278.313167495024, w0=-9.112897079898955, w1=-45.13427258127386\n",
      "Gradient Descent(8116/9999): loss=5278.313167495024, w0=0.5246029201010458, w1=-42.115272581273864\n",
      "Gradient Descent(8117/9999): loss=6541.409654896514, w0=0.5246029201010458, w1=-42.115272581273864\n",
      "Gradient Descent(8118/9999): loss=6541.409654896514, w0=0.5246029201010458, w1=-42.115272581273864\n",
      "Gradient Descent(8119/9999): loss=6541.409654896514, w0=-11.354897079898954, w1=-43.05077258127386\n",
      "Gradient Descent(8120/9999): loss=5790.986548954825, w0=-11.354897079898954, w1=-43.05077258127386\n",
      "Gradient Descent(8121/9999): loss=5790.986548954825, w0=-11.354897079898954, w1=-43.05077258127386\n",
      "Gradient Descent(8122/9999): loss=5790.986548954825, w0=-0.7039970798989543, w1=-41.93477258127386\n",
      "Gradient Descent(8123/9999): loss=4970.571758820519, w0=-0.7039970798989543, w1=-41.93477258127386\n",
      "Gradient Descent(8124/9999): loss=4970.571758820519, w0=-0.7039970798989543, w1=-41.93477258127386\n",
      "Gradient Descent(8125/9999): loss=4970.571758820519, w0=-7.794197079898955, w1=-44.77167258127386\n",
      "Gradient Descent(8126/9999): loss=5744.897580407383, w0=-7.794197079898955, w1=-44.77167258127386\n",
      "Gradient Descent(8127/9999): loss=5744.897580407383, w0=-7.794197079898955, w1=-44.77167258127386\n",
      "Gradient Descent(8128/9999): loss=5744.897580407383, w0=-7.794197079898955, w1=-44.77167258127386\n",
      "Gradient Descent(8129/9999): loss=5744.897580407383, w0=0.924702920101045, w1=-44.72567258127386\n",
      "Gradient Descent(8130/9999): loss=4479.265449742292, w0=0.924702920101045, w1=-44.72567258127386\n",
      "Gradient Descent(8131/9999): loss=4479.265449742292, w0=0.924702920101045, w1=-44.72567258127386\n",
      "Gradient Descent(8132/9999): loss=4479.265449742292, w0=0.924702920101045, w1=-44.72567258127386\n",
      "Gradient Descent(8133/9999): loss=4479.265449742292, w0=0.924702920101045, w1=-44.72567258127386\n",
      "Gradient Descent(8134/9999): loss=4479.265449742292, w0=0.924702920101045, w1=-44.72567258127386\n",
      "Gradient Descent(8135/9999): loss=4479.265449742292, w0=0.924702920101045, w1=-44.72567258127386\n",
      "Gradient Descent(8136/9999): loss=4479.265449742292, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8137/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8138/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8139/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8140/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8141/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8142/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8143/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8144/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8145/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8146/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8147/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8148/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8149/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8150/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8151/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(8152/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8153/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8154/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8155/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8156/9999): loss=5696.979354340228, w0=-7.630497079898956, w1=-45.994572581273864\n",
      "Gradient Descent(8157/9999): loss=5696.979354340228, w0=2.3457029201010444, w1=-41.38747258127386\n",
      "Gradient Descent(8158/9999): loss=4709.245277913506, w0=2.3457029201010444, w1=-41.38747258127386\n",
      "Gradient Descent(8159/9999): loss=4709.245277913506, w0=2.3457029201010444, w1=-41.38747258127386\n",
      "Gradient Descent(8160/9999): loss=4709.245277913506, w0=2.3457029201010444, w1=-41.38747258127386\n",
      "Gradient Descent(8161/9999): loss=4709.245277913506, w0=2.3457029201010444, w1=-41.38747258127386\n",
      "Gradient Descent(8162/9999): loss=4709.245277913506, w0=-13.934197079898958, w1=-42.97197258127386\n",
      "Gradient Descent(8163/9999): loss=5802.4994844197445, w0=-13.934197079898958, w1=-42.97197258127386\n",
      "Gradient Descent(8164/9999): loss=5802.4994844197445, w0=-13.934197079898958, w1=-42.97197258127386\n",
      "Gradient Descent(8165/9999): loss=5802.4994844197445, w0=-13.934197079898958, w1=-42.97197258127386\n",
      "Gradient Descent(8166/9999): loss=5802.4994844197445, w0=-13.934197079898958, w1=-42.97197258127386\n",
      "Gradient Descent(8167/9999): loss=5802.4994844197445, w0=-13.934197079898958, w1=-42.97197258127386\n",
      "Gradient Descent(8168/9999): loss=5802.4994844197445, w0=-2.809597079898957, w1=-42.24827258127386\n",
      "Gradient Descent(8169/9999): loss=4820.937068752974, w0=-2.809597079898957, w1=-42.24827258127386\n",
      "Gradient Descent(8170/9999): loss=4820.937068752974, w0=-2.809597079898957, w1=-42.24827258127386\n",
      "Gradient Descent(8171/9999): loss=4820.937068752974, w0=-2.809597079898957, w1=-42.24827258127386\n",
      "Gradient Descent(8172/9999): loss=4820.937068752974, w0=-2.809597079898957, w1=-42.24827258127386\n",
      "Gradient Descent(8173/9999): loss=4820.937068752974, w0=-2.809597079898957, w1=-42.24827258127386\n",
      "Gradient Descent(8174/9999): loss=4820.937068752974, w0=-2.809597079898957, w1=-42.24827258127386\n",
      "Gradient Descent(8175/9999): loss=4820.937068752974, w0=-12.235997079898956, w1=-44.90657258127386\n",
      "Gradient Descent(8176/9999): loss=5802.4994844197445, w0=-12.235997079898956, w1=-44.90657258127386\n",
      "Gradient Descent(8177/9999): loss=5802.4994844197445, w0=-12.235997079898956, w1=-44.90657258127386\n",
      "Gradient Descent(8178/9999): loss=5802.4994844197445, w0=-12.235997079898956, w1=-44.90657258127386\n",
      "Gradient Descent(8179/9999): loss=5802.4994844197445, w0=-12.235997079898956, w1=-44.90657258127386\n",
      "Gradient Descent(8180/9999): loss=5802.4994844197445, w0=1.4544029201010442, w1=-43.04717258127386\n",
      "Gradient Descent(8181/9999): loss=6449.831875578301, w0=1.4544029201010442, w1=-43.04717258127386\n",
      "Gradient Descent(8182/9999): loss=6449.831875578301, w0=13.521168305654578, w1=-35.14057258127386\n",
      "Gradient Descent(8183/9999): loss=16716.76230516686, w0=13.521168305654578, w1=-35.14057258127386\n",
      "Gradient Descent(8184/9999): loss=16716.76230516686, w0=1.4544029201010442, w1=-43.13547258127386\n",
      "Gradient Descent(8185/9999): loss=8470.533319245422, w0=1.4544029201010442, w1=-43.13547258127386\n",
      "Gradient Descent(8186/9999): loss=8470.533319245422, w0=1.4544029201010442, w1=-43.13547258127386\n",
      "Gradient Descent(8187/9999): loss=8470.533319245422, w0=-10.61236246545249, w1=-53.25967258127386\n",
      "Gradient Descent(8188/9999): loss=4939.029324551553, w0=-10.61236246545249, w1=-53.25967258127386\n",
      "Gradient Descent(8189/9999): loss=4939.029324551553, w0=-10.61236246545249, w1=-53.25967258127386\n",
      "Gradient Descent(8190/9999): loss=4939.029324551553, w0=1.2559375345475097, w1=-52.61517258127386\n",
      "Gradient Descent(8191/9999): loss=6326.20753341114, w0=1.2559375345475097, w1=-52.61517258127386\n",
      "Gradient Descent(8192/9999): loss=6326.20753341114, w0=1.2559375345475097, w1=-52.61517258127386\n",
      "Gradient Descent(8193/9999): loss=6326.20753341114, w0=-10.810827851006025, w1=-59.48297258127386\n",
      "Gradient Descent(8194/9999): loss=4881.464647274435, w0=-2.4988278510060233, w1=-55.684472581273866\n",
      "Gradient Descent(8195/9999): loss=4888.764398301397, w0=-15.159727851006023, w1=-61.15927258127387\n",
      "Gradient Descent(8196/9999): loss=5629.806094955814, w0=-15.159727851006023, w1=-61.15927258127387\n",
      "Gradient Descent(8197/9999): loss=5629.806094955814, w0=-15.159727851006023, w1=-61.15927258127387\n",
      "Gradient Descent(8198/9999): loss=5629.806094955814, w0=-4.727927851006022, w1=-56.78627258127387\n",
      "Gradient Descent(8199/9999): loss=4873.455214408017, w0=-4.727927851006022, w1=-56.78627258127387\n",
      "Gradient Descent(8200/9999): loss=4873.455214408017, w0=-4.727927851006022, w1=-56.78627258127387\n",
      "Gradient Descent(8201/9999): loss=4873.455214408017, w0=-4.727927851006022, w1=-56.78627258127387\n",
      "Gradient Descent(8202/9999): loss=4873.455214408017, w0=-4.727927851006022, w1=-56.78627258127387\n",
      "Gradient Descent(8203/9999): loss=4873.455214408017, w0=-4.727927851006022, w1=-56.78627258127387\n",
      "Gradient Descent(8204/9999): loss=4873.455214408017, w0=-4.727927851006022, w1=-56.78627258127387\n",
      "Gradient Descent(8205/9999): loss=4873.455214408017, w0=-4.727927851006022, w1=-56.78627258127387\n",
      "Gradient Descent(8206/9999): loss=4873.455214408017, w0=-4.727927851006022, w1=-56.78627258127387\n",
      "Gradient Descent(8207/9999): loss=4873.455214408017, w0=-4.727927851006022, w1=-56.78627258127387\n",
      "Gradient Descent(8208/9999): loss=4873.455214408017, w0=-4.727927851006022, w1=-56.78627258127387\n",
      "Gradient Descent(8209/9999): loss=4873.455214408017, w0=-4.727927851006022, w1=-56.78627258127387\n",
      "Gradient Descent(8210/9999): loss=4873.455214408017, w0=-4.727927851006022, w1=-56.78627258127387\n",
      "Gradient Descent(8211/9999): loss=4873.455214408017, w0=-12.746727851006023, w1=-58.68057258127387\n",
      "Gradient Descent(8212/9999): loss=5078.754910782697, w0=1.1423721489939762, w1=-49.66467258127387\n",
      "Gradient Descent(8213/9999): loss=10162.14452089384, w0=-20.188827851006025, w1=-59.62537258127387\n",
      "Gradient Descent(8214/9999): loss=5381.355601674184, w0=-20.188827851006025, w1=-59.62537258127387\n",
      "Gradient Descent(8215/9999): loss=5381.355601674184, w0=-20.188827851006025, w1=-59.62537258127387\n",
      "Gradient Descent(8216/9999): loss=5381.355601674184, w0=-20.188827851006025, w1=-59.62537258127387\n",
      "Gradient Descent(8217/9999): loss=5381.355601674184, w0=-6.894627851006023, w1=-57.84917258127387\n",
      "Gradient Descent(8218/9999): loss=5407.357266838892, w0=-19.80812785100602, w1=-61.59557258127387\n",
      "Gradient Descent(8219/9999): loss=5720.5983458111405, w0=-19.80812785100602, w1=-61.59557258127387\n",
      "Gradient Descent(8220/9999): loss=5720.5983458111405, w0=-11.38332785100602, w1=-56.16967258127387\n",
      "Gradient Descent(8221/9999): loss=5970.9388537972245, w0=-23.450093236559553, w1=-65.36917258127387\n",
      "Gradient Descent(8222/9999): loss=5618.220461298219, w0=-10.923993236559552, w1=-59.218772581273875\n",
      "Gradient Descent(8223/9999): loss=5686.766537933586, w0=-10.923993236559552, w1=-59.218772581273875\n",
      "Gradient Descent(8224/9999): loss=5686.766537933586, w0=-10.923993236559552, w1=-59.218772581273875\n",
      "Gradient Descent(8225/9999): loss=5686.766537933586, w0=-23.378993236559552, w1=-62.021672581273876\n",
      "Gradient Descent(8226/9999): loss=5802.4994844197445, w0=-9.74889323655955, w1=-61.055072581273876\n",
      "Gradient Descent(8227/9999): loss=7144.417590221717, w0=-9.74889323655955, w1=-61.055072581273876\n",
      "Gradient Descent(8228/9999): loss=7144.417590221717, w0=2.0437067634404507, w1=-57.17117258127388\n",
      "Gradient Descent(8229/9999): loss=14160.64003263688, w0=-12.36859323655955, w1=-65.93877258127388\n",
      "Gradient Descent(8230/9999): loss=5403.566485419162, w0=-12.36859323655955, w1=-65.93877258127388\n",
      "Gradient Descent(8231/9999): loss=5403.566485419162, w0=-12.36859323655955, w1=-65.93877258127388\n",
      "Gradient Descent(8232/9999): loss=5403.566485419162, w0=-12.36859323655955, w1=-65.93877258127388\n",
      "Gradient Descent(8233/9999): loss=5403.566485419162, w0=-12.36859323655955, w1=-65.93877258127388\n",
      "Gradient Descent(8234/9999): loss=5403.566485419162, w0=-4.092893236559549, w1=-59.61157258127388\n",
      "Gradient Descent(8235/9999): loss=13019.570873926008, w0=-25.20449323655955, w1=-68.58497258127389\n",
      "Gradient Descent(8236/9999): loss=5177.397000647226, w0=-25.20449323655955, w1=-68.58497258127389\n",
      "Gradient Descent(8237/9999): loss=5177.397000647226, w0=-25.20449323655955, w1=-68.58497258127389\n",
      "Gradient Descent(8238/9999): loss=5177.397000647226, w0=-11.787593236559552, w1=-66.3115725812739\n",
      "Gradient Descent(8239/9999): loss=10724.939394778785, w0=-29.340793236559552, w1=-70.87017258127389\n",
      "Gradient Descent(8240/9999): loss=4950.140139610434, w0=-19.30189323655955, w1=-68.37477258127389\n",
      "Gradient Descent(8241/9999): loss=8208.858848919368, w0=-19.30189323655955, w1=-68.37477258127389\n",
      "Gradient Descent(8242/9999): loss=8208.858848919368, w0=-19.30189323655955, w1=-68.37477258127389\n",
      "Gradient Descent(8243/9999): loss=8208.858848919368, w0=-19.30189323655955, w1=-68.37477258127389\n",
      "Gradient Descent(8244/9999): loss=8208.858848919368, w0=-26.84779323655955, w1=-70.44177258127388\n",
      "Gradient Descent(8245/9999): loss=5060.877478918579, w0=-26.84779323655955, w1=-70.44177258127388\n",
      "Gradient Descent(8246/9999): loss=5060.877478918579, w0=-26.84779323655955, w1=-70.44177258127388\n",
      "Gradient Descent(8247/9999): loss=5060.877478918579, w0=-16.413093236559547, w1=-66.00147258127389\n",
      "Gradient Descent(8248/9999): loss=8501.907805915496, w0=-41.88209323655955, w1=-69.39277258127389\n",
      "Gradient Descent(8249/9999): loss=5802.4994844197445, w0=-41.88209323655955, w1=-69.39277258127389\n",
      "Gradient Descent(8250/9999): loss=5802.4994844197445, w0=-32.21539323655955, w1=-67.85687258127389\n",
      "Gradient Descent(8251/9999): loss=5038.1363226784215, w0=-32.21539323655955, w1=-67.85687258127389\n",
      "Gradient Descent(8252/9999): loss=5038.1363226784215, w0=-32.21539323655955, w1=-67.85687258127389\n",
      "Gradient Descent(8253/9999): loss=5038.1363226784215, w0=-32.21539323655955, w1=-67.85687258127389\n",
      "Gradient Descent(8254/9999): loss=5038.1363226784215, w0=-32.21539323655955, w1=-67.85687258127389\n",
      "Gradient Descent(8255/9999): loss=5038.1363226784215, w0=-20.148627851006015, w1=-58.76147258127389\n",
      "Gradient Descent(8256/9999): loss=6600.342871535727, w0=-20.148627851006015, w1=-58.76147258127389\n",
      "Gradient Descent(8257/9999): loss=6600.342871535727, w0=-20.148627851006015, w1=-58.76147258127389\n",
      "Gradient Descent(8258/9999): loss=6600.342871535727, w0=-29.575027851006013, w1=-61.41977258127389\n",
      "Gradient Descent(8259/9999): loss=5536.843638518376, w0=-29.575027851006013, w1=-61.41977258127389\n",
      "Gradient Descent(8260/9999): loss=5536.843638518376, w0=-29.575027851006013, w1=-61.41977258127389\n",
      "Gradient Descent(8261/9999): loss=5536.843638518376, w0=-29.575027851006013, w1=-61.41977258127389\n",
      "Gradient Descent(8262/9999): loss=5536.843638518376, w0=-29.575027851006013, w1=-61.41977258127389\n",
      "Gradient Descent(8263/9999): loss=5536.843638518376, w0=-14.443527851006012, w1=-54.58187258127389\n",
      "Gradient Descent(8264/9999): loss=8667.482466024689, w0=-24.20502785100601, w1=-60.079172581273895\n",
      "Gradient Descent(8265/9999): loss=4820.0103178069685, w0=-24.20502785100601, w1=-60.079172581273895\n",
      "Gradient Descent(8266/9999): loss=4820.0103178069685, w0=-24.20502785100601, w1=-60.079172581273895\n",
      "Gradient Descent(8267/9999): loss=4820.0103178069685, w0=-24.20502785100601, w1=-60.079172581273895\n",
      "Gradient Descent(8268/9999): loss=4820.0103178069685, w0=-24.20502785100601, w1=-60.079172581273895\n",
      "Gradient Descent(8269/9999): loss=4820.0103178069685, w0=-24.20502785100601, w1=-60.079172581273895\n",
      "Gradient Descent(8270/9999): loss=4820.0103178069685, w0=-24.20502785100601, w1=-60.079172581273895\n",
      "Gradient Descent(8271/9999): loss=4820.0103178069685, w0=-24.20502785100601, w1=-60.079172581273895\n",
      "Gradient Descent(8272/9999): loss=4820.0103178069685, w0=-24.20502785100601, w1=-60.079172581273895\n",
      "Gradient Descent(8273/9999): loss=4820.0103178069685, w0=-7.470527851006011, w1=-58.914972581273894\n",
      "Gradient Descent(8274/9999): loss=11165.971882466945, w0=-14.336127851006012, w1=-61.444372581273896\n",
      "Gradient Descent(8275/9999): loss=5333.948744964362, w0=-14.336127851006012, w1=-61.444372581273896\n",
      "Gradient Descent(8276/9999): loss=5333.948744964362, w0=-14.336127851006012, w1=-61.444372581273896\n",
      "Gradient Descent(8277/9999): loss=5333.948744964362, w0=-14.336127851006012, w1=-61.444372581273896\n",
      "Gradient Descent(8278/9999): loss=5333.948744964362, w0=-14.336127851006012, w1=-61.444372581273896\n",
      "Gradient Descent(8279/9999): loss=5333.948744964362, w0=-6.099527851006011, w1=-58.7449725812739\n",
      "Gradient Descent(8280/9999): loss=10130.149344838144, w0=-6.099527851006011, w1=-58.7449725812739\n",
      "Gradient Descent(8281/9999): loss=10130.149344838144, w0=-6.099527851006011, w1=-58.7449725812739\n",
      "Gradient Descent(8282/9999): loss=10130.149344838144, w0=-22.17152785100601, w1=-65.0467725812739\n",
      "Gradient Descent(8283/9999): loss=4781.087549619153, w0=-22.17152785100601, w1=-65.0467725812739\n",
      "Gradient Descent(8284/9999): loss=4781.087549619153, w0=-22.17152785100601, w1=-65.0467725812739\n",
      "Gradient Descent(8285/9999): loss=4781.087549619153, w0=-21.60461643050238, w1=-64.78213591742373\n",
      "Gradient Descent(8286/9999): loss=4677.037716575503, w0=-21.60461643050238, w1=-64.78213591742373\n",
      "Gradient Descent(8287/9999): loss=4677.037716575503, w0=-21.60461643050238, w1=-64.78213591742373\n",
      "Gradient Descent(8288/9999): loss=4677.037716575503, w0=-21.60461643050238, w1=-64.78213591742373\n",
      "Gradient Descent(8289/9999): loss=4677.037716575503, w0=-21.60461643050238, w1=-64.78213591742373\n",
      "Gradient Descent(8290/9999): loss=4677.037716575503, w0=-21.60461643050238, w1=-64.78213591742373\n",
      "Gradient Descent(8291/9999): loss=4677.037716575503, w0=-21.60461643050238, w1=-64.78213591742373\n",
      "Gradient Descent(8292/9999): loss=4677.037716575503, w0=-21.60461643050238, w1=-64.78213591742373\n",
      "Gradient Descent(8293/9999): loss=4677.037716575503, w0=-21.60461643050238, w1=-64.78213591742373\n",
      "Gradient Descent(8294/9999): loss=4677.037716575503, w0=-13.712316430502378, w1=-61.55873591742373\n",
      "Gradient Descent(8295/9999): loss=6670.84969153408, w0=-29.130116430502376, w1=-64.94763591742374\n",
      "Gradient Descent(8296/9999): loss=5824.647466147129, w0=-18.738916430502375, w1=-64.31763591742374\n",
      "Gradient Descent(8297/9999): loss=5266.371051815346, w0=-18.738916430502375, w1=-64.31763591742374\n",
      "Gradient Descent(8298/9999): loss=5266.371051815346, w0=-18.738916430502375, w1=-64.31763591742374\n",
      "Gradient Descent(8299/9999): loss=5266.371051815346, w0=-31.002116430502376, w1=-70.53393591742375\n",
      "Gradient Descent(8300/9999): loss=5802.4994844197445, w0=-31.002116430502376, w1=-70.53393591742375\n",
      "Gradient Descent(8301/9999): loss=5802.4994844197445, w0=-31.002116430502376, w1=-70.53393591742375\n",
      "Gradient Descent(8302/9999): loss=5802.4994844197445, w0=-31.002116430502376, w1=-70.53393591742375\n",
      "Gradient Descent(8303/9999): loss=5802.4994844197445, w0=-31.002116430502376, w1=-70.53393591742375\n",
      "Gradient Descent(8304/9999): loss=5802.4994844197445, w0=-31.002116430502376, w1=-70.53393591742375\n",
      "Gradient Descent(8305/9999): loss=5802.4994844197445, w0=-31.002116430502376, w1=-70.53393591742375\n",
      "Gradient Descent(8306/9999): loss=5802.4994844197445, w0=-31.002116430502376, w1=-70.53393591742375\n",
      "Gradient Descent(8307/9999): loss=5802.4994844197445, w0=-31.002116430502376, w1=-70.53393591742375\n",
      "Gradient Descent(8308/9999): loss=5802.4994844197445, w0=-31.002116430502376, w1=-70.53393591742375\n",
      "Gradient Descent(8309/9999): loss=5802.4994844197445, w0=-20.112016430502372, w1=-70.11503591742375\n",
      "Gradient Descent(8310/9999): loss=4776.166159073293, w0=-20.112016430502372, w1=-70.11503591742375\n",
      "Gradient Descent(8311/9999): loss=4776.166159073293, w0=-20.112016430502372, w1=-70.11503591742375\n",
      "Gradient Descent(8312/9999): loss=4776.166159073293, w0=-20.112016430502372, w1=-70.11503591742375\n",
      "Gradient Descent(8313/9999): loss=4776.166159073293, w0=-9.758016430502373, w1=-65.61383591742376\n",
      "Gradient Descent(8314/9999): loss=10971.792558705183, w0=-21.824781816055907, w1=-73.41593591742375\n",
      "Gradient Descent(8315/9999): loss=4992.738275546488, w0=-21.824781816055907, w1=-73.41593591742375\n",
      "Gradient Descent(8316/9999): loss=4992.738275546488, w0=-21.824781816055907, w1=-73.41593591742375\n",
      "Gradient Descent(8317/9999): loss=4992.738275546488, w0=-9.671781816055907, w1=-69.05913591742375\n",
      "Gradient Descent(8318/9999): loss=8701.561552245274, w0=-9.671781816055907, w1=-69.05913591742375\n",
      "Gradient Descent(8319/9999): loss=8701.561552245274, w0=-9.671781816055907, w1=-69.05913591742375\n",
      "Gradient Descent(8320/9999): loss=8701.561552245274, w0=-9.671781816055907, w1=-69.05913591742375\n",
      "Gradient Descent(8321/9999): loss=8701.561552245274, w0=-9.671781816055907, w1=-69.05913591742375\n",
      "Gradient Descent(8322/9999): loss=8701.561552245274, w0=-9.671781816055907, w1=-69.05913591742375\n",
      "Gradient Descent(8323/9999): loss=8701.561552245274, w0=-21.55138181605591, w1=-76.06893591742374\n",
      "Gradient Descent(8324/9999): loss=4749.557725543284, w0=-21.55138181605591, w1=-76.06893591742374\n",
      "Gradient Descent(8325/9999): loss=4749.557725543284, w0=-21.55138181605591, w1=-76.06893591742374\n",
      "Gradient Descent(8326/9999): loss=4749.557725543284, w0=-21.55138181605591, w1=-76.06893591742374\n",
      "Gradient Descent(8327/9999): loss=4749.557725543284, w0=-21.55138181605591, w1=-76.06893591742374\n",
      "Gradient Descent(8328/9999): loss=4749.557725543284, w0=-21.55138181605591, w1=-76.06893591742374\n",
      "Gradient Descent(8329/9999): loss=4749.557725543284, w0=-21.55138181605591, w1=-76.06893591742374\n",
      "Gradient Descent(8330/9999): loss=4749.557725543284, w0=-7.941581816055908, w1=-68.11463591742374\n",
      "Gradient Descent(8331/9999): loss=8487.181302294444, w0=-20.602481816055906, w1=-73.58943591742374\n",
      "Gradient Descent(8332/9999): loss=4584.588486600528, w0=-20.602481816055906, w1=-73.58943591742374\n",
      "Gradient Descent(8333/9999): loss=4584.588486600528, w0=-20.602481816055906, w1=-73.58943591742374\n",
      "Gradient Descent(8334/9999): loss=4584.588486600528, w0=-20.602481816055906, w1=-73.58943591742374\n",
      "Gradient Descent(8335/9999): loss=4584.588486600528, w0=-20.602481816055906, w1=-73.58943591742374\n",
      "Gradient Descent(8336/9999): loss=4584.588486600528, w0=-20.602481816055906, w1=-73.58943591742374\n",
      "Gradient Descent(8337/9999): loss=4584.588486600528, w0=-20.602481816055906, w1=-73.58943591742374\n",
      "Gradient Descent(8338/9999): loss=4584.588486600528, w0=-20.602481816055906, w1=-73.58943591742374\n",
      "Gradient Descent(8339/9999): loss=4584.588486600528, w0=-20.602481816055906, w1=-73.58943591742374\n",
      "Gradient Descent(8340/9999): loss=4584.588486600528, w0=-20.602481816055906, w1=-73.58943591742374\n",
      "Gradient Descent(8341/9999): loss=4584.588486600528, w0=-20.602481816055906, w1=-73.58943591742374\n",
      "Gradient Descent(8342/9999): loss=4584.588486600528, w0=-29.76958163793064, w1=-76.81593585472984\n",
      "Gradient Descent(8343/9999): loss=5802.4994844197445, w0=-29.76958163793064, w1=-76.81593585472984\n",
      "Gradient Descent(8344/9999): loss=5802.4994844197445, w0=-29.76958163793064, w1=-76.81593585472984\n",
      "Gradient Descent(8345/9999): loss=5802.4994844197445, w0=-29.76958163793064, w1=-76.81593585472984\n",
      "Gradient Descent(8346/9999): loss=5802.4994844197445, w0=-29.76958163793064, w1=-76.81593585472984\n",
      "Gradient Descent(8347/9999): loss=5802.4994844197445, w0=-22.511281637930637, w1=-72.56163585472984\n",
      "Gradient Descent(8348/9999): loss=4724.426363674973, w0=-22.511281637930637, w1=-72.56163585472984\n",
      "Gradient Descent(8349/9999): loss=4724.426363674973, w0=-22.511281637930637, w1=-72.56163585472984\n",
      "Gradient Descent(8350/9999): loss=4724.426363674973, w0=-22.511281637930637, w1=-72.56163585472984\n",
      "Gradient Descent(8351/9999): loss=4724.426363674973, w0=-22.511281637930637, w1=-72.56163585472984\n",
      "Gradient Descent(8352/9999): loss=4724.426363674973, w0=-22.511281637931035, w1=-72.56163585473001\n",
      "Gradient Descent(8353/9999): loss=4724.426363675206, w0=-22.511281637931035, w1=-72.56163585473001\n",
      "Gradient Descent(8354/9999): loss=4724.426363675206, w0=-22.511281637931035, w1=-72.56163585473001\n",
      "Gradient Descent(8355/9999): loss=4724.426363675206, w0=-22.511281637931035, w1=-72.56163585473001\n",
      "Gradient Descent(8356/9999): loss=4724.426363675206, w0=-22.511281637931035, w1=-72.56163585473001\n",
      "Gradient Descent(8357/9999): loss=4724.426363675206, w0=-22.511281637931035, w1=-72.56163585473001\n",
      "Gradient Descent(8358/9999): loss=4724.426363675206, w0=-22.511281637931035, w1=-72.56163585473001\n",
      "Gradient Descent(8359/9999): loss=4724.426363675206, w0=-22.511281637931035, w1=-72.56163585473001\n",
      "Gradient Descent(8360/9999): loss=4724.426363675206, w0=-22.511281637930917, w1=-72.56163585473\n",
      "Gradient Descent(8361/9999): loss=4724.426363675186, w0=-22.511281637930917, w1=-72.56163585473\n",
      "Gradient Descent(8362/9999): loss=4724.426363675186, w0=-22.511281637930917, w1=-72.56163585473\n",
      "Gradient Descent(8363/9999): loss=4724.426363675186, w0=-9.871681637930916, w1=-68.65293585473\n",
      "Gradient Descent(8364/9999): loss=8306.7978273881, w0=-9.871681637930916, w1=-68.65293585473\n",
      "Gradient Descent(8365/9999): loss=8306.7978273881, w0=-22.532581637930917, w1=-74.12773585473\n",
      "Gradient Descent(8366/9999): loss=4696.119245905992, w0=-13.343911593572276, w1=-70.69334705105317\n",
      "Gradient Descent(8367/9999): loss=7572.95931349137, w0=-13.343911593572276, w1=-70.69334705105317\n",
      "Gradient Descent(8368/9999): loss=7572.95931349137, w0=-19.55171159357228, w1=-76.61464705105317\n",
      "Gradient Descent(8369/9999): loss=4671.850413569406, w0=-19.55171159357228, w1=-76.61464705105317\n",
      "Gradient Descent(8370/9999): loss=4671.850413569406, w0=-19.55171159357228, w1=-76.61464705105317\n",
      "Gradient Descent(8371/9999): loss=4671.850413569406, w0=-9.197711593572278, w1=-72.11344705105317\n",
      "Gradient Descent(8372/9999): loss=9843.359682983553, w0=-9.197711593572278, w1=-72.11344705105317\n",
      "Gradient Descent(8373/9999): loss=9843.359682983553, w0=-9.197711593572278, w1=-72.11344705105317\n",
      "Gradient Descent(8374/9999): loss=9843.359682983553, w0=-9.197711593572278, w1=-72.11344705105317\n",
      "Gradient Descent(8375/9999): loss=9843.359682983553, w0=-31.44111159357228, w1=-78.14874705105318\n",
      "Gradient Descent(8376/9999): loss=5250.377782668387, w0=-31.44111159357228, w1=-78.14874705105318\n",
      "Gradient Descent(8377/9999): loss=5250.377782668387, w0=-19.40381159357228, w1=-76.63574705105317\n",
      "Gradient Descent(8378/9999): loss=5305.835628710614, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8379/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8380/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8381/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8382/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8383/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8384/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8385/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8386/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8387/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8388/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8389/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8390/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8391/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8392/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8393/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8394/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8395/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8396/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8397/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8398/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8399/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8400/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8401/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8402/9999): loss=5298.694985389877, w0=-24.00111159357228, w1=-82.18924705105317\n",
      "Gradient Descent(8403/9999): loss=5298.694985389877, w0=-15.055511593572279, w1=-73.60064705105317\n",
      "Gradient Descent(8404/9999): loss=5201.840103337594, w0=-15.055511593572279, w1=-73.60064705105317\n",
      "Gradient Descent(8405/9999): loss=5201.840103337594, w0=-15.055511593572279, w1=-73.60064705105317\n",
      "Gradient Descent(8406/9999): loss=5201.840103337594, w0=-15.055511593572279, w1=-73.60064705105317\n",
      "Gradient Descent(8407/9999): loss=5201.840103337594, w0=-15.055511593572279, w1=-73.60064705105317\n",
      "Gradient Descent(8408/9999): loss=5201.840103337594, w0=-15.055511593572279, w1=-73.60064705105317\n",
      "Gradient Descent(8409/9999): loss=5201.840103337594, w0=-15.055511593572279, w1=-73.60064705105317\n",
      "Gradient Descent(8410/9999): loss=5201.840103337594, w0=-15.055511593572279, w1=-73.60064705105317\n",
      "Gradient Descent(8411/9999): loss=5201.840103337594, w0=-15.055511593572279, w1=-73.60064705105317\n",
      "Gradient Descent(8412/9999): loss=5201.840103337594, w0=-15.055511593572279, w1=-73.60064705105317\n",
      "Gradient Descent(8413/9999): loss=5201.840103337594, w0=-15.055511593572279, w1=-73.60064705105317\n",
      "Gradient Descent(8414/9999): loss=5201.840103337594, w0=-21.98541159357228, w1=-77.69994705105317\n",
      "Gradient Descent(8415/9999): loss=4925.564617221519, w0=-21.98541159357228, w1=-77.69994705105317\n",
      "Gradient Descent(8416/9999): loss=4925.564617221519, w0=-21.98541159357228, w1=-77.69994705105317\n",
      "Gradient Descent(8417/9999): loss=4925.564617221519, w0=-21.98541159357228, w1=-77.69994705105317\n",
      "Gradient Descent(8418/9999): loss=4925.564617221519, w0=-21.98541159357228, w1=-77.69994705105317\n",
      "Gradient Descent(8419/9999): loss=4925.564617221519, w0=-21.98541159357228, w1=-77.69994705105317\n",
      "Gradient Descent(8420/9999): loss=4925.564617221519, w0=-21.98541159357228, w1=-77.69994705105317\n",
      "Gradient Descent(8421/9999): loss=4925.564617221519, w0=-21.98541159357228, w1=-77.69994705105317\n",
      "Gradient Descent(8422/9999): loss=4925.564617221519, w0=-21.98541159357228, w1=-77.69994705105317\n",
      "Gradient Descent(8423/9999): loss=4925.564617221519, w0=-21.98541159357228, w1=-77.69994705105317\n",
      "Gradient Descent(8424/9999): loss=4925.564617221519, w0=-6.94071159357228, w1=-74.87734705105318\n",
      "Gradient Descent(8425/9999): loss=5654.188562339875, w0=-6.94071159357228, w1=-74.87734705105318\n",
      "Gradient Descent(8426/9999): loss=5654.188562339875, w0=-6.94071159357228, w1=-74.87734705105318\n",
      "Gradient Descent(8427/9999): loss=5654.188562339875, w0=-6.94071159357228, w1=-74.87734705105318\n",
      "Gradient Descent(8428/9999): loss=5654.188562339875, w0=-6.94071159357228, w1=-74.87734705105318\n",
      "Gradient Descent(8429/9999): loss=5654.188562339875, w0=-6.94071159357228, w1=-74.87734705105318\n",
      "Gradient Descent(8430/9999): loss=5654.188562339875, w0=-6.94071159357228, w1=-74.87734705105318\n",
      "Gradient Descent(8431/9999): loss=5654.188562339875, w0=-6.94071159357228, w1=-74.87734705105318\n",
      "Gradient Descent(8432/9999): loss=5654.188562339875, w0=-14.15331159357228, w1=-78.97114705105318\n",
      "Gradient Descent(8433/9999): loss=4559.9034610505905, w0=-14.15331159357228, w1=-78.97114705105318\n",
      "Gradient Descent(8434/9999): loss=4559.9034610505905, w0=-14.15331159357228, w1=-78.97114705105318\n",
      "Gradient Descent(8435/9999): loss=4559.9034610505905, w0=-14.15331159357228, w1=-78.97114705105318\n",
      "Gradient Descent(8436/9999): loss=4559.9034610505905, w0=-14.15331159357228, w1=-78.97114705105318\n",
      "Gradient Descent(8437/9999): loss=4559.9034610505905, w0=-14.15331159357228, w1=-78.97114705105318\n",
      "Gradient Descent(8438/9999): loss=4559.9034610505905, w0=-14.15331159357228, w1=-78.97114705105318\n",
      "Gradient Descent(8439/9999): loss=4559.9034610505905, w0=-0.687611593572278, w1=-71.86824705105317\n",
      "Gradient Descent(8440/9999): loss=10612.656583793429, w0=-11.704311593572278, w1=-79.73534705105317\n",
      "Gradient Descent(8441/9999): loss=4616.729714243932, w0=-11.704311593572278, w1=-79.73534705105317\n",
      "Gradient Descent(8442/9999): loss=4616.729714243932, w0=0.44868840642772234, w1=-75.37854705105316\n",
      "Gradient Descent(8443/9999): loss=8538.488039903923, w0=0.44868840642772234, w1=-75.37854705105316\n",
      "Gradient Descent(8444/9999): loss=8538.488039903923, w0=-13.295711593572276, w1=-81.69534705105316\n",
      "Gradient Descent(8445/9999): loss=4513.740337475956, w0=-13.295711593572276, w1=-81.69534705105316\n",
      "Gradient Descent(8446/9999): loss=4513.740337475956, w0=-13.295711593572276, w1=-81.69534705105316\n",
      "Gradient Descent(8447/9999): loss=4513.740337475956, w0=-13.295711593572276, w1=-81.69534705105316\n",
      "Gradient Descent(8448/9999): loss=4513.740337475956, w0=-13.295711593572276, w1=-81.69534705105316\n",
      "Gradient Descent(8449/9999): loss=4513.740337475956, w0=-13.295711593572276, w1=-81.69534705105316\n",
      "Gradient Descent(8450/9999): loss=4513.740337475956, w0=-13.295711593572276, w1=-81.69534705105316\n",
      "Gradient Descent(8451/9999): loss=4513.740337475956, w0=-13.295711593572276, w1=-81.69534705105316\n",
      "Gradient Descent(8452/9999): loss=4513.740337475956, w0=-13.295711593572276, w1=-81.69534705105316\n",
      "Gradient Descent(8453/9999): loss=4513.740337475956, w0=-13.295711593572276, w1=-81.69534705105316\n",
      "Gradient Descent(8454/9999): loss=4513.740337475956, w0=-13.295711593572276, w1=-81.69534705105316\n",
      "Gradient Descent(8455/9999): loss=4513.740337475956, w0=-13.295711593572276, w1=-81.69534705105316\n",
      "Gradient Descent(8456/9999): loss=4513.740337475956, w0=-13.295711593572276, w1=-81.69534705105316\n",
      "Gradient Descent(8457/9999): loss=4513.740337475956, w0=-13.295711593572276, w1=-81.69534705105316\n",
      "Gradient Descent(8458/9999): loss=4513.740337475956, w0=-4.983711593572275, w1=-77.89684705105316\n",
      "Gradient Descent(8459/9999): loss=6335.9864665574105, w0=-4.983711593572275, w1=-77.89684705105316\n",
      "Gradient Descent(8460/9999): loss=6335.9864665574105, w0=-18.368411593572276, w1=-82.10084705105315\n",
      "Gradient Descent(8461/9999): loss=4651.20988499176, w0=-18.368411593572276, w1=-82.10084705105315\n",
      "Gradient Descent(8462/9999): loss=4651.20988499176, w0=-18.368411593572276, w1=-82.10084705105315\n",
      "Gradient Descent(8463/9999): loss=4651.20988499176, w0=-6.974011593572275, w1=-77.72724705105315\n",
      "Gradient Descent(8464/9999): loss=6270.950448571879, w0=-6.974011593572275, w1=-77.72724705105315\n",
      "Gradient Descent(8465/9999): loss=6270.950448571879, w0=-15.770111593572276, w1=-80.56554705105316\n",
      "Gradient Descent(8466/9999): loss=4556.923022351331, w0=-15.770111593572276, w1=-80.56554705105316\n",
      "Gradient Descent(8467/9999): loss=4556.923022351331, w0=-15.770111593572276, w1=-80.56554705105316\n",
      "Gradient Descent(8468/9999): loss=4556.923022351331, w0=-25.075411593572277, w1=-80.73674705105316\n",
      "Gradient Descent(8469/9999): loss=5790.986548954825, w0=-25.075411593572277, w1=-80.73674705105316\n",
      "Gradient Descent(8470/9999): loss=5790.986548954825, w0=-14.474611593572277, w1=-78.38254705105315\n",
      "Gradient Descent(8471/9999): loss=4466.976097042014, w0=-14.474611593572277, w1=-78.38254705105315\n",
      "Gradient Descent(8472/9999): loss=4466.976097042014, w0=-14.474611593572277, w1=-78.38254705105315\n",
      "Gradient Descent(8473/9999): loss=4466.976097042014, w0=-22.653511593572276, w1=-80.50844705105315\n",
      "Gradient Descent(8474/9999): loss=5756.433339460347, w0=-22.653511593572276, w1=-80.50844705105315\n",
      "Gradient Descent(8475/9999): loss=5756.433339460347, w0=-22.653511593572276, w1=-80.50844705105315\n",
      "Gradient Descent(8476/9999): loss=5756.433339460347, w0=-22.653511593572276, w1=-80.50844705105315\n",
      "Gradient Descent(8477/9999): loss=5756.433339460347, w0=-22.653511593572276, w1=-80.50844705105315\n",
      "Gradient Descent(8478/9999): loss=5756.433339460347, w0=-22.653511593572276, w1=-80.50844705105315\n",
      "Gradient Descent(8479/9999): loss=5756.433339460347, w0=-22.653511593572276, w1=-80.50844705105315\n",
      "Gradient Descent(8480/9999): loss=5756.433339460347, w0=-22.653511593572276, w1=-80.50844705105315\n",
      "Gradient Descent(8481/9999): loss=5756.433339460347, w0=-22.653511593572276, w1=-80.50844705105315\n",
      "Gradient Descent(8482/9999): loss=5756.433339460347, w0=-22.653511593572276, w1=-80.50844705105315\n",
      "Gradient Descent(8483/9999): loss=5756.433339460347, w0=-22.653511593572276, w1=-80.50844705105315\n",
      "Gradient Descent(8484/9999): loss=5756.433339460347, w0=-22.653511593572276, w1=-80.50844705105315\n",
      "Gradient Descent(8485/9999): loss=5756.433339460347, w0=-22.653511593572276, w1=-80.50844705105315\n",
      "Gradient Descent(8486/9999): loss=5756.433339460347, w0=-12.483711593572275, w1=-76.67804705105316\n",
      "Gradient Descent(8487/9999): loss=4582.120592296003, w0=-12.483711593572275, w1=-76.67804705105316\n",
      "Gradient Descent(8488/9999): loss=4582.120592296003, w0=-12.483711593572275, w1=-76.67804705105316\n",
      "Gradient Descent(8489/9999): loss=4582.120592296003, w0=-0.41694620801874116, w1=-57.85064705105316\n",
      "Gradient Descent(8490/9999): loss=14239.790073107853, w0=-0.41694620801874116, w1=-57.85064705105316\n",
      "Gradient Descent(8491/9999): loss=14239.790073107853, w0=-0.41694620801874116, w1=-57.85064705105316\n",
      "Gradient Descent(8492/9999): loss=14239.790073107853, w0=-12.483711593572275, w1=-67.97484705105316\n",
      "Gradient Descent(8493/9999): loss=4832.223843990483, w0=-12.483711593572275, w1=-67.97484705105316\n",
      "Gradient Descent(8494/9999): loss=4832.223843990483, w0=-12.483711593572275, w1=-67.97484705105316\n",
      "Gradient Descent(8495/9999): loss=4832.223843990483, w0=-12.483711593572275, w1=-67.97484705105316\n",
      "Gradient Descent(8496/9999): loss=4832.223843990483, w0=-12.483711593572275, w1=-67.97484705105316\n",
      "Gradient Descent(8497/9999): loss=4832.223843990483, w0=-12.483711593572275, w1=-67.97484705105316\n",
      "Gradient Descent(8498/9999): loss=4832.223843990483, w0=-12.483711593572275, w1=-67.97484705105316\n",
      "Gradient Descent(8499/9999): loss=4832.223843990483, w0=-12.483711593572275, w1=-67.97484705105316\n",
      "Gradient Descent(8500/9999): loss=4832.223843990483, w0=-12.483711593572275, w1=-67.97484705105316\n",
      "Gradient Descent(8501/9999): loss=4832.223843990483, w0=-12.483711593572275, w1=-67.97484705105316\n",
      "Gradient Descent(8502/9999): loss=4832.223843990483, w0=-12.483711593572275, w1=-67.97484705105316\n",
      "Gradient Descent(8503/9999): loss=4832.223843990483, w0=-12.483711593572275, w1=-67.97484705105316\n",
      "Gradient Descent(8504/9999): loss=4832.223843990483, w0=-12.483711593572275, w1=-67.97484705105316\n",
      "Gradient Descent(8505/9999): loss=4832.223843990483, w0=-22.275011593572273, w1=-72.61714705105317\n",
      "Gradient Descent(8506/9999): loss=5742.644034614149, w0=-22.275011593572273, w1=-72.61714705105317\n",
      "Gradient Descent(8507/9999): loss=5742.644034614149, w0=-8.098811593572272, w1=-72.03074705105317\n",
      "Gradient Descent(8508/9999): loss=4894.578609674431, w0=-19.698611593572274, w1=-72.67614705105316\n",
      "Gradient Descent(8509/9999): loss=5445.606928967851, w0=-19.698611593572274, w1=-72.67614705105316\n",
      "Gradient Descent(8510/9999): loss=5445.606928967851, w0=-19.698611593572274, w1=-72.67614705105316\n",
      "Gradient Descent(8511/9999): loss=5445.606928967851, w0=-6.088811593572274, w1=-64.72184705105316\n",
      "Gradient Descent(8512/9999): loss=5491.661530410901, w0=-6.088811593572274, w1=-64.72184705105316\n",
      "Gradient Descent(8513/9999): loss=5491.661530410901, w0=-6.088811593572274, w1=-64.72184705105316\n",
      "Gradient Descent(8514/9999): loss=5491.661530410901, w0=-6.088811593572274, w1=-64.72184705105316\n",
      "Gradient Descent(8515/9999): loss=5491.661530410901, w0=-6.088811593572274, w1=-64.72184705105316\n",
      "Gradient Descent(8516/9999): loss=5491.661530410901, w0=-6.088811593572274, w1=-64.72184705105316\n",
      "Gradient Descent(8517/9999): loss=5491.661530410901, w0=-6.088811593572274, w1=-64.72184705105316\n",
      "Gradient Descent(8518/9999): loss=5491.661530410901, w0=4.37781442211994, w1=-59.21508597609984\n",
      "Gradient Descent(8519/9999): loss=15156.447486244972, w0=4.37781442211994, w1=-59.21508597609984\n",
      "Gradient Descent(8520/9999): loss=15156.447486244972, w0=-8.28698557788006, w1=-70.60968597609984\n",
      "Gradient Descent(8521/9999): loss=4398.118996988323, w0=-8.28698557788006, w1=-70.60968597609984\n",
      "Gradient Descent(8522/9999): loss=4398.118996988323, w0=2.35781442211994, w1=-66.50158597609985\n",
      "Gradient Descent(8523/9999): loss=8548.288022090375, w0=2.35781442211994, w1=-66.50158597609985\n",
      "Gradient Descent(8524/9999): loss=8548.288022090375, w0=-11.85528557788006, w1=-74.50448597609984\n",
      "Gradient Descent(8525/9999): loss=4669.61890669115, w0=-11.85528557788006, w1=-74.50448597609984\n",
      "Gradient Descent(8526/9999): loss=4669.61890669115, w0=-11.85528557788006, w1=-74.50448597609984\n",
      "Gradient Descent(8527/9999): loss=4669.61890669115, w0=-11.85528557788006, w1=-74.50448597609984\n",
      "Gradient Descent(8528/9999): loss=4669.61890669115, w0=-23.455085577880062, w1=-75.14988597609984\n",
      "Gradient Descent(8529/9999): loss=5802.4994844197445, w0=-23.455085577880062, w1=-75.14988597609984\n",
      "Gradient Descent(8530/9999): loss=5802.4994844197445, w0=-11.053585577880062, w1=-71.59758597609984\n",
      "Gradient Descent(8531/9999): loss=4525.8414787894, w0=-11.053585577880062, w1=-71.59758597609984\n",
      "Gradient Descent(8532/9999): loss=4525.8414787894, w0=-11.053585577880062, w1=-71.59758597609984\n",
      "Gradient Descent(8533/9999): loss=4525.8414787894, w0=-11.053585577880062, w1=-71.59758597609984\n",
      "Gradient Descent(8534/9999): loss=4525.8414787894, w0=-11.053585577880062, w1=-71.59758597609984\n",
      "Gradient Descent(8535/9999): loss=4525.8414787894, w0=-3.1889855778800618, w1=-67.68078597609984\n",
      "Gradient Descent(8536/9999): loss=5046.60700071375, w0=-3.1889855778800618, w1=-67.68078597609984\n",
      "Gradient Descent(8537/9999): loss=5046.60700071375, w0=-19.177785577880062, w1=-72.99098597609984\n",
      "Gradient Descent(8538/9999): loss=5756.447719553437, w0=-8.440285577880061, w1=-72.62398597609983\n",
      "Gradient Descent(8539/9999): loss=4353.091418452007, w0=-8.440285577880061, w1=-72.62398597609983\n",
      "Gradient Descent(8540/9999): loss=4353.091418452007, w0=-8.440285577880061, w1=-72.62398597609983\n",
      "Gradient Descent(8541/9999): loss=4353.091418452007, w0=3.0547144221199396, w1=-66.58488597609983\n",
      "Gradient Descent(8542/9999): loss=9658.751304902027, w0=3.0547144221199396, w1=-66.58488597609983\n",
      "Gradient Descent(8543/9999): loss=9658.751304902027, w0=3.0547144221199396, w1=-66.58488597609983\n",
      "Gradient Descent(8544/9999): loss=9658.751304902027, w0=3.0547144221199396, w1=-66.58488597609983\n",
      "Gradient Descent(8545/9999): loss=9658.751304902027, w0=3.0547144221199396, w1=-66.58488597609983\n",
      "Gradient Descent(8546/9999): loss=9658.751304902027, w0=3.0547144221199396, w1=-66.58488597609983\n",
      "Gradient Descent(8547/9999): loss=9658.751304902027, w0=3.05471442146175, w1=-66.58488597644141\n",
      "Gradient Descent(8548/9999): loss=9658.751304138716, w0=-0.14538557853824985, w1=-73.7040859764414\n",
      "Gradient Descent(8549/9999): loss=4361.462095774719, w0=-0.14538557853824985, w1=-73.7040859764414\n",
      "Gradient Descent(8550/9999): loss=4361.462095774719, w0=-0.14538557853824985, w1=-73.7040859764414\n",
      "Gradient Descent(8551/9999): loss=4361.462095774719, w0=13.527814421461752, w1=-66.89038597644141\n",
      "Gradient Descent(8552/9999): loss=12077.579553889449, w0=13.527814421461752, w1=-66.89038597644141\n",
      "Gradient Descent(8553/9999): loss=12077.579553889449, w0=1.2832144214617518, w1=-72.11218597644141\n",
      "Gradient Descent(8554/9999): loss=4401.853554907401, w0=10.403214421461753, w1=-67.83878597644141\n",
      "Gradient Descent(8555/9999): loss=9504.978175300033, w0=-2.1042855785382475, w1=-73.94438597644141\n",
      "Gradient Descent(8556/9999): loss=4531.077250579988, w0=-2.1042855785382475, w1=-73.94438597644141\n",
      "Gradient Descent(8557/9999): loss=4531.077250579988, w0=-2.1042855785382475, w1=-73.94438597644141\n",
      "Gradient Descent(8558/9999): loss=4531.077250579988, w0=-2.1042855785382475, w1=-73.94438597644141\n",
      "Gradient Descent(8559/9999): loss=4531.077250579988, w0=-2.1042855785382475, w1=-73.94438597644141\n",
      "Gradient Descent(8560/9999): loss=4531.077250579988, w0=-2.1042855785382475, w1=-73.94438597644141\n",
      "Gradient Descent(8561/9999): loss=4531.077250579988, w0=-2.1042855785382475, w1=-73.94438597644141\n",
      "Gradient Descent(8562/9999): loss=4531.077250579988, w0=-2.1042855785382475, w1=-73.94438597644141\n",
      "Gradient Descent(8563/9999): loss=4531.077250579988, w0=6.7056144214617515, w1=-73.4018859764414\n",
      "Gradient Descent(8564/9999): loss=5371.673605740594, w0=6.7056144214617515, w1=-73.4018859764414\n",
      "Gradient Descent(8565/9999): loss=5371.673605740594, w0=-23.60288557853825, w1=-82.22308597644141\n",
      "Gradient Descent(8566/9999): loss=5802.4994844197445, w0=-23.60288557853825, w1=-82.22308597644141\n",
      "Gradient Descent(8567/9999): loss=5802.4994844197445, w0=-23.60288557853825, w1=-82.22308597644141\n",
      "Gradient Descent(8568/9999): loss=5802.4994844197445, w0=-23.60288557853825, w1=-82.22308597644141\n",
      "Gradient Descent(8569/9999): loss=5802.4994844197445, w0=-23.60288557853825, w1=-82.22308597644141\n",
      "Gradient Descent(8570/9999): loss=5802.4994844197445, w0=-23.60288557853825, w1=-82.22308597644141\n",
      "Gradient Descent(8571/9999): loss=5802.4994844197445, w0=-23.60288557853825, w1=-82.22308597644141\n",
      "Gradient Descent(8572/9999): loss=5802.4994844197445, w0=-23.60288557853825, w1=-82.22308597644141\n",
      "Gradient Descent(8573/9999): loss=5802.4994844197445, w0=-23.60288557853825, w1=-82.22308597644141\n",
      "Gradient Descent(8574/9999): loss=5802.4994844197445, w0=-13.595385578538249, w1=-81.39058597644141\n",
      "Gradient Descent(8575/9999): loss=5290.233886236235, w0=-13.595385578538249, w1=-81.39058597644141\n",
      "Gradient Descent(8576/9999): loss=5290.233886236235, w0=-1.5286201929847145, w1=-63.75418597644141\n",
      "Gradient Descent(8577/9999): loss=10476.829684016313, w0=-13.595385578538249, w1=-71.23258597644141\n",
      "Gradient Descent(8578/9999): loss=4639.748692317158, w0=-13.595385578538249, w1=-71.23258597644141\n",
      "Gradient Descent(8579/9999): loss=4639.748692317158, w0=-13.595385578538249, w1=-71.23258597644141\n",
      "Gradient Descent(8580/9999): loss=4639.748692317158, w0=-13.595385578538249, w1=-71.23258597644141\n",
      "Gradient Descent(8581/9999): loss=4639.748692317158, w0=-26.783285578538248, w1=-74.85808597644142\n",
      "Gradient Descent(8582/9999): loss=5802.4994844197445, w0=-14.716520192984714, w1=-59.77788597644141\n",
      "Gradient Descent(8583/9999): loss=6723.201629942263, w0=-14.716520192984714, w1=-59.77788597644141\n",
      "Gradient Descent(8584/9999): loss=6723.201629942263, w0=-14.716520192984714, w1=-59.77788597644141\n",
      "Gradient Descent(8585/9999): loss=6723.201629942263, w0=-27.043320192984712, w1=-62.77848597644141\n",
      "Gradient Descent(8586/9999): loss=5779.473613489904, w0=-27.043320192984712, w1=-62.77848597644141\n",
      "Gradient Descent(8587/9999): loss=5779.473613489904, w0=-27.043320192984712, w1=-62.77848597644141\n",
      "Gradient Descent(8588/9999): loss=5779.473613489904, w0=-13.336520192984713, w1=-61.39578597644141\n",
      "Gradient Descent(8589/9999): loss=4673.4690076161205, w0=-2.1377201929847125, w1=-55.19178597644141\n",
      "Gradient Descent(8590/9999): loss=14629.066594948803, w0=-2.1377201929847125, w1=-55.19178597644141\n",
      "Gradient Descent(8591/9999): loss=14629.066594948803, w0=-2.1377201929847125, w1=-55.19178597644141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(8592/9999): loss=14629.066594948803, w0=-2.1377201929847125, w1=-55.19178597644141\n",
      "Gradient Descent(8593/9999): loss=14629.066594948803, w0=-13.244020192984712, w1=-64.13878597644141\n",
      "Gradient Descent(8594/9999): loss=4541.434995727964, w0=-13.244020192984712, w1=-64.13878597644141\n",
      "Gradient Descent(8595/9999): loss=4541.434995727964, w0=-13.244020192984712, w1=-64.13878597644141\n",
      "Gradient Descent(8596/9999): loss=4541.434995727964, w0=-13.244020192984712, w1=-64.13878597644141\n",
      "Gradient Descent(8597/9999): loss=4541.434995727964, w0=-13.244020192984712, w1=-64.13878597644141\n",
      "Gradient Descent(8598/9999): loss=4541.434995727964, w0=-13.244020192984712, w1=-64.13878597644141\n",
      "Gradient Descent(8599/9999): loss=4541.434995727964, w0=-0.9378201929847094, w1=-60.39158597644141\n",
      "Gradient Descent(8600/9999): loss=11343.224473586437, w0=-0.9378201929847094, w1=-60.39158597644141\n",
      "Gradient Descent(8601/9999): loss=11343.224473586437, w0=-0.9378201929847094, w1=-60.39158597644141\n",
      "Gradient Descent(8602/9999): loss=11343.224473586437, w0=-11.39812019298471, w1=-66.79168597644141\n",
      "Gradient Descent(8603/9999): loss=4741.67374970137, w0=-11.39812019298471, w1=-66.79168597644141\n",
      "Gradient Descent(8604/9999): loss=4741.67374970137, w0=-11.39812019298471, w1=-66.79168597644141\n",
      "Gradient Descent(8605/9999): loss=4741.67374970137, w0=-11.39812019298471, w1=-66.79168597644141\n",
      "Gradient Descent(8606/9999): loss=4741.67374970137, w0=-11.39812019298471, w1=-66.79168597644141\n",
      "Gradient Descent(8607/9999): loss=4741.67374970137, w0=-11.39812019298471, w1=-66.79168597644141\n",
      "Gradient Descent(8608/9999): loss=4741.67374970137, w0=-1.7099201929847077, w1=-62.262385976441415\n",
      "Gradient Descent(8609/9999): loss=7848.295426705432, w0=-1.7099201929847077, w1=-62.262385976441415\n",
      "Gradient Descent(8610/9999): loss=7848.295426705432, w0=-1.7099201929847077, w1=-62.262385976441415\n",
      "Gradient Descent(8611/9999): loss=7848.295426705432, w0=-12.547920192984709, w1=-66.50048597644141\n",
      "Gradient Descent(8612/9999): loss=4528.877361727495, w0=-12.547920192984709, w1=-66.50048597644141\n",
      "Gradient Descent(8613/9999): loss=4528.877361727495, w0=-12.547920192984709, w1=-66.50048597644141\n",
      "Gradient Descent(8614/9999): loss=4528.877361727495, w0=-12.547920192984709, w1=-66.50048597644141\n",
      "Gradient Descent(8615/9999): loss=4528.877361727495, w0=-12.547920192984709, w1=-66.50048597644141\n",
      "Gradient Descent(8616/9999): loss=4528.877361727495, w0=0.2229798070152924, w1=-60.10338597644141\n",
      "Gradient Descent(8617/9999): loss=12063.792016552718, w0=-15.10102019298471, w1=-67.3222859764414\n",
      "Gradient Descent(8618/9999): loss=4438.329773967915, w0=-27.167785578538243, w1=-73.20088597644141\n",
      "Gradient Descent(8619/9999): loss=5802.4994844197445, w0=-27.167785578538243, w1=-73.20088597644141\n",
      "Gradient Descent(8620/9999): loss=5802.4994844197445, w0=-27.167785578538243, w1=-73.20088597644141\n",
      "Gradient Descent(8621/9999): loss=5802.4994844197445, w0=-18.310385578538245, w1=-70.07478597644142\n",
      "Gradient Descent(8622/9999): loss=5802.4994844197445, w0=-18.310385578538245, w1=-70.07478597644142\n",
      "Gradient Descent(8623/9999): loss=5802.4994844197445, w0=-18.310385578538245, w1=-70.07478597644142\n",
      "Gradient Descent(8624/9999): loss=5802.4994844197445, w0=-18.310385578538245, w1=-70.07478597644142\n",
      "Gradient Descent(8625/9999): loss=5802.4994844197445, w0=-18.310385578538245, w1=-70.07478597644142\n",
      "Gradient Descent(8626/9999): loss=5802.4994844197445, w0=-18.310385578538245, w1=-70.07478597644142\n",
      "Gradient Descent(8627/9999): loss=5802.4994844197445, w0=-18.310385578538245, w1=-70.07478597644142\n",
      "Gradient Descent(8628/9999): loss=5802.4994844197445, w0=-18.310385578538245, w1=-70.07478597644142\n",
      "Gradient Descent(8629/9999): loss=5802.4994844197445, w0=-18.310385578538245, w1=-70.07478597644142\n",
      "Gradient Descent(8630/9999): loss=5802.4994844197445, w0=-18.310385578538245, w1=-70.07478597644142\n",
      "Gradient Descent(8631/9999): loss=5802.4994844197445, w0=-6.542085578538245, w1=-68.24318597644142\n",
      "Gradient Descent(8632/9999): loss=4442.049729143073, w0=-6.542085578538245, w1=-68.24318597644142\n",
      "Gradient Descent(8633/9999): loss=4442.049729143073, w0=-6.542085578538245, w1=-68.24318597644142\n",
      "Gradient Descent(8634/9999): loss=4442.049729143073, w0=-6.542085578538245, w1=-68.24318597644142\n",
      "Gradient Descent(8635/9999): loss=4442.049729143073, w0=-6.542085578538245, w1=-68.24318597644142\n",
      "Gradient Descent(8636/9999): loss=4442.049729143073, w0=-6.542085578538245, w1=-68.24318597644142\n",
      "Gradient Descent(8637/9999): loss=4442.049729143073, w0=-6.542085578538245, w1=-68.24318597644142\n",
      "Gradient Descent(8638/9999): loss=4442.049729143073, w0=-6.542085578538245, w1=-68.24318597644142\n",
      "Gradient Descent(8639/9999): loss=4442.049729143073, w0=-6.542085578538245, w1=-68.24318597644142\n",
      "Gradient Descent(8640/9999): loss=4442.049729143073, w0=-6.542085578538245, w1=-68.24318597644142\n",
      "Gradient Descent(8641/9999): loss=4442.049729143073, w0=-6.542085578538245, w1=-68.24318597644142\n",
      "Gradient Descent(8642/9999): loss=4442.049729143073, w0=-6.542085578538245, w1=-68.24318597644142\n",
      "Gradient Descent(8643/9999): loss=4442.049729143073, w0=-6.542085578538245, w1=-68.24318597644142\n",
      "Gradient Descent(8644/9999): loss=4442.049729143073, w0=-6.542085578538245, w1=-68.24318597644142\n",
      "Gradient Descent(8645/9999): loss=4442.049729143073, w0=-6.542085578538245, w1=-68.24318597644142\n",
      "Gradient Descent(8646/9999): loss=4442.049729143073, w0=-6.542085578538245, w1=-68.24318597644142\n",
      "Gradient Descent(8647/9999): loss=4442.049729143073, w0=-13.882885578538247, w1=-70.75558597644142\n",
      "Gradient Descent(8648/9999): loss=5744.9348070950655, w0=-1.208585578538246, w1=-65.30908597644142\n",
      "Gradient Descent(8649/9999): loss=4420.517823556713, w0=11.066514421461756, w1=-60.12748597644142\n",
      "Gradient Descent(8650/9999): loss=11167.055696614747, w0=2.1859144214617565, w1=-63.77158597644142\n",
      "Gradient Descent(8651/9999): loss=4430.844999796036, w0=2.1859144214617565, w1=-63.77158597644142\n",
      "Gradient Descent(8652/9999): loss=4430.844999796036, w0=2.1859144214617565, w1=-63.77158597644142\n",
      "Gradient Descent(8653/9999): loss=4430.844999796036, w0=2.1859144214617565, w1=-63.77158597644142\n",
      "Gradient Descent(8654/9999): loss=4430.844999796036, w0=14.25267980701529, w1=-56.77808597644142\n",
      "Gradient Descent(8655/9999): loss=14623.313517818355, w0=9.408879807015289, w1=-62.13338597644142\n",
      "Gradient Descent(8656/9999): loss=6141.783913977482, w0=-7.980106709929633, w1=-70.94686604091817\n",
      "Gradient Descent(8657/9999): loss=5595.248574854867, w0=-7.980106709929633, w1=-70.94686604091817\n",
      "Gradient Descent(8658/9999): loss=5595.248574854867, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8659/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8660/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8661/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8662/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8663/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8664/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8665/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8666/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8667/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8668/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8669/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8670/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8671/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8672/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8673/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8674/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8675/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8676/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8677/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8678/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8679/9999): loss=4455.529656796794, w0=2.749393290070369, w1=-68.89416604091817\n",
      "Gradient Descent(8680/9999): loss=4455.529656796794, w0=11.40609329007037, w1=-66.55326604091816\n",
      "Gradient Descent(8681/9999): loss=6904.926542665655, w0=11.40609329007037, w1=-66.55326604091816\n",
      "Gradient Descent(8682/9999): loss=6904.926542665655, w0=11.40609329007037, w1=-66.55326604091816\n",
      "Gradient Descent(8683/9999): loss=6904.926542665655, w0=11.40609329007037, w1=-66.55326604091816\n",
      "Gradient Descent(8684/9999): loss=6904.926542665655, w0=11.40609329007037, w1=-66.55326604091816\n",
      "Gradient Descent(8685/9999): loss=6904.926542665655, w0=11.40609329007037, w1=-66.55326604091816\n",
      "Gradient Descent(8686/9999): loss=6904.926542665655, w0=11.40609329007037, w1=-66.55326604091816\n",
      "Gradient Descent(8687/9999): loss=6904.926542665655, w0=-1.5495067099296325, w1=-72.85526604091817\n",
      "Gradient Descent(8688/9999): loss=4765.770795669272, w0=-1.5495067099296325, w1=-72.85526604091817\n",
      "Gradient Descent(8689/9999): loss=4765.770795669272, w0=-1.5495067099296325, w1=-72.85526604091817\n",
      "Gradient Descent(8690/9999): loss=4765.770795669272, w0=-1.5495067099296325, w1=-72.85526604091817\n",
      "Gradient Descent(8691/9999): loss=4765.770795669272, w0=-1.5495067099296325, w1=-72.85526604091817\n",
      "Gradient Descent(8692/9999): loss=4765.770795669272, w0=-1.5495067099296325, w1=-72.85526604091817\n",
      "Gradient Descent(8693/9999): loss=4765.770795669272, w0=10.976393290070368, w1=-71.21576604091817\n",
      "Gradient Descent(8694/9999): loss=6004.069930513632, w0=2.940793290070367, w1=-72.20496604091817\n",
      "Gradient Descent(8695/9999): loss=4558.316581891598, w0=2.940793290070367, w1=-72.20496604091817\n",
      "Gradient Descent(8696/9999): loss=4558.316581891598, w0=2.940793290070367, w1=-72.20496604091817\n",
      "Gradient Descent(8697/9999): loss=4558.316581891598, w0=2.940793290070367, w1=-72.20496604091817\n",
      "Gradient Descent(8698/9999): loss=4558.316581891598, w0=2.940793290070367, w1=-72.20496604091817\n",
      "Gradient Descent(8699/9999): loss=4558.316581891598, w0=12.464093290070366, w1=-67.38456604091817\n",
      "Gradient Descent(8700/9999): loss=6639.679965497301, w0=12.464093290070366, w1=-67.38456604091817\n",
      "Gradient Descent(8701/9999): loss=6639.679965497301, w0=12.464093290070366, w1=-67.38456604091817\n",
      "Gradient Descent(8702/9999): loss=6639.679965497301, w0=12.464093290070366, w1=-67.38456604091817\n",
      "Gradient Descent(8703/9999): loss=6639.679965497301, w0=12.464093290070366, w1=-67.38456604091817\n",
      "Gradient Descent(8704/9999): loss=6639.679965497301, w0=12.464093290070366, w1=-67.38456604091817\n",
      "Gradient Descent(8705/9999): loss=6639.679965497301, w0=12.464093290070366, w1=-67.38456604091817\n",
      "Gradient Descent(8706/9999): loss=6639.679965497301, w0=12.464093290070366, w1=-67.38456604091817\n",
      "Gradient Descent(8707/9999): loss=6639.679965497301, w0=12.464093290070366, w1=-67.38456604091817\n",
      "Gradient Descent(8708/9999): loss=6639.679965497301, w0=-6.237306709929637, w1=-76.14156604091818\n",
      "Gradient Descent(8709/9999): loss=5582.276907434882, w0=-6.237306709929637, w1=-76.14156604091818\n",
      "Gradient Descent(8710/9999): loss=5582.276907434882, w0=-6.237306709929637, w1=-76.14156604091818\n",
      "Gradient Descent(8711/9999): loss=5582.276907434882, w0=-6.237306709929637, w1=-76.14156604091818\n",
      "Gradient Descent(8712/9999): loss=5582.276907434882, w0=-6.237306709929637, w1=-76.14156604091818\n",
      "Gradient Descent(8713/9999): loss=5582.276907434882, w0=8.673393290070363, w1=-74.11336604091818\n",
      "Gradient Descent(8714/9999): loss=6721.042161346151, w0=-0.47660670992963716, w1=-77.73916604091818\n",
      "Gradient Descent(8715/9999): loss=4432.43068496635, w0=-0.47660670992963716, w1=-77.73916604091818\n",
      "Gradient Descent(8716/9999): loss=4432.43068496635, w0=-0.47660670992963716, w1=-77.73916604091818\n",
      "Gradient Descent(8717/9999): loss=4432.43068496635, w0=-0.47660670992963716, w1=-77.73916604091818\n",
      "Gradient Descent(8718/9999): loss=4432.43068496635, w0=-0.47660670992963716, w1=-77.73916604091818\n",
      "Gradient Descent(8719/9999): loss=4432.43068496635, w0=-0.47660670992963716, w1=-77.73916604091818\n",
      "Gradient Descent(8720/9999): loss=4432.43068496635, w0=12.940293290070361, w1=-75.46576604091818\n",
      "Gradient Descent(8721/9999): loss=8431.91365556644, w0=0.8735279045168269, w1=-81.07136604091818\n",
      "Gradient Descent(8722/9999): loss=5583.358876830522, w0=12.697127904516828, w1=-78.04056604091818\n",
      "Gradient Descent(8723/9999): loss=4420.94722809858, w0=12.697127904516828, w1=-78.04056604091818\n",
      "Gradient Descent(8724/9999): loss=4420.94722809858, w0=12.697127904516828, w1=-78.04056604091818\n",
      "Gradient Descent(8725/9999): loss=4420.94722809858, w0=12.697127904516828, w1=-78.04056604091818\n",
      "Gradient Descent(8726/9999): loss=4420.94722809858, w0=12.697127904516828, w1=-78.04056604091818\n",
      "Gradient Descent(8727/9999): loss=4420.94722809858, w0=26.389727904516832, w1=-68.08876604091819\n",
      "Gradient Descent(8728/9999): loss=13725.685083760838, w0=13.934727904516832, w1=-70.89166604091818\n",
      "Gradient Descent(8729/9999): loss=4386.455425761133, w0=13.934727904516832, w1=-70.89166604091818\n",
      "Gradient Descent(8730/9999): loss=4386.455425761133, w0=24.191227904516833, w1=-64.63306604091818\n",
      "Gradient Descent(8731/9999): loss=8547.577352841474, w0=24.191227904516833, w1=-64.63306604091818\n",
      "Gradient Descent(8732/9999): loss=8547.577352841474, w0=24.191227904516833, w1=-64.63306604091818\n",
      "Gradient Descent(8733/9999): loss=8547.577352841474, w0=24.191227904516833, w1=-64.63306604091818\n",
      "Gradient Descent(8734/9999): loss=8547.577352841474, w0=24.191227904516833, w1=-64.63306604091818\n",
      "Gradient Descent(8735/9999): loss=8547.577352841474, w0=24.191227904516833, w1=-64.63306604091818\n",
      "Gradient Descent(8736/9999): loss=8547.577352841474, w0=17.89622790451683, w1=-68.56566604091817\n",
      "Gradient Descent(8737/9999): loss=4498.574970734475, w0=17.89622790451683, w1=-68.56566604091817\n",
      "Gradient Descent(8738/9999): loss=4498.574970734475, w0=17.89622790451683, w1=-68.56566604091817\n",
      "Gradient Descent(8739/9999): loss=4498.574970734475, w0=17.89622790451683, w1=-68.56566604091817\n",
      "Gradient Descent(8740/9999): loss=4498.574970734475, w0=17.89622790451683, w1=-68.56566604091817\n",
      "Gradient Descent(8741/9999): loss=4498.574970734475, w0=17.89622790451683, w1=-68.56566604091817\n",
      "Gradient Descent(8742/9999): loss=4498.574970734475, w0=17.89622790451683, w1=-68.56566604091817\n",
      "Gradient Descent(8743/9999): loss=4498.574970734475, w0=27.504027904516832, w1=-65.94006604091817\n",
      "Gradient Descent(8744/9999): loss=13967.741936813445, w0=27.504027904516832, w1=-65.94006604091817\n",
      "Gradient Descent(8745/9999): loss=13967.741936813445, w0=15.437262518963298, w1=-74.39946604091817\n",
      "Gradient Descent(8746/9999): loss=4691.801591074458, w0=15.437262518963298, w1=-74.39946604091817\n",
      "Gradient Descent(8747/9999): loss=4691.801591074458, w0=15.437262518963298, w1=-74.39946604091817\n",
      "Gradient Descent(8748/9999): loss=4691.801591074458, w0=15.437262518963298, w1=-74.39946604091817\n",
      "Gradient Descent(8749/9999): loss=4691.801591074458, w0=15.437262518963298, w1=-74.39946604091817\n",
      "Gradient Descent(8750/9999): loss=4691.801591074458, w0=15.437262518963298, w1=-74.39946604091817\n",
      "Gradient Descent(8751/9999): loss=4691.801591074458, w0=15.437262518963298, w1=-74.39946604091817\n",
      "Gradient Descent(8752/9999): loss=4691.801591074458, w0=15.437262518963298, w1=-74.39946604091817\n",
      "Gradient Descent(8753/9999): loss=4691.801591074458, w0=15.437262518963298, w1=-74.39946604091817\n",
      "Gradient Descent(8754/9999): loss=4691.801591074458, w0=15.437262518963298, w1=-74.39946604091817\n",
      "Gradient Descent(8755/9999): loss=4691.801591074458, w0=15.437262518963298, w1=-74.39946604091817\n",
      "Gradient Descent(8756/9999): loss=4691.801591074458, w0=15.437262518963298, w1=-74.39946604091817\n",
      "Gradient Descent(8757/9999): loss=4691.801591074458, w0=15.437262518963298, w1=-74.39946604091817\n",
      "Gradient Descent(8758/9999): loss=4691.801591074458, w0=15.437262518963298, w1=-74.39946604091817\n",
      "Gradient Descent(8759/9999): loss=4691.801591074458, w0=15.437262518963298, w1=-74.39946604091817\n",
      "Gradient Descent(8760/9999): loss=4691.801591074458, w0=15.437262518963298, w1=-74.39946604091817\n",
      "Gradient Descent(8761/9999): loss=4691.801591074458, w0=4.0932625189632965, w1=-79.05346604091817\n",
      "Gradient Descent(8762/9999): loss=5135.315487881726, w0=4.0932625189632965, w1=-79.05346604091817\n",
      "Gradient Descent(8763/9999): loss=5135.315487881726, w0=4.0932625189632965, w1=-79.05346604091817\n",
      "Gradient Descent(8764/9999): loss=5135.315487881726, w0=4.0932625189632965, w1=-79.05346604091817\n",
      "Gradient Descent(8765/9999): loss=5135.315487881726, w0=4.0932625189632965, w1=-79.05346604091817\n",
      "Gradient Descent(8766/9999): loss=5135.315487881726, w0=12.976362518963297, w1=-77.97316604091817\n",
      "Gradient Descent(8767/9999): loss=4380.267255643923, w0=12.976362518963297, w1=-77.97316604091817\n",
      "Gradient Descent(8768/9999): loss=4380.267255643923, w0=12.976362518963297, w1=-77.97316604091817\n",
      "Gradient Descent(8769/9999): loss=4380.267255643923, w0=12.976362518963297, w1=-77.97316604091817\n",
      "Gradient Descent(8770/9999): loss=4380.267255643923, w0=12.976362518963297, w1=-77.97316604091817\n",
      "Gradient Descent(8771/9999): loss=4380.267255643923, w0=12.976362518963297, w1=-77.97316604091817\n",
      "Gradient Descent(8772/9999): loss=4380.267255643923, w0=12.976362518963297, w1=-77.97316604091817\n",
      "Gradient Descent(8773/9999): loss=4380.267255643923, w0=21.833762518963297, w1=-74.84706604091818\n",
      "Gradient Descent(8774/9999): loss=9596.93340849385, w0=21.833762518963297, w1=-74.84706604091818\n",
      "Gradient Descent(8775/9999): loss=9596.93340849385, w0=21.833762518963297, w1=-74.84706604091818\n",
      "Gradient Descent(8776/9999): loss=9596.93340849385, w0=21.833762518963297, w1=-74.84706604091818\n",
      "Gradient Descent(8777/9999): loss=9596.93340849385, w0=21.833762518963297, w1=-74.84706604091818\n",
      "Gradient Descent(8778/9999): loss=9596.93340849385, w0=21.833762518963297, w1=-74.84706604091818\n",
      "Gradient Descent(8779/9999): loss=9596.93340849385, w0=21.833762518963297, w1=-74.84706604091818\n",
      "Gradient Descent(8780/9999): loss=9596.93340849385, w0=21.833762518963297, w1=-74.84706604091818\n",
      "Gradient Descent(8781/9999): loss=9596.93340849385, w0=28.5939625189633, w1=-69.43846604091817\n",
      "Gradient Descent(8782/9999): loss=16018.464799448095, w0=28.5939625189633, w1=-69.43846604091817\n",
      "Gradient Descent(8783/9999): loss=16018.464799448095, w0=12.159762518963298, w1=-76.31046604091817\n",
      "Gradient Descent(8784/9999): loss=4194.728647845666, w0=12.159762518963298, w1=-76.31046604091817\n",
      "Gradient Descent(8785/9999): loss=4194.728647845666, w0=12.159762518963298, w1=-76.31046604091817\n",
      "Gradient Descent(8786/9999): loss=4194.728647845666, w0=12.159762518963298, w1=-76.31046604091817\n",
      "Gradient Descent(8787/9999): loss=4194.728647845666, w0=12.159762518963298, w1=-76.31046604091817\n",
      "Gradient Descent(8788/9999): loss=4194.728647845666, w0=-1.9702374810367047, w1=-78.19456604091818\n",
      "Gradient Descent(8789/9999): loss=5790.986548954825, w0=-1.9702374810367047, w1=-78.19456604091818\n",
      "Gradient Descent(8790/9999): loss=5790.986548954825, w0=-1.9702374810367047, w1=-78.19456604091818\n",
      "Gradient Descent(8791/9999): loss=5790.986548954825, w0=-1.9702374810367047, w1=-78.19456604091818\n",
      "Gradient Descent(8792/9999): loss=5790.986548954825, w0=-1.9702374810367047, w1=-78.19456604091818\n",
      "Gradient Descent(8793/9999): loss=5790.986548954825, w0=6.374562518963295, w1=-75.45026604091818\n",
      "Gradient Descent(8794/9999): loss=4475.724665903989, w0=6.374562518963295, w1=-75.45026604091818\n",
      "Gradient Descent(8795/9999): loss=4475.724665903989, w0=6.374562518963295, w1=-75.45026604091818\n",
      "Gradient Descent(8796/9999): loss=4475.724665903989, w0=6.374562518963295, w1=-75.45026604091818\n",
      "Gradient Descent(8797/9999): loss=4475.724665903989, w0=6.374562518963295, w1=-75.45026604091818\n",
      "Gradient Descent(8798/9999): loss=4475.724665903989, w0=6.374562518963295, w1=-75.45026604091818\n",
      "Gradient Descent(8799/9999): loss=4475.724665903989, w0=6.374562518963295, w1=-75.45026604091818\n",
      "Gradient Descent(8800/9999): loss=4475.724665903989, w0=6.374562518963295, w1=-75.45026604091818\n",
      "Gradient Descent(8801/9999): loss=4475.724665903989, w0=6.374562518963295, w1=-75.45026604091818\n",
      "Gradient Descent(8802/9999): loss=4475.724665903989, w0=6.374562518963295, w1=-75.45026604091818\n",
      "Gradient Descent(8803/9999): loss=4475.724665903989, w0=6.374562518963295, w1=-75.45026604091818\n",
      "Gradient Descent(8804/9999): loss=4475.724665903989, w0=6.374562518963295, w1=-75.45026604091818\n",
      "Gradient Descent(8805/9999): loss=4475.724665903989, w0=6.374562518963295, w1=-75.45026604091818\n",
      "Gradient Descent(8806/9999): loss=4475.724665903989, w0=6.374562518958238, w1=-75.4502660409192\n",
      "Gradient Descent(8807/9999): loss=4475.724665905816, w0=6.374562518958238, w1=-75.4502660409192\n",
      "Gradient Descent(8808/9999): loss=4475.724665905816, w0=6.374562518958238, w1=-75.4502660409192\n",
      "Gradient Descent(8809/9999): loss=4475.724665905816, w0=18.98926251895824, w1=-72.4681660409192\n",
      "Gradient Descent(8810/9999): loss=7355.695303895272, w0=18.98926251895824, w1=-72.4681660409192\n",
      "Gradient Descent(8811/9999): loss=7355.695303895272, w0=18.98926251895824, w1=-72.4681660409192\n",
      "Gradient Descent(8812/9999): loss=7355.695303895272, w0=18.98926251895824, w1=-72.4681660409192\n",
      "Gradient Descent(8813/9999): loss=7355.695303895272, w0=18.98926251895824, w1=-72.4681660409192\n",
      "Gradient Descent(8814/9999): loss=7355.695303895272, w0=10.481062518958238, w1=-77.0611660409192\n",
      "Gradient Descent(8815/9999): loss=4306.230535764809, w0=10.481062518958238, w1=-77.0611660409192\n",
      "Gradient Descent(8816/9999): loss=4306.230535764809, w0=10.481062518958238, w1=-77.0611660409192\n",
      "Gradient Descent(8817/9999): loss=4306.230535764809, w0=-6.983137481041764, w1=-78.6133660409192\n",
      "Gradient Descent(8818/9999): loss=5802.4994844197445, w0=-6.983137481041764, w1=-78.6133660409192\n",
      "Gradient Descent(8819/9999): loss=5802.4994844197445, w0=4.514262518958235, w1=-71.5359660409192\n",
      "Gradient Descent(8820/9999): loss=4367.836578848586, w0=17.364662518958234, w1=-70.5278660409192\n",
      "Gradient Descent(8821/9999): loss=10275.803357232671, w0=17.364662518958234, w1=-70.5278660409192\n",
      "Gradient Descent(8822/9999): loss=10275.803357232671, w0=17.364662518958234, w1=-70.5278660409192\n",
      "Gradient Descent(8823/9999): loss=10275.803357232671, w0=5.2978971334047, w1=-77.40596604091921\n",
      "Gradient Descent(8824/9999): loss=4360.846244739974, w0=5.2978971334047, w1=-77.40596604091921\n",
      "Gradient Descent(8825/9999): loss=4360.846244739974, w0=5.2978971334047, w1=-77.40596604091921\n",
      "Gradient Descent(8826/9999): loss=4360.846244739974, w0=5.2978971334047, w1=-77.40596604091921\n",
      "Gradient Descent(8827/9999): loss=4360.846244739974, w0=-10.690902866595302, w1=-82.7161660409192\n",
      "Gradient Descent(8828/9999): loss=5802.4994844197445, w0=-10.690902866595302, w1=-82.7161660409192\n",
      "Gradient Descent(8829/9999): loss=5802.4994844197445, w0=-10.690902866595302, w1=-82.7161660409192\n",
      "Gradient Descent(8830/9999): loss=5802.4994844197445, w0=1.3758625189582325, w1=-70.62896604091921\n",
      "Gradient Descent(8831/9999): loss=4382.065282723497, w0=1.3758625189582325, w1=-70.62896604091921\n",
      "Gradient Descent(8832/9999): loss=4382.065282723497, w0=1.3758625189582325, w1=-70.62896604091921\n",
      "Gradient Descent(8833/9999): loss=4382.065282723497, w0=1.3758625189582325, w1=-70.62896604091921\n",
      "Gradient Descent(8834/9999): loss=4382.065282723497, w0=1.3758625189582325, w1=-70.62896604091921\n",
      "Gradient Descent(8835/9999): loss=4382.065282723497, w0=1.3758625189582325, w1=-70.62896604091921\n",
      "Gradient Descent(8836/9999): loss=4382.065282723497, w0=1.3758625189582325, w1=-70.62896604091921\n",
      "Gradient Descent(8837/9999): loss=4382.065282723497, w0=13.527062518958234, w1=-67.47496604091921\n",
      "Gradient Descent(8838/9999): loss=10766.141948962435, w0=13.527062518958234, w1=-67.47496604091921\n",
      "Gradient Descent(8839/9999): loss=10766.141948962435, w0=7.426362518958234, w1=-72.82156604091921\n",
      "Gradient Descent(8840/9999): loss=4563.943393738116, w0=7.426362518958234, w1=-72.82156604091921\n",
      "Gradient Descent(8841/9999): loss=4563.943393738116, w0=-0.11953748104176665, w1=-74.88856604091922\n",
      "Gradient Descent(8842/9999): loss=5031.250830753903, w0=11.848162518958233, w1=-68.98926604091922\n",
      "Gradient Descent(8843/9999): loss=5155.316080413815, w0=5.865362518958232, w1=-72.03836604091921\n",
      "Gradient Descent(8844/9999): loss=4477.099654495241, w0=5.865362518958232, w1=-72.03836604091921\n",
      "Gradient Descent(8845/9999): loss=4477.099654495241, w0=5.865362518958232, w1=-72.03836604091921\n",
      "Gradient Descent(8846/9999): loss=4477.099654495241, w0=20.90526251895823, w1=-64.26746604091922\n",
      "Gradient Descent(8847/9999): loss=14039.801140252483, w0=8.838497133404697, w1=-70.50106604091921\n",
      "Gradient Descent(8848/9999): loss=5280.430222974601, w0=8.838497133404697, w1=-70.50106604091921\n",
      "Gradient Descent(8849/9999): loss=5280.430222974601, w0=8.838497133404697, w1=-70.50106604091921\n",
      "Gradient Descent(8850/9999): loss=5280.430222974601, w0=8.838497133404697, w1=-70.50106604091921\n",
      "Gradient Descent(8851/9999): loss=5280.430222974601, w0=8.838497133404697, w1=-70.50106604091921\n",
      "Gradient Descent(8852/9999): loss=5280.430222974601, w0=8.838497133404697, w1=-70.50106604091921\n",
      "Gradient Descent(8853/9999): loss=5280.430222974601, w0=8.838497133404697, w1=-70.50106604091921\n",
      "Gradient Descent(8854/9999): loss=5280.430222974601, w0=8.838497133404697, w1=-70.50106604091921\n",
      "Gradient Descent(8855/9999): loss=5280.430222974601, w0=8.838497133404697, w1=-70.50106604091921\n",
      "Gradient Descent(8856/9999): loss=5280.430222974601, w0=-3.228268252148837, w1=-78.12356604091921\n",
      "Gradient Descent(8857/9999): loss=5318.27869733037, w0=-3.228268252148837, w1=-78.12356604091921\n",
      "Gradient Descent(8858/9999): loss=5318.27869733037, w0=-3.228268252148837, w1=-78.12356604091921\n",
      "Gradient Descent(8859/9999): loss=5318.27869733037, w0=-3.228268252148837, w1=-78.12356604091921\n",
      "Gradient Descent(8860/9999): loss=5318.27869733037, w0=-3.228268252148837, w1=-78.12356604091921\n",
      "Gradient Descent(8861/9999): loss=5318.27869733037, w0=-3.228268252148837, w1=-78.12356604091921\n",
      "Gradient Descent(8862/9999): loss=5318.27869733037, w0=-3.228268252148837, w1=-78.12356604091921\n",
      "Gradient Descent(8863/9999): loss=5318.27869733037, w0=-3.228268252148837, w1=-78.12356604091921\n",
      "Gradient Descent(8864/9999): loss=5318.27869733037, w0=-3.228268252148837, w1=-78.12356604091921\n",
      "Gradient Descent(8865/9999): loss=5318.27869733037, w0=-3.228268252148837, w1=-78.12356604091921\n",
      "Gradient Descent(8866/9999): loss=5318.27869733037, w0=7.238431747851164, w1=-72.61676604091922\n",
      "Gradient Descent(8867/9999): loss=4751.734537377754, w0=7.238431747851164, w1=-72.61676604091922\n",
      "Gradient Descent(8868/9999): loss=4751.734537377754, w0=7.238431747851164, w1=-72.61676604091922\n",
      "Gradient Descent(8869/9999): loss=4751.734537377754, w0=-4.038368252148835, w1=-73.97946604091922\n",
      "Gradient Descent(8870/9999): loss=5457.116781377274, w0=-4.038368252148835, w1=-73.97946604091922\n",
      "Gradient Descent(8871/9999): loss=5457.116781377274, w0=-4.038368252148835, w1=-73.97946604091922\n",
      "Gradient Descent(8872/9999): loss=5457.116781377274, w0=-4.038368252148835, w1=-73.97946604091922\n",
      "Gradient Descent(8873/9999): loss=5457.116781377274, w0=-4.038368252148835, w1=-73.97946604091922\n",
      "Gradient Descent(8874/9999): loss=5457.116781377274, w0=-4.038368252148835, w1=-73.97946604091922\n",
      "Gradient Descent(8875/9999): loss=5457.116781377274, w0=-4.038368252148835, w1=-73.97946604091922\n",
      "Gradient Descent(8876/9999): loss=5457.116781377274, w0=-4.038368252148835, w1=-73.97946604091922\n",
      "Gradient Descent(8877/9999): loss=5457.116781377274, w0=6.5196317478511645, w1=-70.66876604091922\n",
      "Gradient Descent(8878/9999): loss=4920.313451758066, w0=-3.044268252148836, w1=-73.91196604091922\n",
      "Gradient Descent(8879/9999): loss=4736.720629580024, w0=-3.044268252148836, w1=-73.91196604091922\n",
      "Gradient Descent(8880/9999): loss=4736.720629580024, w0=-3.044268252148836, w1=-73.91196604091922\n",
      "Gradient Descent(8881/9999): loss=4736.720629580024, w0=-3.044268252148836, w1=-73.91196604091922\n",
      "Gradient Descent(8882/9999): loss=4736.720629580024, w0=-3.044268252148836, w1=-73.91196604091922\n",
      "Gradient Descent(8883/9999): loss=4736.720629580024, w0=-3.044268252148836, w1=-73.91196604091922\n",
      "Gradient Descent(8884/9999): loss=4736.720629580024, w0=9.022497133404698, w1=-68.63606604091922\n",
      "Gradient Descent(8885/9999): loss=4674.321028104319, w0=9.022497133404698, w1=-68.63606604091922\n",
      "Gradient Descent(8886/9999): loss=4674.321028104319, w0=9.022497133404698, w1=-68.63606604091922\n",
      "Gradient Descent(8887/9999): loss=4674.321028104319, w0=9.022497133404698, w1=-68.63606604091922\n",
      "Gradient Descent(8888/9999): loss=4674.321028104319, w0=9.022497133404698, w1=-68.63606604091922\n",
      "Gradient Descent(8889/9999): loss=4674.321028104319, w0=9.022497133404698, w1=-68.63606604091922\n",
      "Gradient Descent(8890/9999): loss=4674.321028104319, w0=9.022497133404698, w1=-68.63606604091922\n",
      "Gradient Descent(8891/9999): loss=4674.321028104319, w0=9.022497133404698, w1=-68.63606604091922\n",
      "Gradient Descent(8892/9999): loss=4674.321028104319, w0=9.022497133404698, w1=-68.63606604091922\n",
      "Gradient Descent(8893/9999): loss=4674.321028104319, w0=9.022497133404698, w1=-68.63606604091922\n",
      "Gradient Descent(8894/9999): loss=4674.321028104319, w0=21.089262518958233, w1=-56.333366040919216\n",
      "Gradient Descent(8895/9999): loss=14940.125146563707, w0=21.089262518958233, w1=-56.333366040919216\n",
      "Gradient Descent(8896/9999): loss=14940.125146563707, w0=10.646262518958231, w1=-62.14806604091922\n",
      "Gradient Descent(8897/9999): loss=4930.6938520187505, w0=10.646262518958231, w1=-62.14806604091922\n",
      "Gradient Descent(8898/9999): loss=4930.6938520187505, w0=10.646262518958231, w1=-62.14806604091922\n",
      "Gradient Descent(8899/9999): loss=4930.6938520187505, w0=3.19706251895823, w1=-64.97566604091922\n",
      "Gradient Descent(8900/9999): loss=4789.467852005278, w0=3.19706251895823, w1=-64.97566604091922\n",
      "Gradient Descent(8901/9999): loss=4789.467852005278, w0=3.19706251895823, w1=-64.97566604091922\n",
      "Gradient Descent(8902/9999): loss=4789.467852005278, w0=3.19706251895823, w1=-64.97566604091922\n",
      "Gradient Descent(8903/9999): loss=4789.467852005278, w0=3.19706251895823, w1=-64.97566604091922\n",
      "Gradient Descent(8904/9999): loss=4789.467852005278, w0=15.967962518958231, w1=-58.57856604091922\n",
      "Gradient Descent(8905/9999): loss=10727.605261941635, w0=15.967962518958231, w1=-58.57856604091922\n",
      "Gradient Descent(8906/9999): loss=10727.605261941635, w0=3.901197133404697, w1=-65.04906604091921\n",
      "Gradient Descent(8907/9999): loss=4743.306319205805, w0=3.901197133404697, w1=-65.04906604091921\n",
      "Gradient Descent(8908/9999): loss=4743.306319205805, w0=3.901197133404697, w1=-65.04906604091921\n",
      "Gradient Descent(8909/9999): loss=4743.306319205805, w0=3.901197133404697, w1=-65.04906604091921\n",
      "Gradient Descent(8910/9999): loss=4743.306319205805, w0=3.901197133404697, w1=-65.04906604091921\n",
      "Gradient Descent(8911/9999): loss=4743.306319205805, w0=3.901197133404697, w1=-65.04906604091921\n",
      "Gradient Descent(8912/9999): loss=4743.306319205805, w0=3.901197133404697, w1=-65.04906604091921\n",
      "Gradient Descent(8913/9999): loss=4743.306319205805, w0=3.901197133404697, w1=-65.04906604091921\n",
      "Gradient Descent(8914/9999): loss=4743.306319205805, w0=3.901197133404697, w1=-65.04906604091921\n",
      "Gradient Descent(8915/9999): loss=4743.306319205805, w0=14.058297133404697, w1=-62.32526604091922\n",
      "Gradient Descent(8916/9999): loss=6241.054649371502, w0=14.058297133404697, w1=-62.32526604091922\n",
      "Gradient Descent(8917/9999): loss=6241.054649371502, w0=14.058297133404697, w1=-62.32526604091922\n",
      "Gradient Descent(8918/9999): loss=6241.054649371502, w0=14.058297133404697, w1=-62.32526604091922\n",
      "Gradient Descent(8919/9999): loss=6241.054649371502, w0=14.058297133404697, w1=-62.32526604091922\n",
      "Gradient Descent(8920/9999): loss=6241.054649371502, w0=14.058297133404697, w1=-62.32526604091922\n",
      "Gradient Descent(8921/9999): loss=6241.054649371502, w0=1.0973971334046944, w1=-64.66786604091922\n",
      "Gradient Descent(8922/9999): loss=4676.829287913506, w0=1.0973971334046944, w1=-64.66786604091922\n",
      "Gradient Descent(8923/9999): loss=4676.829287913506, w0=1.0973971334046944, w1=-64.66786604091922\n",
      "Gradient Descent(8924/9999): loss=4676.829287913506, w0=13.816597133404695, w1=-59.19176604091922\n",
      "Gradient Descent(8925/9999): loss=10868.905881736286, w0=13.816597133404695, w1=-59.19176604091922\n",
      "Gradient Descent(8926/9999): loss=10868.905881736286, w0=13.816597133404695, w1=-59.19176604091922\n",
      "Gradient Descent(8927/9999): loss=10868.905881736286, w0=13.816597133404695, w1=-59.19176604091922\n",
      "Gradient Descent(8928/9999): loss=10868.905881736286, w0=-5.755702866595303, w1=-64.27866604091922\n",
      "Gradient Descent(8929/9999): loss=5698.883065243532, w0=-5.755702866595303, w1=-64.27866604091922\n",
      "Gradient Descent(8930/9999): loss=5698.883065243532, w0=-5.755702866595303, w1=-64.27866604091922\n",
      "Gradient Descent(8931/9999): loss=5698.883065243532, w0=-5.755702866595303, w1=-64.27866604091922\n",
      "Gradient Descent(8932/9999): loss=5698.883065243532, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8933/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8934/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8935/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8936/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8937/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8938/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8939/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8940/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8941/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8942/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8943/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8944/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8945/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8946/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8947/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8948/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8949/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8950/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8951/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8952/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8953/9999): loss=4746.396365393966, w0=3.1310971334046958, w1=-61.03986604091922\n",
      "Gradient Descent(8954/9999): loss=4746.396365393966, w0=-8.935668252148838, w1=-67.84976604091922\n",
      "Gradient Descent(8955/9999): loss=5802.4994844197445, w0=-8.935668252148838, w1=-67.84976604091922\n",
      "Gradient Descent(8956/9999): loss=5802.4994844197445, w0=3.0536317478511616, w1=-67.56146604091921\n",
      "Gradient Descent(8957/9999): loss=4514.282918839199, w0=3.0536317478511616, w1=-67.56146604091921\n",
      "Gradient Descent(8958/9999): loss=4514.282918839199, w0=3.0536317478511616, w1=-67.56146604091921\n",
      "Gradient Descent(8959/9999): loss=4514.282918839199, w0=15.021331747851162, w1=-61.66216604091922\n",
      "Gradient Descent(8960/9999): loss=7472.3237756105555, w0=15.021331747851162, w1=-61.66216604091922\n",
      "Gradient Descent(8961/9999): loss=7472.3237756105555, w0=15.021331747851162, w1=-61.66216604091922\n",
      "Gradient Descent(8962/9999): loss=7472.3237756105555, w0=15.021331747851162, w1=-61.66216604091922\n",
      "Gradient Descent(8963/9999): loss=7472.3237756105555, w0=-0.3964682521488374, w1=-65.05106604091922\n",
      "Gradient Descent(8964/9999): loss=5490.578523600736, w0=-0.3964682521488374, w1=-65.05106604091922\n",
      "Gradient Descent(8965/9999): loss=5490.578523600736, w0=13.485731747851164, w1=-64.76366604091922\n",
      "Gradient Descent(8966/9999): loss=4615.923380507747, w0=13.485731747851164, w1=-64.76366604091922\n",
      "Gradient Descent(8967/9999): loss=4615.923380507747, w0=13.485731747851164, w1=-64.76366604091922\n",
      "Gradient Descent(8968/9999): loss=4615.923380507747, w0=13.485731747851164, w1=-64.76366604091922\n",
      "Gradient Descent(8969/9999): loss=4615.923380507747, w0=13.485731747851164, w1=-64.76366604091922\n",
      "Gradient Descent(8970/9999): loss=4615.923380507747, w0=13.485731747851164, w1=-64.76366604091922\n",
      "Gradient Descent(8971/9999): loss=4615.923380507747, w0=13.485731747851164, w1=-64.76366604091922\n",
      "Gradient Descent(8972/9999): loss=4615.923380507747, w0=13.485731747851164, w1=-64.76366604091922\n",
      "Gradient Descent(8973/9999): loss=4615.923380507747, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8974/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8975/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8976/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8977/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8978/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8979/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8980/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8981/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8982/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8983/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8984/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8985/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8986/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8987/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8988/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8989/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8990/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8991/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8992/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8993/9999): loss=5791.024726166479, w0=0.8024317478511627, w1=-66.81606604091922\n",
      "Gradient Descent(8994/9999): loss=5791.024726166479, w0=11.353631747851164, w1=-64.47906604091922\n",
      "Gradient Descent(8995/9999): loss=4558.372485104195, w0=11.353631747851164, w1=-64.47906604091922\n",
      "Gradient Descent(8996/9999): loss=4558.372485104195, w0=11.353631747851164, w1=-64.47906604091922\n",
      "Gradient Descent(8997/9999): loss=4558.372485104195, w0=20.010331747851165, w1=-62.138166040919224\n",
      "Gradient Descent(8998/9999): loss=5222.606769754768, w0=20.010331747851165, w1=-62.138166040919224\n",
      "Gradient Descent(8999/9999): loss=5222.606769754768, w0=20.010331747851165, w1=-62.138166040919224\n",
      "Gradient Descent(9000/9999): loss=5222.606769754768, w0=32.781231747851166, w1=-55.74106604091922\n",
      "Gradient Descent(9001/9999): loss=16613.405616048487, w0=32.781231747851166, w1=-55.74106604091922\n",
      "Gradient Descent(9002/9999): loss=16613.405616048487, w0=32.781231747851166, w1=-55.74106604091922\n",
      "Gradient Descent(9003/9999): loss=16613.405616048487, w0=32.781231747851166, w1=-55.74106604091922\n",
      "Gradient Descent(9004/9999): loss=16613.405616048487, w0=22.405631747851167, w1=-56.388166040919224\n",
      "Gradient Descent(9005/9999): loss=8845.060690725433, w0=4.723731747851165, w1=-64.37876604091923\n",
      "Gradient Descent(9006/9999): loss=5560.727838075716, w0=4.723731747851165, w1=-64.37876604091923\n",
      "Gradient Descent(9007/9999): loss=5560.727838075716, w0=4.723731747851165, w1=-64.37876604091923\n",
      "Gradient Descent(9008/9999): loss=5560.727838075716, w0=4.723731747851165, w1=-64.37876604091923\n",
      "Gradient Descent(9009/9999): loss=5560.727838075716, w0=14.213131747851165, w1=-60.87496604091923\n",
      "Gradient Descent(9010/9999): loss=4664.106777241436, w0=14.213131747851165, w1=-60.87496604091923\n",
      "Gradient Descent(9011/9999): loss=4664.106777241436, w0=4.343531747851165, w1=-61.214066040919235\n",
      "Gradient Descent(9012/9999): loss=5487.379449285378, w0=15.964131747851166, w1=-57.279966040919234\n",
      "Gradient Descent(9013/9999): loss=5694.322143691754, w0=15.964131747851166, w1=-57.279966040919234\n",
      "Gradient Descent(9014/9999): loss=5694.322143691754, w0=15.964131747851166, w1=-57.279966040919234\n",
      "Gradient Descent(9015/9999): loss=5694.322143691754, w0=6.595031747851165, w1=-59.47856604091923\n",
      "Gradient Descent(9016/9999): loss=5019.6266223179755, w0=17.981831747851167, w1=-59.36716604091923\n",
      "Gradient Descent(9017/9999): loss=5862.174278190518, w0=30.0485971334047, w1=-46.64426604091923\n",
      "Gradient Descent(9018/9999): loss=16917.249636505752, w0=20.8756971334047, w1=-53.25076604091923\n",
      "Gradient Descent(9019/9999): loss=10459.752811308801, w0=9.911597133404698, w1=-60.620066040919234\n",
      "Gradient Descent(9020/9999): loss=4507.200012393583, w0=9.911597133404698, w1=-60.620066040919234\n",
      "Gradient Descent(9021/9999): loss=4507.200012393583, w0=9.911597133404698, w1=-60.620066040919234\n",
      "Gradient Descent(9022/9999): loss=4507.200012393583, w0=9.911597133404698, w1=-60.620066040919234\n",
      "Gradient Descent(9023/9999): loss=4507.200012393583, w0=9.911597133404698, w1=-60.620066040919234\n",
      "Gradient Descent(9024/9999): loss=4507.200012393583, w0=20.1680971334047, w1=-54.36146604091923\n",
      "Gradient Descent(9025/9999): loss=8352.486038743165, w0=10.6237971334047, w1=-60.272066040919235\n",
      "Gradient Descent(9026/9999): loss=4538.147932683321, w0=21.1149971334047, w1=-57.655866040919236\n",
      "Gradient Descent(9027/9999): loss=9441.254894709062, w0=9.048231747851165, w1=-67.45786604091924\n",
      "Gradient Descent(9028/9999): loss=4385.540555611406, w0=9.048231747851165, w1=-67.45786604091924\n",
      "Gradient Descent(9029/9999): loss=4385.540555611406, w0=9.048231747851165, w1=-67.45786604091924\n",
      "Gradient Descent(9030/9999): loss=4385.540555611406, w0=9.048231747851165, w1=-67.45786604091924\n",
      "Gradient Descent(9031/9999): loss=4385.540555611406, w0=9.048231747851165, w1=-67.45786604091924\n",
      "Gradient Descent(9032/9999): loss=4385.540555611406, w0=9.048231747851165, w1=-67.45786604091924\n",
      "Gradient Descent(9033/9999): loss=4385.540555611406, w0=9.048231747851165, w1=-67.45786604091924\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(9034/9999): loss=4385.540555611406, w0=9.048231747851165, w1=-67.45786604091924\n",
      "Gradient Descent(9035/9999): loss=4385.540555611406, w0=20.48593174785117, w1=-61.83716604091924\n",
      "Gradient Descent(9036/9999): loss=8198.34467027248, w0=20.48593174785117, w1=-61.83716604091924\n",
      "Gradient Descent(9037/9999): loss=8198.34467027248, w0=8.419166362297634, w1=-71.16966604091924\n",
      "Gradient Descent(9038/9999): loss=4538.1423410967955, w0=8.419166362297634, w1=-71.16966604091924\n",
      "Gradient Descent(9039/9999): loss=4538.1423410967955, w0=8.419166362297634, w1=-71.16966604091924\n",
      "Gradient Descent(9040/9999): loss=4538.1423410967955, w0=8.419166362297634, w1=-71.16966604091924\n",
      "Gradient Descent(9041/9999): loss=4538.1423410967955, w0=8.419166362297634, w1=-71.16966604091924\n",
      "Gradient Descent(9042/9999): loss=4538.1423410967955, w0=8.419166362297634, w1=-71.16966604091924\n",
      "Gradient Descent(9043/9999): loss=4538.1423410967955, w0=8.419166362297634, w1=-71.16966604091924\n",
      "Gradient Descent(9044/9999): loss=4538.1423410967955, w0=8.419166362297634, w1=-71.16966604091924\n",
      "Gradient Descent(9045/9999): loss=4538.1423410967955, w0=8.419166362297634, w1=-71.16966604091924\n",
      "Gradient Descent(9046/9999): loss=4538.1423410967955, w0=8.419166362297634, w1=-71.16966604091924\n",
      "Gradient Descent(9047/9999): loss=4538.1423410967955, w0=20.051666362297635, w1=-67.33566604091924\n",
      "Gradient Descent(9048/9999): loss=7140.927211283875, w0=20.051666362297635, w1=-67.33566604091924\n",
      "Gradient Descent(9049/9999): loss=7140.927211283875, w0=7.724866362297636, w1=-70.33626604091924\n",
      "Gradient Descent(9050/9999): loss=5514.676097796739, w0=7.724866362297636, w1=-70.33626604091924\n",
      "Gradient Descent(9051/9999): loss=5514.676097796739, w0=7.724866362297636, w1=-70.33626604091924\n",
      "Gradient Descent(9052/9999): loss=5514.676097796739, w0=7.724866362297636, w1=-70.33626604091924\n",
      "Gradient Descent(9053/9999): loss=5514.676097796739, w0=17.620966362297636, w1=-64.31096604091924\n",
      "Gradient Descent(9054/9999): loss=4319.946992331181, w0=17.620966362297636, w1=-64.31096604091924\n",
      "Gradient Descent(9055/9999): loss=4319.946992331181, w0=17.620966362297636, w1=-64.31096604091924\n",
      "Gradient Descent(9056/9999): loss=4319.946992331181, w0=17.620966362297636, w1=-64.31096604091924\n",
      "Gradient Descent(9057/9999): loss=4319.946992331181, w0=17.620966362297636, w1=-64.31096604091924\n",
      "Gradient Descent(9058/9999): loss=4319.946992331181, w0=17.620966362297636, w1=-64.31096604091924\n",
      "Gradient Descent(9059/9999): loss=4319.946992331181, w0=17.620966362297636, w1=-64.31096604091924\n",
      "Gradient Descent(9060/9999): loss=4319.946992331181, w0=17.620966362297636, w1=-64.31096604091924\n",
      "Gradient Descent(9061/9999): loss=4319.946992331181, w0=17.620966362297636, w1=-64.31096604091924\n",
      "Gradient Descent(9062/9999): loss=4319.946992331181, w0=17.620966362297636, w1=-64.31096604091924\n",
      "Gradient Descent(9063/9999): loss=4319.946992331181, w0=24.472566362297638, w1=-61.48436604091924\n",
      "Gradient Descent(9064/9999): loss=7882.276750706337, w0=6.552766362297639, w1=-65.73386604091924\n",
      "Gradient Descent(9065/9999): loss=4664.870886293196, w0=6.552766362297639, w1=-65.73386604091924\n",
      "Gradient Descent(9066/9999): loss=4664.870886293196, w0=6.552766362297639, w1=-65.73386604091924\n",
      "Gradient Descent(9067/9999): loss=4664.870886293196, w0=16.528966362297638, w1=-61.126766040919236\n",
      "Gradient Descent(9068/9999): loss=5428.926968456151, w0=16.528966362297638, w1=-61.126766040919236\n",
      "Gradient Descent(9069/9999): loss=5428.926968456151, w0=24.91136636229764, w1=-58.518466040919236\n",
      "Gradient Descent(9070/9999): loss=15948.743843992568, w0=24.91136636229764, w1=-58.518466040919236\n",
      "Gradient Descent(9071/9999): loss=15948.743843992568, w0=16.555066362297637, w1=-63.814466040919235\n",
      "Gradient Descent(9072/9999): loss=5521.491700652308, w0=16.555066362297637, w1=-63.814466040919235\n",
      "Gradient Descent(9073/9999): loss=5521.491700652308, w0=16.555066362297637, w1=-63.814466040919235\n",
      "Gradient Descent(9074/9999): loss=5521.491700652308, w0=16.555066362297637, w1=-63.814466040919235\n",
      "Gradient Descent(9075/9999): loss=5521.491700652308, w0=16.555066362297637, w1=-63.814466040919235\n",
      "Gradient Descent(9076/9999): loss=5521.491700652308, w0=16.555066362297637, w1=-63.814466040919235\n",
      "Gradient Descent(9077/9999): loss=5521.491700652308, w0=16.555066362297637, w1=-63.814466040919235\n",
      "Gradient Descent(9078/9999): loss=5521.491700652308, w0=16.555066362297637, w1=-63.814466040919235\n",
      "Gradient Descent(9079/9999): loss=5521.491700652308, w0=7.404666362297638, w1=-67.12896604091924\n",
      "Gradient Descent(9080/9999): loss=4601.48843452172, w0=7.404666362297638, w1=-67.12896604091924\n",
      "Gradient Descent(9081/9999): loss=4601.48843452172, w0=7.404666362297638, w1=-67.12896604091924\n",
      "Gradient Descent(9082/9999): loss=4601.48843452172, w0=19.93076636229764, w1=-60.97856604091924\n",
      "Gradient Descent(9083/9999): loss=8932.639817048399, w0=19.93076636229764, w1=-60.97856604091924\n",
      "Gradient Descent(9084/9999): loss=8932.639817048399, w0=5.797166362297638, w1=-65.71576604091923\n",
      "Gradient Descent(9085/9999): loss=4377.329597992246, w0=5.797166362297638, w1=-65.71576604091923\n",
      "Gradient Descent(9086/9999): loss=4377.329597992246, w0=5.797166362297638, w1=-65.71576604091923\n",
      "Gradient Descent(9087/9999): loss=4377.329597992246, w0=5.797166362297638, w1=-65.71576604091923\n",
      "Gradient Descent(9088/9999): loss=4377.329597992246, w0=5.797166362297638, w1=-65.71576604091923\n",
      "Gradient Descent(9089/9999): loss=4377.329597992246, w0=5.797166362297638, w1=-65.71576604091923\n",
      "Gradient Descent(9090/9999): loss=4377.329597992246, w0=5.797166362297638, w1=-65.71576604091923\n",
      "Gradient Descent(9091/9999): loss=4377.329597992246, w0=5.797166362297638, w1=-65.71576604091923\n",
      "Gradient Descent(9092/9999): loss=4377.329597992246, w0=5.797166362297638, w1=-65.71576604091923\n",
      "Gradient Descent(9093/9999): loss=4377.329597992246, w0=5.797166362297638, w1=-65.71576604091923\n",
      "Gradient Descent(9094/9999): loss=4377.329597992246, w0=5.797166362297638, w1=-65.71576604091923\n",
      "Gradient Descent(9095/9999): loss=4377.329597992246, w0=5.797166362297638, w1=-65.71576604091923\n",
      "Gradient Descent(9096/9999): loss=4377.329597992246, w0=5.797166362297638, w1=-65.71576604091923\n",
      "Gradient Descent(9097/9999): loss=4377.329597992246, w0=19.442466362297637, w1=-62.009266040919236\n",
      "Gradient Descent(9098/9999): loss=10165.096954987659, w0=19.442466362297637, w1=-62.009266040919236\n",
      "Gradient Descent(9099/9999): loss=10165.096954987659, w0=19.442466362297637, w1=-62.009266040919236\n",
      "Gradient Descent(9100/9999): loss=10165.096954987659, w0=19.442466362297637, w1=-62.009266040919236\n",
      "Gradient Descent(9101/9999): loss=10165.096954987659, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9102/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9103/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9104/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9105/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9106/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9107/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9108/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9109/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9110/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9111/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9112/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9113/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9114/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9115/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9116/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9117/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9118/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9119/9999): loss=4243.209234084796, w0=11.496566362297635, w1=-66.14866604091924\n",
      "Gradient Descent(9120/9999): loss=4243.209234084796, w0=26.628066362297638, w1=-59.31076604091924\n",
      "Gradient Descent(9121/9999): loss=16039.255319430584, w0=26.628066362297638, w1=-59.31076604091924\n",
      "Gradient Descent(9122/9999): loss=16039.255319430584, w0=13.875266362297637, w1=-63.45076604091924\n",
      "Gradient Descent(9123/9999): loss=4721.900623479362, w0=13.875266362297637, w1=-63.45076604091924\n",
      "Gradient Descent(9124/9999): loss=4721.900623479362, w0=13.875266362297637, w1=-63.45076604091924\n",
      "Gradient Descent(9125/9999): loss=4721.900623479362, w0=1.1919663622976362, w1=-65.50316604091924\n",
      "Gradient Descent(9126/9999): loss=5770.347083979284, w0=1.1919663622976362, w1=-65.50316604091924\n",
      "Gradient Descent(9127/9999): loss=5770.347083979284, w0=1.1919663622976362, w1=-65.50316604091924\n",
      "Gradient Descent(9128/9999): loss=5770.347083979284, w0=1.1919663622976362, w1=-65.50316604091924\n",
      "Gradient Descent(9129/9999): loss=5770.347083979284, w0=1.1919663622976362, w1=-65.50316604091924\n",
      "Gradient Descent(9130/9999): loss=5770.347083979284, w0=13.25873174785117, w1=-52.47126604091924\n",
      "Gradient Descent(9131/9999): loss=4802.946634354818, w0=13.25873174785117, w1=-52.47126604091924\n",
      "Gradient Descent(9132/9999): loss=4802.946634354818, w0=13.25873174785117, w1=-52.47126604091924\n",
      "Gradient Descent(9133/9999): loss=4802.946634354818, w0=13.25873174785117, w1=-52.47126604091924\n",
      "Gradient Descent(9134/9999): loss=4802.946634354818, w0=13.25873174785117, w1=-52.47126604091924\n",
      "Gradient Descent(9135/9999): loss=4802.946634354818, w0=21.00823174785117, w1=-47.67896604091924\n",
      "Gradient Descent(9136/9999): loss=14650.157312783966, w0=9.084131747851169, w1=-50.879566040919244\n",
      "Gradient Descent(9137/9999): loss=4743.306301140472, w0=9.084131747851169, w1=-50.879566040919244\n",
      "Gradient Descent(9138/9999): loss=4743.306301140472, w0=9.084131747851169, w1=-50.879566040919244\n",
      "Gradient Descent(9139/9999): loss=4743.306301140472, w0=17.437231747851172, w1=-45.51396604091924\n",
      "Gradient Descent(9140/9999): loss=12249.089777797984, w0=8.20853174785117, w1=-47.019366040919245\n",
      "Gradient Descent(9141/9999): loss=4749.925773882208, w0=8.20853174785117, w1=-47.019366040919245\n",
      "Gradient Descent(9142/9999): loss=4749.925773882208, w0=8.20853174785117, w1=-47.019366040919245\n",
      "Gradient Descent(9143/9999): loss=4749.925773882208, w0=8.20853174785117, w1=-47.019366040919245\n",
      "Gradient Descent(9144/9999): loss=4749.925773882208, w0=8.20853174785117, w1=-47.019366040919245\n",
      "Gradient Descent(9145/9999): loss=4749.925773882208, w0=8.20853174785117, w1=-47.019366040919245\n",
      "Gradient Descent(9146/9999): loss=4749.925773882208, w0=8.20853174785117, w1=-47.019366040919245\n",
      "Gradient Descent(9147/9999): loss=4749.925773882208, w0=8.20853174785117, w1=-47.019366040919245\n",
      "Gradient Descent(9148/9999): loss=4749.925773882208, w0=8.20853174785117, w1=-47.019366040919245\n",
      "Gradient Descent(9149/9999): loss=4749.925773882208, w0=8.20853174785117, w1=-47.019366040919245\n",
      "Gradient Descent(9150/9999): loss=4749.925773882208, w0=17.15413174785117, w1=-38.430766040919245\n",
      "Gradient Descent(9151/9999): loss=12957.962429723402, w0=5.087366362297637, w1=-45.81426604091924\n",
      "Gradient Descent(9152/9999): loss=4733.160254401733, w0=5.087366362297637, w1=-45.81426604091924\n",
      "Gradient Descent(9153/9999): loss=4733.160254401733, w0=17.31066636229764, w1=-43.48006604091924\n",
      "Gradient Descent(9154/9999): loss=12185.635409389766, w0=9.707166362297638, w1=-47.22866604091924\n",
      "Gradient Descent(9155/9999): loss=4501.0247922994695, w0=9.707166362297638, w1=-47.22866604091924\n",
      "Gradient Descent(9156/9999): loss=4501.0247922994695, w0=9.707166362297638, w1=-47.22866604091924\n",
      "Gradient Descent(9157/9999): loss=4501.0247922994695, w0=9.707166362297638, w1=-47.22866604091924\n",
      "Gradient Descent(9158/9999): loss=4501.0247922994695, w0=9.707166362297638, w1=-47.22866604091924\n",
      "Gradient Descent(9159/9999): loss=4501.0247922994695, w0=9.707166362297638, w1=-47.22866604091924\n",
      "Gradient Descent(9160/9999): loss=4501.0247922994695, w0=9.707166362297638, w1=-47.22866604091924\n",
      "Gradient Descent(9161/9999): loss=4501.0247922994695, w0=21.53076636229764, w1=-44.19786604091924\n",
      "Gradient Descent(9162/9999): loss=14016.937131825573, w0=11.06446636229764, w1=-50.36446604091924\n",
      "Gradient Descent(9163/9999): loss=4513.731080084674, w0=11.06446636229764, w1=-50.36446604091924\n",
      "Gradient Descent(9164/9999): loss=4513.731080084674, w0=11.06446636229764, w1=-50.36446604091924\n",
      "Gradient Descent(9165/9999): loss=4513.731080084674, w0=24.48136636229764, w1=-48.09106604091924\n",
      "Gradient Descent(9166/9999): loss=14588.182360009854, w0=12.414600976744104, w1=-56.327766040919236\n",
      "Gradient Descent(9167/9999): loss=4520.6941521132, w0=12.414600976744104, w1=-56.327766040919236\n",
      "Gradient Descent(9168/9999): loss=4520.6941521132, w0=12.414600976744104, w1=-56.327766040919236\n",
      "Gradient Descent(9169/9999): loss=4520.6941521132, w0=22.052100976744107, w1=-53.30876604091924\n",
      "Gradient Descent(9170/9999): loss=8919.784077537419, w0=11.991600976744106, w1=-58.06366604091924\n",
      "Gradient Descent(9171/9999): loss=4811.876669517864, w0=11.991600976744106, w1=-58.06366604091924\n",
      "Gradient Descent(9172/9999): loss=4811.876669517864, w0=22.460900976744107, w1=-55.644066040919235\n",
      "Gradient Descent(9173/9999): loss=9000.706281374329, w0=12.396500976744107, w1=-61.57606604091924\n",
      "Gradient Descent(9174/9999): loss=4503.976759402289, w0=12.396500976744107, w1=-61.57606604091924\n",
      "Gradient Descent(9175/9999): loss=4503.976759402289, w0=12.396500976744107, w1=-61.57606604091924\n",
      "Gradient Descent(9176/9999): loss=4503.976759402289, w0=12.396500976744107, w1=-61.57606604091924\n",
      "Gradient Descent(9177/9999): loss=4503.976759402289, w0=12.396500976744107, w1=-61.57606604091924\n",
      "Gradient Descent(9178/9999): loss=4503.976759402289, w0=12.396500976744107, w1=-61.57606604091924\n",
      "Gradient Descent(9179/9999): loss=4503.976759402289, w0=12.396500976744107, w1=-61.57606604091924\n",
      "Gradient Descent(9180/9999): loss=4503.976759402289, w0=-1.6311990232558955, w1=-62.511766040919234\n",
      "Gradient Descent(9181/9999): loss=5802.4994844197445, w0=-1.6311990232558955, w1=-62.511766040919234\n",
      "Gradient Descent(9182/9999): loss=5802.4994844197445, w0=8.614800976744105, w1=-58.33366604091923\n",
      "Gradient Descent(9183/9999): loss=4416.329319217064, w0=8.614800976744105, w1=-58.33366604091923\n",
      "Gradient Descent(9184/9999): loss=4416.329319217064, w0=8.614800976744105, w1=-58.33366604091923\n",
      "Gradient Descent(9185/9999): loss=4416.329319217064, w0=8.614800976744105, w1=-58.33366604091923\n",
      "Gradient Descent(9186/9999): loss=4416.329319217064, w0=8.614800976744105, w1=-58.33366604091923\n",
      "Gradient Descent(9187/9999): loss=4416.329319217064, w0=8.614800976744105, w1=-58.33366604091923\n",
      "Gradient Descent(9188/9999): loss=4416.329319217064, w0=8.614800976744105, w1=-58.33366604091923\n",
      "Gradient Descent(9189/9999): loss=4416.329319217064, w0=8.614800976744105, w1=-58.33366604091923\n",
      "Gradient Descent(9190/9999): loss=4416.329319217064, w0=20.76790097674411, w1=-54.24546604091923\n",
      "Gradient Descent(9191/9999): loss=13330.23844913175, w0=20.76790097674411, w1=-54.24546604091923\n",
      "Gradient Descent(9192/9999): loss=13330.23844913175, w0=5.237800976744106, w1=-59.57056604091923\n",
      "Gradient Descent(9193/9999): loss=4391.0183902693625, w0=5.237800976744106, w1=-59.57056604091923\n",
      "Gradient Descent(9194/9999): loss=4391.0183902693625, w0=5.237800976744106, w1=-59.57056604091923\n",
      "Gradient Descent(9195/9999): loss=4391.0183902693625, w0=12.912600976744107, w1=-56.76706604091923\n",
      "Gradient Descent(9196/9999): loss=7893.890618908286, w0=-4.135899023255893, w1=-57.897466040919234\n",
      "Gradient Descent(9197/9999): loss=5802.4994844197445, w0=-4.135899023255893, w1=-57.897466040919234\n",
      "Gradient Descent(9198/9999): loss=5802.4994844197445, w0=-4.135899023255893, w1=-57.897466040919234\n",
      "Gradient Descent(9199/9999): loss=5802.4994844197445, w0=-4.135899023255893, w1=-57.897466040919234\n",
      "Gradient Descent(9200/9999): loss=5802.4994844197445, w0=-4.135899023255893, w1=-57.897466040919234\n",
      "Gradient Descent(9201/9999): loss=5802.4994844197445, w0=-4.135899023255893, w1=-57.897466040919234\n",
      "Gradient Descent(9202/9999): loss=5802.4994844197445, w0=-4.135899023255893, w1=-57.897466040919234\n",
      "Gradient Descent(9203/9999): loss=5802.4994844197445, w0=-4.135899023255893, w1=-57.897466040919234\n",
      "Gradient Descent(9204/9999): loss=5802.4994844197445, w0=7.930866362297641, w1=-50.66856604091923\n",
      "Gradient Descent(9205/9999): loss=4523.880372012728, w0=7.930866362297641, w1=-50.66856604091923\n",
      "Gradient Descent(9206/9999): loss=4523.880372012728, w0=16.921866362297642, w1=-46.67736604091923\n",
      "Gradient Descent(9207/9999): loss=14874.401904401602, w0=6.874066362297642, w1=-50.61156604091923\n",
      "Gradient Descent(9208/9999): loss=5308.945542436877, w0=-2.166433637702358, w1=-53.809266040919226\n",
      "Gradient Descent(9209/9999): loss=5306.124327477072, w0=-9.35163363770236, w1=-56.122366040919225\n",
      "Gradient Descent(9210/9999): loss=5802.4994844197445, w0=-9.35163363770236, w1=-56.122366040919225\n",
      "Gradient Descent(9211/9999): loss=5802.4994844197445, w0=-9.35163363770236, w1=-56.122366040919225\n",
      "Gradient Descent(9212/9999): loss=5802.4994844197445, w0=-1.2005336377023585, w1=-53.864466040919226\n",
      "Gradient Descent(9213/9999): loss=5781.548994611205, w0=12.205466362297642, w1=-53.160466040919225\n",
      "Gradient Descent(9214/9999): loss=4765.714725990441, w0=12.205466362297642, w1=-53.160466040919225\n",
      "Gradient Descent(9215/9999): loss=4765.714725990441, w0=12.205466362297642, w1=-53.160466040919225\n",
      "Gradient Descent(9216/9999): loss=4765.714725990441, w0=12.205466362297642, w1=-53.160466040919225\n",
      "Gradient Descent(9217/9999): loss=4765.714725990441, w0=12.205466362297642, w1=-53.160466040919225\n",
      "Gradient Descent(9218/9999): loss=4765.714725990441, w0=0.43056636229764145, w1=-55.916066040919226\n",
      "Gradient Descent(9219/9999): loss=5767.960678020792, w0=13.215366362297642, w1=-54.93386604091923\n",
      "Gradient Descent(9220/9999): loss=6138.193652107702, w0=-0.8089336377023582, w1=-61.39556604091923\n",
      "Gradient Descent(9221/9999): loss=5677.973217103694, w0=-0.8089336377023582, w1=-61.39556604091923\n",
      "Gradient Descent(9222/9999): loss=5677.973217103694, w0=7.535866362297641, w1=-58.651266040919225\n",
      "Gradient Descent(9223/9999): loss=4949.376606091998, w0=7.535866362297641, w1=-58.651266040919225\n",
      "Gradient Descent(9224/9999): loss=4949.376606091998, w0=-0.6430336377023593, w1=-60.77716604091923\n",
      "Gradient Descent(9225/9999): loss=5249.794295552481, w0=-0.6430336377023593, w1=-60.77716604091923\n",
      "Gradient Descent(9226/9999): loss=5249.794295552481, w0=-0.6430336377023593, w1=-60.77716604091923\n",
      "Gradient Descent(9227/9999): loss=5249.794295552481, w0=11.49586636229764, w1=-57.838766040919225\n",
      "Gradient Descent(9228/9999): loss=7013.5109912703, w0=11.49586636229764, w1=-57.838766040919225\n",
      "Gradient Descent(9229/9999): loss=7013.5109912703, w0=11.49586636229764, w1=-57.838766040919225\n",
      "Gradient Descent(9230/9999): loss=7013.5109912703, w0=2.868366362297639, w1=-59.72736604091922\n",
      "Gradient Descent(9231/9999): loss=4867.962171739422, w0=-10.020233637702361, w1=-59.76846604091922\n",
      "Gradient Descent(9232/9999): loss=5802.4994844197445, w0=-10.020233637702361, w1=-59.76846604091922\n",
      "Gradient Descent(9233/9999): loss=5802.4994844197445, w0=0.9573663622976412, w1=-56.30486604091922\n",
      "Gradient Descent(9234/9999): loss=5756.447744935002, w0=0.9573663622976412, w1=-56.30486604091922\n",
      "Gradient Descent(9235/9999): loss=5756.447744935002, w0=15.133566362297643, w1=-55.718466040919225\n",
      "Gradient Descent(9236/9999): loss=5974.968117156426, w0=15.133566362297643, w1=-55.718466040919225\n",
      "Gradient Descent(9237/9999): loss=5974.968117156426, w0=15.133566362297643, w1=-55.718466040919225\n",
      "Gradient Descent(9238/9999): loss=5974.968117156426, w0=3.6659663622976417, w1=-58.46446604091923\n",
      "Gradient Descent(9239/9999): loss=5077.079197226473, w0=3.6659663622976417, w1=-58.46446604091923\n",
      "Gradient Descent(9240/9999): loss=5077.079197226473, w0=3.6659663622976417, w1=-58.46446604091923\n",
      "Gradient Descent(9241/9999): loss=5077.079197226473, w0=14.923266362297642, w1=-55.71536604091923\n",
      "Gradient Descent(9242/9999): loss=8954.29791122781, w0=14.923266362297642, w1=-55.71536604091923\n",
      "Gradient Descent(9243/9999): loss=8954.29791122781, w0=14.923266362297642, w1=-55.71536604091923\n",
      "Gradient Descent(9244/9999): loss=8954.29791122781, w0=2.8565009767441083, w1=-63.35296604091923\n",
      "Gradient Descent(9245/9999): loss=4424.872922484772, w0=2.8565009767441083, w1=-63.35296604091923\n",
      "Gradient Descent(9246/9999): loss=4424.872922484772, w0=12.182700976744108, w1=-58.71946604091923\n",
      "Gradient Descent(9247/9999): loss=9509.021563134245, w0=12.182700976744108, w1=-58.71946604091923\n",
      "Gradient Descent(9248/9999): loss=9509.021563134245, w0=12.182700976744108, w1=-58.71946604091923\n",
      "Gradient Descent(9249/9999): loss=9509.021563134245, w0=12.182700976744108, w1=-58.71946604091923\n",
      "Gradient Descent(9250/9999): loss=9509.021563134245, w0=0.9986009767441075, w1=-62.23406604091923\n",
      "Gradient Descent(9251/9999): loss=4521.516304761623, w0=0.9986009767441075, w1=-62.23406604091923\n",
      "Gradient Descent(9252/9999): loss=4521.516304761623, w0=0.9986009767441075, w1=-62.23406604091923\n",
      "Gradient Descent(9253/9999): loss=4521.516304761623, w0=14.605900976744106, w1=-57.05726604091923\n",
      "Gradient Descent(9254/9999): loss=11417.057001438261, w0=6.164400976744105, w1=-58.88466604091923\n",
      "Gradient Descent(9255/9999): loss=4928.174282502711, w0=16.532500976744103, w1=-53.641866040919226\n",
      "Gradient Descent(9256/9999): loss=15299.196690188817, w0=3.968600976744103, w1=-62.483866040919224\n",
      "Gradient Descent(9257/9999): loss=5087.567638709999, w0=3.968600976744103, w1=-62.483866040919224\n",
      "Gradient Descent(9258/9999): loss=5087.567638709999, w0=3.968600976744103, w1=-62.483866040919224\n",
      "Gradient Descent(9259/9999): loss=5087.567638709999, w0=3.968600976744103, w1=-62.483866040919224\n",
      "Gradient Descent(9260/9999): loss=5087.567638709999, w0=3.968600976744103, w1=-62.483866040919224\n",
      "Gradient Descent(9261/9999): loss=5087.567638709999, w0=3.968600976744103, w1=-62.483866040919224\n",
      "Gradient Descent(9262/9999): loss=5087.567638709999, w0=3.968600976744103, w1=-62.483866040919224\n",
      "Gradient Descent(9263/9999): loss=5087.567638709999, w0=13.944800976744103, w1=-57.87676604091922\n",
      "Gradient Descent(9264/9999): loss=12673.135724493604, w0=9.478200976744102, w1=-63.997566040919224\n",
      "Gradient Descent(9265/9999): loss=5803.5028239472385, w0=9.478200976744102, w1=-63.997566040919224\n",
      "Gradient Descent(9266/9999): loss=5803.5028239472385, w0=9.478200976744102, w1=-63.997566040919224\n",
      "Gradient Descent(9267/9999): loss=5803.5028239472385, w0=9.478200976744102, w1=-63.997566040919224\n",
      "Gradient Descent(9268/9999): loss=5803.5028239472385, w0=9.478200976744102, w1=-63.997566040919224\n",
      "Gradient Descent(9269/9999): loss=5803.5028239472385, w0=9.478200976744102, w1=-63.997566040919224\n",
      "Gradient Descent(9270/9999): loss=5803.5028239472385, w0=9.478200976744102, w1=-63.997566040919224\n",
      "Gradient Descent(9271/9999): loss=5803.5028239472385, w0=9.478200976744102, w1=-63.997566040919224\n",
      "Gradient Descent(9272/9999): loss=5803.5028239472385, w0=17.753900976744102, w1=-57.67036604091923\n",
      "Gradient Descent(9273/9999): loss=15162.51611234382, w0=11.665600976744102, w1=-61.27446604091923\n",
      "Gradient Descent(9274/9999): loss=5964.015621812392, w0=11.665600976744102, w1=-61.27446604091923\n",
      "Gradient Descent(9275/9999): loss=5964.015621812392, w0=11.665600976744102, w1=-61.27446604091923\n",
      "Gradient Descent(9276/9999): loss=5964.015621812392, w0=11.665600976744102, w1=-61.27446604091923\n",
      "Gradient Descent(9277/9999): loss=5964.015621812392, w0=11.665600976744102, w1=-61.27446604091923\n",
      "Gradient Descent(9278/9999): loss=5964.015621812392, w0=11.665600976744102, w1=-61.27446604091923\n",
      "Gradient Descent(9279/9999): loss=5964.015621812392, w0=11.665600976744102, w1=-61.27446604091923\n",
      "Gradient Descent(9280/9999): loss=5964.015621812392, w0=11.665600976744102, w1=-61.27446604091923\n",
      "Gradient Descent(9281/9999): loss=5964.015621812392, w0=11.665600976744102, w1=-61.27446604091923\n",
      "Gradient Descent(9282/9999): loss=5964.015621812392, w0=11.665600976744102, w1=-61.27446604091923\n",
      "Gradient Descent(9283/9999): loss=5964.015621812392, w0=6.232200976744102, w1=-65.63136604091923\n",
      "Gradient Descent(9284/9999): loss=4570.612965569255, w0=6.232200976744102, w1=-65.63136604091923\n",
      "Gradient Descent(9285/9999): loss=4570.612965569255, w0=6.232200976744102, w1=-65.63136604091923\n",
      "Gradient Descent(9286/9999): loss=4570.612965569255, w0=18.298966362297637, w1=-52.013066040919234\n",
      "Gradient Descent(9287/9999): loss=12257.401159242749, w0=18.298966362297637, w1=-52.013066040919234\n",
      "Gradient Descent(9288/9999): loss=12257.401159242749, w0=18.298966362297637, w1=-52.013066040919234\n",
      "Gradient Descent(9289/9999): loss=12257.401159242749, w0=18.298966362297637, w1=-52.013066040919234\n",
      "Gradient Descent(9290/9999): loss=12257.401159242749, w0=18.298966362297637, w1=-52.013066040919234\n",
      "Gradient Descent(9291/9999): loss=12257.401159242749, w0=18.298966362297637, w1=-52.013066040919234\n",
      "Gradient Descent(9292/9999): loss=12257.401159242749, w0=6.232200976744103, w1=-59.62336604091924\n",
      "Gradient Descent(9293/9999): loss=4400.721000794977, w0=6.232200976744103, w1=-59.62336604091924\n",
      "Gradient Descent(9294/9999): loss=4400.721000794977, w0=6.232200976744103, w1=-59.62336604091924\n",
      "Gradient Descent(9295/9999): loss=4400.721000794977, w0=6.232200976744103, w1=-59.62336604091924\n",
      "Gradient Descent(9296/9999): loss=4400.721000794977, w0=-2.4263990232558967, w1=-61.59776604091924\n",
      "Gradient Descent(9297/9999): loss=5802.4994844197445, w0=-2.4263990232558967, w1=-61.59776604091924\n",
      "Gradient Descent(9298/9999): loss=5802.4994844197445, w0=14.063100976744106, w1=-54.86126604091924\n",
      "Gradient Descent(9299/9999): loss=6091.69081561733, w0=-1.9256990232558948, w1=-60.17146604091924\n",
      "Gradient Descent(9300/9999): loss=5802.4994844197445, w0=-1.9256990232558948, w1=-60.17146604091924\n",
      "Gradient Descent(9301/9999): loss=5802.4994844197445, w0=-1.9256990232558948, w1=-60.17146604091924\n",
      "Gradient Descent(9302/9999): loss=5802.4994844197445, w0=-1.9256990232558948, w1=-60.17146604091924\n",
      "Gradient Descent(9303/9999): loss=5802.4994844197445, w0=11.491200976744103, w1=-57.89806604091924\n",
      "Gradient Descent(9304/9999): loss=4397.758684164672, w0=11.491200976744103, w1=-57.89806604091924\n",
      "Gradient Descent(9305/9999): loss=4397.758684164672, w0=11.491200976744103, w1=-57.89806604091924\n",
      "Gradient Descent(9306/9999): loss=4397.758684164672, w0=11.491200976744103, w1=-57.89806604091924\n",
      "Gradient Descent(9307/9999): loss=4397.758684164672, w0=11.491200976744103, w1=-57.89806604091924\n",
      "Gradient Descent(9308/9999): loss=4397.758684164672, w0=19.766900976744104, w1=-51.57086604091924\n",
      "Gradient Descent(9309/9999): loss=14195.47915893566, w0=7.70013559119057, w1=-58.26046604091924\n",
      "Gradient Descent(9310/9999): loss=4414.547379400831, w0=7.70013559119057, w1=-58.26046604091924\n",
      "Gradient Descent(9311/9999): loss=4414.547379400831, w0=7.70013559119057, w1=-58.26046604091924\n",
      "Gradient Descent(9312/9999): loss=4414.547379400831, w0=7.70013559119057, w1=-58.26046604091924\n",
      "Gradient Descent(9313/9999): loss=4414.547379400831, w0=7.70013559119057, w1=-58.26046604091924\n",
      "Gradient Descent(9314/9999): loss=4414.547379400831, w0=7.70013559119057, w1=-58.26046604091924\n",
      "Gradient Descent(9315/9999): loss=4414.547379400831, w0=7.70013559119057, w1=-58.26046604091924\n",
      "Gradient Descent(9316/9999): loss=4414.547379400831, w0=7.70013559119057, w1=-58.26046604091924\n",
      "Gradient Descent(9317/9999): loss=4414.547379400831, w0=17.00173559119057, w1=-50.26536604091924\n",
      "Gradient Descent(9318/9999): loss=16384.568746656798, w0=17.00173559119057, w1=-50.26536604091924\n",
      "Gradient Descent(9319/9999): loss=16384.568746656798, w0=4.934970205637036, w1=-58.72936604091924\n",
      "Gradient Descent(9320/9999): loss=7243.098256103776, w0=-4.961129794362964, w1=-63.71736604091924\n",
      "Gradient Descent(9321/9999): loss=5164.330159606064, w0=-4.961129794362964, w1=-63.71736604091924\n",
      "Gradient Descent(9322/9999): loss=5164.330159606064, w0=-4.961129794362964, w1=-63.71736604091924\n",
      "Gradient Descent(9323/9999): loss=5164.330159606064, w0=-4.961129794362964, w1=-63.71736604091924\n",
      "Gradient Descent(9324/9999): loss=5164.330159606064, w0=-4.961129794362964, w1=-63.71736604091924\n",
      "Gradient Descent(9325/9999): loss=5164.330159606064, w0=-4.961129794362964, w1=-63.71736604091924\n",
      "Gradient Descent(9326/9999): loss=5164.330159606064, w0=-4.961129794362964, w1=-63.71736604091924\n",
      "Gradient Descent(9327/9999): loss=5164.330159606064, w0=8.187270205637038, w1=-58.117566040919236\n",
      "Gradient Descent(9328/9999): loss=5499.883196416951, w0=20.254035591190572, w1=-48.16126604091924\n",
      "Gradient Descent(9329/9999): loss=16451.964789470956, w0=9.29783559119057, w1=-52.719866040919236\n",
      "Gradient Descent(9330/9999): loss=5266.575500043575, w0=9.29783559119057, w1=-52.719866040919236\n",
      "Gradient Descent(9331/9999): loss=5266.575500043575, w0=20.68003559119057, w1=-47.336266040919234\n",
      "Gradient Descent(9332/9999): loss=16600.021586627405, w0=9.90653559119057, w1=-54.52686604091924\n",
      "Gradient Descent(9333/9999): loss=6962.094213240325, w0=-2.160229794362964, w1=-59.30086604091924\n",
      "Gradient Descent(9334/9999): loss=4587.098374074629, w0=11.325270205637036, w1=-55.89436604091924\n",
      "Gradient Descent(9335/9999): loss=12024.005400086327, w0=11.325270205637036, w1=-55.89436604091924\n",
      "Gradient Descent(9336/9999): loss=12024.005400086327, w0=11.325270205637036, w1=-55.89436604091924\n",
      "Gradient Descent(9337/9999): loss=12024.005400086327, w0=11.325270205637036, w1=-55.89436604091924\n",
      "Gradient Descent(9338/9999): loss=12024.005400086327, w0=3.441470205637035, w1=-58.59666604091924\n",
      "Gradient Descent(9339/9999): loss=4345.510929777278, w0=3.441470205637035, w1=-58.59666604091924\n",
      "Gradient Descent(9340/9999): loss=4345.510929777278, w0=3.441470205637035, w1=-58.59666604091924\n",
      "Gradient Descent(9341/9999): loss=4345.510929777278, w0=3.441470205637035, w1=-58.59666604091924\n",
      "Gradient Descent(9342/9999): loss=4345.510929777278, w0=3.441470205637035, w1=-58.59666604091924\n",
      "Gradient Descent(9343/9999): loss=4345.510929777278, w0=3.441470205637035, w1=-58.59666604091924\n",
      "Gradient Descent(9344/9999): loss=4345.510929777278, w0=3.441470205637035, w1=-58.59666604091924\n",
      "Gradient Descent(9345/9999): loss=4345.510929777278, w0=3.441470205637035, w1=-58.59666604091924\n",
      "Gradient Descent(9346/9999): loss=4345.510929777278, w0=3.441470205637035, w1=-58.59666604091924\n",
      "Gradient Descent(9347/9999): loss=4345.510929777278, w0=12.417770205637035, w1=-54.649866040919235\n",
      "Gradient Descent(9348/9999): loss=9871.20998366511, w0=12.417770205637035, w1=-54.649866040919235\n",
      "Gradient Descent(9349/9999): loss=9871.20998366511, w0=0.3510048200835012, w1=-63.14656604091924\n",
      "Gradient Descent(9350/9999): loss=4490.017979005952, w0=0.3510048200835012, w1=-63.14656604091924\n",
      "Gradient Descent(9351/9999): loss=4490.017979005952, w0=0.3510048200835012, w1=-63.14656604091924\n",
      "Gradient Descent(9352/9999): loss=4490.017979005952, w0=0.3510048200835012, w1=-63.14656604091924\n",
      "Gradient Descent(9353/9999): loss=4490.017979005952, w0=8.428504820083502, w1=-60.55026604091924\n",
      "Gradient Descent(9354/9999): loss=7635.796125615647, w0=-5.7560951799165, w1=-65.98876604091924\n",
      "Gradient Descent(9355/9999): loss=4683.785036817647, w0=-5.7560951799165, w1=-65.98876604091924\n",
      "Gradient Descent(9356/9999): loss=4683.785036817647, w0=-5.7560951799165, w1=-65.98876604091924\n",
      "Gradient Descent(9357/9999): loss=4683.785036817647, w0=-5.7560951799165, w1=-65.98876604091924\n",
      "Gradient Descent(9358/9999): loss=4683.785036817647, w0=-5.7560951799165, w1=-65.98876604091924\n",
      "Gradient Descent(9359/9999): loss=4683.785036817647, w0=-5.7560951799165, w1=-65.98876604091924\n",
      "Gradient Descent(9360/9999): loss=4683.785036817647, w0=-5.7560951799165, w1=-65.98876604091924\n",
      "Gradient Descent(9361/9999): loss=4683.785036817647, w0=-5.7560951799165, w1=-65.98876604091924\n",
      "Gradient Descent(9362/9999): loss=4683.785036817647, w0=-5.7560951799165, w1=-65.98876604091924\n",
      "Gradient Descent(9363/9999): loss=4683.785036817647, w0=-5.7560951799165, w1=-65.98876604091924\n",
      "Gradient Descent(9364/9999): loss=4683.785036817647, w0=-5.7560951799165, w1=-65.98876604091924\n",
      "Gradient Descent(9365/9999): loss=4683.785036817647, w0=-5.7560951799165, w1=-65.98876604091924\n",
      "Gradient Descent(9366/9999): loss=4683.785036817647, w0=6.3106702056370345, w1=-58.874466040919245\n",
      "Gradient Descent(9367/9999): loss=5903.915441818048, w0=6.3106702056370345, w1=-58.874466040919245\n",
      "Gradient Descent(9368/9999): loss=5903.915441818048, w0=6.3106702056370345, w1=-58.874466040919245\n",
      "Gradient Descent(9369/9999): loss=5903.915441818048, w0=6.3106702056370345, w1=-58.874466040919245\n",
      "Gradient Descent(9370/9999): loss=5903.915441818048, w0=6.3106702056370345, w1=-58.874466040919245\n",
      "Gradient Descent(9371/9999): loss=5903.915441818048, w0=6.3106702056370345, w1=-58.874466040919245\n",
      "Gradient Descent(9372/9999): loss=5903.915441818048, w0=6.3106702056370345, w1=-58.874466040919245\n",
      "Gradient Descent(9373/9999): loss=5903.915441818048, w0=6.3106702056370345, w1=-58.874466040919245\n",
      "Gradient Descent(9374/9999): loss=5903.915441818048, w0=6.27750160637194, w1=-58.89334395051261\n",
      "Gradient Descent(9375/9999): loss=5890.8309160308645, w0=6.27750160637194, w1=-58.89334395051261\n",
      "Gradient Descent(9376/9999): loss=5890.8309160308645, w0=6.27750160637194, w1=-58.89334395051261\n",
      "Gradient Descent(9377/9999): loss=5890.8309160308645, w0=-3.0429983936280607, w1=-61.461943950512605\n",
      "Gradient Descent(9378/9999): loss=4812.498978644294, w0=5.140901606371939, w1=-59.90954395051261\n",
      "Gradient Descent(9379/9999): loss=6114.539737754741, w0=5.140901606371939, w1=-59.90954395051261\n",
      "Gradient Descent(9380/9999): loss=6114.539737754741, w0=-6.262098393628062, w1=-63.34814395051261\n",
      "Gradient Descent(9381/9999): loss=5399.546743595797, w0=-6.262098393628062, w1=-63.34814395051261\n",
      "Gradient Descent(9382/9999): loss=5399.546743595797, w0=-6.262098393628062, w1=-63.34814395051261\n",
      "Gradient Descent(9383/9999): loss=5399.546743595797, w0=-6.262098393628062, w1=-63.34814395051261\n",
      "Gradient Descent(9384/9999): loss=5399.546743595797, w0=3.1247016063719375, w1=-60.08454395051261\n",
      "Gradient Descent(9385/9999): loss=4533.259195669283, w0=3.1247016063719375, w1=-60.08454395051261\n",
      "Gradient Descent(9386/9999): loss=4533.259195669283, w0=3.1247016063719375, w1=-60.08454395051261\n",
      "Gradient Descent(9387/9999): loss=4533.259195669283, w0=3.1247016063719375, w1=-60.08454395051261\n",
      "Gradient Descent(9388/9999): loss=4533.259195669283, w0=3.1247016063719375, w1=-60.08454395051261\n",
      "Gradient Descent(9389/9999): loss=4533.259195669283, w0=3.1247016063719375, w1=-60.08454395051261\n",
      "Gradient Descent(9390/9999): loss=4533.259195669283, w0=3.1247016063719375, w1=-60.08454395051261\n",
      "Gradient Descent(9391/9999): loss=4533.259195669283, w0=11.507101606371938, w1=-57.47624395051261\n",
      "Gradient Descent(9392/9999): loss=14043.480521473573, w0=-0.5596637791815962, w1=-66.9931439505126\n",
      "Gradient Descent(9393/9999): loss=4325.730606897124, w0=-0.5596637791815962, w1=-66.9931439505126\n",
      "Gradient Descent(9394/9999): loss=4325.730606897124, w0=7.716036220818404, w1=-60.665943950512606\n",
      "Gradient Descent(9395/9999): loss=11887.092898480554, w0=7.716036220818404, w1=-60.665943950512606\n",
      "Gradient Descent(9396/9999): loss=11887.092898480554, w0=-6.762263779181595, w1=-71.9844439505126\n",
      "Gradient Descent(9397/9999): loss=4914.214342825282, w0=-6.762263779181595, w1=-71.9844439505126\n",
      "Gradient Descent(9398/9999): loss=4914.214342825282, w0=-6.762263779181595, w1=-71.9844439505126\n",
      "Gradient Descent(9399/9999): loss=4914.214342825282, w0=-6.762263779181595, w1=-71.9844439505126\n",
      "Gradient Descent(9400/9999): loss=4914.214342825282, w0=-19.613660489568225, w1=-72.75664375285012\n",
      "Gradient Descent(9401/9999): loss=5802.4994844197445, w0=-19.613660489568225, w1=-72.75664375285012\n",
      "Gradient Descent(9402/9999): loss=5802.4994844197445, w0=-19.613660489568225, w1=-72.75664375285012\n",
      "Gradient Descent(9403/9999): loss=5802.4994844197445, w0=-8.226860489568224, w1=-72.64524375285012\n",
      "Gradient Descent(9404/9999): loss=5192.200261229183, w0=2.766339510431777, w1=-68.81334375285012\n",
      "Gradient Descent(9405/9999): loss=5157.226315330179, w0=2.766339510431777, w1=-68.81334375285012\n",
      "Gradient Descent(9406/9999): loss=5157.226315330179, w0=-6.797560489568223, w1=-72.05654375285012\n",
      "Gradient Descent(9407/9999): loss=4576.0854223272745, w0=-6.797560489568223, w1=-72.05654375285012\n",
      "Gradient Descent(9408/9999): loss=4576.0854223272745, w0=-6.797560489568223, w1=-72.05654375285012\n",
      "Gradient Descent(9409/9999): loss=4576.0854223272745, w0=-6.797560489568223, w1=-72.05654375285012\n",
      "Gradient Descent(9410/9999): loss=4576.0854223272745, w0=-6.797560489568223, w1=-72.05654375285012\n",
      "Gradient Descent(9411/9999): loss=4576.0854223272745, w0=-6.797560489568223, w1=-72.05654375285012\n",
      "Gradient Descent(9412/9999): loss=4576.0854223272745, w0=-6.797560489568223, w1=-72.05654375285012\n",
      "Gradient Descent(9413/9999): loss=4576.0854223272745, w0=5.5017395104317774, w1=-68.96834375285012\n",
      "Gradient Descent(9414/9999): loss=5682.230946125977, w0=-5.511660489568223, w1=-75.94224375285012\n",
      "Gradient Descent(9415/9999): loss=4729.9212495779375, w0=9.51473951043178, w1=-74.32054375285011\n",
      "Gradient Descent(9416/9999): loss=7266.79053571909, w0=9.51473951043178, w1=-74.32054375285011\n",
      "Gradient Descent(9417/9999): loss=7266.79053571909, w0=9.51473951043178, w1=-74.32054375285011\n",
      "Gradient Descent(9418/9999): loss=7266.79053571909, w0=18.676139510431778, w1=-66.74594375285011\n",
      "Gradient Descent(9419/9999): loss=16820.379274625124, w0=10.945139510431776, w1=-71.35474375285011\n",
      "Gradient Descent(9420/9999): loss=10671.341223031712, w0=-7.130060489568226, w1=-72.12044375285011\n",
      "Gradient Descent(9421/9999): loss=4358.798476553247, w0=-7.130060489568226, w1=-72.12044375285011\n",
      "Gradient Descent(9422/9999): loss=4358.798476553247, w0=-7.130060489568226, w1=-72.12044375285011\n",
      "Gradient Descent(9423/9999): loss=4358.798476553247, w0=1.8746395104317752, w1=-67.86034375285011\n",
      "Gradient Descent(9424/9999): loss=9044.132316183166, w0=1.8746395104317752, w1=-67.86034375285011\n",
      "Gradient Descent(9425/9999): loss=9044.132316183166, w0=1.8746395104317752, w1=-67.86034375285011\n",
      "Gradient Descent(9426/9999): loss=9044.132316183166, w0=1.8746395104317752, w1=-67.86034375285011\n",
      "Gradient Descent(9427/9999): loss=9044.132316183166, w0=1.8746395104317752, w1=-67.86034375285011\n",
      "Gradient Descent(9428/9999): loss=9044.132316183166, w0=-10.192125875121759, w1=-76.83714375285011\n",
      "Gradient Descent(9429/9999): loss=4602.217912327005, w0=-10.192125875121759, w1=-76.83714375285011\n",
      "Gradient Descent(9430/9999): loss=4602.217912327005, w0=-10.192125875121759, w1=-76.83714375285011\n",
      "Gradient Descent(9431/9999): loss=4602.217912327005, w0=2.145074124878244, w1=-74.60254375285011\n",
      "Gradient Descent(9432/9999): loss=8872.443853193607, w0=2.145074124878244, w1=-74.60254375285011\n",
      "Gradient Descent(9433/9999): loss=8872.443853193607, w0=2.145074124878244, w1=-74.60254375285011\n",
      "Gradient Descent(9434/9999): loss=8872.443853193607, w0=2.145074124878244, w1=-74.60254375285011\n",
      "Gradient Descent(9435/9999): loss=8872.443853193607, w0=2.145074124878244, w1=-74.60254375285011\n",
      "Gradient Descent(9436/9999): loss=8872.443853193607, w0=2.145074124878244, w1=-74.60254375285011\n",
      "Gradient Descent(9437/9999): loss=8872.443853193607, w0=2.145074124878244, w1=-74.60254375285011\n",
      "Gradient Descent(9438/9999): loss=8872.443853193607, w0=-11.160525875121758, w1=-77.12014375285011\n",
      "Gradient Descent(9439/9999): loss=4706.545512985489, w0=-0.16732587512175634, w1=-73.28824375285011\n",
      "Gradient Descent(9440/9999): loss=9469.475709230945, w0=-20.952025875121755, w1=-84.66564375285012\n",
      "Gradient Descent(9441/9999): loss=5733.421876235781, w0=-20.952025875121755, w1=-84.66564375285012\n",
      "Gradient Descent(9442/9999): loss=5733.421876235781, w0=-9.713225875121756, w1=-83.51744375285011\n",
      "Gradient Descent(9443/9999): loss=4797.709926258255, w0=-9.713225875121756, w1=-83.51744375285011\n",
      "Gradient Descent(9444/9999): loss=4797.709926258255, w0=-9.713225875121756, w1=-83.51744375285011\n",
      "Gradient Descent(9445/9999): loss=4797.709926258255, w0=-22.168225875121756, w1=-86.3203437528501\n",
      "Gradient Descent(9446/9999): loss=5802.4994844197445, w0=-22.168225875121756, w1=-86.3203437528501\n",
      "Gradient Descent(9447/9999): loss=5802.4994844197445, w0=-22.168225875121756, w1=-86.3203437528501\n",
      "Gradient Descent(9448/9999): loss=5802.4994844197445, w0=-22.168225875121756, w1=-86.3203437528501\n",
      "Gradient Descent(9449/9999): loss=5802.4994844197445, w0=-12.687025875121755, w1=-86.0548437528501\n",
      "Gradient Descent(9450/9999): loss=4800.87456867306, w0=-12.687025875121755, w1=-86.0548437528501\n",
      "Gradient Descent(9451/9999): loss=4800.87456867306, w0=-12.687025875121755, w1=-86.0548437528501\n",
      "Gradient Descent(9452/9999): loss=4800.87456867306, w0=-12.687025875121755, w1=-86.0548437528501\n",
      "Gradient Descent(9453/9999): loss=4800.87456867306, w0=-12.687025875121755, w1=-86.0548437528501\n",
      "Gradient Descent(9454/9999): loss=4800.87456867306, w0=-12.687025875121755, w1=-86.0548437528501\n",
      "Gradient Descent(9455/9999): loss=4800.87456867306, w0=-12.687025875121755, w1=-86.0548437528501\n",
      "Gradient Descent(9456/9999): loss=4800.87456867306, w0=-12.687025875121755, w1=-86.0548437528501\n",
      "Gradient Descent(9457/9999): loss=4800.87456867306, w0=-12.687025875121755, w1=-86.0548437528501\n",
      "Gradient Descent(9458/9999): loss=4800.87456867306, w0=-12.687025875121755, w1=-86.0548437528501\n",
      "Gradient Descent(9459/9999): loss=4800.87456867306, w0=-4.3422258751217555, w1=-83.31054375285011\n",
      "Gradient Descent(9460/9999): loss=5258.896858192118, w0=-11.126225875121756, w1=-84.1806437528501\n",
      "Gradient Descent(9461/9999): loss=4570.644198351856, w0=-11.126225875121756, w1=-84.1806437528501\n",
      "Gradient Descent(9462/9999): loss=4570.644198351856, w0=-11.126225875121756, w1=-84.1806437528501\n",
      "Gradient Descent(9463/9999): loss=4570.644198351856, w0=0.940539510431778, w1=-74.13974375285011\n",
      "Gradient Descent(9464/9999): loss=6416.5595747021725, w0=0.940539510431778, w1=-74.13974375285011\n",
      "Gradient Descent(9465/9999): loss=6416.5595747021725, w0=0.940539510431778, w1=-74.13974375285011\n",
      "Gradient Descent(9466/9999): loss=6416.5595747021725, w0=0.940539510431778, w1=-74.13974375285011\n",
      "Gradient Descent(9467/9999): loss=6416.5595747021725, w0=-9.663260489568222, w1=-81.20064375285011\n",
      "Gradient Descent(9468/9999): loss=5151.620778472358, w0=-9.663260489568222, w1=-81.20064375285011\n",
      "Gradient Descent(9469/9999): loss=5151.620778472358, w0=2.4035048959853125, w1=-72.19654375285012\n",
      "Gradient Descent(9470/9999): loss=8582.755640352772, w0=2.4035048959853125, w1=-72.19654375285012\n",
      "Gradient Descent(9471/9999): loss=8582.755640352772, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9472/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9473/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9474/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9475/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9476/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9477/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9478/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9479/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9480/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9481/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9482/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9483/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9484/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9485/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9486/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9487/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9488/9999): loss=4708.781385410046, w0=-0.018695104014687658, w1=-79.96744375285012\n",
      "Gradient Descent(9489/9999): loss=4708.781385410046, w0=-9.721595104014687, w1=-85.46514375285011\n",
      "Gradient Descent(9490/9999): loss=5802.4994844197445, w0=-2.648595104014687, w1=-82.89294375285012\n",
      "Gradient Descent(9491/9999): loss=4551.021688015302, w0=-2.648595104014687, w1=-82.89294375285012\n",
      "Gradient Descent(9492/9999): loss=4551.021688015302, w0=-2.648595104014687, w1=-82.89294375285012\n",
      "Gradient Descent(9493/9999): loss=4551.021688015302, w0=-2.648595104014687, w1=-82.89294375285012\n",
      "Gradient Descent(9494/9999): loss=4551.021688015302, w0=-2.648595104014687, w1=-82.89294375285012\n",
      "Gradient Descent(9495/9999): loss=4551.021688015302, w0=-2.648595104014687, w1=-82.89294375285012\n",
      "Gradient Descent(9496/9999): loss=4551.021688015302, w0=-2.648595104014687, w1=-82.89294375285012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(9497/9999): loss=4551.021688015302, w0=-2.648595104014687, w1=-82.89294375285012\n",
      "Gradient Descent(9498/9999): loss=4551.021688015302, w0=-11.832395104014687, w1=-83.41174375285011\n",
      "Gradient Descent(9499/9999): loss=5802.4994844197445, w0=-11.832395104014687, w1=-83.41174375285011\n",
      "Gradient Descent(9500/9999): loss=5802.4994844197445, w0=-11.832395104014687, w1=-83.41174375285011\n",
      "Gradient Descent(9501/9999): loss=5802.4994844197445, w0=-11.832395104014687, w1=-83.41174375285011\n",
      "Gradient Descent(9502/9999): loss=5802.4994844197445, w0=-4.1575951040146855, w1=-80.60824375285011\n",
      "Gradient Descent(9503/9999): loss=4589.435707971007, w0=-4.1575951040146855, w1=-80.60824375285011\n",
      "Gradient Descent(9504/9999): loss=4589.435707971007, w0=-4.1575951040146855, w1=-80.60824375285011\n",
      "Gradient Descent(9505/9999): loss=4589.435707971007, w0=-4.1575951040146855, w1=-80.60824375285011\n",
      "Gradient Descent(9506/9999): loss=4589.435707971007, w0=-4.1575951040146855, w1=-80.60824375285011\n",
      "Gradient Descent(9507/9999): loss=4589.435707971007, w0=7.474904895985315, w1=-76.77424375285011\n",
      "Gradient Descent(9508/9999): loss=6601.466599983459, w0=7.474904895985315, w1=-76.77424375285011\n",
      "Gradient Descent(9509/9999): loss=6601.466599983459, w0=7.474904895985315, w1=-76.77424375285011\n",
      "Gradient Descent(9510/9999): loss=6601.466599983459, w0=7.474904895985315, w1=-76.77424375285011\n",
      "Gradient Descent(9511/9999): loss=6601.466599983459, w0=7.474904895985315, w1=-76.77424375285011\n",
      "Gradient Descent(9512/9999): loss=6601.466599983459, w0=7.474904895985315, w1=-76.77424375285011\n",
      "Gradient Descent(9513/9999): loss=6601.466599983459, w0=7.474904895985315, w1=-76.77424375285011\n",
      "Gradient Descent(9514/9999): loss=6601.466599983459, w0=7.474904895985315, w1=-76.77424375285011\n",
      "Gradient Descent(9515/9999): loss=6601.466599983459, w0=7.474904895985315, w1=-76.77424375285011\n",
      "Gradient Descent(9516/9999): loss=6601.466599983459, w0=5.358504895985314, w1=-83.07104375285012\n",
      "Gradient Descent(9517/9999): loss=4398.059257628247, w0=5.358504895985314, w1=-83.07104375285012\n",
      "Gradient Descent(9518/9999): loss=4398.059257628247, w0=5.358504895985314, w1=-83.07104375285012\n",
      "Gradient Descent(9519/9999): loss=4398.059257628247, w0=5.358504895985314, w1=-83.07104375285012\n",
      "Gradient Descent(9520/9999): loss=4398.059257628247, w0=5.358504895985314, w1=-83.07104375285012\n",
      "Gradient Descent(9521/9999): loss=4398.059257628247, w0=5.358504895985314, w1=-83.07104375285012\n",
      "Gradient Descent(9522/9999): loss=4398.059257628247, w0=5.358504895985314, w1=-83.07104375285012\n",
      "Gradient Descent(9523/9999): loss=4398.059257628247, w0=18.574604895985317, w1=-77.41294375285011\n",
      "Gradient Descent(9524/9999): loss=10003.922392330056, w0=18.574604895985317, w1=-77.41294375285011\n",
      "Gradient Descent(9525/9999): loss=10003.922392330056, w0=6.507839510431783, w1=-85.4834437528501\n",
      "Gradient Descent(9526/9999): loss=4380.290717251058, w0=6.507839510431783, w1=-85.4834437528501\n",
      "Gradient Descent(9527/9999): loss=4380.290717251058, w0=6.507839510431783, w1=-85.4834437528501\n",
      "Gradient Descent(9528/9999): loss=4380.290717251058, w0=-17.83486048956822, w1=-87.5522437528501\n",
      "Gradient Descent(9529/9999): loss=5802.4994844197445, w0=-17.83486048956822, w1=-87.5522437528501\n",
      "Gradient Descent(9530/9999): loss=5802.4994844197445, w0=-17.83486048956822, w1=-87.5522437528501\n",
      "Gradient Descent(9531/9999): loss=5802.4994844197445, w0=-17.83486048956822, w1=-87.5522437528501\n",
      "Gradient Descent(9532/9999): loss=5802.4994844197445, w0=-17.83486048956822, w1=-87.5522437528501\n",
      "Gradient Descent(9533/9999): loss=5802.4994844197445, w0=-17.83486048956822, w1=-87.5522437528501\n",
      "Gradient Descent(9534/9999): loss=5802.4994844197445, w0=-17.83486048956822, w1=-87.5522437528501\n",
      "Gradient Descent(9535/9999): loss=5802.4994844197445, w0=-17.83486048956822, w1=-87.5522437528501\n",
      "Gradient Descent(9536/9999): loss=5802.4994844197445, w0=-17.83486048956822, w1=-87.5522437528501\n",
      "Gradient Descent(9537/9999): loss=5802.4994844197445, w0=-17.83486048956822, w1=-87.5522437528501\n",
      "Gradient Descent(9538/9999): loss=5802.4994844197445, w0=-4.284060489568223, w1=-76.7628437528501\n",
      "Gradient Descent(9539/9999): loss=5686.6408132798015, w0=-4.284060489568223, w1=-76.7628437528501\n",
      "Gradient Descent(9540/9999): loss=5686.6408132798015, w0=-4.284060489568223, w1=-76.7628437528501\n",
      "Gradient Descent(9541/9999): loss=5686.6408132798015, w0=6.605639510431779, w1=-69.02674375285011\n",
      "Gradient Descent(9542/9999): loss=4893.315661073209, w0=-5.192560489568223, w1=-73.63514375285011\n",
      "Gradient Descent(9543/9999): loss=5230.530196454933, w0=-5.192560489568223, w1=-73.63514375285011\n",
      "Gradient Descent(9544/9999): loss=5230.530196454933, w0=-5.192560489568223, w1=-73.63514375285011\n",
      "Gradient Descent(9545/9999): loss=5230.530196454933, w0=-5.192560489568223, w1=-73.63514375285011\n",
      "Gradient Descent(9546/9999): loss=5230.530196454933, w0=-5.192560489568223, w1=-73.63514375285011\n",
      "Gradient Descent(9547/9999): loss=5230.530196454933, w0=-5.192560489568223, w1=-73.63514375285011\n",
      "Gradient Descent(9548/9999): loss=5230.530196454933, w0=-5.192560489568223, w1=-73.63514375285011\n",
      "Gradient Descent(9549/9999): loss=5230.530196454933, w0=7.483839510431778, w1=-72.20484375285011\n",
      "Gradient Descent(9550/9999): loss=7077.967657356239, w0=7.483839510431778, w1=-72.20484375285011\n",
      "Gradient Descent(9551/9999): loss=7077.967657356239, w0=7.483839510431778, w1=-72.20484375285011\n",
      "Gradient Descent(9552/9999): loss=7077.967657356239, w0=7.483839510431778, w1=-72.20484375285011\n",
      "Gradient Descent(9553/9999): loss=7077.967657356239, w0=-10.591360489568224, w1=-72.9705437528501\n",
      "Gradient Descent(9554/9999): loss=5226.486437863567, w0=-0.4342604895682243, w1=-70.24674375285011\n",
      "Gradient Descent(9555/9999): loss=5562.8746473388765, w0=-0.4342604895682243, w1=-70.24674375285011\n",
      "Gradient Descent(9556/9999): loss=5562.8746473388765, w0=-9.051160489568224, w1=-71.2428437528501\n",
      "Gradient Descent(9557/9999): loss=4928.440459891486, w0=3.733639510431777, w1=-70.2606437528501\n",
      "Gradient Descent(9558/9999): loss=7962.555779886168, w0=-14.124260489568224, w1=-76.8552437528501\n",
      "Gradient Descent(9559/9999): loss=5644.612517867923, w0=-14.124260489568224, w1=-76.8552437528501\n",
      "Gradient Descent(9560/9999): loss=5644.612517867923, w0=-14.124260489568224, w1=-76.8552437528501\n",
      "Gradient Descent(9561/9999): loss=5644.612517867923, w0=-14.124260489568224, w1=-76.8552437528501\n",
      "Gradient Descent(9562/9999): loss=5644.612517867923, w0=-6.865960489568224, w1=-72.6009437528501\n",
      "Gradient Descent(9563/9999): loss=4909.896198888737, w0=-6.865960489568224, w1=-72.6009437528501\n",
      "Gradient Descent(9564/9999): loss=4909.896198888737, w0=-6.865960489568224, w1=-72.6009437528501\n",
      "Gradient Descent(9565/9999): loss=4909.896198888737, w0=-6.865960489568224, w1=-72.6009437528501\n",
      "Gradient Descent(9566/9999): loss=4909.896198888737, w0=-15.482860489568223, w1=-73.5970437528501\n",
      "Gradient Descent(9567/9999): loss=5778.412019244679, w0=-15.482860489568223, w1=-73.5970437528501\n",
      "Gradient Descent(9568/9999): loss=5778.412019244679, w0=-15.482860489568223, w1=-73.5970437528501\n",
      "Gradient Descent(9569/9999): loss=5778.412019244679, w0=-15.482860489568223, w1=-73.5970437528501\n",
      "Gradient Descent(9570/9999): loss=5778.412019244679, w0=-3.6660604895682223, w1=-70.0872437528501\n",
      "Gradient Descent(9571/9999): loss=5108.177137273257, w0=-3.6660604895682223, w1=-70.0872437528501\n",
      "Gradient Descent(9572/9999): loss=5108.177137273257, w0=-3.6660604895682223, w1=-70.0872437528501\n",
      "Gradient Descent(9573/9999): loss=5108.177137273257, w0=6.70193951043178, w1=-63.7098437528501\n",
      "Gradient Descent(9574/9999): loss=12732.119371030416, w0=-0.6139604895682194, w1=-70.5173437528501\n",
      "Gradient Descent(9575/9999): loss=5217.797871970842, w0=-0.6139604895682194, w1=-70.5173437528501\n",
      "Gradient Descent(9576/9999): loss=5217.797871970842, w0=-10.00616048956822, w1=-71.70294375285009\n",
      "Gradient Descent(9577/9999): loss=4743.456614160594, w0=5.738539510431782, w1=-67.93614375285009\n",
      "Gradient Descent(9578/9999): loss=11025.795913159416, w0=-6.328225875121753, w1=-74.35184375285009\n",
      "Gradient Descent(9579/9999): loss=4550.957647159484, w0=-16.620025875121755, w1=-74.84044375285009\n",
      "Gradient Descent(9580/9999): loss=5802.4994844197445, w0=-16.620025875121755, w1=-74.84044375285009\n",
      "Gradient Descent(9581/9999): loss=5802.4994844197445, w0=-16.620025875121755, w1=-74.84044375285009\n",
      "Gradient Descent(9582/9999): loss=5802.4994844197445, w0=-16.620025875121755, w1=-74.84044375285009\n",
      "Gradient Descent(9583/9999): loss=5802.4994844197445, w0=-16.620025875121755, w1=-74.84044375285009\n",
      "Gradient Descent(9584/9999): loss=5802.4994844197445, w0=-3.8692258751217548, w1=-69.2394437528501\n",
      "Gradient Descent(9585/9999): loss=4651.06670152675, w0=-3.8692258751217548, w1=-69.2394437528501\n",
      "Gradient Descent(9586/9999): loss=4651.06670152675, w0=-3.8692258751217548, w1=-69.2394437528501\n",
      "Gradient Descent(9587/9999): loss=4651.06670152675, w0=-13.053025875121754, w1=-69.75824375285009\n",
      "Gradient Descent(9588/9999): loss=5353.538990600631, w0=-13.053025875121754, w1=-69.75824375285009\n",
      "Gradient Descent(9589/9999): loss=5353.538990600631, w0=-3.808625875121754, w1=-68.53074375285009\n",
      "Gradient Descent(9590/9999): loss=4758.425665317848, w0=-3.808625875121754, w1=-68.53074375285009\n",
      "Gradient Descent(9591/9999): loss=4758.425665317848, w0=-3.808625875121754, w1=-68.53074375285009\n",
      "Gradient Descent(9592/9999): loss=4758.425665317848, w0=-3.808625875121754, w1=-68.53074375285009\n",
      "Gradient Descent(9593/9999): loss=4758.425665317848, w0=-3.808625875121754, w1=-68.53074375285009\n",
      "Gradient Descent(9594/9999): loss=4758.425665317848, w0=-3.808625875121754, w1=-68.53074375285009\n",
      "Gradient Descent(9595/9999): loss=4758.425665317848, w0=-3.808625875121754, w1=-68.53074375285009\n",
      "Gradient Descent(9596/9999): loss=4758.425665317848, w0=-3.808625875121754, w1=-68.53074375285009\n",
      "Gradient Descent(9597/9999): loss=4758.425665317848, w0=-3.808625875121754, w1=-68.53074375285009\n",
      "Gradient Descent(9598/9999): loss=4758.425665317848, w0=-3.808625875121754, w1=-68.53074375285009\n",
      "Gradient Descent(9599/9999): loss=4758.425665317848, w0=-12.250125875121755, w1=-70.35814375285008\n",
      "Gradient Descent(9600/9999): loss=4990.807515244332, w0=-12.250125875121755, w1=-70.35814375285008\n",
      "Gradient Descent(9601/9999): loss=4990.807515244332, w0=-12.250125875121755, w1=-70.35814375285008\n",
      "Gradient Descent(9602/9999): loss=4990.807515244332, w0=-12.250125875121755, w1=-70.35814375285008\n",
      "Gradient Descent(9603/9999): loss=4990.807515244332, w0=-12.250125875121755, w1=-70.35814375285008\n",
      "Gradient Descent(9604/9999): loss=4990.807515244332, w0=-12.250125875121755, w1=-70.35814375285008\n",
      "Gradient Descent(9605/9999): loss=4990.807515244332, w0=-12.250125875121755, w1=-70.35814375285008\n",
      "Gradient Descent(9606/9999): loss=4990.807515244332, w0=-12.250125875121755, w1=-70.35814375285008\n",
      "Gradient Descent(9607/9999): loss=4990.807515244332, w0=-12.250125875121755, w1=-70.35814375285008\n",
      "Gradient Descent(9608/9999): loss=4990.807515244332, w0=-1.5396258751217538, w1=-66.33024375285008\n",
      "Gradient Descent(9609/9999): loss=8277.798723943213, w0=-1.5396258751217538, w1=-66.33024375285008\n",
      "Gradient Descent(9610/9999): loss=8277.798723943213, w0=-21.371825875121754, w1=-74.10714375285008\n",
      "Gradient Descent(9611/9999): loss=5790.986548954807, w0=-21.371825875121754, w1=-74.10714375285008\n",
      "Gradient Descent(9612/9999): loss=5790.986548954807, w0=-14.120825875121753, w1=-69.20454375285007\n",
      "Gradient Descent(9613/9999): loss=4815.019989475304, w0=-14.120825875121753, w1=-69.20454375285007\n",
      "Gradient Descent(9614/9999): loss=4815.019989475304, w0=-14.120825875121753, w1=-69.20454375285007\n",
      "Gradient Descent(9615/9999): loss=4815.019989475304, w0=-1.1781258751217507, w1=-61.31784375285007\n",
      "Gradient Descent(9616/9999): loss=11588.539374126172, w0=-1.1781258751217507, w1=-61.31784375285007\n",
      "Gradient Descent(9617/9999): loss=11588.539374126172, w0=-1.1781258751217507, w1=-61.31784375285007\n",
      "Gradient Descent(9618/9999): loss=11588.539374126172, w0=-1.1781258751217507, w1=-61.31784375285007\n",
      "Gradient Descent(9619/9999): loss=11588.539374126172, w0=-1.1781258751217507, w1=-61.31784375285007\n",
      "Gradient Descent(9620/9999): loss=11588.539374126172, w0=-9.29652587512175, w1=-62.624943752850065\n",
      "Gradient Descent(9621/9999): loss=5330.662941390721, w0=-9.29652587512175, w1=-62.624943752850065\n",
      "Gradient Descent(9622/9999): loss=5330.662941390721, w0=-9.29652587512175, w1=-62.624943752850065\n",
      "Gradient Descent(9623/9999): loss=5330.662941390721, w0=-9.29652587512175, w1=-62.624943752850065\n",
      "Gradient Descent(9624/9999): loss=5330.662941390721, w0=-19.75682587512175, w1=-69.02504375285007\n",
      "Gradient Descent(9625/9999): loss=5802.4994844197445, w0=-7.799225875121747, w1=-67.63494375285006\n",
      "Gradient Descent(9626/9999): loss=4655.139272056051, w0=-7.799225875121747, w1=-67.63494375285006\n",
      "Gradient Descent(9627/9999): loss=4655.139272056051, w0=-7.799225875121747, w1=-67.63494375285006\n",
      "Gradient Descent(9628/9999): loss=4655.139272056051, w0=-7.799225875121747, w1=-67.63494375285006\n",
      "Gradient Descent(9629/9999): loss=4655.139272056051, w0=-15.755925875121747, w1=-70.14264375285006\n",
      "Gradient Descent(9630/9999): loss=5802.4994844197445, w0=-15.755925875121747, w1=-70.14264375285006\n",
      "Gradient Descent(9631/9999): loss=5802.4994844197445, w0=-2.0633258751217447, w1=-60.190843752850064\n",
      "Gradient Descent(9632/9999): loss=4961.839149644295, w0=-2.0633258751217447, w1=-60.190843752850064\n",
      "Gradient Descent(9633/9999): loss=4961.839149644295, w0=-13.504225875121744, w1=-61.950543752850066\n",
      "Gradient Descent(9634/9999): loss=5802.4994844197445, w0=-13.504225875121744, w1=-61.950543752850066\n",
      "Gradient Descent(9635/9999): loss=5802.4994844197445, w0=-2.009225875121743, w1=-55.91144375285006\n",
      "Gradient Descent(9636/9999): loss=4473.832139522084, w0=-2.009225875121743, w1=-55.91144375285006\n",
      "Gradient Descent(9637/9999): loss=4473.832139522084, w0=-2.009225875121743, w1=-55.91144375285006\n",
      "Gradient Descent(9638/9999): loss=4473.832139522084, w0=-9.194425875121745, w1=-58.22454375285006\n",
      "Gradient Descent(9639/9999): loss=5802.4994844197445, w0=-9.194425875121745, w1=-58.22454375285006\n",
      "Gradient Descent(9640/9999): loss=5802.4994844197445, w0=-9.194425875121745, w1=-58.22454375285006\n",
      "Gradient Descent(9641/9999): loss=5802.4994844197445, w0=-9.194425875121745, w1=-58.22454375285006\n",
      "Gradient Descent(9642/9999): loss=5802.4994844197445, w0=-9.194425875121745, w1=-58.22454375285006\n",
      "Gradient Descent(9643/9999): loss=5802.4994844197445, w0=-9.194425875121745, w1=-58.22454375285006\n",
      "Gradient Descent(9644/9999): loss=5802.4994844197445, w0=-9.194425875121745, w1=-58.22454375285006\n",
      "Gradient Descent(9645/9999): loss=5802.4994844197445, w0=-9.194425875121745, w1=-58.22454375285006\n",
      "Gradient Descent(9646/9999): loss=5802.4994844197445, w0=-9.194425875121745, w1=-58.22454375285006\n",
      "Gradient Descent(9647/9999): loss=5802.4994844197445, w0=5.055174124878256, w1=-57.96934375285006\n",
      "Gradient Descent(9648/9999): loss=4838.789980805538, w0=5.055174124878256, w1=-57.96934375285006\n",
      "Gradient Descent(9649/9999): loss=4838.789980805538, w0=5.055174124878256, w1=-57.96934375285006\n",
      "Gradient Descent(9650/9999): loss=4838.789980805538, w0=5.055174124878256, w1=-57.96934375285006\n",
      "Gradient Descent(9651/9999): loss=4838.789980805538, w0=5.055174124878256, w1=-57.96934375285006\n",
      "Gradient Descent(9652/9999): loss=4838.789980805538, w0=5.055174124878256, w1=-57.96934375285006\n",
      "Gradient Descent(9653/9999): loss=4838.789980805538, w0=15.643874124878257, w1=-52.84154375285006\n",
      "Gradient Descent(9654/9999): loss=15661.467388728903, w0=1.459274124878256, w1=-58.280043752850055\n",
      "Gradient Descent(9655/9999): loss=4720.325348154138, w0=1.459274124878256, w1=-58.280043752850055\n",
      "Gradient Descent(9656/9999): loss=4720.325348154138, w0=1.459274124878256, w1=-58.280043752850055\n",
      "Gradient Descent(9657/9999): loss=4720.325348154138, w0=-10.607491260675278, w1=-64.77974375285005\n",
      "Gradient Descent(9658/9999): loss=5802.4994844197445, w0=-10.607491260675278, w1=-64.77974375285005\n",
      "Gradient Descent(9659/9999): loss=5802.4994844197445, w0=-10.607491260675278, w1=-64.77974375285005\n",
      "Gradient Descent(9660/9999): loss=5802.4994844197445, w0=-0.11629126067527729, w1=-62.16354375285005\n",
      "Gradient Descent(9661/9999): loss=4520.526732981187, w0=-0.11629126067527729, w1=-62.16354375285005\n",
      "Gradient Descent(9662/9999): loss=4520.526732981187, w0=-0.11629126067527729, w1=-62.16354375285005\n",
      "Gradient Descent(9663/9999): loss=4520.526732981187, w0=9.750308739324723, w1=-59.526143752850054\n",
      "Gradient Descent(9664/9999): loss=8129.544016866788, w0=21.817074124878257, w1=-47.22344375285005\n",
      "Gradient Descent(9665/9999): loss=16923.876981732334, w0=9.750308739324723, w1=-58.86824375285005\n",
      "Gradient Descent(9666/9999): loss=5054.265879735931, w0=9.750308739324723, w1=-58.86824375285005\n",
      "Gradient Descent(9667/9999): loss=5054.265879735931, w0=-2.024591260675278, w1=-61.62384375285005\n",
      "Gradient Descent(9668/9999): loss=5412.486165031934, w0=-2.024591260675278, w1=-61.62384375285005\n",
      "Gradient Descent(9669/9999): loss=5412.486165031934, w0=13.195408739324721, w1=-53.73444375285005\n",
      "Gradient Descent(9670/9999): loss=6968.1891651542755, w0=13.195408739324721, w1=-53.73444375285005\n",
      "Gradient Descent(9671/9999): loss=6968.1891651542755, w0=13.195408739324721, w1=-53.73444375285005\n",
      "Gradient Descent(9672/9999): loss=6968.1891651542755, w0=13.195408739324721, w1=-53.73444375285005\n",
      "Gradient Descent(9673/9999): loss=6968.1891651542755, w0=4.7113087393247195, w1=-58.14644375285005\n",
      "Gradient Descent(9674/9999): loss=4397.85823203319, w0=4.7113087393247195, w1=-58.14644375285005\n",
      "Gradient Descent(9675/9999): loss=4397.85823203319, w0=4.7113087393247195, w1=-58.14644375285005\n",
      "Gradient Descent(9676/9999): loss=4397.85823203319, w0=4.7113087393247195, w1=-58.14644375285005\n",
      "Gradient Descent(9677/9999): loss=4397.85823203319, w0=4.7113087393247195, w1=-58.14644375285005\n",
      "Gradient Descent(9678/9999): loss=4397.85823203319, w0=4.7113087393247195, w1=-58.14644375285005\n",
      "Gradient Descent(9679/9999): loss=4397.85823203319, w0=-2.4738912606752814, w1=-60.459543752850045\n",
      "Gradient Descent(9680/9999): loss=5802.4994844197445, w0=9.080108739324722, w1=-56.51784375285005\n",
      "Gradient Descent(9681/9999): loss=4764.28114962941, w0=9.080108739324722, w1=-56.51784375285005\n",
      "Gradient Descent(9682/9999): loss=4764.28114962941, w0=-1.6809912606752793, w1=-59.32424375285005\n",
      "Gradient Descent(9683/9999): loss=5744.200782257238, w0=-1.6809912606752793, w1=-59.32424375285005\n",
      "Gradient Descent(9684/9999): loss=5744.200782257238, w0=-1.6809912606752793, w1=-59.32424375285005\n",
      "Gradient Descent(9685/9999): loss=5744.200782257238, w0=-1.6809912606752793, w1=-59.32424375285005\n",
      "Gradient Descent(9686/9999): loss=5744.200782257238, w0=-1.6809912606752793, w1=-59.32424375285005\n",
      "Gradient Descent(9687/9999): loss=5744.200782257238, w0=14.808508739324724, w1=-52.58774375285005\n",
      "Gradient Descent(9688/9999): loss=9919.45518539963, w0=1.347808739324723, w1=-56.14214375285005\n",
      "Gradient Descent(9689/9999): loss=4547.321602310939, w0=1.347808739324723, w1=-56.14214375285005\n",
      "Gradient Descent(9690/9999): loss=4547.321602310939, w0=1.347808739324723, w1=-56.14214375285005\n",
      "Gradient Descent(9691/9999): loss=4547.321602310939, w0=11.839008739324724, w1=-53.525943752850054\n",
      "Gradient Descent(9692/9999): loss=9379.748442632095, w0=11.839008739324724, w1=-53.525943752850054\n",
      "Gradient Descent(9693/9999): loss=9379.748442632095, w0=11.839008739324724, w1=-53.525943752850054\n",
      "Gradient Descent(9694/9999): loss=9379.748442632095, w0=-1.1428912606752757, w1=-60.577343752850055\n",
      "Gradient Descent(9695/9999): loss=4547.010162096139, w0=-1.1428912606752757, w1=-60.577343752850055\n",
      "Gradient Descent(9696/9999): loss=4547.010162096139, w0=-1.1428912606752757, w1=-60.577343752850055\n",
      "Gradient Descent(9697/9999): loss=4547.010162096139, w0=-1.1428912606752757, w1=-60.577343752850055\n",
      "Gradient Descent(9698/9999): loss=4547.010162096139, w0=-11.475191260675276, w1=-63.134943752850056\n",
      "Gradient Descent(9699/9999): loss=5802.4994844197445, w0=-11.475191260675276, w1=-63.134943752850056\n",
      "Gradient Descent(9700/9999): loss=5802.4994844197445, w0=-11.475191260675276, w1=-63.134943752850056\n",
      "Gradient Descent(9701/9999): loss=5802.4994844197445, w0=-11.475191260675276, w1=-63.134943752850056\n",
      "Gradient Descent(9702/9999): loss=5802.4994844197445, w0=-11.475191260675276, w1=-63.134943752850056\n",
      "Gradient Descent(9703/9999): loss=5802.4994844197445, w0=-11.475191260675276, w1=-63.134943752850056\n",
      "Gradient Descent(9704/9999): loss=5802.4994844197445, w0=-11.475191260675276, w1=-63.134943752850056\n",
      "Gradient Descent(9705/9999): loss=5802.4994844197445, w0=1.0150087393247258, w1=-62.130443752850056\n",
      "Gradient Descent(9706/9999): loss=4797.625348766875, w0=1.0157896354746558, w1=-62.13042495663959\n",
      "Gradient Descent(9707/9999): loss=4797.164845357069, w0=1.0157896354746558, w1=-62.13042495663959\n",
      "Gradient Descent(9708/9999): loss=4797.164845357069, w0=1.0157896354746558, w1=-62.13042495663959\n",
      "Gradient Descent(9709/9999): loss=4797.164845357069, w0=1.0157896354746558, w1=-62.13042495663959\n",
      "Gradient Descent(9710/9999): loss=4797.164845357069, w0=1.0157896354746558, w1=-62.13042495663959\n",
      "Gradient Descent(9711/9999): loss=4797.164845357069, w0=1.0157896354746558, w1=-62.13042495663959\n",
      "Gradient Descent(9712/9999): loss=4797.164845357069, w0=1.0157896354746558, w1=-62.13042495663959\n",
      "Gradient Descent(9713/9999): loss=4797.164845357069, w0=1.0157896354746558, w1=-62.13042495663959\n",
      "Gradient Descent(9714/9999): loss=4797.164845357069, w0=14.623089635474654, w1=-56.95362495663959\n",
      "Gradient Descent(9715/9999): loss=7153.8426319824275, w0=4.954489635474653, w1=-57.92712495663959\n",
      "Gradient Descent(9716/9999): loss=4527.432646559204, w0=4.954489635474653, w1=-57.92712495663959\n",
      "Gradient Descent(9717/9999): loss=4527.432646559204, w0=4.954489635474653, w1=-57.92712495663959\n",
      "Gradient Descent(9718/9999): loss=4527.432646559204, w0=4.954489635474653, w1=-57.92712495663959\n",
      "Gradient Descent(9719/9999): loss=4527.432646559204, w0=4.954489635474653, w1=-57.92712495663959\n",
      "Gradient Descent(9720/9999): loss=4527.432646559204, w0=4.954489635474653, w1=-57.92712495663959\n",
      "Gradient Descent(9721/9999): loss=4527.432646559204, w0=12.792489635474652, w1=-55.64212495663959\n",
      "Gradient Descent(9722/9999): loss=6107.655478605588, w0=12.792489635474652, w1=-55.64212495663959\n",
      "Gradient Descent(9723/9999): loss=6107.655478605588, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9724/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9725/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9726/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9727/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9728/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9729/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9730/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9731/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9732/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9733/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9734/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9735/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9736/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9737/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9738/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9739/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9740/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9741/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9742/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9743/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9744/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9745/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9746/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9747/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9748/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9749/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9750/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9751/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9752/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9753/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9754/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9755/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9756/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9757/9999): loss=4766.255435429677, w0=0.7257242499211181, w1=-63.10422495663959\n",
      "Gradient Descent(9758/9999): loss=4766.255435429677, w0=15.148024249921118, w1=-59.80172495663959\n",
      "Gradient Descent(9759/9999): loss=10176.860796843404, w0=15.148024249921118, w1=-59.80172495663959\n",
      "Gradient Descent(9760/9999): loss=10176.860796843404, w0=15.148024249921118, w1=-59.80172495663959\n",
      "Gradient Descent(9761/9999): loss=10176.860796843404, w0=15.148024249921118, w1=-59.80172495663959\n",
      "Gradient Descent(9762/9999): loss=10176.860796843404, w0=-2.602175750078885, w1=-63.66022495663959\n",
      "Gradient Descent(9763/9999): loss=5422.57261407706, w0=-2.602175750078885, w1=-63.66022495663959\n",
      "Gradient Descent(9764/9999): loss=5422.57261407706, w0=-2.602175750078885, w1=-63.66022495663959\n",
      "Gradient Descent(9765/9999): loss=5422.57261407706, w0=-2.602175750078885, w1=-63.66022495663959\n",
      "Gradient Descent(9766/9999): loss=5422.57261407706, w0=-2.602175750078885, w1=-63.66022495663959\n",
      "Gradient Descent(9767/9999): loss=5422.57261407706, w0=-2.602175750078885, w1=-63.66022495663959\n",
      "Gradient Descent(9768/9999): loss=5422.57261407706, w0=-2.602175750078885, w1=-63.66022495663959\n",
      "Gradient Descent(9769/9999): loss=5422.57261407706, w0=9.464589635474649, w1=-56.84392495663959\n",
      "Gradient Descent(9770/9999): loss=4595.9309820866565, w0=9.464589635474649, w1=-56.84392495663959\n",
      "Gradient Descent(9771/9999): loss=4595.9309820866565, w0=9.464589635474649, w1=-56.84392495663959\n",
      "Gradient Descent(9772/9999): loss=4595.9309820866565, w0=9.464589635474649, w1=-56.84392495663959\n",
      "Gradient Descent(9773/9999): loss=4595.9309820866565, w0=19.46738963547465, w1=-50.89612495663959\n",
      "Gradient Descent(9774/9999): loss=13640.197641862398, w0=19.46738963547465, w1=-50.89612495663959\n",
      "Gradient Descent(9775/9999): loss=13640.197641862398, w0=9.21438963547465, w1=-51.91762495663959\n",
      "Gradient Descent(9776/9999): loss=4382.195302066424, w0=9.21438963547465, w1=-51.91762495663959\n",
      "Gradient Descent(9777/9999): loss=4382.195302066424, w0=22.47938963547465, w1=-50.075024956639595\n",
      "Gradient Descent(9778/9999): loss=15276.428882868091, w0=14.533289635474649, w1=-57.532424956639595\n",
      "Gradient Descent(9779/9999): loss=5828.786983862579, w0=14.533289635474649, w1=-57.532424956639595\n",
      "Gradient Descent(9780/9999): loss=5828.786983862579, w0=3.5752896354746486, w1=-58.8028249566396\n",
      "Gradient Descent(9781/9999): loss=5524.930723687035, w0=3.5752896354746486, w1=-58.8028249566396\n",
      "Gradient Descent(9782/9999): loss=5524.930723687035, w0=3.5752896354746486, w1=-58.8028249566396\n",
      "Gradient Descent(9783/9999): loss=5524.930723687035, w0=3.5752896354746486, w1=-58.8028249566396\n",
      "Gradient Descent(9784/9999): loss=5524.930723687035, w0=18.61518963547465, w1=-51.0319249566396\n",
      "Gradient Descent(9785/9999): loss=10114.706152998908, w0=12.531889635474649, w1=-52.3235249566396\n",
      "Gradient Descent(9786/9999): loss=4467.214444472578, w0=12.531889635474649, w1=-52.3235249566396\n",
      "Gradient Descent(9787/9999): loss=4467.214444472578, w0=12.531889635474649, w1=-52.3235249566396\n",
      "Gradient Descent(9788/9999): loss=4467.214444472578, w0=3.3480896354746488, w1=-52.8423249566396\n",
      "Gradient Descent(9789/9999): loss=5273.009538053413, w0=3.3480896354746488, w1=-52.8423249566396\n",
      "Gradient Descent(9790/9999): loss=5273.009538053413, w0=3.3480896354746488, w1=-52.8423249566396\n",
      "Gradient Descent(9791/9999): loss=5273.009538053413, w0=3.3480896354746488, w1=-52.8423249566396\n",
      "Gradient Descent(9792/9999): loss=5273.009538053413, w0=3.3480896354746488, w1=-52.8423249566396\n",
      "Gradient Descent(9793/9999): loss=5273.009538053413, w0=13.054289635474651, w1=-51.5569249566396\n",
      "Gradient Descent(9794/9999): loss=4539.541902043549, w0=13.054289635474651, w1=-51.5569249566396\n",
      "Gradient Descent(9795/9999): loss=4539.541902043549, w0=13.054289635474651, w1=-51.5569249566396\n",
      "Gradient Descent(9796/9999): loss=4539.541902043549, w0=13.054289635474651, w1=-51.5569249566396\n",
      "Gradient Descent(9797/9999): loss=4539.541902043549, w0=13.054289635474651, w1=-51.5569249566396\n",
      "Gradient Descent(9798/9999): loss=4539.541902043549, w0=13.054289635474651, w1=-51.5569249566396\n",
      "Gradient Descent(9799/9999): loss=4539.541902043549, w0=24.54928963547465, w1=-45.5178249566396\n",
      "Gradient Descent(9800/9999): loss=15764.14197634143, w0=15.320589635474649, w1=-47.0232249566396\n",
      "Gradient Descent(9801/9999): loss=4601.305347695863, w0=15.320589635474649, w1=-47.0232249566396\n",
      "Gradient Descent(9802/9999): loss=4601.305347695863, w0=15.320589635474649, w1=-47.0232249566396\n",
      "Gradient Descent(9803/9999): loss=4601.305347695863, w0=15.320589635474649, w1=-47.0232249566396\n",
      "Gradient Descent(9804/9999): loss=4601.305347695863, w0=24.44058963547465, w1=-42.7498249566396\n",
      "Gradient Descent(9805/9999): loss=14184.361565533514, w0=10.814589635474652, w1=-47.5976249566396\n",
      "Gradient Descent(9806/9999): loss=5213.324780846947, w0=10.814589635474652, w1=-47.5976249566396\n",
      "Gradient Descent(9807/9999): loss=5213.324780846947, w0=10.814589635474652, w1=-47.5976249566396\n",
      "Gradient Descent(9808/9999): loss=5213.324780846947, w0=20.138089635474653, w1=-42.9887249566396\n",
      "Gradient Descent(9809/9999): loss=5967.762675136666, w0=20.138089635474653, w1=-42.9887249566396\n",
      "Gradient Descent(9810/9999): loss=5967.762675136666, w0=20.138089635474653, w1=-42.9887249566396\n",
      "Gradient Descent(9811/9999): loss=5967.762675136666, w0=20.138089635474653, w1=-42.9887249566396\n",
      "Gradient Descent(9812/9999): loss=5967.762675136666, w0=20.138089635474653, w1=-42.9887249566396\n",
      "Gradient Descent(9813/9999): loss=5967.762675136666, w0=20.138089635474653, w1=-42.9887249566396\n",
      "Gradient Descent(9814/9999): loss=5967.762675136666, w0=9.766289635474653, w1=-43.3961249566396\n",
      "Gradient Descent(9815/9999): loss=5176.241428915486, w0=9.766289635474653, w1=-43.3961249566396\n",
      "Gradient Descent(9816/9999): loss=5176.241428915486, w0=21.833055021028187, w1=-39.50452495663961\n",
      "Gradient Descent(9817/9999): loss=7711.119954025122, w0=6.473355021028185, w1=-48.72822495663961\n",
      "Gradient Descent(9818/9999): loss=5350.096510132331, w0=15.525255021028185, w1=-43.335624956639606\n",
      "Gradient Descent(9819/9999): loss=4823.9661713874875, w0=15.525255021028185, w1=-43.335624956639606\n",
      "Gradient Descent(9820/9999): loss=4823.9661713874875, w0=15.525255021028185, w1=-43.335624956639606\n",
      "Gradient Descent(9821/9999): loss=4823.9661713874875, w0=15.525255021028185, w1=-43.335624956639606\n",
      "Gradient Descent(9822/9999): loss=4823.9661713874875, w0=26.689455021028188, w1=-39.40522495663961\n",
      "Gradient Descent(9823/9999): loss=15201.021193348635, w0=14.125555021028187, w1=-48.247224956639606\n",
      "Gradient Descent(9824/9999): loss=4474.864871126385, w0=14.125555021028187, w1=-48.247224956639606\n",
      "Gradient Descent(9825/9999): loss=4474.864871126385, w0=14.125555021028187, w1=-48.247224956639606\n",
      "Gradient Descent(9826/9999): loss=4474.864871126385, w0=-0.004444978971815061, w1=-50.1313249566396\n",
      "Gradient Descent(9827/9999): loss=5793.264170645536, w0=-0.004444978971815061, w1=-50.1313249566396\n",
      "Gradient Descent(9828/9999): loss=5793.264170645536, w0=-0.004444978971815061, w1=-50.1313249566396\n",
      "Gradient Descent(9829/9999): loss=5793.264170645536, w0=12.06232040658172, w1=-39.8077249566396\n",
      "Gradient Descent(9830/9999): loss=4788.976542503577, w0=12.06232040658172, w1=-39.8077249566396\n",
      "Gradient Descent(9831/9999): loss=4788.976542503577, w0=12.06232040658172, w1=-39.8077249566396\n",
      "Gradient Descent(9832/9999): loss=4788.976542503577, w0=21.97092040658172, w1=-35.6786249566396\n",
      "Gradient Descent(9833/9999): loss=15173.927662448541, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9834/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9835/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9836/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9837/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9838/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9839/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9840/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9841/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9842/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9843/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9844/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9845/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9846/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9847/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9848/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9849/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9850/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9851/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9852/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9853/9999): loss=4705.950728418275, w0=11.684520406581719, w1=-40.219124956639604\n",
      "Gradient Descent(9854/9999): loss=4705.950728418275, w0=-1.9300795934182844, w1=-41.816324956639605\n",
      "Gradient Descent(9855/9999): loss=5802.4994844197445, w0=-1.9300795934182844, w1=-41.816324956639605\n",
      "Gradient Descent(9856/9999): loss=5802.4994844197445, w0=-1.9300795934182844, w1=-41.816324956639605\n",
      "Gradient Descent(9857/9999): loss=5802.4994844197445, w0=-1.9300795934182844, w1=-41.816324956639605\n",
      "Gradient Descent(9858/9999): loss=5802.4994844197445, w0=-1.9300795934182844, w1=-41.816324956639605\n",
      "Gradient Descent(9859/9999): loss=5802.4994844197445, w0=-1.9300795934182844, w1=-41.816324956639605\n",
      "Gradient Descent(9860/9999): loss=5802.4994844197445, w0=10.239820406581716, w1=-40.9226249566396\n",
      "Gradient Descent(9861/9999): loss=4697.820296382173, w0=10.239820406581716, w1=-40.9226249566396\n",
      "Gradient Descent(9862/9999): loss=4697.820296382173, w0=10.239820406581716, w1=-40.9226249566396\n",
      "Gradient Descent(9863/9999): loss=4697.820296382173, w0=10.239820406581716, w1=-40.9226249566396\n",
      "Gradient Descent(9864/9999): loss=4697.820296382173, w0=20.869320406581714, w1=-37.824024956639605\n",
      "Gradient Descent(9865/9999): loss=9935.582235368582, w0=8.80255502102818, w1=-48.437724956639606\n",
      "Gradient Descent(9866/9999): loss=5664.34425884068, w0=8.80255502102818, w1=-48.437724956639606\n",
      "Gradient Descent(9867/9999): loss=5664.34425884068, w0=8.80255502102818, w1=-48.437724956639606\n",
      "Gradient Descent(9868/9999): loss=5664.34425884068, w0=8.80255502102818, w1=-48.437724956639606\n",
      "Gradient Descent(9869/9999): loss=5664.34425884068, w0=8.80255502102818, w1=-48.437724956639606\n",
      "Gradient Descent(9870/9999): loss=5664.34425884068, w0=18.80345502102818, w1=-42.94232495663961\n",
      "Gradient Descent(9871/9999): loss=5087.875147712854, w0=18.80345502102818, w1=-42.94232495663961\n",
      "Gradient Descent(9872/9999): loss=5087.875147712854, w0=18.80345502102818, w1=-42.94232495663961\n",
      "Gradient Descent(9873/9999): loss=5087.875147712854, w0=18.80345502102818, w1=-42.94232495663961\n",
      "Gradient Descent(9874/9999): loss=5087.875147712854, w0=26.880955021028182, w1=-40.34602495663961\n",
      "Gradient Descent(9875/9999): loss=14742.012371912511, w0=13.091855021028183, w1=-45.17142495663961\n",
      "Gradient Descent(9876/9999): loss=4448.57883912382, w0=25.15862040658172, w1=-38.05712495663961\n",
      "Gradient Descent(9877/9999): loss=14636.2493614539, w0=16.10522040658172, w1=-46.55242495663961\n",
      "Gradient Descent(9878/9999): loss=4659.539834092338, w0=16.10522040658172, w1=-46.55242495663961\n",
      "Gradient Descent(9879/9999): loss=4659.539834092338, w0=16.10522040658172, w1=-46.55242495663961\n",
      "Gradient Descent(9880/9999): loss=4659.539834092338, w0=16.10522040658172, w1=-46.55242495663961\n",
      "Gradient Descent(9881/9999): loss=4659.539834092338, w0=27.54252040658172, w1=-42.589524956639615\n",
      "Gradient Descent(9882/9999): loss=12410.229567620654, w0=15.475755021028185, w1=-49.27672495663961\n",
      "Gradient Descent(9883/9999): loss=4524.546033880461, w0=-4.026644978971817, w1=-52.64572495663961\n",
      "Gradient Descent(9884/9999): loss=5802.4994844197445, w0=-4.026644978971817, w1=-52.64572495663961\n",
      "Gradient Descent(9885/9999): loss=5802.4994844197445, w0=-4.026644978971817, w1=-52.64572495663961\n",
      "Gradient Descent(9886/9999): loss=5802.4994844197445, w0=-4.026644978971817, w1=-52.64572495663961\n",
      "Gradient Descent(9887/9999): loss=5802.4994844197445, w0=-4.026644978971817, w1=-52.64572495663961\n",
      "Gradient Descent(9888/9999): loss=5802.4994844197445, w0=-4.026644978971817, w1=-52.64572495663961\n",
      "Gradient Descent(9889/9999): loss=5802.4994844197445, w0=-4.026644978971817, w1=-52.64572495663961\n",
      "Gradient Descent(9890/9999): loss=5802.4994844197445, w0=-4.026644978971817, w1=-52.64572495663961\n",
      "Gradient Descent(9891/9999): loss=5802.4994844197445, w0=-4.026644978971817, w1=-52.64572495663961\n",
      "Gradient Descent(9892/9999): loss=5802.4994844197445, w0=-4.026644978971817, w1=-52.64572495663961\n",
      "Gradient Descent(9893/9999): loss=5802.4994844197445, w0=-4.026644978971817, w1=-52.64572495663961\n",
      "Gradient Descent(9894/9999): loss=5802.4994844197445, w0=-4.026644978971817, w1=-52.64572495663961\n",
      "Gradient Descent(9895/9999): loss=5802.4994844197445, w0=8.086255021028183, w1=-50.481024956639615\n",
      "Gradient Descent(9896/9999): loss=5468.624625789917, w0=23.177755021028183, w1=-44.523224956639616\n",
      "Gradient Descent(9897/9999): loss=8851.518084894418, w0=11.110989635474649, w1=-53.85572495663962\n",
      "Gradient Descent(9898/9999): loss=4745.050745158155, w0=11.110989635474649, w1=-53.85572495663962\n",
      "Gradient Descent(9899/9999): loss=4745.050745158155, w0=11.110989635474649, w1=-53.85572495663962\n",
      "Gradient Descent(9900/9999): loss=4745.050745158155, w0=11.110989635474649, w1=-53.85572495663962\n",
      "Gradient Descent(9901/9999): loss=4745.050745158155, w0=11.110989635474649, w1=-53.85572495663962\n",
      "Gradient Descent(9902/9999): loss=4745.050745158155, w0=11.110989635474649, w1=-53.85572495663962\n",
      "Gradient Descent(9903/9999): loss=4745.050745158155, w0=11.110989635474649, w1=-53.85572495663962\n",
      "Gradient Descent(9904/9999): loss=4745.050745158155, w0=11.110989635474649, w1=-53.85572495663962\n",
      "Gradient Descent(9905/9999): loss=4745.050745158155, w0=11.110989635474649, w1=-53.85572495663962\n",
      "Gradient Descent(9906/9999): loss=4745.050745158155, w0=23.26398963547465, w1=-49.49892495663962\n",
      "Gradient Descent(9907/9999): loss=6122.264512405018, w0=23.26398963547465, w1=-49.49892495663962\n",
      "Gradient Descent(9908/9999): loss=6122.264512405018, w0=13.63938963547465, w1=-50.23742495663962\n",
      "Gradient Descent(9909/9999): loss=4812.387034070869, w0=13.63938963547465, w1=-50.23742495663962\n",
      "Gradient Descent(9910/9999): loss=4812.387034070869, w0=13.63938963547465, w1=-50.23742495663962\n",
      "Gradient Descent(9911/9999): loss=4812.387034070869, w0=13.63938963547465, w1=-50.23742495663962\n",
      "Gradient Descent(9912/9999): loss=4812.387034070869, w0=13.63938963547465, w1=-50.23742495663962\n",
      "Gradient Descent(9913/9999): loss=4812.387034070869, w0=13.63938963547465, w1=-50.23742495663962\n",
      "Gradient Descent(9914/9999): loss=4812.387034070869, w0=13.63938963547465, w1=-50.23742495663962\n",
      "Gradient Descent(9915/9999): loss=4812.387034070869, w0=13.63938963547465, w1=-50.23742495663962\n",
      "Gradient Descent(9916/9999): loss=4812.387034070869, w0=13.63938963547465, w1=-50.23742495663962\n",
      "Gradient Descent(9917/9999): loss=4812.387034070869, w0=13.63938963547465, w1=-50.23742495663962\n",
      "Gradient Descent(9918/9999): loss=4812.387034070869, w0=13.63938963547465, w1=-50.23742495663962\n",
      "Gradient Descent(9919/9999): loss=4812.387034070869, w0=13.63938963547465, w1=-50.23742495663962\n",
      "Gradient Descent(9920/9999): loss=4812.387034070869, w0=13.63938963547465, w1=-50.23742495663962\n",
      "Gradient Descent(9921/9999): loss=4812.387034070869, w0=25.497789635474653, w1=-48.58162495663962\n",
      "Gradient Descent(9922/9999): loss=8862.932437325297, w0=25.497789635474653, w1=-48.58162495663962\n",
      "Gradient Descent(9923/9999): loss=8862.932437325297, w0=25.497789635474653, w1=-48.58162495663962\n",
      "Gradient Descent(9924/9999): loss=8862.932437325297, w0=12.797089635474652, w1=-56.426124956639626\n",
      "Gradient Descent(9925/9999): loss=5272.466583598437, w0=12.797089635474652, w1=-56.426124956639626\n",
      "Gradient Descent(9926/9999): loss=5272.466583598437, w0=12.797089635474652, w1=-56.426124956639626\n",
      "Gradient Descent(9927/9999): loss=5272.466583598437, w0=31.688089635474654, w1=-48.24292495663963\n",
      "Gradient Descent(9928/9999): loss=8564.75500494249, w0=31.688089635474654, w1=-48.24292495663963\n",
      "Gradient Descent(9929/9999): loss=8564.75500494249, w0=31.688089635474654, w1=-48.24292495663963\n",
      "Gradient Descent(9930/9999): loss=8564.75500494249, w0=3.3212896354746526, w1=-54.03342495663963\n",
      "Gradient Descent(9931/9999): loss=5756.447733419311, w0=3.3212896354746526, w1=-54.03342495663963\n",
      "Gradient Descent(9932/9999): loss=5756.447733419311, w0=3.3212896354746526, w1=-54.03342495663963\n",
      "Gradient Descent(9933/9999): loss=5756.447733419311, w0=3.3212896354746526, w1=-54.03342495663963\n",
      "Gradient Descent(9934/9999): loss=5756.447733419311, w0=12.760489635474654, w1=-53.998224956639625\n",
      "Gradient Descent(9935/9999): loss=4540.172626771251, w0=12.760489635474654, w1=-53.998224956639625\n",
      "Gradient Descent(9936/9999): loss=4540.172626771251, w0=23.016989635474655, w1=-47.739624956639624\n",
      "Gradient Descent(9937/9999): loss=9116.556235762735, w0=23.016989635474655, w1=-47.739624956639624\n",
      "Gradient Descent(9938/9999): loss=9116.556235762735, w0=23.016989635474655, w1=-47.739624956639624\n",
      "Gradient Descent(9939/9999): loss=9116.556235762735, w0=23.016989635474655, w1=-47.739624956639624\n",
      "Gradient Descent(9940/9999): loss=9116.556235762735, w0=23.016989635474655, w1=-47.739624956639624\n",
      "Gradient Descent(9941/9999): loss=9116.556235762735, w0=2.168689635474653, w1=-55.83372495663963\n",
      "Gradient Descent(9942/9999): loss=5253.528855698278, w0=2.168689635474653, w1=-55.83372495663963\n",
      "Gradient Descent(9943/9999): loss=5253.528855698278, w0=2.168689635474653, w1=-55.83372495663963\n",
      "Gradient Descent(9944/9999): loss=5253.528855698278, w0=2.168689635474653, w1=-55.83372495663963\n",
      "Gradient Descent(9945/9999): loss=5253.528855698278, w0=14.443789635474655, w1=-50.652124956639625\n",
      "Gradient Descent(9946/9999): loss=4917.453136953931, w0=14.443789635474655, w1=-50.652124956639625\n",
      "Gradient Descent(9947/9999): loss=4917.453136953931, w0=3.7941896354746536, w1=-52.70382495663962\n",
      "Gradient Descent(9948/9999): loss=5142.251904468883, w0=3.7941896354746536, w1=-52.70382495663962\n",
      "Gradient Descent(9949/9999): loss=5142.251904468883, w0=3.7941896354746536, w1=-52.70382495663962\n",
      "Gradient Descent(9950/9999): loss=5142.251904468883, w0=3.7941896354746536, w1=-52.70382495663962\n",
      "Gradient Descent(9951/9999): loss=5142.251904468883, w0=3.7941896354746536, w1=-52.70382495663962\n",
      "Gradient Descent(9952/9999): loss=5142.251904468883, w0=3.7941896354746536, w1=-52.70382495663962\n",
      "Gradient Descent(9953/9999): loss=5142.251904468883, w0=3.7941896354746536, w1=-52.70382495663962\n",
      "Gradient Descent(9954/9999): loss=5142.251904468883, w0=12.992989635474654, w1=-46.77162495663962\n",
      "Gradient Descent(9955/9999): loss=8657.704485196347, w0=0.9262242499211197, w1=-54.19732495663962\n",
      "Gradient Descent(9956/9999): loss=4543.317723697646, w0=0.9262242499211197, w1=-54.19732495663962\n",
      "Gradient Descent(9957/9999): loss=4543.317723697646, w0=0.9262242499211197, w1=-54.19732495663962\n",
      "Gradient Descent(9958/9999): loss=4543.317723697646, w0=0.9262242499211197, w1=-54.19732495663962\n",
      "Gradient Descent(9959/9999): loss=4543.317723697646, w0=14.19122424992112, w1=-52.35472495663962\n",
      "Gradient Descent(9960/9999): loss=9415.580120833263, w0=14.19122424992112, w1=-52.35472495663962\n",
      "Gradient Descent(9961/9999): loss=9415.580120833263, w0=14.19122424992112, w1=-52.35472495663962\n",
      "Gradient Descent(9962/9999): loss=9415.580120833263, w0=14.19122424992112, w1=-52.35472495663962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(9963/9999): loss=9415.580120833263, w0=14.19122424992112, w1=-52.35472495663962\n",
      "Gradient Descent(9964/9999): loss=9415.580120833263, w0=2.124458864367586, w1=-59.81682495663962\n",
      "Gradient Descent(9965/9999): loss=4418.819780540913, w0=2.124458864367586, w1=-59.81682495663962\n",
      "Gradient Descent(9966/9999): loss=4418.819780540913, w0=2.124458864367586, w1=-59.81682495663962\n",
      "Gradient Descent(9967/9999): loss=4418.819780540913, w0=13.360558864367587, w1=-53.36062495663962\n",
      "Gradient Descent(9968/9999): loss=11155.241121274867, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9969/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9970/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9971/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9972/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9973/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9974/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9975/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9976/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9977/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9978/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9979/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9980/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9981/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9982/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9983/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9984/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9985/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9986/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9987/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9988/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9989/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9990/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9991/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9992/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9993/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9994/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9995/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9996/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9997/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9998/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n",
      "Gradient Descent(9999/9999): loss=4472.186473889554, w0=3.6886588643675857, w1=-58.98262495663962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  3.68865886, -58.98262496, -47.07943869, -19.16375168,\n",
       "         36.22084282, -19.16375168,  55.40128108,  -0.74920947,\n",
       "         18.61724876,  81.14277043,  -0.31134503,  15.10164449,\n",
       "        -25.75068631,  -5.02039865,   2.67596952, -33.126093  ,\n",
       "        -17.06280678,   2.51189108,   0.        ]), 4472.1864738895538)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### WRONG RESULTS\n",
    "logistic_regression(y_train_0, x_train_0, np.zeros(x_train_0.shape[1]), 10000, 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
