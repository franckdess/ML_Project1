{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from proj1_helpers import load_csv_data\n",
    "from functions import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set = load_csv_data('Data/train.csv', sub_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>s</td>\n",
       "      <td>138.470</td>\n",
       "      <td>51.655</td>\n",
       "      <td>97.827</td>\n",
       "      <td>27.980</td>\n",
       "      <td>0.91</td>\n",
       "      <td>124.711</td>\n",
       "      <td>2.666</td>\n",
       "      <td>3.064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>258.733</td>\n",
       "      <td>2</td>\n",
       "      <td>67.435</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.444</td>\n",
       "      <td>46.062</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-2.475</td>\n",
       "      <td>113.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100001</td>\n",
       "      <td>b</td>\n",
       "      <td>160.937</td>\n",
       "      <td>68.768</td>\n",
       "      <td>103.235</td>\n",
       "      <td>48.146</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.473</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.916</td>\n",
       "      <td>164.546</td>\n",
       "      <td>1</td>\n",
       "      <td>46.226</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.158</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>46.226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100002</td>\n",
       "      <td>b</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>162.172</td>\n",
       "      <td>125.953</td>\n",
       "      <td>35.635</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.148</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.186</td>\n",
       "      <td>260.414</td>\n",
       "      <td>1</td>\n",
       "      <td>44.251</td>\n",
       "      <td>2.053</td>\n",
       "      <td>-2.028</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>44.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100003</td>\n",
       "      <td>b</td>\n",
       "      <td>143.905</td>\n",
       "      <td>81.417</td>\n",
       "      <td>80.943</td>\n",
       "      <td>0.414</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060</td>\n",
       "      <td>86.062</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100004</td>\n",
       "      <td>b</td>\n",
       "      <td>175.864</td>\n",
       "      <td>16.915</td>\n",
       "      <td>134.805</td>\n",
       "      <td>16.405</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>3.891</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.871</td>\n",
       "      <td>53.131</td>\n",
       "      <td>0</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>-999.00</td>\n",
       "      <td>-999.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id Prediction  DER_mass_MMC  DER_mass_transverse_met_lep  DER_mass_vis  \\\n",
       "0  100000          s       138.470                       51.655        97.827   \n",
       "1  100001          b       160.937                       68.768       103.235   \n",
       "2  100002          b      -999.000                      162.172       125.953   \n",
       "3  100003          b       143.905                       81.417        80.943   \n",
       "4  100004          b       175.864                       16.915       134.805   \n",
       "\n",
       "   DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  DER_prodeta_jet_jet  \\\n",
       "0    27.980                  0.91           124.711                2.666   \n",
       "1    48.146               -999.00          -999.000             -999.000   \n",
       "2    35.635               -999.00          -999.000             -999.000   \n",
       "3     0.414               -999.00          -999.000             -999.000   \n",
       "4    16.405               -999.00          -999.000             -999.000   \n",
       "\n",
       "   DER_deltar_tau_lep       ...        PRI_met_phi  PRI_met_sumet  \\\n",
       "0               3.064       ...             -0.277        258.733   \n",
       "1               3.473       ...             -1.916        164.546   \n",
       "2               3.148       ...             -2.186        260.414   \n",
       "3               3.310       ...              0.060         86.062   \n",
       "4               3.891       ...             -0.871         53.131   \n",
       "\n",
       "   PRI_jet_num  PRI_jet_leading_pt  PRI_jet_leading_eta  PRI_jet_leading_phi  \\\n",
       "0            2              67.435                2.150                0.444   \n",
       "1            1              46.226                0.725                1.158   \n",
       "2            1              44.251                2.053               -2.028   \n",
       "3            0            -999.000             -999.000             -999.000   \n",
       "4            0            -999.000             -999.000             -999.000   \n",
       "\n",
       "   PRI_jet_subleading_pt  PRI_jet_subleading_eta  PRI_jet_subleading_phi  \\\n",
       "0                 46.062                    1.24                  -2.475   \n",
       "1               -999.000                 -999.00                -999.000   \n",
       "2               -999.000                 -999.00                -999.000   \n",
       "3               -999.000                 -999.00                -999.000   \n",
       "4               -999.000                 -999.00                -999.000   \n",
       "\n",
       "   PRI_jet_all_pt  \n",
       "0         113.497  \n",
       "1          46.226  \n",
       "2          44.251  \n",
       "3           0.000  \n",
       "4           0.000  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set_pd = pd.read_csv('Data/train.csv')\n",
    "train_set_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5000, 30), (5000,))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_set[1]\n",
    "y_train = train_set[0]\n",
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares_GD(y, tx, initial_w, max_iters, gamma):\n",
    "    ws = [initial_w]\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        gradient = compute_gradient_least_square(y, tx, w)\n",
    "        loss = compute_mse(y, tx, w)\n",
    "        w = w - gamma*gradient\n",
    "        print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return loss, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares_SGD(y, tx, initial_w, max_iters, gamma):\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):    \n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, batch_size):\n",
    "            gradient = compute_stoch_gradient(minibatch_y, minibatch_tx, w)\n",
    "            loss = compute_mse(minibatch_y, minibatch_tx, w)\n",
    "            new_w = w - gamma*gradient\n",
    "            w = new_w\n",
    "            ws.append(w)\n",
    "            losses.append(loss)\n",
    "            print(\"Gradient Descent({bi}/{ti}): loss={l}, w0={w0}, w1={w1}\".format(\n",
    "            bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]))\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def least_squares(y, tx):\n",
    "    A = tx.T@tx\n",
    "    b = tx.T@y\n",
    "    w = np.linalg.solve(A, b)\n",
    "    loss = compute_mse(y, tx, w)\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lambda_):\n",
    "    X = tx.T@tx\n",
    "    N = X.shape[0]\n",
    "    A = (X + 2*N*lambda_*np.identity(N))\n",
    "    b = tx.T@y\n",
    "    w = np.linalg.solve(A, b)\n",
    "    loss = compute_mse(y, tx, w)\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_regression(y, tx, initial_w, max_iters, gamma):\n",
    "    losses, ws = gradient_descent_log_reg(y, tx, initial_w, max_iters, gamma)\n",
    "    w = ws[len(ws)-1]\n",
    "    loss = losses[len(losses)-1]\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reg_logistic_regression(y, tx, lambda_, initial_w, max_iters, gamma):\n",
    "    return w, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TESTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/49): loss=3465.6359037997163, w0=521117.82870000013, w1=-189374.79889999997\n",
      "Gradient Descent(1/49): loss=-2486.844060172789, w0=831351.5735000003, w1=-325559.7786\n",
      "Gradient Descent(2/49): loss=-5399.616732797607, w0=1149143.5613000004, w1=-457040.87590000004\n",
      "Gradient Descent(3/49): loss=-6297.625699061386, w0=1472572.2956000005, w1=-586610.6890000001\n",
      "Gradient Descent(4/49): loss=-7138.0699880005595, w0=1796866.0640000007, w1=-714869.0591000002\n",
      "Gradient Descent(5/49): loss=-7679.177954851813, w0=2123392.4971000007, w1=-842382.4794000002\n",
      "Gradient Descent(6/49): loss=-8128.1824379837035, w0=2451824.0467000008, w1=-969285.3562000002\n",
      "Gradient Descent(7/49): loss=-8300.876469957508, w0=2781041.3036000007, w1=-1095963.0080000001\n",
      "Gradient Descent(8/49): loss=-8404.492889141791, w0=3111191.8376000007, w1=-1222376.4798\n",
      "Gradient Descent(9/49): loss=-8427.518760071629, w0=3441557.8974000006, w1=-1348723.0736\n",
      "Gradient Descent(10/49): loss=-8588.699856580515, w0=3772335.564200001, w1=-1474938.8514\n",
      "Gradient Descent(11/49): loss=-8680.803340299875, w0=4102666.2068000007, w1=-1600991.7175\n",
      "Gradient Descent(12/49): loss=-8772.906824019236, w0=4433285.479700001, w1=-1726940.0218\n",
      "Gradient Descent(13/49): loss=-8841.984436808758, w0=4764010.086500001, w1=-1852851.2926\n",
      "Gradient Descent(14/49): loss=-8841.984436808758, w0=5094734.693300001, w1=-1978762.5634\n",
      "Gradient Descent(15/49): loss=-8830.47150134384, w0=5425553.381500001, w1=-2104667.0855\n",
      "Gradient Descent(16/49): loss=-8865.010307738601, w0=5756443.326900002, w1=-2230546.1199\n",
      "Gradient Descent(17/49): loss=-8865.010307738601, w0=6087333.272300001, w1=-2356425.1542999996\n",
      "Gradient Descent(18/49): loss=-8865.010307738601, w0=6418223.217700001, w1=-2482304.1886999994\n",
      "Gradient Descent(19/49): loss=-8922.5749850632, w0=6747806.487800001, w1=-2608012.5098999995\n",
      "Gradient Descent(20/49): loss=-8922.5749850632, w0=7077389.7579000015, w1=-2733720.8310999996\n",
      "Gradient Descent(21/49): loss=-8922.5749850632, w0=7406973.028000002, w1=-2859429.1522999997\n",
      "Gradient Descent(22/49): loss=-8911.062049598278, w0=7736628.470200002, w1=-2985118.3263999997\n",
      "Gradient Descent(23/49): loss=-8911.062049598278, w0=8066283.912400003, w1=-3110807.5004999996\n",
      "Gradient Descent(24/49): loss=-8911.062049598278, w0=8395939.354600003, w1=-3236496.6745999996\n",
      "Gradient Descent(25/49): loss=-8899.549114133357, w0=8725708.889800003, w1=-3362081.8881999995\n",
      "Gradient Descent(26/49): loss=-8968.626726922881, w0=9055618.068700003, w1=-3487607.6227999995\n",
      "Gradient Descent(27/49): loss=-8968.626726922881, w0=9385527.247600002, w1=-3613133.3573999996\n",
      "Gradient Descent(28/49): loss=-8968.626726922881, w0=9715436.426500002, w1=-3738659.0919999997\n",
      "Gradient Descent(29/49): loss=-9003.165533317639, w0=10045394.375100002, w1=-3864177.8203\n",
      "Gradient Descent(30/49): loss=-9003.165533317639, w0=10375352.323700001, w1=-3989696.5486\n",
      "Gradient Descent(31/49): loss=-9003.165533317639, w0=10705310.272300001, w1=-4115215.2769\n",
      "Gradient Descent(32/49): loss=-9003.165533317639, w0=11035268.220900001, w1=-4240734.0052\n",
      "Gradient Descent(33/49): loss=-8991.65259785272, w0=11365308.315900002, w1=-4366250.6657\n",
      "Gradient Descent(34/49): loss=-8991.65259785272, w0=11695348.410900002, w1=-4491767.3262\n",
      "Gradient Descent(35/49): loss=-8991.65259785272, w0=12025388.505900003, w1=-4617283.9867\n",
      "Gradient Descent(36/49): loss=-8991.65259785272, w0=12355428.600900004, w1=-4742800.6472000005\n",
      "Gradient Descent(37/49): loss=-8991.65259785272, w0=12685468.695900004, w1=-4868317.307700001\n",
      "Gradient Descent(38/49): loss=-8991.65259785272, w0=13015508.790900005, w1=-4993833.968200001\n",
      "Gradient Descent(39/49): loss=-8991.65259785272, w0=13345548.885900006, w1=-5119350.628700001\n",
      "Gradient Descent(40/49): loss=-9026.191404247484, w0=13675662.970200006, w1=-5244804.261200001\n",
      "Gradient Descent(41/49): loss=-9026.191404247484, w0=14005777.054500006, w1=-5370257.893700002\n",
      "Gradient Descent(42/49): loss=-9026.191404247484, w0=14335891.138800006, w1=-5495711.526200002\n",
      "Gradient Descent(43/49): loss=-9026.191404247484, w0=14666005.223100007, w1=-5621165.158700002\n",
      "Gradient Descent(44/49): loss=-9026.191404247484, w0=14996119.307400007, w1=-5746618.791200003\n",
      "Gradient Descent(45/49): loss=-9026.191404247484, w0=15326233.391700007, w1=-5872072.423700003\n",
      "Gradient Descent(46/49): loss=-9026.191404247484, w0=15656347.476000007, w1=-5997526.056200003\n",
      "Gradient Descent(47/49): loss=-9026.191404247484, w0=15986461.560300007, w1=-6122979.688700004\n",
      "Gradient Descent(48/49): loss=-9026.191404247484, w0=16316575.644600008, w1=-6248433.321200004\n",
      "Gradient Descent(49/49): loss=-9026.191404247484, w0=16646689.728900008, w1=-6373886.953700004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franckdessimoz/Desktop/Data Science - MA1/Machine Learning/ML_project1/functions.py:6: RuntimeWarning: overflow encountered in exp\n",
      "  s = 1/(1+np.exp(-x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  1.66466897e+07,  -6.37388695e+06,  -7.86989366e+06,\n",
       "         -4.85908502e+06,   5.66313768e+07,   4.37225618e+07,\n",
       "          5.67353302e+07,  -2.21532397e+05,  -2.06054409e+06,\n",
       "         -1.60289066e+07,  -1.64571787e+05,   4.64494524e+04,\n",
       "          5.67054850e+07,  -2.99843355e+06,   5.65749275e+03,\n",
       "         -3.84891290e+03,  -4.63425119e+06,   9.36452370e+03,\n",
       "         -4.82389740e+03,  -4.24051529e+06,   1.78686900e+02,\n",
       "         -2.09846542e+07,  -1.12367500e+05,   3.43089398e+07,\n",
       "          3.92530024e+07,   3.92558566e+07,   5.42587303e+07,\n",
       "          5.67241063e+07,   5.67229048e+07,  -8.39622012e+06]),\n",
       " -9026.1914042474837)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### WRONG RESULTS\n",
    "logistic_regression(y_train, x_train, np.zeros(x_train.shape[1]), 50, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
